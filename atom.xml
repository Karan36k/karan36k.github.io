<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="https://www.w3.org/2005/Atom">
  <title>Machine Learning</title>
  
  <subtitle>Data Science</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://massivefile.com/"/>
  <updated>2020-05-05T23:20:49.983Z</updated>
  <id>https://massivefile.com/</id>
  
  <author>
    <name>Karan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Choosing the best regression model</title>
    <link href="https://massivefile.com/ChoosingBestRegressionModel/"/>
    <id>https://massivefile.com/ChoosingBestRegressionModel/</id>
    <published>2020-05-06T00:56:53.000Z</published>
    <updated>2020-05-05T23:20:49.983Z</updated>
    
    <content type="html"><![CDATA[<body>  <div tabindex="-1" id="notebook" class="border-box-sizing">    <div class="container" id="notebook-container"><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1 id="Choosing-the-best-Regressioin-Model">Choosing the best Regressioin Model<a class="anchor-link" href="#Choosing-the-best-Regressioin-Model">&#182;</a></h1></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>In this notebook we will compare all the regression model on a dataset with 10000 values.<br>Models we will cover:</p><ul><li>Multiple Linear regression</li><li>Polynomial Regression</li><li>RBF kernel SVR</li><li>Decision Trees</li><li>Random Forest</li></ul><a id="more"></a><p>Download the data from here - <span class="exturl" data-url="aHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL2RhdGFzZXRzL0NvbWJpbmVkK0N5Y2xlK1Bvd2VyK1BsYW50">https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant<i class="fa fa-external-link-alt"></i></span></p><p>Here is an example of a regression model for refresh of your memory :) <br><img src = 'https://lh3.googleusercontent.com/proxy/6uQ_IUyxG98KI0wS6nmfETVbFdKD795i6SMiFWgkcLA8r0olkshE2SElk4Knk16oCJuvcY_BXh1vqetBII07_mmC6VE19ZuImEuaxshSTZKpU0r4boUE'/></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3>Let's Start<br></h3><h3 id="Importing-the-libraries-and-reading-in-the-dataset">Importing the libraries and reading in the dataset<a class="anchor-link" href="#Importing-the-libraries-and-reading-in-the-dataset">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[205]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[206]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;00.xlsx&#39;</span><span class="p">)</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span> <span class="c1">#10000 rows and 5 columns</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[206]:</div><div class="output_text output_subarea output_execute_result"><pre>(9568, 5)</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[207]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[207]:</div><div class="output_html rendered_html output_subarea output_execute_result"><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>AT</th>      <th>V</th>      <th>AP</th>      <th>RH</th>      <th>PE</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>14.96</td>      <td>41.76</td>      <td>1024.07</td>      <td>73.17</td>      <td>463.26</td>    </tr>    <tr>      <th>1</th>      <td>25.18</td>      <td>62.96</td>      <td>1020.04</td>      <td>59.08</td>      <td>444.37</td>    </tr>    <tr>      <th>2</th>      <td>5.11</td>      <td>39.40</td>      <td>1012.16</td>      <td>92.14</td>      <td>488.56</td>    </tr>    <tr>      <th>3</th>      <td>20.86</td>      <td>57.32</td>      <td>1010.24</td>      <td>76.64</td>      <td>446.48</td>    </tr>    <tr>      <th>4</th>      <td>10.82</td>      <td>37.50</td>      <td>1009.23</td>      <td>96.62</td>      <td>473.90</td>    </tr>  </tbody></table></div></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[208]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[208]:</div><div class="output_html rendered_html output_subarea output_execute_result"><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>AT</th>      <th>V</th>      <th>AP</th>      <th>RH</th>      <th>PE</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>9568.000000</td>      <td>9568.000000</td>      <td>9568.000000</td>      <td>9568.000000</td>      <td>9568.000000</td>    </tr>    <tr>      <th>mean</th>      <td>19.651231</td>      <td>54.305804</td>      <td>1013.259078</td>      <td>73.308978</td>      <td>454.365009</td>    </tr>    <tr>      <th>std</th>      <td>7.452473</td>      <td>12.707893</td>      <td>5.938784</td>      <td>14.600269</td>      <td>17.066995</td>    </tr>    <tr>      <th>min</th>      <td>1.810000</td>      <td>25.360000</td>      <td>992.890000</td>      <td>25.560000</td>      <td>420.260000</td>    </tr>    <tr>      <th>25%</th>      <td>13.510000</td>      <td>41.740000</td>      <td>1009.100000</td>      <td>63.327500</td>      <td>439.750000</td>    </tr>    <tr>      <th>50%</th>      <td>20.345000</td>      <td>52.080000</td>      <td>1012.940000</td>      <td>74.975000</td>      <td>451.550000</td>    </tr>    <tr>      <th>75%</th>      <td>25.720000</td>      <td>66.540000</td>      <td>1017.260000</td>      <td>84.830000</td>      <td>468.430000</td>    </tr>    <tr>      <th>max</th>      <td>37.110000</td>      <td>81.560000</td>      <td>1033.300000</td>      <td>100.160000</td>      <td>495.760000</td>    </tr>  </tbody></table></div></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[209]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span> <span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="c1">#.values will create an array instead of a dataframe object</span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span> <span class="p">,</span> <span class="mi">4</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">values</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[210]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">T</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[210]:</div><div class="output_text output_subarea output_execute_result"><pre>array([[463.26, 444.37, 488.56, ..., 429.57, 435.74, 453.28]])</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[211]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">T</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[211]:</div><div class="output_text output_subarea output_execute_result"><pre>array([[  14.96,   25.18,    5.11, ...,   31.32,   24.48,   21.6 ],       [  41.76,   62.96,   39.4 , ...,   74.33,   69.45,   62.52],       [1024.07, 1020.04, 1012.16, ..., 1012.92, 1013.86, 1017.23],       [  73.17,   59.08,   92.14, ...,   36.48,   62.39,   67.87]])</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Train-test-split">Train test split<a class="anchor-link" href="#Train-test-split">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[212]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="c1">#80-20 split</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[213]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[213]:</div><div class="output_text output_subarea output_execute_result"><pre>(7654, 4)</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[214]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[214]:</div><div class="output_text output_subarea output_execute_result"><pre>&lt;matplotlib.collections.PathCollection at 0x1a233ecf50&gt;</pre></div></div><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Multiple-Linear-Regression">Multiple Linear Regression<a class="anchor-link" href="#Multiple-Linear-Regression">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[215]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#doing covariance test</span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span><span class="n">ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="n">results</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>                                 OLS Regression Results                                =======================================================================================Dep. Variable:                      y   R-squared (uncentered):                   1.000Model:                            OLS   Adj. R-squared (uncentered):              1.000Method:                 Least Squares   F-statistic:                          1.939e+07Date:                Wed, 06 May 2020   Prob (F-statistic):                        0.00Time:                        04:34:09   Log-Likelihood:                         -29068.No. Observations:                9568   AIC:                                  5.814e+04Df Residuals:                    9564   BIC:                                  5.817e+04Df Model:                           4                                                  Covariance Type:            nonrobust                                                  ==============================================================================                 coef    std err          t      P&gt;|t|      [0.025      0.975]------------------------------------------------------------------------------x1            -1.6781      0.015   -109.169      0.000      -1.708      -1.648x2            -0.2726      0.008    -34.019      0.000      -0.288      -0.257x3             0.5028      0.000   1209.083      0.000       0.502       0.504x4            -0.0999      0.004    -22.678      0.000      -0.109      -0.091==============================================================================Omnibus:                      491.038   Durbin-Watson:                   2.021Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1475.265Skew:                          -0.224   Prob(JB):                         0.00Kurtosis:                       4.871   Cond. No.                         336.==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[216]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span> <span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="c1">#print intercept and coefficient</span><span class="nb">print</span><span class="p">(</span><span class="n">regressor</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>[[-1.97 -0.24  0.06 -0.16]]  [452.84]</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[217]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#visualizing results</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="p">,</span> <span class="n">y</span> <span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Independent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Multiple Linear Regression&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Evaluation-Preformance">Evaluation Preformance<a class="anchor-link" href="#Evaluation-Preformance">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[218]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span><span class="c1">#closer the r2 to 1, better is the score</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[218]:</div><div class="output_text output_subarea output_execute_result"><pre>0.9325315554761303</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Polynomial-regression">Polynomial regression<a class="anchor-link" href="#Polynomial-regression">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[219]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># importing libraries for polynomial transform</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span><span class="c1"># for creating pipeline</span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="n">results</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;polynomial&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">5</span><span class="p">))</span> <span class="p">,</span> <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())]</span><span class="c1"># creating pipeline and fitting it on data</span><span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[219]:</div><div class="output_text output_subarea output_execute_result"><pre>Pipeline(memory=None,         steps=[(&#39;polynomial&#39;,                 PolynomialFeatures(degree=5, include_bias=True,                                    interaction_only=False, order=&#39;C&#39;)),                (&#39;model&#39;,                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,                                  normalize=False))],         verbose=False)</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[220]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;purple&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Independent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Polynomial Regresion&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Evaluation-Preformance">Evaluation Preformance<a class="anchor-link" href="#Evaluation-Preformance">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[221]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span><span class="c1">#this score is better than multiple linear regression</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[221]:</div><div class="output_text output_subarea output_execute_result"><pre>0.9447852145170457</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="RBF-Kernel-SVR">RBF Kernel SVR<a class="anchor-link" href="#RBF-Kernel-SVR">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[222]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="n">sc_X</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="n">sc_y</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">sc_X</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span><span class="n">Y_train</span> <span class="o">=</span> <span class="n">sc_y</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span> <span class="o">=</span> <span class="s1">&#39;rbf&#39;</span><span class="p">)</span><span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">sc_y</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sc_X</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)))</span><span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">y_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span><span class="mi">1</span><span class="p">))</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stderr output_text"><pre>/Users/karan7k/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().  y = column_or_1d(y, warn=True)</pre></div></div><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>[[434.05 431.23] [457.94 460.01] [461.03 461.14] ... [470.6  473.26] [439.42 438.  ] [460.92 463.28]]</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[223]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Independent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Support Vector Regresion&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[224]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="c1">#so far the best model is SVR</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[224]:</div><div class="output_text output_subarea output_execute_result"><pre>0.9480784049986258</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Decision-Tree-Regression">Decision Tree Regression<a class="anchor-link" href="#Decision-Tree-Regression">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[225]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span><span class="n">treo</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="n">treo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span> <span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="c1">#plotting the result after fitting</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;purple&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">treo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Independent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Decision Tree Regression&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Evaluating-Results">Evaluating Results<a class="anchor-link" href="#Evaluating-Results">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[226]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">treo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span><span class="c1">#so far decision tree regression is the worst model</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[226]:</div><div class="output_text output_subarea output_execute_result"><pre>0.9226091050550043</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Random-Forest">Random Forest<a class="anchor-link" href="#Random-Forest">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[237]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="c1">#plotting the result after fitting</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Independent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Random Forest Regression&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stderr output_text"><pre>/Users/karan7k/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().  This is separate from the ipykernel package so we can avoid doing imports until</pre></div></div><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Evaluating-Results">Evaluating Results<a class="anchor-link" href="#Evaluating-Results">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[240]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span><span class="c1"># Best results we have</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[240]:</div><div class="output_text output_subarea output_execute_result"><pre>0.9650087123017985</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Conclusion:">Conclusion:<a class="anchor-link" href="#Conclusion:">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="These-are-the-exaluation-results-of-various-results:">These are the exaluation results of various results:<a class="anchor-link" href="#These-are-the-exaluation-results-of-various-results:">&#182;</a></h3><p><br>NOTE:   "Higher the Better"</p><ul><li>Multiple Linear regression - 0.9325315554761303</li><li>Polynomial Regression - 0.9447852145170457</li><li>RBF kernel SVR - 0.9480784049986258</li><li>Decision Trees - 0.9226091050550043</li><li>Random Forest - 0.9650087123017985</li></ul></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3>Therefore the Random Forest Model Fits to our data well,<br> Considering the present scanario we will choose the random forest method for our further process</h3><p>NOTE: To be considered that we have not taken to account overfitting and high variance low bais issue in this model.<br>Also we have not considered the hyperparameter tuning for any of the hperparameters involved.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="More-Content">More Content<a class="anchor-link" href="#More-Content">&#182;</a></h2><p>If you want to see the separate implementation and theory of these models on the website with a different dataset.Please click on these links below<br></p><ul><li>Simple Linear Regression - <a href="https://massivefile.com/simple_linear_regression/">https://massivefile.com/simple_linear_regression/</a>    </li><li>Multiple Linear regression - <a href="https://massivefile.com/multiple_linear_regression/">https://massivefile.com/multiple_linear_regression/</a></li><li>Polynomial Regression - <a href="https://massivefile.com/PolynomialRegression/">https://massivefile.com/PolynomialRegression/</a></li><li>Non Linear Regerssion - <a href="https://massivefile.com/NoneLinearRegression/">https://massivefile.com/NoneLinearRegression/</a></li><li>RBF kernel SVR - <a href="https://massivefile.com/supportvectorregression/">https://massivefile.com/supportvectorregression/</a></li><li>Decision Trees - <a href="https://massivefile.com/decisiontreeregression/">https://massivefile.com/decisiontreeregression/</a></li><li>Random Forest - <a href="https://massivefile.com/randomforestregression/">https://massivefile.com/randomforestregression/</a></li></ul></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span> </pre></div>    </div></div></div></div>    </div>  </div></body>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;
  &lt;div tabindex=&quot;-1&quot; id=&quot;notebook&quot; class=&quot;border-box-sizing&quot;&gt;
    &lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Choosing-the-best-Regressioin-Model&quot;&gt;Choosing the best Regressioin Model&lt;a class=&quot;anchor-link&quot; href=&quot;#Choosing-the-best-Regressioin-Model&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;In this notebook we will compare all the regression model on a dataset with 10000 values.&lt;br&gt;
Models we will cover:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multiple Linear regression&lt;/li&gt;
&lt;li&gt;Polynomial Regression&lt;/li&gt;
&lt;li&gt;RBF kernel SVR&lt;/li&gt;
&lt;li&gt;Decision Trees&lt;/li&gt;
&lt;li&gt;Random Forest&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="best regression model" scheme="https://massivefile.com/tags/best-regression-model/"/>
    
  </entry>
  
  <entry>
    <title>Decision Tree regression Implementation</title>
    <link href="https://massivefile.com/decisiontreeregression/"/>
    <id>https://massivefile.com/decisiontreeregression/</id>
    <published>2020-05-06T00:56:53.000Z</published>
    <updated>2020-05-05T23:21:11.713Z</updated>
    
    <content type="html"><![CDATA[<body>  <div tabindex="-1" id="notebook" class="border-box-sizing">    <div class="container" id="notebook-container"><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Decision-Tree-Regression">Decision Tree Regression<a class="anchor-link" href="#Decision-Tree-Regression">&#182;</a></h2><p>A decision tree is a flowchart-like structure in which each internal node represents a "test" on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes)</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Here is how a decision tree looks like: <br> <br><a id="more"></a><img src = 'https://live.staticflickr.com/7143/6463738329_55faa2b606_b.jpg' width = '400'  height = '300'></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>For this model we will be using decision tree to predict a salary of an employee with position level of 6.5</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Lets-Start">Lets Start<a class="anchor-link" href="#Lets-Start">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[1]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Importing the libraries</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Importing-the-dataset-/-Create-Own">Importing the dataset / Create Own<a class="anchor-link" href="#Importing-the-dataset-/-Create-Own">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[2]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Position&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Business Analyst&#39;</span><span class="p">,</span> <span class="s1">&#39;Junior Consultant&#39;</span><span class="p">,</span> <span class="s1">&#39;Senior Consultant&#39;</span><span class="p">,</span> <span class="s1">&#39;Manager&#39;</span><span class="p">,</span> <span class="s1">&#39;Country Manager&#39;</span><span class="p">,</span> <span class="s1">&#39;Region Manager&#39;</span><span class="p">,</span> <span class="s1">&#39;Partner&#39;</span><span class="p">,</span> <span class="s1">&#39;Senior Partner&#39;</span><span class="p">,</span> <span class="s1">&#39;c-level&#39;</span><span class="p">,</span> <span class="s1">&#39;CEO&#39;</span><span class="p">],</span> <span class="s1">&#39;Level&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="s1">&#39;Salary&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">45000</span><span class="p">,</span> <span class="mi">50000</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mi">80000</span><span class="p">,</span> <span class="mi">110000</span><span class="p">,</span> <span class="mi">150000</span><span class="p">,</span> <span class="mi">200000</span><span class="p">,</span> <span class="mi">300000</span><span class="p">,</span> <span class="mi">500000</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">]})</span><span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span> <span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>            Position  Level   Salary0   Business Analyst      1    450001  Junior Consultant      2    500002  Senior Consultant      3    600003            Manager      4    800004    Country Manager      5   1100005     Region Manager      6   1500006            Partner      7   2000007     Senior Partner      8   3000008            c-level      9   5000009                CEO     10  1000000</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[4]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>[[ 1  2  3  4  5  6  7  8  9 10]]  [[  45000   50000   60000   80000  110000  150000  200000  300000  500000  1000000]]</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Fitting-Decision-Tree-Regression-to-the-dataset">Fitting Decision Tree Regression to the dataset<a class="anchor-link" href="#Fitting-Decision-Tree-Regression-to-the-dataset">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[7]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="c1"># Predicting a new result</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">6.5</span><span class="p">]])</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Visualising-the-Decision-Tree-Regression-results-(higher-resolution)">Visualising the Decision Tree Regression results (higher resolution)<a class="anchor-link" href="#Visualising-the-Decision-Tree-Regression-results-(higher-resolution)">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[9]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mf">0.01</span><span class="p">)</span><span class="n">X_grid</span> <span class="o">=</span> <span class="n">X_grid</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_grid</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Truth or Bluff (Decision Tree Regression)&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position level&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Salary&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div>    </div>  </div></body>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;
  &lt;div tabindex=&quot;-1&quot; id=&quot;notebook&quot; class=&quot;border-box-sizing&quot;&gt;
    &lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Decision-Tree-Regression&quot;&gt;Decision Tree Regression&lt;a class=&quot;anchor-link&quot; href=&quot;#Decision-Tree-Regression&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;A decision tree is a flowchart-like structure in which each internal node represents a &quot;test&quot; on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Here is how a decision tree looks like: &lt;br&gt; &lt;br&gt;
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Non Linear Regression" scheme="https://massivefile.com/tags/Non-Linear-Regression/"/>
    
  </entry>
  
  <entry>
    <title>Support Vector Regression Implementation</title>
    <link href="https://massivefile.com/supportvectorregression/"/>
    <id>https://massivefile.com/supportvectorregression/</id>
    <published>2020-05-06T00:56:53.000Z</published>
    <updated>2020-05-05T23:23:23.841Z</updated>
    
    <content type="html"><![CDATA[<body>  <div tabindex="-1" id="notebook" class="border-box-sizing">    <div class="container" id="notebook-container"><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Support-Vector-Regression">Support Vector Regression<a class="anchor-link" href="#Support-Vector-Regression">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>We are going to implement a linear support vector regression</p><a id="more"></a></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Support vector regression is a type of support vector machine</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>SVR is tube like structure.<br>We do not care about the points in the tube whereas we care about the points outside the tube as it determines the tube position.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Here is how a SVR looks like: <br><img src = 'https://upload.wikimedia.org/wikipedia/commons/2/2a/Svm_max_sep_hyperplane_with_margin.png'  width="400" height="300"/><br><br><br>For this model we will be using decision tree to predict a salary of an employee with position level of 6.5<br><br></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Note: We also use a non linear SVR that looks like this: <br><img src = 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/512px-Kernel_Machine.svg.png'/></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>For this example we will use a RBF kernel support vector machine.We use kernel to determine the linearity of out support vector machines.The kernel we mostly use in the non linear support vecotor is RBF kernel.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Let-us-start">Let us start<a class="anchor-link" href="#Let-us-start">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[52]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Importing-the-dataset-/-Create-Own">Importing the dataset / Create Own<a class="anchor-link" href="#Importing-the-dataset-/-Create-Own">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[62]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Position&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Business Analyst&#39;</span><span class="p">,</span> <span class="s1">&#39;Junior Consultant&#39;</span><span class="p">,</span> <span class="s1">&#39;Senior Consultant&#39;</span><span class="p">,</span> <span class="s1">&#39;Manager&#39;</span><span class="p">,</span> <span class="s1">&#39;Country Manager&#39;</span><span class="p">,</span> <span class="s1">&#39;Region Manager&#39;</span><span class="p">,</span> <span class="s1">&#39;Partner&#39;</span><span class="p">,</span> <span class="s1">&#39;Senior Partner&#39;</span><span class="p">,</span> <span class="s1">&#39;c-level&#39;</span><span class="p">,</span> <span class="s1">&#39;CEO&#39;</span><span class="p">],</span> <span class="s1">&#39;Level&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="s1">&#39;Salary&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">45000</span><span class="p">,</span> <span class="mi">50000</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mi">80000</span><span class="p">,</span> <span class="mi">110000</span><span class="p">,</span> <span class="mi">150000</span><span class="p">,</span> <span class="mi">200000</span><span class="p">,</span> <span class="mi">300000</span><span class="p">,</span> <span class="mi">500000</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">]})</span><span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span> <span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>            Position  Level   Salary0   Business Analyst      1    450001  Junior Consultant      2    500002  Senior Consultant      3    600003            Manager      4    800004    Country Manager      5   1100005     Region Manager      6   1500006            Partner      7   2000007     Senior Partner      8   3000008            c-level      9   5000009                CEO     10  1000000</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[63]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>[[ 1  2  3  4  5  6  7  8  9 10]]  [[  45000   50000   60000   80000  110000  150000  200000  300000  500000  1000000]]</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Feature-Scaling">Feature Scaling<a class="anchor-link" href="#Feature-Scaling">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="n">sc_x</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="n">sc_y</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="n">x</span> <span class="o">=</span> <span class="n">sc_x</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="n">y</span> <span class="o">=</span> <span class="n">sc_y</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Fitting-Linear-Regression-to-the-dataset">Fitting Linear Regression to the dataset<a class="anchor-link" href="#Fitting-Linear-Regression-to-the-dataset">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[56]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="n">lin_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="n">lin_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[56]:</div><div class="output_text output_subarea output_execute_result"><pre>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,         normalize=False)</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Fitting-SVR-to-the-dataset">Fitting SVR to the dataset<a class="anchor-link" href="#Fitting-SVR-to-the-dataset">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span> <span class="o">=</span> <span class="s1">&#39;rbf&#39;</span><span class="p">)</span><span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Predicting-a-new-result">Predicting a new result<a class="anchor-link" href="#Predicting-a-new-result">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[45]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">6.5</span><span class="p">]])</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">sc_y</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Visualising-the-SVR-results">Visualising the SVR results<a class="anchor-link" href="#Visualising-the-SVR-results">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[46]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Truth or Bluff (SVR)&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position level&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Salary&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Visualising-the-SVR-results-(for-higher-resolution-and-smoother-curve)">Visualising the SVR results (for higher resolution and smoother curve)<a class="anchor-link" href="#Visualising-the-SVR-results-(for-higher-resolution-and-smoother-curve)">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[20]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mf">0.01</span><span class="p">)</span> <span class="c1"># choice of 0.01 instead of 0.1 step because the data is feature scaled</span><span class="n">X_grid</span> <span class="o">=</span> <span class="n">X_grid</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_grid</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Truth or Bluff (SVR)&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position level&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Salary&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span> </pre></div>    </div></div></div></div>    </div>  </div></body>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;
  &lt;div tabindex=&quot;-1&quot; id=&quot;notebook&quot; class=&quot;border-box-sizing&quot;&gt;
    &lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Support-Vector-Regression&quot;&gt;Support Vector Regression&lt;a class=&quot;anchor-link&quot; href=&quot;#Support-Vector-Regression&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We are going to implement a linear support vector regression&lt;/p&gt;
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Non Linear Regression" scheme="https://massivefile.com/tags/Non-Linear-Regression/"/>
    
  </entry>
  
  <entry>
    <title>Random Forest regression Implementation</title>
    <link href="https://massivefile.com/randomforestregression/"/>
    <id>https://massivefile.com/randomforestregression/</id>
    <published>2020-05-06T00:55:53.000Z</published>
    <updated>2020-05-05T23:22:43.399Z</updated>
    
    <content type="html"><![CDATA[<body>  <div tabindex="-1" id="notebook" class="border-box-sizing">    <div class="container" id="notebook-container"><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Random-Forest-Regression">Random Forest Regression<a class="anchor-link" href="#Random-Forest-Regression">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Random forest is a non linear regression algorithm that creates decision trees on data samples and then gets the prediction from each of them and finally selects the best solution by majority vote.<br>*It is a type of ensemble learning that means combining many models into one and here it combines many decision trees.</p><p>To see the decision tree model implementation <a href='https://massivefile.com/decisiontreesimp/' target = '_blank'>click here </a></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Here-is-how-Random-Forest-looks-like:">Here is how Random Forest looks like:<a id="more"></a><a class="anchor-link" href="#Here-is-how-Random-Forest-looks-like:">&#182;</a></h3></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src = 'https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png'></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h4 id="Now-Let-us-start">Now Let us start<a class="anchor-link" href="#Now-Let-us-start">&#182;</a></h4></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>For this model we will be using random forest to predict a salary of an employee with position level of 6.5</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Importing-the-libraries">Importing the libraries<a class="anchor-link" href="#Importing-the-libraries">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[6]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Importing-the-dataset-/-Create-Own">Importing the dataset / Create Own<a class="anchor-link" href="#Importing-the-dataset-/-Create-Own">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[9]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Position&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Business Analyst&#39;</span><span class="p">,</span> <span class="s1">&#39;Junior Consultant&#39;</span><span class="p">,</span> <span class="s1">&#39;Senior Consultant&#39;</span><span class="p">,</span> <span class="s1">&#39;Manager&#39;</span><span class="p">,</span> <span class="s1">&#39;Country Manager&#39;</span><span class="p">,</span> <span class="s1">&#39;Region Manager&#39;</span><span class="p">,</span> <span class="s1">&#39;Partner&#39;</span><span class="p">,</span> <span class="s1">&#39;Senior Partner&#39;</span><span class="p">,</span> <span class="s1">&#39;c-level&#39;</span><span class="p">,</span> <span class="s1">&#39;CEO&#39;</span><span class="p">],</span> <span class="s1">&#39;Level&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="s1">&#39;Salary&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">45000</span><span class="p">,</span> <span class="mi">50000</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mi">80000</span><span class="p">,</span> <span class="mi">110000</span><span class="p">,</span> <span class="mi">150000</span><span class="p">,</span> <span class="mi">200000</span><span class="p">,</span> <span class="mi">300000</span><span class="p">,</span> <span class="mi">500000</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">]})</span><span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span> <span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>            Position  Level   Salary0   Business Analyst      1    450001  Junior Consultant      2    500002  Senior Consultant      3    600003            Manager      4    800004    Country Manager      5   1100005     Region Manager      6   1500006            Partner      7   2000007     Senior Partner      8   3000008            c-level      9   5000009                CEO     10  1000000</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Fitting-Random-Forest-Regression-to-the-dataset">Fitting Random Forest Regression to the dataset<a class="anchor-link" href="#Fitting-Random-Forest-Regression-to-the-dataset">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[10]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[10]:</div><div class="output_text output_subarea output_execute_result"><pre>RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,           max_features=&#39;auto&#39;, max_leaf_nodes=None,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,           oob_score=False, random_state=0, verbose=0, warm_start=False)</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Predicting-a-new-result">Predicting a new result<a class="anchor-link" href="#Predicting-a-new-result">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[11]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">6.5</span><span class="p">]])</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Visualising-the-Random-Forest-Regression-results-(higher-resolution)">Visualising the Random Forest Regression results (higher resolution)<a class="anchor-link" href="#Visualising-the-Random-Forest-Regression-results-(higher-resolution)">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[14]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mf">0.01</span><span class="p">)</span><span class="n">X_grid</span> <span class="o">=</span> <span class="n">X_grid</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_grid</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_grid</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Truth or Bluff (Random Forest Regression)&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position level&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Salary&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span> </pre></div>    </div></div></div></div>    </div>  </div></body>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;
  &lt;div tabindex=&quot;-1&quot; id=&quot;notebook&quot; class=&quot;border-box-sizing&quot;&gt;
    &lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Random-Forest-Regression&quot;&gt;Random Forest Regression&lt;a class=&quot;anchor-link&quot; href=&quot;#Random-Forest-Regression&quot;&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Random forest is a non linear regression algorithm that creates decision trees on data samples and then gets the prediction from each of them and finally selects the best solution by majority vote.&lt;br&gt;
*It is a type of ensemble learning that means combining many models into one and here it combines many decision trees.&lt;/p&gt;
&lt;p&gt;To see the decision tree model implementation &lt;a href=&#39;https://massivefile.com/decisiontreesimp/&#39; target = &#39;_blank&#39;&gt;click here &lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Here-is-how-Random-Forest-looks-like:&quot;&gt;Here is how Random Forest looks like:
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Random Forest Regression" scheme="https://massivefile.com/tags/Random-Forest-Regression/"/>
    
  </entry>
  
  <entry>
    <title>Non Linear regression Implementation</title>
    <link href="https://massivefile.com/NoneLinearRegression/"/>
    <id>https://massivefile.com/NoneLinearRegression/</id>
    <published>2020-05-05T00:56:53.000Z</published>
    <updated>2020-05-05T23:21:29.628Z</updated>
    
    <content type="html"><![CDATA[<body><b>Non Linear Regression Full Implementation with the dataset EDA and Other Techniques.<br>You will use use the most basic and the Non Linear model to predict results.</a> </b><a id="more"></a>  <div tabindex="-1" id="notebook" class="border-box-sizing">    <div class="container" id="notebook-container"><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1><center>Non Linear Regression Analysis</center></h1></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>If the data shows a curvy trend, then linear regression will not produce very accurate results when compared to a non-linear regression because, as the name implies, linear regression presumes that the data is linear. Let's learn about non linear regressions and apply an example on python. In this notebook, we fit a non-linear model to the datapoints corrensponding to China's GDP from 1960 to 2014.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="importing_libraries">Importing required libraries</h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[2]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span><span class="o">%</span><span class="k">matplotlib</span> inline</pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Though Linear regression is very good to solve many problems, it cannot be used for all datasets. First recall how linear regression, could model a dataset. It models a linear relation between a dependent variable y and independent variable x. It had a simple equation, of degree 1, for example y = $2x$ + 3.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[3]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span><span class="c1">##You can adjust the slope and intercept to verify the changes in the graph</span><span class="n">y</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">3</span><span class="n">y_noise</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="n">ydata</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">y_noise</span><span class="c1">#plt.figure(figsize=(8,6))</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span>  <span class="s1">&#39;bo&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Indepdendent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Non-linear regressions are a relationship between independent variables $x$ and a dependent variable $y$ which result in a non-linear function modeled data. Essentially any relationship that is not linear can be termed as non-linear, and is usually represented by the polynomial of $k$ degrees (maximum power of $x$).</p>$$ \ y = a x^3 + b x^2 + c x + d \ $$<p>Non-linear functions can have elements like exponentials, logarithms, fractions, and others. For example: $$ y = \log(x)$$</p><p>Or even, more complicated such as :$$ y = \log(a x^3 + b x^2 + c x + d)$$</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Let's take a look at a cubic function's graph.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[4]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span><span class="c1">##You can adjust the slope and intercept to verify the changes in the graph</span><span class="n">y</span> <span class="o">=</span> <span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">3</span><span class="n">y_noise</span> <span class="o">=</span> <span class="mi">20</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="n">ydata</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">y_noise</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span>  <span class="s1">&#39;bo&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Indepdendent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>As you can see, this function has $x^3$ and $x^2$ as independent variables. Also, the graphic of this function is not a straight line over the 2D plane. So this is a non-linear function.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Some other types of non-linear functions are:</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Quadratic">Quadratic<a class="anchor-link" href="#Quadratic">&#182;</a></h3></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html">$$ Y = X^2 $$</div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[5]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span><span class="c1">##You can adjust the slope and intercept to verify the changes in the graph</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="n">y_noise</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="n">ydata</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">y_noise</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span>  <span class="s1">&#39;bo&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Indepdendent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5gUVdbA4d+BIQ1RkhiYARVZsyyIcVdZxVXENa+r6GfENYuYQAysijkvJlZZFUcMuMbFgHHNCIoRBSQrCoIkiTNzvj9uN/TMdHVX93R1dTjv89Qz09VdVadnuk9X33vrXFFVjDHGFI8GYQdgjDEmuyzxG2NMkbHEb4wxRcYSvzHGFBlL/MYYU2RKwg7Aj/bt22uXLl3CDsMYY/LK5MmTf1HVDrXX50Xi79KlC5MmTQo7DGOMySsiMifeemvqMcaYImOJ3xhjiowlfmOMKTKW+I0xpshY4jfGmCITWOIXkc4i8paITBWRr0Xkgsj64SLyg4hMiSz9goohmYoK6NIFGjRwPysqworEGGOyJ8jhnJXARar6qYi0BCaLyITIfXeo6q0BHruGigoYNgzmzoWyMhgxwq0/4wxYtcr9PmeOuw0wYEC2IjPGmOwLLPGr6gJgQeT3FSIyFdgiqOPFtXYt/73tW84YsUudBN+s2cakH7VqlfuAsMRvjClkWWnjF5EuQA/g48iqc0XkCxEZLSKbBHbggQPZ/cq+VK1aU2P1qlWweHH8TebODSwaY4zJCYEnfhFpATwDDFLV5cB9wNbArrhvBLd5bHeGiEwSkUmLFi1K7+AnnUT76kX8jSd8b1JWlt6hjDGmPrLZ5yhBzsAlIo2Al4BXVfX2OPd3AV5S1R0T7adXr16aVskGVb5tsjOr15fwez4FZMNd7drB6tU1m3tKS2HUKGvqMcZkV0VFzT5HyEw+EpHJqtqr9vogR/UI8BAwNTbpi8hmMQ87AvgqqBgQYen/nU8PpvAH3t2wurQU7rrL/VHLy0HE/bSkb4wJw7Bh3n2OQQjsjF9E9gHeBb4EqiOrLweOwzXzKDAb+HukI9hT2mf8AKtWsXbTzrxR3Yf+q8dtGNVjCd4YkysaNIB4qVgEqqvrrvfL64w/yFE97xHbtrLR+KCOGWvjEM5S7mk5kL//dgvVs+a4U3tjjMkB0Tzldf4dVJ9jQV65G20vmzPH/UGvX34O1Sp8c849YYdmjDFAzTwVT2kp3DF4XiDHLsjEX7u9bD6d+Q9HssXL/4LffgsvMGNMUYo3Yideu35UeTmMGzKJIwaVw3PPZTyegkz88cbi38kgWlcvhUceyX5AxpiiVbsFInoRqdeZvgjMng0Hf3sHtGgBf/pTxmMqyMQfr13sQ/ZkSuPecOed9estMcaYFHiN2GnYMP7jy8qAH36Ap56C00+HVq0yHlNBJv4RI1z7WKzSUmHlwAth+nQYn5X+ZWOM8awGUFUVL09FaomNHOlOUM8/P5CYCjLxDxgQf4z+PnccBVtuCXfcEXaIxpgi4TUyJ5qX6lxLdPhv8MADcMQRrkMgAAWZ+MEl/9mz3Yfm7NmRcfuNGsF558Gbb8Lnn4ccoTGmGMRvgdh4PVGdPPXoo/Drr3DhhYHFVLCJ39PAge6vfuedYUdijCkCXi0QcS8ira52uWm33WCvvQKLqfgS/yabwKmnwuOPw08/hR2NMaYIxD2zj2f8eJg2zZ3tS7zrXzOj+BI/wAUXwPr1rgPFGGNyxW23QefOcPTRgR6mOBP/NtvA4YfDvffaBV3GmNwweTK8/bY7MW3UKNBDFWfiB7j4YteB8vDDYUdijDHubL9VK9cPGbDiTfx77QV77AG33+4G1BpjTFjmznUXbA0cGMgFW7UVb+IHd9Y/cyY8/3zYkRhjitldd7nO3AsuyMrhijvxH344bLUV3Hpr2JEYY4rV0qVufOdf/+o6drOguBN/w4YwaBB8+CG8/37Y0RhjitG//gUrV8JFF9VYHeQcvMWd+MGN6W/bFm65JexIjDHFZu1ad8HW/vvD73+/YbVXRc9MJX9L/M2bw7nnunb+b78NOxpjTDF5/HH48Ue49NIaq4Oeg9cSP7jE37SptfUbY7Knutq1NOyyC/TtW+Mur4qeXutTVXSJP267WYcOrslnzBj36WuMMUH7739h6lR3tl+rPINXRc9MzcFbVIk/YbvZ4MFQWQl33x12mMaYPJVSh+zNN7uKbcccU+euRBU9M0JVc37p2bOnZkJ5uapL+TWX8vLIA/76V9VWrVSXLcvI8YwxxeOxx1RLS2vmltJSt76ODz5wD7jrroT7Ky9XFXE/4+4nCWCSxsmp4u7Lbb169dJJkybVez8NGrh/R20ikdkYJ0+GXr3gppvqdLYYY0wiXbrEn0e3vNxV5KzhsMPgvffcBi1aBBaTiExW1V611xdVU0/SdrOePeGAA9wMXWvWZC0uY0z+890h+/XX8MILblKoAJN+IkWV+H21mw0d6ur0P/JIVmMzxuQ33x2yN93khpGfd17gMXkpqsTvayacPn2gd2/X8VJZGVqsxpj84uvEcs4cN3b/jDOgXbusxherqBI/+JgJRwSGDHHF28aNCyFCY0w+8nVieeutrrNx8ODQ4oQAE7+IdBaRt0Rkqoh8LSIXRNa3FZEJIjI98nOToGJIRewwrK6DDmPZ5r+DG2+M3xtsjDFxJDyxXLgQHnyQGXudSJd9tgykBo9fQZ7xVwIXqep2wB7AOSKyPTAEeENVuwFvRG6Hqvb4/tlzG3DpL5fB55+7OTCNMaa+7r4bXbuWYz6+JLAaPH5lbTiniDwPjIws+6nqAhHZDHhbVbsn2jZTwzm9xBuGVcJ6ZjXchi17b+EqdwY48bExpsAtXQrl5fy38kD6r3q6zt1xh3xmQKjDOUWkC9AD+BjYVFUXAER+dvTY5gwRmSQikxYtWhRofPGGYVXSiOurLoMPP+S4zd4O5euYMaZA3HMPLF/Olasuj3t3pmrw+BV44heRFsAzwCBVXe53O1Udpaq9VLVXhw4dggsQ72FYozmVBXTitJ9HhPJ1zBiTv6L9hi3kN5ZcdQc/7NKPJeU94j42UzV4/Ao08YtII1zSr1DV/0RW/xxp4iHyc2GQMfgRbxgWwFqachsXcQBvsOOqjzNWEtUYU9hi+w3P4AHaVi/mhG+voF+/gGvw+BTkqB4BHgKmqurtMXe9AJwU+f0kIPQJb2sPw4p1P2eymLYMY0TWv44ZY/JTtJ5+E9ZwMbfyJn14e+2ejB/vY8hnFgTWuSsi+wDvAl8C1ZHVl+Pa+Z8CyoC5wDGquiTRvoLu3K2tdmfvFVzLtVzFwZtN4eUfd8laHMaY/BStC/Z37ud+zmJ/XudN9t9YFyxLst65q6rvqaqo6s6qumtkGa+qi1V1f1XtFvmZMOmHoXbTzz85j2W04v7O14UXlDEmJ8UrxVxWBo1Yx1Bu4CN2503+BGS/Ld9L0V2560ftpp825W2Ye9j5lE8cB199FXZ4xpgc4TXHR79+cHrjRylnLv/gakBCacv3UlRlmetl8WL3cd6/P4wdG24sxpic4FWKeeuy9Xy2ujszl7Wjx7qJlJULI0aE0JZvZZnrqV07Nzfvk0/apOzGGMB7/P0f5lbQctEsdhl3FdUq8euChcgSfyoGD4ZmzXLn+5oxJlTx2uwbUslVJSOgRw/XQpCDLPGnokMHOOccV1Z1+vSwozHGhCzeNUAnNX6CrpUz4KqrcrbUiyX+VF10ETRpAtfZCB9jil3tgSBblVVyR9trYeed4S9/CTs8T5b4U7XppnD22fDYYzBtWtjRGGNCFluK+fvrxtLqp2lw9dVufGeOyt3Ictmll0LTpnDttWFHYozJFZWVcM01sMsucPjhYUeTkCX+dHTsuLGt/7vvwo7GGJMLKipgxgwYPjynz/bBZ+IXkXIROSDyezMRaRlsWHngkkvcWf8114QdiTEmbJWVrgWgRw847LCwo0kqaeIXkYHAOOCByKotgeeCDCovdOjgxvWPHQtTp4YdjTEmTGPGwPffu7P9HB3JE8vPGf85wN7AcgBVnY7H5ClF55JL3Fiu4cPDjsQYE5Z169zZfs+ecOihYUfji5/Ev1ZV10VviEgJkPt1HrKhfXsYNAieesrNz2uMKT6jR8OsWS7558HZPvhL/O+IyOVAMxHpCzwNvBhsWHnkoougdWt3sYYxprisXu0S/l57wUEHhR2Nb34S/xBgEa6u/t+B8cAVQQaVVzbZBC6+GF54ASZODDsaY0xA4pVf5oEH4Mcf3QWdeXK2D1adMzNWrICttnI9+q+9FnY0xpgMi5ZfXrVq47oOzVYyp9HWNNttJ3j99fCCS8CrOmdJgg2+JEFbvqrunKHY8l/LljBkiDvzf+cd2HffsCMyxmRQdCrFWKeuHkmz1Qvz8kJOzzN+ESlPtKGqxqlCHYxcOuOvqHAvgrlzXWW+DTW2V6+Grbd2Z/7vvptXX/uMMYlFp1KMas1SZrIVH7AX/fWl8AJLIuV6/Ko6J7oAa4FdgJ1xo3yylvRziddsOxUVuHLNV10F778P48eHHaoxJoNql1++hFtoy6/cs1l+lmj3cwHX6cBE4EjgaOAjETk16MByUbyve6tWufUAnHaaO+u//PLszqhsjAlUbPnlTfmJQdzJUw2P44Rbdgk3sDT5GdVzCdBDVU9W1ZOAnsBlwYaVm7xm29mwvlEj1973xRfwxBNZi8sYE6zY8stXch2NWUeTm67JqVm1UuEn8c8HVsTcXgHMCyac3BZvtp0664891lXnu/JKd0WfMaYgDBgAs9+cyTklD9DozNM57KJtwg4pbZ6JX0QGi8hg4AfgYxEZLiJXAx8BM7IVYC6Ijt+dM6dun21paa2ZGBs0gOuvh5kz4cEHsxmmMSZoV1/tvtlfeWXYkdRLojP+lpHle1xRtmif9vPAgoDjyhmxHbrgOnWjyb+83H39q/N17+CD4Q9/cJU7V67MarzGmIB8/rlLCOefD5tvHnY09WIXcCURPdOvrbzczbrj6cMP3WXc//iHlXMwphAcdBB88omrwtmmTdjR+JLycM6YDTuIyC0iMl5E3owuwYSZexJ16Ma9hDtqzz3hyCPhlltg4cIsRGqMCcwbb8Crr7ohfHmS9BPx07lbAXwLdAX+AcwGPgkwppzi1aHbtm2CMf1R11/vLuyyyVqMyV/V1W661bIyN992AfCT+Nup6kPAelV9R1VPBfZItpGIjBaRhSLyVcy64SLyg4hMiSz96hF7VsSO342K3k44ph+ge3c4/XRXyGlGUfWHG1M4nnwSPv3UFWJr2jTsaDLCT+JfH/m5QEQOEZEeuFm4knkYiFen9A5V3TWy5PwlrrHjd0U2duguWRL/8XWahq6+Gho3dhd1GWPyy9q17mxul13ijOLIX34S/3Ui0hq4CLgYeBC4MNlGqvo/wCM95pcBA1xHbnW1+zlggM8x/QCbbeaKtz39tOvwNcbkj5Ej3SQrN9+c8xOopyLpM1HVl1R1map+pap9VLWnqr5Qj2OeKyJfRJqCNvF6kIicISKTRGTSokWL6nG4YHg1AY2IV7rjkkugUyc3aUsejKIyxgCLF7vmnYMOggMPDDuajEp0AdelkZ//FJG7ay9pHu8+YGtgV9y1ALd5PVBVR6lqL1Xt1aFDhzQPFxyvJqABA+KM9nm+hSvl8OGHMG5c2KEbYxKIvn/van8tVUuX89K+t4QdUsYlOuOfGvk5CZgcZ0mZqv6sqlWqWg38C+idzn5yRbwmIK8Kno83OQV23NHV7V+7NvFQUGNMKKLv30ZzpnM29/AQp3HstTsW3vtTVT0XoCFwS6LHJNm+C/BVzO3NYn6/EHjCz3569uyp+aK8XNWl/JpLebmqvvKKKuik42/T0tKa95eWqj72WMjBG1Pkou/fcRypK2ium7Jg4/s3DwGTNE5OTdjGr6pVuGqcKRORscCHQHcRmS8ipwE3i8iXIvIF0AcfncT5xuuCrzlzoMvf/8yPO/2ZbZ64lmarfqlxf52hoMaYrJs7F/7A/ziK/3Azl/IznTasLyRJSzaIyG1AN+Bp4LfoelX9T7ChbZRLM3Al41XiIapn06/5eM3O3MdZnMfIGveJWBl/Y8K0VXkV4+buRgcW0Z3vWI0bwZG0REuOSrtkA9AWWAz8CTg0svTPbHiFI95on1iT1+zAA3ImZ3I/2/N1jfu8hogaY7Kj4s+P8ns+4zJu2pD0PUfr5TEr0haA6Ly8Xmf+7fiF6XTjE3bjz7wKCKWlHpU+jTGBq6iA64eu4PV52zK/pAsHt/qAJb9KzXm181B9irQ1FZFzROTeyNj70SIyOpgwC0N0tE+5x3T1i2nPraVXcyATOITx3uWdjTGBi47kGTDvBjbjJ86tvJPVa4QxYzaO1is0fpp6xgCdgD8D7+DKNaxIuEURijc8M1Gzzy2rzmaabMvjnQYze9q6gnxxGZMPhg2DjqtmMZjbGcMJTGT3gh9s4Sfxb6OqVwK/qeojwCHATsGGlV+8xu7Dxou8altPYwbpHbT6aRrcdVd2AzbGbDB3LtzOYCopYSg31FhfqFIp0rZURHYEWuPG55uIYcO8K3VGm31qT9kI8DL9eJH+rmzzgqKZ1MyYlAR9seOADq9xBM8xgmH8EFN/spAHW/hJ/KMiNXWuAF4AvgFuCjSqPJNospYorxfRrZvf4SZlHzIk84EZk+e8vk3XTv5pfzisX8/Ikgv4XrbmdgZvWF2II3lqiHdVV2Skz6Ze92V7yfUrdxNerRvx2GPqfbXu0KFuxQcfhPQMjMlN9X5vJXP77aqgb130opaXq4q4fSfb9rHHNKXHhwWPK3cTJf6fgAnAqUBrr8dlY8n1xO/3hef5YlmxQnWLLVR79lStrMxy9MbkLpH4iV9k42P8fDjE9dNPqq1aqR58sGp1te+Y6vVBk2XpJP6GuJE8/wZ+Bp4DjgWaeW0T1JLriV81A2cAY8e6f8d99wUQnTH5yU9S9/PhENeJJ6o2bqz63XcZjylXeCV+zzZ+dVU0X1XVU4DOkQ+Aw4FZIlJoterqLV6lzpQceyz06eNm6srB+QeMCYOfeS98T4oU63//gzFj3FwZ226bUkx++vRyna8pZVR1Ha5TdyqwHNg+yKCKkoib7WfFChg6NOxojMkJiea9iEppUiSA9evhnHPcztKYEjWtD5ockzDxi0iZiFwiIp8CL+Gafw5T1R5Zia7YbL89DB4MDz1k0zQaE5Hs27SfD4ca/vlP+Oord/1MosJaHlL+oMlF8dp/XNMQHwBzgFuBXl6Py8aSD238GbNiheqWW6ruuqvq+vVhR2NMYfnhB9UWLVQPOcRXh65X312+j+pJdMY/FOiiqherav5USMt3LVrAHXfAlCmu6ccYk7bY8f3t28PzXS9g9cpK/vjZXVQ8Hueqylrbel1DUO8+vZBZdc5cpAqHHALvvgtTp8KWWybfxhhTQzRxR6+qP5jxjOcQhnEd1zMsaUVcr7k18qk2v1d1Tkv8uWrWLNhhBzjoIPhP1ua8MaZgxCbuZqzia3ZgNc3YlSmspzGQOIk3aODOwWrLpwmT6lOWuaufdSYzNnw13borNzW5Cp59Fl58MeywjMkb0fdQ7Nn6VVxDV2ZzJvdvSPqQeAhmIYze8eJnOOczcdaNy3Qgpm6b4hVLL+Ib2YHfTjmXJx9aGWihKmMKQex7KGoHvuIibmM0p/Auf6zx+ERJvCBG73go8bpDRH4H7AC0FpEjY+5qBTQNOrBiVLvKZyWNGKgP8P7ifVh05pXMqbwDqFn2Od86lYwJUu33UAOqeJDTWUobLuXmGo9NlsSj761hw9w3g3yfjStWojP+7ri5dduwca7dQ4HfAwODD634xPva+QF7cw9nc3blXfTm4w3rC32iCGPSUfs9dA73sAcfM4g7oV172rXbONb/pJPceyjRt+h8H73jKd4Yz9gF2DPZY4JeCn0cf3RMcLz6H6DakmU6jy30c3bSEtYlrEWSL+OLjQlC7PuojNm6guY6noO0vKzmmP18KrRWH6RapG3DA6ADcDkwChgdXZJtl8mlkBN/vBdgvOVQnlcFHcoIz6JQxfJiNsbLxvdAtb5EP11Bc+3edHad90A+FVqrD6/En3Q4p4h8ALwLTAaqYr4pxOv0DUQhD+f0Giscz5P8lb/wArsyhXmlv6szBrkQxh0bU18VFfDxoMe5+5cBXLPJHWz9z0F1mmgKYaimH2mP4xeRKaq6a2CR+VDIid/rBRjPpvzE1+zA7Cbd+e5f73L8iQ197avQXszGJPTzz67uVbdu8P770LBhnYcUy0lS2uP4gZdEpF8AMRm8h5O1a1d3KNmK0k58e+Zd9Fz7Iccv/qfvfRXCuGNjfDv3XFi5EkaPjpv0obCHavrhJ/FfgEv+a0RkuYisEJHlQQdWLLxegHfdFb/i4N73DoD+/V052RkzfO2rWF7MxjBunFuGD3dn/R5SruhZaOI1/GdiwXUCLwS+ilnXFjed4/TIz0387KuQO3dV0xiJM3++auvWqvvuq1pVVb99GVMoFi1S7djRTWFqlW1VtX6duwIMALqq6rUi0hnYTFUnJtnuj8BK4FFV3TGy7mZgiareKCJDIon/smQfToXcxp+20aPhtNPg7rvhvPPCjsaY8B13HDzzDEyeDDvtFHY0OaE+bfz3AnsCx0durwTuSbaRqv4PWFJr9WHAI5HfH8FN5WjSccopcPDBcNllMG1a2NEYE66nnoInnoCrr7ak74OfxL+7qp4DrAFQ1V8hpspRajZV1QWR/SwAOno9UETOEJFJIjJpkc1BW5cIPPggNG3qLkGsqkq+jTGF6Kef4KyzYLfd3ImQScpP4l8vIg0BBRCRDkDggwNVdZSq9lLVXh06dAj6cPlp883dZC0ffQS33hp2NMZknyoMHOhqmDz6KJR4lh8zMfwk/ruBZ4GOIjICeA+4Ps3j/SwimwFEfi5Mcz9Fb0P55gHH8d/So6m64ir44ouwwzImux5+GF56CW64AX73u7CjyRtJE7+qVgCXAjcAC4DDVfXpNI/3AnBS5PeTgOfT3E9Rq1G+GeHkVffyS+Um/Nr/BFizJuzwjMmOmTPh/PNh333dT+ObZ+IXkbbRBXdmPhZ4HHfW3jbZjkVkLPAh0F1E5ovIacCNQF8RmQ70jdw2KapdevYXOnAKo9lk3pdWstMUh8pKOPFEd4HWo4+6y9aNb4kaxCbj2vUFKAN+jfzeBpgLJJyFS1WP87hr/9TDNLHilW9+mX7cy9mcffvt0K8f7G9/ZlPAbrwRPvjAff21S9NT5vkxqapdVXUr4FXgUFVtr6rtcDX6bRLYEHm9zu/ufAt07+5G+SypPZLWmALxySfwj3/A3/4Gxx+f/PGmDj/fj3ZT1fHRG6r6MrBvcCGZZLxKM1x5Q6k7A/r5Z9cJ4Lf6mzH5YsUKl+w7deLpPvfadKRp8pP4fxGRK0Ski4iUi8gwYHHQgRlvCeuM9OwJ11/vrmB88MGMH3vDaCJ7s5kAeb7OzjsPZs5kwkmPcfKFm2yYnzo6Ham9Hn2KV8dBa9bcaQvcBXwWWe4C2ibbLpNLodfqybiqKtW+fVWbNVP9+uuM7dYmejHZ4PU6e++sx9yNq64qmolU6ot0a/XkAqvVk4affoKdd4ZOnWDiRHeFbz0VSw1zE654r7Ot+J4p0oOWe+0Mb79Ng8YlNveED2nX6hGRbUVklIi8JiJvRpdgwjQZ06kTPPIIfPklDB6ckV3GG02UaL0x6aj9emrEOsZyHJXa0LXllJTY3BP15KeN/2lcE88VwCUxi8kRnu2hBx8Ml1wC990HTz5Z7+PYm81kQ+3X0y1cQm8+YUiH0e7rJTb3RL3Fa/+JXYDJyR4T9GJt/N6StruvW6e6556qLVuqTpuWdF/RWv7t2rkltq6/tfGbbIh9nR3BM6qgI0suqPM6s7knkqMe9fiH467cfRZYG/OBkbWB4tbG781Xu/vcudCjhzuV+vDDuO390TIQsVcExyotdSOHwF0cPHeu292IEUU0a5HJmooKuP/Smbz44++Z3Xhbpo56j+NOSrcocPGqz2Trs+KsVnUXd2WFJX5vvidYf+klOPRQV8kwmsFjeH2AxLJOXFNbRUVAJwJr1sDee7t6PJ9+Cl0TFgowHrwSf9Iapqpqf/EcVlYWP2HXaXfv3x+GDHGXuu+5p5vIJYafDlrrxDWxan9LjI6lhwwk/3PPdQn/+ect6QfAz6ie0sgFXKMit7uJSP/gQzN+pNTJde21robP2WfDZ5/VuMtPB6114ppYtYsFgrtd7zqBDz3klssvh7/8pZ47M/H4GdXzb2AdsFfk9nzgusAiMilJeBVvbSUlMHYstG8PRx1Vo55PvA+QWDZiwtQWyPDeyZPhnHPggAPgmmvq3G1XjmdIvB7f2IVIrzDwWcy6z5Ntl8nFRvXUX+wIiL90+lgrSxqrHnSQamVl3MfEG9VjTKyMXz27cKHbuKxMddGiOnfbqLLU4TGqx0/i/wBoBnwaub01MDHZdplcLPGnJ5rIwSXw2DfM2Y1HuV8uuyzsME2eymgiXrdOdb/9VJs2Vf3kk7gPsTINqatP4u8LvAMsAiqA2cB+ybbL5GKJP3Xx3pS1l0dbnOV+efzxsMM1eSpjY+nPPde9FseM8XxI7ZOX6CKS5jGLgFfi9zP14gTgSOBk3CxcvVT17cw0NJmgxOt4q+30lXfCH/4Ap51Wp7M3lrWrGi8DBrghvtXV7meqo3kqKuCS9qNh5Ej+1XIwFXKC52PtyvHM8Ttf2b64mbP6AH8ILhyTKX462DYrbwzjxrnO3sMOc4Xdaqkxv6+VvzUZVFEB/z7tPUYsPpPX6MtZK25K+NqyMg0ZFO9rQOwC3Au8BpwSWV4B7km2XSYXa+pJnVd7aNy22E8/dSt691ZdtcrXfqxd1dTXPpt/rwtpr9+yrbZhia/XlpVpSA31KNnwNbBjZCeISAPgS1XdIcDPoxrsyt3UxSvBIOLeWuXlca6wfO45OPJI+Otf3ZBPESCFK4ONScWyZXzTZk868RO78zEz6LbhLnttZU7aZZmB73CTrUd1Br7IVGAmGPHG948Z45J43LbYww+HG25wVTyHD9+w2tpVTcZVVhLNsJQAABZ8SURBVMKxx9KN6RzFMzWSPthrKxv8JP52wFQReVtE3ga+ATqIyAsi8kKg0Zl68ep48+ysvfRSOPlkd+HMI48A1q5qMkzVXTn+6qtMPu1eJpb2qXG3vbayJF77T+yC69j1XJJtn4nF2vgzJ+nY67VrVfffX7WkRHXChA3bWLuqyYjrr3cvuqFDVdVeW0GjPlMvikg50E1VXxeRZkCJqq4I6LOoDmvjzxxfZZyXLYN99nFDg957D3baKYsRmoL1+OPua+fxx7t2xwZ+BxWadNVn6sWBwDjggciqLYHnMhueyRZf9VVat4bx46FFCzeLl5XlND55NiO+/rprRtx3Xxg92pJ+yPz89c8B9gaWA6jqdKBjkEGZ4PjurO3cGV5+GVauhAMPhF9+CTw2E776XKzndc3Hy9dOgiOOgO7d4dlnoUmToMI3PvlJ/GtVdV30hoiUAMnbh0xOitdZK+LepHXe6DvvDC++6O7s1899CJiCE032InDiielfrBfvavHNV01nt+H9oF07ePVV2GQTuxI8F8Rr+I9dgJuBy4FvcXV7ngVGJNsuyT5nA18CU/DofIhdrHM3sxIVb4tbZOv551UbNlTt21d1zZowQjYB8VPTye/FerVfS5szX2fSRRfSXvW77zyPZxU2g+OVX/1cwNUAOA04EBDgVeBBTbZh4n3OxtX88dV+YJ27wfDV0Rv18MNu1q7DD4ennoJGjYIP0ATOz5Sbfi+oit1XBxbyDvuyBT8woNObvLigV8Lj2bSewUi7c1dVq3GduWer6tGq+q/6JH2TO1KaSOPkk+Huu90VviefDFVV9T6+feUPn59+e78XVEWbETdhCRPoSzlzOKrJf/nbrRvzTiCTt5jUxfsaEMnrAgwHfgEWA0twpZmv8trG7wLMAj4FJgNneDzmDGASMKmsrCyob0JFLa06PNFx2AMHqlZVpX1s+8qfG1Kq6eTDE6OW6WeNe+saGuuJHV+ps63VfsouUq3HD1wITAC6xqzbCtfUc6HXdn4WYPPIz47A58AfEz3e2viDkXbyvfxy9+CzzlKtrk7r2JYAckO810C0rT7lC6qWL1fday/XH/Tss76PZx/4wUkn8X8GtI+zvgMx0zDWd4l8q7g40WMs8QcnrSsnq6tVL720XsnfJtXIHRm5ejY26Y8bl9bx7CrezEsn8X+Vzn3JFqA50DLm9w+AgxJtY4k/B1VXq15yiXsJnX12ys0+dsaf+3wn4uXLVffe21fST3Qs+yaQeekk/k/TuS/ZEmku+jyyfA0MS7aNJf4cFZv8Tz+9xsTtyWS0icHn8exs0j/fiXjJEtU99nBJ/+mn0z6enQgEI53EX4W7Wrf2sgJY77VdEIsl/hxWXa16xRXupXT88W7SbJ9Svp4gTXY2mTpfiXjhQtVdd1Vt3Fj1uefqdTxr+guGV+L3VaQtbDaOPw/ceCMMHerG+T/xREqX5Qc9ttvGjqcu6QQ8P/wAffvCrFluiO+f/1yv49n/KBj1mYjFmOSGDNk4zv/gg2H5ct+bBj2228aOpy5hTafvvoO994Z58+CVV3wl/WTXbNi8D9llid9kznnnuXK7774L++0HP//sa7OgZ/myWcScVC6Y80rE9536iSvZvWoVvP22q7bp47jxirfFHj/ejHGjRsWZKc5kRrz2n1xbrI0/98V2np7Ucbyub1KquvXWqtOm+do2yDZ4a+NP729Qu0P8jUtfUW3eXLVLF1//1yjruA0PqXbu5tJiiT83Jeqc3bfJh7q6RTvVdu1U333X976CGnVTKKN60n0e9U6+99/vRu7ssovqjz+mFLN13IbHEr/JKD9VHf+4+XTVbt3cqI+xY8MOOe8lOmtP9oGQdvKtqto4ZPfgg92Y/RTiTVQSws74g2eJ32RUshovG5LKL7+o7rOPW3H11fWq71PsvP7m7dolb8ZJ64x/xQrVI45wDzzzTNX1633HmuzEoNia2sJiid9klNcZZLyk8vi/1+i45v+nCvpC4yO1rO2KvG9yCYOfv7lXUk/5grmZM1V32km1QQPV229PuSxHsjN9+79nhyV+k1F+qzpuTDjVeiG3aSUNdAo7a1e+T6uDsZgThp9vWYmacXxfMPfmm+5rRJs2qq++mlas1q6fGyzxm4zyewZZO1kdyCu6hDa6hDbanxcSNjfYaJyaEv3NUzm79voA6VJW5cpuN2igut12KY3cqc1G8uQGS/wm4/ycjcdLTF35Xifxe1XQ6xmiJcRvO7bkUVeis3a/7enxtmvDEn2B/u7Gscem1InrFad9aIfPEr8JhVfybsJqfYCBqqAfN9lHdc6cOtvmW3NBNpulUm32if2wrL3tXrynsyjXtTRSvfvutOdYqM2a6cJnid+EItnojlMbj9F1TVu49uRa1R3z6Yw/22e4qXb0xn5YRmNtQKVeyT+0kgY6U7rqy8M/CiZYExpL/CY0sWd+7SLXdNU4C5wxQ3W33dzL8ZRTVJcu3bBdvjQXZPtDyut4DRv6i+O522a4b1qg/2k+QJ8YtSyYQE2oLPGb3LZ2rZvSsUEDXdmusw7o+Jr3B0UOynazlNeH4llnJfmwrKpSHTnSrWzdWvXRR4MJ0OQES/wmL7w8/CP9Vrqrgj7AQG3Dkpw9y48VRrNUylMYTpum2qePC+zAA1XnzQsuOJMTLPGbvFBertqUVXozF2slDXQBm+oxPKnlZal3OGazczGnm6XWrlW97jrVJk3cWf4DD2SsA9fkNkv8Ji/ENpn0YLJ+Qk9V0PEcpPrtt773E2QizuZk4fXe54QJqttv7/4AxxyTcoE1k98s8Zu8ULvJpCHr9Xzu1GXSSrWkRPWii1SXLk2aEINqesnmmX29jjVz5sY6O1ttpfrSS5kP0OQ8S/wmL3glu6fv+dlN6C6iq1u214sb3amNWeOZEIPqbM1mW35ax1q0SPXCC11F1ObN3ZW4q1dnPjiTFyzxm7yR8Gx+0iR9t+n+qqAz6aIn8og2ZH2dhJiJBB0vjmyO3knpWMuWqV57rWqrVq7kwmmnqc6fn/mgTF6xxG8KhojqAby2oezDdLbWU3lQG7N2w2Pq2yTjtX27djl2xr9kiSt33aaNu/Pww1W/+SbzwZi8ZInfFIyNCbFaD+V5nUgvVdD5DTur3nyz6q+/qmr9OkbrU/s+UxJ+eM2cqTpokGrLlhsT/qRJmQ/C5DVL/KZg1E2I1Xp4k/G6YPvIGPXmzVXPPVf1yy/TPkaiZpZsDxONHqtLWZVOGPK66lFHueackhLV449X/fzz4AIwec0Sv8mabCRGz2N8+qnqiSe6zk1Q3WMP1Yce2lAGwq+cqhM0d67rpN1qKxfEJpuoXnZZVi/AsoJr+ckSv8mKnLmQadEi1dtuU/3d71wQTZqoHnmk6tNP6xMPrkiaxDLRR1CvRLlggep996n+8Y8bA9h3X7ejLI/SyZn/qUmZJX6TFTl1pqzqrlD96CPVCy5Q3XRTVdA1NNbxHKRncY924zstbVbtmfzTSd5pJcrKStWJE1VHjFDdffeNG263nRutM316Gk8+M3Luf2p8y6nEDxwEfAfMAIYke7wl/vwR5HDHep9FV1bqsZu+pbcyWKexzYbg5rGFPtP8BNWRI3X8PyZqt7I1vo8RLyZfiXLZMjfF4Y03qh56qCulEH1g796uxMIXX+REaYV8mxfBbOSV+MXdlz0i0hCYBvQF5gOfAMep6jde2/Tq1UsnTZqUpQhNfXTpAnPm1F1fXg6zZ6e/34oKOOMMWLVq47rSUhg1CgYM8L+fBg1c2gJlG2bwJ96kD2+xH2/TiZ8BWEtjvqM7U9mOGSXb0ee0rdjrb2VQVgYdO0Lz5iDiGdOqVSBU04rlbMYCOjOPMubSjRlcdug38M03MHNmNBDYZhv405+gTx+3bLpp+n+oAAT1PzXBE5HJqtqrzvoQEv+ewHBV/XPk9lAAVb3BaxtL/PkjUwm6tkwlH8/9lCmbV81j8x8mshufsD3fsD3f0JVZNKDWe6SkBNq2Zd7iUn6rasI6GiMoTVhLY9bRkhW0YSkNqa6x2Toa0XjH7rDddrDjjtC7N+y2G7Rr5/8JhCCo/6kJnlfiLwkhli2AeTG35wO7136QiJwBnAFQVlaWnchMvUUTwbBhMHeuO0keMaL+CWLu3NTWexkxIn4SG3G9cOKJZShlPMPRG+5rwhrKmMe01+e6gy1e7JYlS3hr1Goas44mrKWaBqyjMetozApasqKkLT9XtmUhHZlLGYualnH1A5tz/P/Ff8tVVGT+b5YpQf1PTYjitf8EuQDHAA/G3D4R+GeibayN3yRqN0+17d/r8al2YmYqJhs1Y4JCrnTuAnsCr8bcHgoMTbSNJX6T9oxTGTiG174ylbBt1IwJilfibxDCl4xPgG4i0lVEGgN/A14IIQ6TRwYMcG3K5eUg4n6OGgXjx9dstgF3e9iwzB3Dq0kj1cd7yVQzljF+Zb1zF0BE+gF3Ag2B0ao6ItHjrXPXeNk4SqcmEaiurrs+FwU5aiaX+w5M8Lw6d8M440dVx6vqtqq6dbKkb0wiXv3+mR4PUFHhEnSDBu5nRUXm9j1ihOtgjlVa6tbXR3Q0zpw57sNxzhx3u76xB/m3MFkSr/0n1xZr4zdestExmq1jZLoWThB9B9YRnV/Ilc7ddBZL/CaRoAuIZbvzNVPPJ4grbq0jOr94Jf5Q2vhTZW38JkzZ7EfI5MVSQfQdFEKfSjHJqTZ+Y/JJffsRvNrE460fNixzo5SC6DvIVp+KCVi8rwG5tlhTjwlTfdq1420bbYKp3RRT+3GZaJ7JdDOYtfHnF6ypx5j0pTss0qu5xUvDhlBVVXd9LhVEsyGi+cOaeozx4Gd44oABLvFWV7uffhNdqhdhVVUFM7Qzk9L9W5jcYYnfFLWgxrpHpdr2Hb36t75XAxuTiDX1mKIWdK35eKN0vFipY5Np1tRjikKqV5UGXScntp4PuLP4WNHbdmZvsskSvykY6TTbZGN4YrRNXBXGjKnZjDNmjFtvbeUmm6ypxxSMdJptbHYpU8isqccUvHSabTJVWtmYfBLG1IvGBKKsLP4Zf7JmmwEDLNGb4mJn/KZgBFXe2JhCY4nfFAxrtjHGH2vqMQXFmm2MSc7O+I0xpshY4jfGmCJjid8YY4qMJX5jjCkylviNMabI5EXJBhFZBKQwnUXOaA/8EnYQWVaMzxmK83kX43OG/Hre5araofbKvEj8+UpEJsWrk1HIivE5Q3E+72J8zlAYz9uaeowxpshY4jfGmCJjiT9Yo8IOIATF+JyhOJ93MT5nKIDnbW38xhhTZOyM3xhjiowlfmOMKTKW+LNERC4WERWR9mHHEjQRuUVEvhWRL0TkWRFpE3ZMQRGRg0TkOxGZISJDwo4nG0Sks4i8JSJTReRrEbkg7JiyRUQaishnIvJS2LHUhyX+LBCRzkBfIMEkgAVlArCjqu4MTAOGhhxPIESkIXAPcDCwPXCciGwfblRZUQlcpKrbAXsA5xTJ8wa4AJgadhD1ZYk/O+4ALgWKoiddVV9T1crIzY+ALcOMJ0C9gRmqOlNV1wFPAIeFHFPgVHWBqn4a+X0FLhFuEW5UwRORLYFDgAfDjqW+LPEHTET+Avygqp+HHUtITgVeDjuIgGwBzIu5PZ8iSICxRKQL0AP4ONxIsuJO3AlcddiB1JfNwJUBIvI60CnOXcOAy4EDsxtR8BI9Z1V9PvKYYbhmgYpsxpZFEmddUXyrAxCRFsAzwCBVXR52PEESkf7AQlWdLCL7hR1PfVnizwBVPSDeehHZCegKfC4i4Jo8PhWR3qr6UxZDzDiv5xwlIicB/YH9tXAvFpkPdI65vSXwY0ixZJWINMIl/QpV/U/Y8WTB3sBfRKQf0BRoJSKPqeoJIceVFruAK4tEZDbQS1XzpbJfWkTkIOB2YF9VXRR2PEERkRJc5/X+wA/AJ8Dxqvp1qIEFTNxZzCPAElUdFHY82RY5479YVfuHHUu6rI3fBGEk0BKYICJTROT+sAMKQqQD+1zgVVwH51OFnvQj9gZOBP4U+f9OiZwJmzxhZ/zGGFNk7IzfGGOKjCV+Y4wpMpb4jTGmyFjiN8aYImOJ3xhjiowlfhMoEVmZ4uP3y1TlQxEZLiIXZ2hfD4vI0Wluu2u84Y4i0lxEFotI61rrnxORv6aw/81FZFySx3j+XUVkdjFUjTUbWeI3Jni7AnUSv6r+BrwGHB5dF/kQ2Afw9eEnIiWq+qOqpvWhZIqTJX6TFZEzzrdFZFykVn9F5ArQaE37b0XkPeDImG2ai8hoEfkkUgP9sMj6k0XkeRF5JVIL/+qYbYZF1r0OdI9Zv3Xk8ZNF5F0R+V1k/cMicreIfCAiM6Nn9eKMFJFvROS/QMeYffUUkXci+3pVRDaLrH9bRG4SkYkiMk1E/iAijYFrgGMjFzodW+tPMxb4W8ztI4BXVHWViPSOxPVZ5Gf3mOf/tIi8CLwmIl1E5KvIfV0iz+/TyLJXzL5biZsf4RsRuV9E6rz/ReSESPxTROQBcaWnTaFRVVtsCWwBVkZ+7gcsw9WzaQB8iDuzbYqrcNkNV/TsKeClyDbXAydEfm+DK4/QHDgZWAC0A5oBXwG9gJ7Al0Ap0AqYgbu0HuANoFvk992BNyO/Pww8HYlpe1yZZXAfQBOAhsDmwFLgaKAR8AHQIfK4Y4HRkd/fBm6L/N4PeD3y+8nASI+/T2NgIdAucvsV4JDI762AksjvBwDPxOxvPtA2crsL8FXk91KgaeT3bsCkmL//GmCryHOaABwduW820B7YDngRaBRZfy/wf2G/hmzJ/GJF2kw2TVTV+QAiMgWXsFYCs1R1emT9Y8AZkccfiCuMFW2nbwqURX6foKqLI9v8B/chAvCsqq6KrH8h8rMFsBfwdORLBkCTmLieU9Vq4BsR2TSy7o/AWFWtAn4UkTcj67sDO+LKUYBLogti9hUtWDY58vwSUtV1kTiPFpFncM1Cr0Xubg08IiLdcFU/G8VsOkFVl8TZZSNgpIjsClQB28bcN1FVZwKIyFjc3yy2b2B/3IfnJ5Hn1gz3oWQKjCV+k01rY36vYuPrz6tuiABHqep3NVaK7B5nG408Pt6+GgBLVXVXH3HFllqOty8BvlbVPZPsK/b5JTMWuCKy7+dVdX1k/bXAW6p6hLi692/HbPObx74uBH4GdsE97zUx98X7m8US4BFVLcgZ08xG1sZvwvYt0FVEto7cPi7mvleB82L6AnrE3NdXRNqKSDNc5+j7wP+AI0SkmYi0BA4FUFcrfpaIHBPZj4jILkni+h/wN3FzrG4G9Ims/w7oICJ7RvbVSER2SLKvFbiidV7ewjXLnIP7EIhqjav6Ca55x4/WwILIN5gTcd9IonqLSNdI2/6xwHu1tn0D982jI0Dk71vu87gmj1jiN6FS1TW4pp3/Rjp358TcfS2u6eKLSOfltTH3vQeMAabg2r4nqZsO8MnoOuDdmMcPAE4Tkc+Br0k+ReKzwHRcn8F9wDuReNfh2vpviuxrCq4ZKZG3gO09OneJJOlncH0W/4u562bgBhF5n5oJPJF7gZNE5CNcM0/sN4MPgRtxfSKzIs8xNo5vcN88XhORL3D9AJv5PK7JI1ad0+QdETkZN6/BuWHHYkw+sjN+Y4wpMnbGb4wxRcbO+I0xpshY4jfGmCJjid8YY4qMJX5jjCkylviNMabI/D9apafwq0onkgAAAABJRU5ErkJggg=="></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Exponential">Exponential<a class="anchor-link" href="#Exponential">&#182;</a></h3></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>An exponential function with base c is defined by $$ Y = a + b c^X$$ where b 0, c &gt; 0 , c 1, and x is any real number. The base, c, is constant and the exponent, x, is a variable.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[6]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span><span class="c1">##You can adjust the slope and intercept to verify the changes in the graph</span><span class="n">Y</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Indepdendent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Logarithmic">Logarithmic<a class="anchor-link" href="#Logarithmic">&#182;</a></h3><p>The response $y$ is a results of applying logarithmic map from input $x$'s to output variable $y$. It is one of the simplest form of <strong>log()</strong>: i.e. $$ y = \log(x)$$</p><p>Please consider that instead of $x$, we can use $X$, which can be polynomial representation of the $x$'s. In general form it would be written as<br>\begin{equation}y = \log(X)\end{equation}</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[7]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span><span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Indepdendent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stderr output_text"><pre>/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in log  This is separate from the ipykernel package so we can avoid doing imports until</pre></div></div><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Sigmoidal/Logistic">Sigmoidal/Logistic<a class="anchor-link" href="#Sigmoidal/Logistic">&#182;</a></h3></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html">$$ Y = a + \frac{b}{1+ c^{(X-d)}}$$</div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[8]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span>    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>    <span class="n">Y</span> <span class="o">=</span> <span class="mi">5</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">X</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Indepdendent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><a id="ref2"></a></p><h1 id="Non-Linear-Regression-example">Non-Linear Regression example<a class="anchor-link" href="#Non-Linear-Regression-example">&#182;</a></h1></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>For an example, we're going to try and fit a non-linear model to the datapoints corresponding to China's GDP from 1960 to 2014. We download a dataset with two columns, the first, a year between 1960 and 2014, the second, China's corresponding annual gross domestic income in US dollars for that year.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[9]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span><span class="c1">#downloading dataset</span><span class="o">!</span>wget -nv -O china_gdp.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/china_gdp.csv    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;china_gdp.csv&quot;</span><span class="p">)</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>2020-01-14 14:56:32 URL:https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/china_gdp.csv [1218/1218] -&gt; &#34;china_gdp.csv&#34; [1]</pre></div></div><div class="output_area">    <div class="prompt output_prompt">Out[9]:</div><div class="output_html rendered_html output_subarea output_execute_result"><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Year</th>      <th>Value</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1960</td>      <td>5.918412e+10</td>    </tr>    <tr>      <th>1</th>      <td>1961</td>      <td>4.955705e+10</td>    </tr>    <tr>      <th>2</th>      <td>1962</td>      <td>4.668518e+10</td>    </tr>    <tr>      <th>3</th>      <td>1963</td>      <td>5.009730e+10</td>    </tr>    <tr>      <th>4</th>      <td>1964</td>      <td>5.906225e+10</td>    </tr>    <tr>      <th>5</th>      <td>1965</td>      <td>6.970915e+10</td>    </tr>    <tr>      <th>6</th>      <td>1966</td>      <td>7.587943e+10</td>    </tr>    <tr>      <th>7</th>      <td>1967</td>      <td>7.205703e+10</td>    </tr>    <tr>      <th>8</th>      <td>1968</td>      <td>6.999350e+10</td>    </tr>    <tr>      <th>9</th>      <td>1969</td>      <td>7.871882e+10</td>    </tr>  </tbody></table></div></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><strong>Did you know?</strong> When it comes to Machine Learning, you will likely be working with large datasets. As a business, where can you host your data? IBM is offering a unique opportunity for businesses, with 10 Tb of IBM Cloud Object Storage: <span class="exturl" data-url="aHR0cDovL2NvY2wudXMvTUwwMTAxRU4tSUJNLU9mZmVyLUND">Sign up now for free<i class="fa fa-external-link-alt"></i></span></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Plotting-the-Dataset">Plotting the Dataset<a class="anchor-link" href="#Plotting-the-Dataset">&#182;</a></h3><p>This is what the datapoints look like. It kind of looks like an either logistic or exponential function. The growth starts off slow, then from 2005 on forward, the growth is very significant. And finally, it decelerate slightly in the 2010s.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[10]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Year&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Value&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;GDP&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Year&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Choosing-a-model">Choosing a model<a class="anchor-link" href="#Choosing-a-model">&#182;</a></h3><p>From an initial look at the plot, we determine that the logistic function could be a good approximation,since it has the property of starting with a slow growth, increasing growth in the middle, and then decreasing again at the end; as illustrated below:</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[11]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span><span class="n">Y</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">X</span><span class="p">))</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dependent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Indepdendent Variable&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>The formula for the logistic function is the following:</p>$$ \hat{Y} = \frac1{1+e^{\beta_1(X-\beta_2)}}$$<p>$\beta_1$: Controls the curve's steepness,</p><p>$\beta_2$: Slides the curve on the x-axis.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Building-The-Model">Building The Model<a class="anchor-link" href="#Building-The-Model">&#182;</a></h3><p>Now, let's build our regression model and initialize its parameters.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[12]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Beta_1</span><span class="p">,</span> <span class="n">Beta_2</span><span class="p">):</span>     <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">Beta_1</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">Beta_2</span><span class="p">)))</span>     <span class="k">return</span> <span class="n">y</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Lets look at a sample sigmoid line that might fit with the data:</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[13]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">beta_1</span> <span class="o">=</span> <span class="mf">0.10</span><span class="n">beta_2</span> <span class="o">=</span> <span class="mf">1990.0</span><span class="c1">#logistic function</span><span class="n">Y_pred</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">beta_1</span> <span class="p">,</span> <span class="n">beta_2</span><span class="p">)</span><span class="c1">#plot initial prediction against datapoints</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">Y_pred</span><span class="o">*</span><span class="mf">15000000000000.</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[13]:</div><div class="output_text output_subarea output_execute_result"><pre>[&lt;matplotlib.lines.Line2D at 0x7f51a17930b8&gt;]</pre></div></div><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Our task here is to find the best parameters for our model. Lets first normalize our x and y:</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Lets normalize our data</span><span class="n">xdata</span> <span class="o">=</span><span class="n">x_data</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span><span class="n">ydata</span> <span class="o">=</span><span class="n">y_data</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="n">y_data</span><span class="p">)</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h4 id="How-we-find-the-best-parameters-for-our-fit-line?">How we find the best parameters for our fit line?<a class="anchor-link" href="#How-we-find-the-best-parameters-for-our-fit-line?">&#182;</a></h4><p>we can use <strong>curve_fit</strong> which uses non-linear least squares to fit our sigmoid function, to data. Optimal values for the parameters so that the sum of the squared residuals of sigmoid(xdata, *popt) - ydata is minimized.</p><p>popt are our optimized parameters.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">curve_fit</span><span class="n">popt</span><span class="p">,</span> <span class="n">pcov</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">,</span> <span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">)</span><span class="c1">#print the final parameters</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot; beta_1 = </span><span class="si">%f</span><span class="s2">, beta_2 = </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">popt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">popt</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Now we plot our resulting regression model.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1960</span><span class="p">,</span> <span class="mi">2015</span><span class="p">,</span> <span class="mi">55</span><span class="p">)</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span><span class="n">y</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">popt</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;GDP&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Year&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Practice">Practice<a class="anchor-link" href="#Practice">&#182;</a></h2><p>Can you calculate what is the accuracy of our model?</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># write your code here</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Double-click <strong>here</strong> for the solution.</p><!-- Your answer is below:# split data into train/testmsk = np.random.rand(len(df)) < 0.8train_x = xdata[msk]test_x = xdata[~msk]train_y = ydata[msk]test_y = ydata[~msk]# build the model using train setpopt, pcov = curve_fit(sigmoid, train_x, train_y)# predict using test sety_hat = sigmoid(test_x, *popt)# evaluationprint("Mean absolute error: %.2f" % np.mean(np.absolute(y_hat - test_y)))print("Residual sum of squares (MSE): %.2f" % np.mean((y_hat - test_y) ** 2))from sklearn.metrics import r2_scoreprint("R2-score: %.2f" % r2_score(y_hat , test_y) )--></div></div></div>    </div>  </div></body>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;
&lt;b&gt;Non Linear Regression Full Implementation with the dataset EDA and Other Techniques.
&lt;br&gt;You will use use the most basic and the Non Linear model to predict results.
&lt;/a&gt; &lt;/b&gt;
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Non Linear Regression" scheme="https://massivefile.com/tags/Non-Linear-Regression/"/>
    
  </entry>
  
  <entry>
    <title>Multiple Linear regression Implementation</title>
    <link href="https://massivefile.com/multiple_linear_regression/"/>
    <id>https://massivefile.com/multiple_linear_regression/</id>
    <published>2020-05-04T00:56:53.000Z</published>
    <updated>2020-05-05T23:21:25.514Z</updated>
    
    <content type="html"><![CDATA[<body><b>Note - Multiple Linear Regression Full Implementation with the dataset EDA and Other Techniques.  You will use use the most basic and the Multiple Linear model to predict the car consumption fuel results.Please Download the FuelConsumption.Csv dataset from <a href= "https://www.kaggle.com/anderas/car-consume" target="_blank">Kaggle</a> </b><a id="more"></a> <div tabindex="-1" id="notebook" class="border-box-sizing">    <div class="container" id="notebook-container"><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1><center>Multiple Linear Regression</center></h1><p><h4>About this Notebook</h4>In this notebook, we learn how to use scikit-learn to implement Multiple linear regression. We download a dataset that is related to fuel consumption and Carbon dioxide emission of cars. Then, we split our data into training and test sets, create a model using training set, Evaluate your model using test set, and finally use model to predict unknown value</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1>Table of contents</h1><p><div class="alert alert-block alert-info" style="margin-top: 20px">    <ol>        <li><a href="#understanding-data">Understanding the Data</a></li>        <li><a href="#reading_data">Reading the Data in</a></li>        <li><a href="#multiple_regression_model">Multiple Regression Model</a></li>        <li><a href="#prediction">Prediction</a></li>        <li><a href="#practice">Practice</a></li>    </ol></div><br></p><hr></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Importing-Needed-packages">Importing Needed packages<a class="anchor-link" href="#Importing-Needed-packages">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[43]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span><span class="kn">import</span> <span class="nn">pylab</span> <span class="k">as</span> <span class="nn">pl</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="o">%</span><span class="k">matplotlib</span> inline</pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Downloading-Data">Downloading Data<a class="anchor-link" href="#Downloading-Data">&#182;</a></h3><p>You will use use the most basic and the Multiple from start to end Linear model to predict the car consumption fuel results. Please Download the FuelConsumption.Csv dataset from <a href= "https://www.kaggle.com/anderas/car-consume" target="_blank">Kaggle</a></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="understanding_data">Understanding the Data</h2><h3 id="FuelConsumption.csv:"><code>FuelConsumption.csv</code>:<a class="anchor-link" href="#FuelConsumption.csv:">&#182;</a></h3><p>We have downloaded a fuel consumption dataset, <strong><code>FuelConsumption.csv</code></strong>, which contains model-specific fuel consumption ratings and estimated carbon dioxide emissions for new light-duty vehicles for retail sale in Canada. <span class="exturl" data-url="aHR0cDovL29wZW4uY2FuYWRhLmNhL2RhdGEvZW4vZGF0YXNldC85OGYxYTEyOS1mNjI4LTRjZTQtYjI0ZC02ZjE2YmYyNGRkNjQ=">Dataset source<i class="fa fa-external-link-alt"></i></span></p><ul><li><strong>MODELYEAR</strong> e.g. 2014</li><li><strong>MAKE</strong> e.g. Acura</li><li><strong>MODEL</strong> e.g. ILX</li><li><strong>VEHICLE CLASS</strong> e.g. SUV</li><li><strong>ENGINE SIZE</strong> e.g. 4.7</li><li><strong>CYLINDERS</strong> e.g 6</li><li><strong>TRANSMISSION</strong> e.g. A6</li><li><strong>FUELTYPE</strong> e.g. z</li><li><strong>FUEL CONSUMPTION in CITY(L/100 km)</strong> e.g. 9.9</li><li><strong>FUEL CONSUMPTION in HWY (L/100 km)</strong> e.g. 8.9</li><li><strong>FUEL CONSUMPTION COMB (L/100 km)</strong> e.g. 9.2</li><li><strong>CO2 EMISSIONS (g/km)</strong> e.g. 182   --&gt; low --&gt; 0</li></ul></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="reading_data">Reading the data in</h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[44]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;FuelConsumption.csv&quot;</span><span class="p">)</span><span class="c1"># take a look at the dataset</span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1067 entries, 0 to 1066Data columns (total 13 columns): #   Column                    Non-Null Count  Dtype  ---  ------                    --------------  -----   0   MODELYEAR                 1067 non-null   int64   1   MAKE                      1067 non-null   object  2   MODEL                     1067 non-null   object  3   VEHICLECLASS              1067 non-null   object  4   ENGINESIZE                1067 non-null   float64 5   CYLINDERS                 1067 non-null   int64   6   TRANSMISSION              1067 non-null   object  7   FUELTYPE                  1067 non-null   object  8   FUELCONSUMPTION_CITY      1067 non-null   float64 9   FUELCONSUMPTION_HWY       1067 non-null   float64 10  FUELCONSUMPTION_COMB      1067 non-null   float64 11  FUELCONSUMPTION_COMB_MPG  1067 non-null   int64   12  CO2EMISSIONS              1067 non-null   int64  dtypes: float64(4), int64(4), object(5)memory usage: 108.5+ KB</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[47]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[47]:</div><div class="output_html rendered_html output_subarea output_execute_result"><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>MODELYEAR</th>      <th>MAKE</th>      <th>MODEL</th>      <th>VEHICLECLASS</th>      <th>ENGINESIZE</th>      <th>CYLINDERS</th>      <th>TRANSMISSION</th>      <th>FUELTYPE</th>      <th>FUELCONSUMPTION_CITY</th>      <th>FUELCONSUMPTION_HWY</th>      <th>FUELCONSUMPTION_COMB</th>      <th>FUELCONSUMPTION_COMB_MPG</th>      <th>CO2EMISSIONS</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>2014</td>      <td>ACURA</td>      <td>ILX</td>      <td>COMPACT</td>      <td>2.0</td>      <td>4</td>      <td>AS5</td>      <td>Z</td>      <td>9.9</td>      <td>6.7</td>      <td>8.5</td>      <td>33</td>      <td>196</td>    </tr>    <tr>      <th>1</th>      <td>2014</td>      <td>ACURA</td>      <td>ILX</td>      <td>COMPACT</td>      <td>2.4</td>      <td>4</td>      <td>M6</td>      <td>Z</td>      <td>11.2</td>      <td>7.7</td>      <td>9.6</td>      <td>29</td>      <td>221</td>    </tr>    <tr>      <th>2</th>      <td>2014</td>      <td>ACURA</td>      <td>ILX HYBRID</td>      <td>COMPACT</td>      <td>1.5</td>      <td>4</td>      <td>AV7</td>      <td>Z</td>      <td>6.0</td>      <td>5.8</td>      <td>5.9</td>      <td>48</td>      <td>136</td>    </tr>    <tr>      <th>3</th>      <td>2014</td>      <td>ACURA</td>      <td>MDX 4WD</td>      <td>SUV - SMALL</td>      <td>3.5</td>      <td>6</td>      <td>AS6</td>      <td>Z</td>      <td>12.7</td>      <td>9.1</td>      <td>11.1</td>      <td>25</td>      <td>255</td>    </tr>    <tr>      <th>4</th>      <td>2014</td>      <td>ACURA</td>      <td>RDX AWD</td>      <td>SUV - SMALL</td>      <td>3.5</td>      <td>6</td>      <td>AS6</td>      <td>Z</td>      <td>12.1</td>      <td>8.7</td>      <td>10.6</td>      <td>27</td>      <td>244</td>    </tr>  </tbody></table></div></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Lets-select-some-features-that-we-want-to-use-for-regression.">Lets select some features that we want to use for regression.<a class="anchor-link" href="#Lets-select-some-features-that-we-want-to-use-for-regression.">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[48]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">cdf</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;ENGINESIZE&#39;</span><span class="p">,</span><span class="s1">&#39;CYLINDERS&#39;</span><span class="p">,</span><span class="s1">&#39;FUELCONSUMPTION_CITY&#39;</span><span class="p">,</span><span class="s1">&#39;FUELCONSUMPTION_HWY&#39;</span><span class="p">,</span><span class="s1">&#39;FUELCONSUMPTION_COMB&#39;</span><span class="p">,</span><span class="s1">&#39;CO2EMISSIONS&#39;</span><span class="p">]]</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Lets-plot-Emission-values-with-respect-to-Engine-size:">Lets plot Emission values with respect to Engine size:<a class="anchor-link" href="#Lets-plot-Emission-values-with-respect-to-Engine-size:">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[60]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#plt.scatter(cdf.iloc[:,0:1], cdf.iloc[:, 5:6], color = &#39;blue&#39;)</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cdf</span><span class="o">.</span><span class="n">ENGINESIZE</span><span class="p">,</span> <span class="n">cdf</span><span class="o">.</span><span class="n">CO2EMISSIONS</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Engine size&quot;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Emission&quot;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h4 id="Creating-train-and-test-dataset">Creating train and test dataset<a class="anchor-link" href="#Creating-train-and-test-dataset">&#182;</a></h4><p>Train/Test Split involves splitting the dataset into training and testing sets respectively, which are mutually exclusive. After which, you train with the training set and test with the testing set. This will provide a more accurate evaluation on out-of-sample accuracy because the testing dataset is not part of the dataset that have been used to train the data. It is more realistic for real world problems.</p><p>This means that we know the outcome of each data point in this dataset, making it great to test with! And since this data has not been used to train the model, the model has no knowledge of the outcome of these data points. So, in essence, its truly an out-of-sample testing.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[18]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">random</span><span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:</span> <span class="p">,</span> <span class="p">[</span><span class="s1">&#39;ENGINESIZE&#39;</span><span class="p">,</span><span class="s1">&#39;CYLINDERS&#39;</span><span class="p">,</span><span class="s1">&#39;FUELCONSUMPTION_COMB&#39;</span><span class="p">]]</span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;CO2EMISSIONS&#39;</span><span class="p">]]</span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Independent Variables x shape:&#39;</span> <span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="p">,</span> <span class="s1">&#39;Dependent Variables y shape:&#39;</span> <span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="c1">#TO USE THIS METHID FIRST SPLIT TO TRAIN AND TEST FIRST AND THEN SPLIT TO X AND Y</span><span class="c1">#random.seed(2) #SAME NUMBER SO THAT ALL PEOPLE CAN GET THE SAME RESULTS</span><span class="c1">#msk = np.random.rand(len(df)) &lt; 0.8</span><span class="c1">#train = cdf[msk]</span><span class="c1">#test = cdf[~msk]</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span> <span class="p">,</span> <span class="n">y</span> <span class="p">,</span> <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span><span class="nb">print</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span> <span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="p">,</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span> <span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span> <span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>Independent Variables x shape: (1067, 3)  Dependent Variables y shape: (1067, 1)(853, 3)  (214, 3)  (853, 1)  (214, 1)</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h4 id="Train-data-distribution">Train data distribution<a class="anchor-link" href="#Train-data-distribution">&#182;</a></h4></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[64]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ENGINESIZE</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">CO2EMISSIONS</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Engine size&quot;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Emission&quot;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span><span class="c1">#here we can visualize that there is some linear co-realtion that is why we thought of using linear regression</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="multiple_regression_model">Multiple Regression Model</h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>In reality, there are multiple variables that predict the Co2emission. When more than one independent variable is present, the process is called multiple linear regression. For example, predicting co2emission using FUELCONSUMPTION_COMB, EngineSize and Cylinders of cars. The good thing here is that Multiple linear regression is the extension of simple linear regression model.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[20]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="n">regr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="n">regr</span><span class="o">.</span><span class="n">fit</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="c1"># The coefficients</span><span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Coefficients: &#39;</span><span class="p">,</span> <span class="n">regr</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Intercepts:&#39;</span><span class="p">,</span> <span class="n">regr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>Coefficients:  [[10.46518783  7.80348963  9.41989717]]Intercepts: [66.59282561]</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>As mentioned before, <strong>Coefficient</strong> and <strong>Intercept</strong> , are the parameters of the fit line. Given that it is a multiple linear regression, with 3 parameters, and knowing that the parameters are the intercept and coefficients of hyperplane, sklearn can estimate them from our data. Scikit-learn uses plain Ordinary Least Squares method to solve this problem.</p><h4 id="Ordinary-Least-Squares-(OLS)">Ordinary Least Squares (OLS)<a class="anchor-link" href="#Ordinary-Least-Squares-(OLS)">&#182;</a></h4><p>OLS is a method for estimating the unknown parameters in a linear regression model. OLS chooses the parameters of a linear function of a set of explanatory variables by minimizing the sum of the squares of the differences between the target dependent variable and those predicted by the linear function. In other words, it tries to minimizes the sum of squared errors (SSE) or mean squared error (MSE) between the target variable (y) and our predicted output ($\hat{y}$) over all samples in the dataset.</p><p>OLS can find the best parameters using of the following methods:</p><pre><code>- Solving the model parameters analytically using closed-form equations- Using an optimization algorithm (Gradient Descent, Stochastic Gradient Descent, Newtons Method, etc.)</code></pre></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="prediction">Prediction</h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[37]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">math</span><span class="n">y_hat</span><span class="o">=</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="nb">print</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)))</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>1.235646895151453</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><h2 id="practice">Practice</h2>Try to use a multiple linear regression with the same dataset but this time use <strong>FUEL CONSUMPTION in CITY</strong> and <strong>FUEL CONSUMPTION in HWY</strong> instead of FUELCONSUMPTION_COMB. Does it result in better accuracy?</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Evaluation">Evaluation<a class="anchor-link" href="#Evaluation">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[42]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#we can directly initialize classes like this too</span><span class="n">mse</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span> <span class="n">rmse</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Root Mean Squared Error :&#39;</span><span class="p">,</span><span class="n">rmse</span><span class="p">)</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span><span class="c1">#import statsmodels.api as sm</span><span class="c1">print('r2_score is :', r2_score(y_hat,y_test))</span><span class="c1">#x2 = sm.add_constant(x)</span><span class="c1">#est = sm.OLS(y, x2)</span><span class="c1">#est2 = est.fit()</span><span class="c1">#print(est2.summary())</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>Root Mean Squared Error : 23.09064357449966</pre><pre>r2_score is : 0.8299022074881567</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><br><br><b> Due to some reason i can not run this, Please run the above cell. This will give us the p-value and the r2 score too. We can elinimate the values with the p-value below 0.05 and consider the features which have the p-value more than 0.05 which is our significance level.We should run this test till we have all the features with p-value less than 0.05 eliminated.</b></p><p><h2> More on topic</h2><br>Please find Context <a href="https://massivefile.com/Theory_hypothesis/" target="_blank"> Null Hypothesis </a><br>Please find Context <a href="https://massivefile.com/Theory_RSquared/" target="_blank"> R Squared </a></div></div></div>    </div>  </div></body>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;
&lt;b&gt;Note - Multiple Linear Regression Full Implementation with the dataset EDA and Other Techniques.
  You will use use the most basic and the Multiple Linear model to predict the car consumption fuel results.
Please Download the FuelConsumption.Csv dataset from &lt;a href= &quot;https://www.kaggle.com/anderas/car-consume&quot; target=&quot;_blank&quot;&gt;Kaggle&lt;/a&gt; &lt;/b&gt;
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Multiple Linear Regression" scheme="https://massivefile.com/tags/Multiple-Linear-Regression/"/>
    
  </entry>
  
  <entry>
    <title>Polynomial Regression Implementation</title>
    <link href="https://massivefile.com/PolynomialRegression/"/>
    <id>https://massivefile.com/PolynomialRegression/</id>
    <published>2020-05-04T00:56:53.000Z</published>
    <updated>2020-05-05T23:22:09.240Z</updated>
    
    <content type="html"><![CDATA[<body><b>Polynomial Regression Full Implementation.<br>You will use use the most basic and the Polynomial model to predict results.</a> </b><a id="more"></a>  <div tabindex="-1" id="notebook" class="border-box-sizing">    <div class="container" id="notebook-container"><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1><center>Polynomial Regression</center></h1><p><h4>About this Notebook</h4>In this notebook, we learn how to use scikit-learn for Polynomial regression. We download a dataset that is related to fuel consumption and Carbon dioxide emission of cars. Then, we split our data into training and test sets, create a model using training set, evaluate our model using test set, and finally use model to predict unknown value.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1>Table of contents</h1><p><div class="alert alert-block alert-info" style="margin-top: 20px">    <ol>        <li><a href="#download_data">Downloading Data</a></li>        <li><a href="#polynomial_regression">Polynomial regression</a></li>        <li><a href="#evaluation">Evaluation</a></li>        <li><a href="#practice">Practice</a></li>    </ol></div><br></p><hr></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Importing-Needed-packages">Importing Needed packages<a class="anchor-link" href="#Importing-Needed-packages">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[2]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span><span class="kn">import</span> <span class="nn">pylab</span> <span class="k">as</span> <span class="nn">pl</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="o">%</span><span class="k">matplotlib</span> inline</pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Creating-the-data">Creating the data<a class="anchor-link" href="#Creating-the-data">&#182;</a></h2><p>Sometimes, the trend of data is not really linear, and looks curvy. In this case we can use Polynomial regression methods. In fact, many different regressions exist that can be used to fit whatever the dataset looks like, such as quadratic, cubic, and so on, and it can go on and on to infinite degrees.</p><p>In essence, we can call all of these, polynomial regression, where the relationship between theindependent variablexand thedependent variableyis modeled as annth degreepolynomialinx. Lets say you want to have a polynomial regression (let's make 2 degree polynomial):</p><p>$y = b + \theta_1  x + \theta_2 x^2$</p><p>Now, the question is: how we can fit our data on this equation while we have only x values, such as <strong>Engine Size</strong>? Well, we can create a few additional features: 1, $x$, and $x^2$.</p><p><strong>PloynomialFeatures()</strong> function in Scikit-learn library, drives a new feature sets from the original feature set. That is, a matrix will be generated consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, lets say the original feature set has only one feature, <em>ENGINESIZE</em>. Now, if we select the degree of the polynomial to be 2, then it generates 3 features, degree=0, degree=1 and degree=2:</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[170]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span><span class="n">y</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#-1 in the x value will retain the x shape and will change the y shape only</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="c1"># plotting dataset</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predictor&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Target&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>(200, 1)  (200, 1)</pre></div></div><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAnYAAAFCCAYAAAB8V5DfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df5yddX3n/ddnJjACSSDWwQaSGPY2tk0opckEKXVbXHVJ1S3UNVu6aWG33nBjaNf+cLtiH5Za667dsq21D2Nuqa6wTYtorWIrKCLeagOaGZYKCSCphBBIYXQDmQBOyMzn/uO6znBmcmbmTDIzZ+Y6r+fjMY851/e6rnO+c5Ew73x/RmYiSZKk+a+j1RWQJEnS9DDYSZIkVYTBTpIkqSIMdpIkSRVhsJMkSaoIg50kSVJFLGh1BeaCl73sZbly5cpWV0OSJGlSfX1938vM7kbnDHbAypUr6e3tbXU1JEmSJhURj453zq5YSZKkijDYSZIkVYTBTpIkqSIMdpIkSRVhsJMkSaoIg50kSVJFGOwkSZIqwmAnSZJUES5QPMP6BwbZvK2PXfsPsnrpYrZsWkf3oq5WV0uSJFWQLXYzbPO2Pu7Ze4BnB4e4Z+8BNm/ra3WVJElSRRnsZtiu/QcZGi5eDw0Xx5IkSTPBYDfDVi9dTGf5lDs7imNJkqSZYLCbYVs2rWPtiiWc0tXJ2hVL2LJpXaurJEmSKsrJEzOse1EXn7rqglZXQ5IktQFb7CRJkirCYCdJklQRBjtJkqSKMNhJkiRVhMFOkiSpIgx2kiRJFWGwkyRJqgiDnSRJUkUY7CRJkirCYCdJklQRBjtJkqSKmNVgFxEfj4inIuL+urKXRsTtEfFw+X1J3blrImJ3RDwUERfVla+LiPvKcx+KiCjLuyLik2X5NyNi5Wz+fJIkSa002y12nwA2jCl7F3BHZq4C7iiPiYjVwKXAmvKeLRHRWd7zEeBKYFX5VXvPtwEHMvOVwJ8CfzRjP4kkSdIcM6vBLjO/BvyfMcUXAzeUr28ALqkrvykzBzPzEWA3cF5ELAUWZ+ZdmZnAjWPuqb3Xp4HX1VrzJEmSqm4ujLF7eWbuByi/n16Wnwk8VnfdvrLszPL12PJR92TmEeAZ4IcafWhEXBkRvRHR29/fP00/iiRJUuvMhWA3nkYtbTlB+UT3HF2Y+dHM7MnMnu7u7mOsoiRJ0twxF4Ldk2X3KuX3p8ryfcDyuuuWAU+U5csalI+6JyIWAKdydNevJElSJc2FYHcLcHn5+nLgc3Xll5YzXc+imCTxrbK7diAizi/Hz1025p7ae70V+Eo5Dk+SJKnyFszmh0XEXwMXAi+LiH3AtcAHgJsj4m3AXmAjQGbujIibgV3AEeDqzBwq3+rtFDNsTwJuLb8APgb8r4jYTdFSd+ks/FiSJElzQtigBT09Pdnb29vqakiSJE0qIvoys6fRubnQFStJkqRpYLCTJEmqCIOdJElSRRjsJEmSKsJgJ0mSVBEGO0mSpIow2EmSJFWEwU6SJKkiDHaSJEkVYbCTJEmqCIOdJElSRRjsJEmSKsJgJ0mSVBEGO0mSpIow2EmSJFWEwU6SJKkiDHaSJEkVYbCTJEmqCIOdJElSRRjsJEmSKsJgJ0mSVBEGO0mSpIow2EmSJFWEwU6SJKkiDHaSJEkVYbCTJEmqCIOdJElSRRjsJEmSKsJgJ0mSVBEGO0mSpIow2EmSJFWEwU6SJKkiDHaSJEkVsaDVFZAkSZrv+gcG2bytj137D7J66WK2bFpH96KuWa+HLXaSJEnHafO2Pu7Ze4BnB4e4Z+8BNm/ra0k95kywi4jfjIidEXF/RPx1RLwkIl4aEbdHxMPl9yV1118TEbsj4qGIuKiufF1E3Fee+1BERGt+IkmS1C527T/I0HDxemi4OG6FORHsIuJM4D8BPZl5NtAJXAq8C7gjM1cBd5THRMTq8vwaYAOwJSI6y7f7CHAlsKr82jCLP4okSWpDq5cuprNMVZ0dxXErzIlgV1oAnBQRC4CTgSeAi4EbyvM3AJeUry8GbsrMwcx8BNgNnBcRS4HFmXlXZiZwY909kiRJM2LLpnWsXbGEU7o6WbtiCVs2rWtJPebE5InMfDwirgP2As8DX8rML0XEyzNzf3nN/og4vbzlTODuurfYV5a9UL4eWy5JkjRjuhd18amrLmh1NeZGi105du5i4CzgDOCUiPjliW5pUJYTlDf6zCsjojcievv7+6daZUmSpDlnTgQ74PXAI5nZn5kvAJ8BLgCeLLtXKb8/VV6/D1hed/8yiq7bfeXrseVHycyPZmZPZvZ0d3dP6w8jSZLUCnMl2O0Fzo+Ik8tZrK8DHgBuAS4vr7kc+Fz5+hbg0ojoioizKCZJfKvsth2IiPPL97ms7h5Non9gkI1bt7Pm2tvYuHU7/QODra6SJEmagjkR7DLzm8CngXuA+yjq9VHgA8AbIuJh4A3lMZm5E7gZ2AXcBlydmUPl270d+AuKCRX/BNw6ez/J/DZX1uCRJEnHZk5MngDIzGuBa8cUD1K03jW6/v3A+xuU9wJnT3sF28BcWYNHkiQdmznRYqe5Ya6swSNJko6NwU4j5soaPJIk6djMma5Ytd5cWYNHkiQdG1vsJEmSKsJgJ0mSVBEGO0mSpIow2EmSJFWEwU6SJKkinBWrcfUPDLJ5Wx+79h9k9dLFbNm0ju5FXa2uliRJGoctdhqXW4xJkjS/GOw0LrcYkyRpfjHYaVxuMSZJ0vxisNO43GJMkqT5xckTGpdbjEmS2kGVJgvaYidJktpalSYLGuwkSVJbq9JkQYOdJElqa6uXLqYjXjwOgv6BwdZV6DgY7CRJUlvbsmkdJ5/44rSD5w8fmbfdsQY7SZLU1roXdZHkyPFQzt/uWIOdJElqe1VZu9VgJ0mS2l5V1m51HTtJktT2qrJ2qy12kiRJFWGwkyRJqgiDnSRJUkUY7CRJkirCYCdJklQRBjtJkqSKMNhJkiRVhMFOkiSpIgx2kiRJFdFUsIuI34mIHx7n3Msj4nemt1qSJEmaqmZb7P4bsGKcc8vK85IkSWqhZoNdTHDuVODwNNRFkiRJx2HBeCci4jXAz9QV/YeIeP2Yy04CLgYemIG6SZIkaQrGDXbA64Bry9cJXNXgmgQeAn5tmuslSZKkKZqoK/YPKVrkTqboiv2Z8rj+a0Fmrs7Mrx1vRSLitIj4dEQ8GBEPRMRPRcRLI+L2iHi4/L6k7vprImJ3RDwUERfVla+LiPvKcx+KiIm6kSVJkipj3GCXmUOZOZiZPwBOysxvlMf1XzmNdfkz4LbM/FHgJyi6d98F3JGZq4A7ymMiYjVwKbAG2ABsiYjO8n0+AlwJrCq/NkxjHSVJkuaspiZPZOZgRLwkIq6MiL+MiFsj4pUAEfGWiFh1PJWIiMUULYIfKz/vcGY+TTF+74byshuAS8rXFwM3leHyEWA3cF5ELAUWZ+ZdZei8se4eSZKkSmt2HbszgHuBDwPrgX8NLC5PvxH4z8dZj38B9AP/MyL+d0T8RUScArw8M/cDlN9PL68/E3is7v59ZdmZ5eux5ZIkSZXX7HIn/6O89scouj/rx63dCfzscdZjAbAW+Ehm/iTwLGW36zgajZvLCcqPfoOi9bE3Inr7+/unWl9JkqQ5p9lgdxHwnszczdFB6XGOv1VsH7AvM79ZHn+aIug9WXavUn5/qu765XX3LwOeKMuXNSg/SmZ+NDN7MrOnu7v7OKsvSZLUes0Guy7g6XHOLQKGjqcSmfnPwGMR8SNl0euAXcAtwOVl2eXA58rXtwCXRkRXRJxFMUniW2V37UBEnF/Ohr2s7h5JkqRKm2gdu3r3U0xY+GKDcxcB90xDXX4d2BYRJwLfBf4jRfC8OSLeBuwFNgJk5s6IuJki/B0Brs7MWrh8O/AJiuVYbi2/JEmSKq/ZYPcnwF9FxBDwV2XZK8v1464A3nq8FcnMe4GeBqdeN8717wfe36C8Fzj7eOsjSZI03zQV7DLzk+UYtz8ENpfFNwHPA+/MzM/PUP0kSZLUpGZb7MjMD0bE/wT+JcWyI98HvpaZB2aqcpIkSWpe08EOIDOfAf5uhuoi0T8wyOZtfezaf5DVSxezZdM6uhd1tbpakiTNC00Fu4g4b4LTw8AzwD9l5vC01Epta/O2Pu7Ze4ChYbhn7wE2b+vjU1dd0OpqSZI0LzTbYnc34yz0W+eZiPjTzHzfcdZJbWzX/oMMlf88GBqGHXsOsHHrdlvuJElqQrPr2G2k2MLry8BVwC+U379CsSjw/wP8LXBtRLxjBuqpNrF66WI6x/yprLXcSZKkiTUb7N4A3JGZF2Xm9Zl5S/n9DcAdwKsz823A/wtcOVOVVfVt2bSOtSuWjCobGi5a8iRJ0sSm0mL3yXHO3QS8pXz9BeBfHG+l1L66F3XxqasuYP3KJSMtd50dRUueJEmaWLPB7kTgFeOcWwmcUL7+AXD4OOskjbTcndLVydoVS9iyaV2rqyRJ0pzX7OSJW4H/FhFPZObf1woj4s0Uuz/Utu36UeCR6a2i2lGt5U6SJDWv2WD368Dngc9HxA+AfqAb6AJ6y/NQtNj90XRXUpIkSZNrdkuxJ4HzIuLngVcDS4H9wN3124ll5sdmpJaSJEma1KTBLiJOBP4j8PXMvAW4ZcZrJTXBXSokSRpt0skTmXkY+CBF16vUcv0Dg2zcup1X/9cvs2PPAZ4dHHKtO0mSaH5W7EPAipmsiNSs2rZjw3V7objWnSRJzQe79wK/FxGvmsnKSM2o33asxrXuJElqflbsZmAhsDMiHqKYOFG/d2xm5kXTXTmpkdVLF3PP3gMj4a4jcK07SZJoPtgtAvaUX1CEPKkltmxa56QJSZIaaHa5k/NnuiJSs1y8WJKkxpodYydJkqQ5rtmuWAAi4hTg/wJeMvZcZn5ruiolSZKkqWsq2JWLFG8FfhnoHOey8colSZI0C5rtin038Cbg7UAAvw38GrAD+CfgLTNSO0mSJDWt2WD3i8AfAJ8oj7+WmR8pJ1XsAn5mBuomSZKkKWg22L0CuC8zh4AXgJPrzn0U+PfTXTFJkiRNTbOTJ77Pi2vX7QPOAb5RHp8GnDLN9ZKOS//AoGvdSZLaTrMtdjsowhzAZ4E/iIjfjIhfB/4Y2D4TlZOOVW0/2WcHh7hn7wE2b+trdZUkSZpxzbbY/XdgZfn6fcCPAtdRTKS4l2LLMWnOqN9Pdmi4OJYkqeqa3XnibuDu8vXTwJsiYiFwcmY+NYP1k45J/X6ynR3FsSRJVTduV2xEfDcifmK885l5yFCnuWrLpnWsXbGEU7o6WbtiCVs2rWt1lSRJmnETtditBBxtrnlpvP1knVQhSaoy94pVW3FShSSpyiYLdjkrtZBmiZMqJElVNtnkifdGxPeaeJ/MzMuno0LSTHJShSSpyiYLducCg028jy17mhe2bFp31Bg7SZKqYrJgd0lmfmtWagJERCfQCzyemW+OiJcCn6SYyLEH+HeZeaC89hrgbcAQ8J8y84tl+TqKPW1PAr4AvCMzDZ4Cxp9UIUlSFcy1yRPvAB6oO34XcEdmrgLuKI+JiNXApcAaYAOwpQyFAB8BrgRWlV8bZqfqkiRJrTVngl1ELAPeBPxFXfHFwA3l6xuAS+rKb8rMwcx8BNgNnBcRS4HFmXlX2Up3Y909kiRJlTZngh3wQeB3gOG6spdn5n6A8vvpZfmZwGN11+0ry84sX48tlyRJqrxxg11mdszW+LqIeDPwVGY2u6hYNCjLCcobfeaVEdEbEb39/f1NfqwkSdLcNVda7H4a+PmI2APcBPyriPhL4Mmye5Xye20Ls33A8rr7lwFPlOXLGpQfJTM/mpk9mdnT3d09nT+LJElSS8yJYJeZ12TmssxcSTEp4iuZ+cvALUBtfbzLgc+Vr28BLo2Irog4i2KSxLfK7tqBiDg/IgK4rO4eSZKkSptsuZNW+wBwc0S8DdgLbATIzJ0RcTOwCzgCXJ2ZQ+U9b+fF5U5uLb8kSZIqL1ziDXp6erK3t7fV1ZAkSZpURPRlZk+jc3OiK1aSJEnHz2AnSZJUEQY7SZKkijDYSZIkVYTBTpIkqSIMdpIkSRVhsJMkSaqIub5AsTQn9Q8MsnlbH7v2H2T10sVs2bSO7kVdra6WJKnN2WInHYPN2/q4Z+8Bnh0c4p69B9i8ra/VVZIkyWAnHYtd+w8yNFy8HhoujiVJajWDnXQMVi9dTGf5t6ezoziWJKnVHGMnHYMtm9YdNcYORo+9W3X6IiB5+KlDjsOTJM2KyMxW16Hlenp6sre3t9XV0DxWC3R9jx5guMFfqc4OWLtiCZ+66oLZr5wkqVIioi8zexqdsytWmga1yRSNQh0U4/B27DnAJR/+B/oHBme3cpKktmGwk6ZB/WSKidz72NPOoJUkzRiDnTQN6idTTMYZtJJmWv/AIBu3bmfNtbexcet2ewraiMFOmgZbNq1j7YolnHxiJwu7FnDyiR2sX7mEc5efetS1zqCVNNNca7N9OStWmgbdi7oaTozoHxjkiht38O19zwBwzrLTRmbQStJMca3N9mWwk2ZQ96IuPnv1a1pdDUltZtXpC7n3sWdGHas9GOykWeDespJmV0xyrKpyjJ00CxzvImk2PfzUwITHqi6DnTQLxo532bHngDPVJM0Ytz1sXwY7aRY0Wg7FljtJM6F/YJAXhpJM6Aj48TNPddJWGzHYSbOgthxKPWeqSZoJm7f1cd/jTzOcEAEndHY4preNGOykWVBbDmX9yiUNu0dcTFTSdHGpk/ZmsJNmUa3l7pSuTtauWDLSPeLkCknTxfF17c3lTqRZNN5Cxv4LW1KzJls+acumdUedV/sw2Ekt1j8wSNStMdUZ/gtb0vhqLfxDwy9Owqr/B+N4/4BUe7ArVmqxzdv6eO7wkZHjk05c4L+wJY3LFn5NxGAntdiu/QcZzhePk+LAyRSSGnEMnSZisJNarNH/pJ1MIWk8403CkgAiMye/quJ6enqyt7e31dVQm2o0EPrC6+7k2cGhkWtOPrGDNWec6l6zkiQioi8zexqeM9gZ7DT3bNy6fWRwdGcHnHTCAp5/4cjI8doVSxwcLUltaqJgZ1esNAeN7WoZznSwtCRpUrbYYYud5r76FryajoBzlp3K9Zett1tWktqILXbSPFXbamznE89w0gkL6HhxuTuGE+597BknVkiSRsyJYBcRyyPizoh4ICJ2RsQ7yvKXRsTtEfFw+X1J3T3XRMTuiHgoIi6qK18XEfeV5z4UEdHoM6X5oDY79rnDwzz/wpGG19gtK0mqmRPBDjgC/HZm/hhwPnB1RKwG3gXckZmrgDvKY8pzlwJrgA3AlojoLN/rI8CVwKrya8Ns/iDSdBq7EGkjrmElSaqZE1uKZeZ+YH/5eiAiHgDOBC4GLiwvuwH4KvBfyvKbMnMQeCQidgPnRcQeYHFm3gUQETcClwC3ztoPI02j1UsXj5od++NnngoE3973NFCMsXMNK2nua7SsETDhnq/SsZgTwa5eRKwEfhL4JvDyMvSRmfsj4vTysjOBu+tu21eWvVC+HlsuzUuNNvP2f/zS/LN5Wx99jx5gOGHHngO89rqv8srTF3Lf40+Pu+erdCzmVLCLiIXA3wC/kZkHJxge1+hETlDe6LOupOiyZcWKFVOvrDQL3MxbqoaxWwceGjzCt/c9PVLmMkaaLnNljB0RcQJFqNuWmZ8pi5+MiKXl+aXAU2X5PmB53e3LgCfK8mUNyo+SmR/NzJ7M7Onu7p6+H0SaQx7cf5Czr/0iK9/195x97Rd50F8cUkuMNxbWPV813eZEsCtnrn4MeCAz/6Tu1C3A5eXry4HP1ZVfGhFdEXEWxSSJb5XdtgMRcX75npfV3SO1lf6BQd74oa9zaLCYTXto8Ahv3XpXi2sltactm9axsOvFTrLOch1K93zVdJsrXbE/DfwKcF9E3FuWvRv4AHBzRLwN2AtsBMjMnRFxM7CLYkbt1ZlZ21jz7cAngJMoJk04cUJtafO2vlFdP8BIyJM0u7oXdXHnOy90zKxmnDtP4M4TqqY1197Gs4NDR5WvX7nEXyiSNI+584TUhlYvXUxng+lE9zx6wN0qJKmiDHZSRW3ZtI61r1gyahsygKGEvkcP8OD+g2zcup01197Gxq3b6R8YbE1FJUnTxq5Y7IpVtY3XJbuwawHPHz7CUL54fOc7L7SLVpLmuIm6YufK5AlJM2T10sXs2HPgqPKxEykODR7htdd9lSQd2C010Gj3CP+OaK6xK1aquLHLLEzk0OARnh0cYseeA1z4x3faPSvV2bytj3v2HuDZwaGRnSKkucZgJ1VcbZmFc5efOqX7nj085C8utb3+gcGRsah9jxb7NoM7RWjuMthJbaB7URefvfo1rF+5ZNRK9+cuP5X1K4sFUhvxF5faXX0rXf26kO4UobnKMXZSG9myad24Y4Qu+fA3uPexZ0Zd7y8utbtd+w+OtNIBdAScdGLnyN8faa4x2EltpHtRF5+66oKG5z7wlnP4tx/ZzrOHixm0AbwwlPQPDDpAXG1r9dLF3LO36ILt7IC1K5aM+3dImgvsipUEwLs+c99IqANI4L7Hn3acndralk3r3M9V84otdpIA+Pa+p48qc4C42snY5Uzed/HZvOdz97u8ieYVW+wkjcsB4mon9RMl+h49wBs/9HV27CmXN3ErPs0TBjtJAJyzbPRyKAF2Palt9A8MjlrOZDgZNQt2KG291vxgV6wkAK6/bL2r6qttXXHjjlFBrhFbrzUfGOwkARPPmAW3U1K1fXvfM0eVdQC1lU4Wdi2w9Vrzgl2xkpoyle2U6lfr37h1u1uTad7pCFhXLt69fuUS7nznhf5DRvOCLXaSmlK/UOtks2VrIXBomJEQ6NpfmkvGtkD/2NLF7HzixT/T5yw7zT+zmpdssZPUlNVLF4/ajmyi8UY7n3hmVAjc+cTR3VzSbBiv9XhsC/QJnR0j2+utX7mE6y/raXHNpWNjsJPUlKks1NoRo//X8tzhYbtkNWMm6vq/4sbekSVLduw5wBU39h41A3ZoGL7z5ACfuuoCdr53A5+66gK7XTVv2RUrqSmTTa6o6R8Y5LnDR44qb9Ql2+yEDCduaCITdf2PXXj72/uK3VTGzoDtiJit6kozyhY7SdOq0S9NaDwur9kJGVOZuKH2M3b8Z9+jByZsHW40PnQ4hxtcKc0/BjtJ02q8SRWNxuU1OyFjKhM31H7G/rkaTkbC/9iFt89ZdmrD8aFrzjj1qDJpPjLYSZpW9ZMsOqJY/2u8cXnNTsiYysQNtZ8tm9bRMaYntRb+r79s/ZhJEevZsmkd5y4/jY4o/oyeu/xU16hTZUTmJEttt4Genp7s7e1tdTWkSphsPFz9+VWnLwSCh58acIydjsvGrdtHxtl1dhTb4blciaoqIvoys+HUbYMdBjtpNvkLWDPB8K92MlGwc1aspFk10Xi5+l/OZ/3QKXz3e8/y3OEhOgK6FgRnn3mav7DbTKPABjQMcf4DQbLFDrDFTppNE7XYXfLhb3DvYxMvZhzAKV0LGM7kVS9fBCQPP3XIVpqKuuTD/8C9j724ZMm5y0/jhM6w1VdtbaIWOydPSJpVEy103Ggj9rESODR4hOcOD3HvY09z72PPuAxKhTVah85Z0tL47IqVNKtmqsvMX/Dz14P7D/LWrXdxaPAIC7sW8OmrfoofnWDm8+qli0e12DlLWnqRLXaS5oxzlp026ri2hMXYpSwa8Rf8/NBo+69aqIOiNfatW+8aub7ROnRT2d5OajeOscMxdtJcMdHMxvHG3518YicRTOsYO2dYzpxGYyx37Dlw1HV7PvAmwP8WUiPOipU0L0zUTfudJw8dVbawnEQxlTXw3nfx2bznc/ePe7xl07oJ9x7V8Wk0Pm5h14KRFjsowvrGrdsNc9IxsMUOW+yk+eDsa7846pd/R0AEk86MHNtCdNIJC3j+hSPjHq9dsYRd+w/y7ODQyHuc0tXJzvdumJWfc76rBemdTxykI4LhHGbNGaeOhLNGLXa/9fpXselj32Q4i/+urzp9IQ/3H3LWqzQOW+wkzXtjN2kfToopskxtn9n6cNjoeOcTz9ARo4cfB0H/wCDdi7ravmuw0c4h33lyYCTEdUQHzx8+wlBdm0F9q2etRXRsC2kEkEVY/85Th4r/vjgpRpoqg52keWHNGadO2PI20T6ztfvGavQ+tWBS79DgEa64cQefvfo1R3XTXnHjDk7o7Gh50Gs2cE4lmDbqxq6f6NB4zcGjH3R9OGvU3T42fHdE8d/CWa/S1DkrVtK8MHYm5Kev+qmmZkZu2bSOHz/ztKPKO4KG7zM0PDyqtanm3seeYePW7ex8YnQI+fa+Z7hn74GWr6VXC5yT1aPZ68Zeu2PPATb82ddHtXA2qzMmDmerly6ms/xt1NlRzHx11qt0bCrZYhcRG4A/AzqBv8jMD7S4SpKOU6OWnmbGXXUv6uKEzqPXSznpxM6R+z911QUjrVPPv9Cgaa/Uu+dA0WVY6oyiN7g+6PU9eoA119420k358FMDDVvGRndpLuKFoSEe2D8AFMu+XH9Zz5Qmg9TPLJ1K13TtukYtefXXHo+TTlzAlk3rxm0tbNQ9207d29J0qtzkiYjoBL4DvAHYB+wAfikzd413j5MnpGpbc+1toyZDAKxfuWQk0F1xY++obauatbBrAa88fSH3Pf70hAGo0QSA+kkEjdTqV1MLRX2PHhgZf1Zb3294zP/Ga59XC0y1cYNDw8ngkaGjrl9zxiL2fO85nj1cPKPOgLWvWAIwYR3H6oij6wIvTj6ZaDs5Sc1rty3FzgN2Z+Z3M/MwcBNwcYvrJKmFVi9dTH2j3cKuBaM2kz+WUAeQJNdf1sPaFUsmXER5bAta/8AgfY9OHJjGtrjVukXrg9NwNg5SP37mqQw8/wLr3/9lduw5wHOHhzk0eITnXzg61AHsfGJgJNQBDGXx+bXu72YWiF6/cgnffPfrWb9y9PX1Y+TcCkyaeVXsij0TeKzueB/w6rEXRcSVwJUAK1asmJ2aSZpV9UtvnHTigqOW3oCph4vOKIJPRxSzZS+87k5WL13MS07o4LnD4ye12sxagNde98XhEq4AAAtUSURBVNWGAave6qWLeXD/Qd7yke08d3ho4ovHePjJQ6OC2rFYdfoirrixd2Sv1pNP7ASSjug4apxdLSjXussbdbnWfia3ApNmVhW7YjcCF2Xm/10e/wpwXmb++nj32BUrVVMzXX8bt25vuPNBI2vOWMTJJy5g1/6DBDGyrEdtdu1EEws6AtaV3ZuTfV5HwEtO6OAHLwxPGgBnQtHFfMpRs17Xryy6d6+4cQff3lecm2g84FjtvlSMNF3abR27fcDyuuNlwBMtqoukFmqm668IKi+2TJ10Qic/eGFo1MzYjngxwEDRLTp2ssJzh49QLsXW0HA23zo4nEzY+ldfr6kEv44ofr7hHGbwSI6695QTO6Fua7YLr7vzqPt37T9I96IuPnv1a5r/0DoT7SwiaXpUMdjtAFZFxFnA48ClwL9vbZUktUIzXX9FUPnpkePJWpVqrYBjNROwap/fbAvhZM5ZdtqUxweuPmPxuN2l9T/n6qWLj6qnXafS3Fe5rliAiHgj8EGK5U4+npnvn+h6u2KlapqJrr9GM2yb0RHwzXe/HijG2I3tti26XzvpiOC5w0cmDYq193v1f/3ylFrtmt0erTZbuNaSec6yU7n+svV2nUpzQLt1xZKZXwC+0Op6SGqtmej6G9sKmOPMTK1XWz6kForufOeFRy2xEsCaMxaPWtMtiHHH7b3khA66F3VN2GrXqKu22Va3sS2ZkuaHKi53IkkzZuwOGOcsO23U8h5jVwbpKENd/e4JtdB0SlfnSFltiZFaGN353g3c+c4LOXf5aQ3fc80ZpwJw/WU9rF+55Khrzl1+6rj1l1RdlWyxk6SZMrYVcLydIJrp/p1sDGB9q9l4S4hMtMTI2FbBc5efZleqVHGVHGM3VY6xk9QKM738h8uLSNU00Rg7gx0GO0mSNH+025ZikiRJbclgJ0mSVBEGO0mSpIow2EmSJFWEwU6SJKkiDHaSJEkVYbCTJEmqCIOdJElSRRjsJEmSKsKdJ4CI6AcebXU9psnLgO+1uhIV4HOcHj7H6eFznB4+x+nhc5wex/McX5GZ3Y1OGOwqJiJ6x9tmRM3zOU4Pn+P08DlOD5/j9PA5To+Zeo52xUqSJFWEwU6SJKkiDHbV89FWV6AifI7Tw+c4PXyO08PnOD18jtNjRp6jY+wkSZIqwhY7SZKkijDYVUREvC8ivh0R90bElyLijLpz10TE7oh4KCIuamU957qI+OOIeLB8ln8bEafVnfM5NikiNkbEzogYjoieMed8jlMQERvKZ7U7It7V6vrMFxHx8Yh4KiLuryt7aUTcHhEPl9+XtLKO80FELI+IOyPigfLv9DvKcp/lFETESyLiWxHxj+VzfG9ZPu3P0WBXHX+cmedk5rnA3wG/BxARq4FLgTXABmBLRHS2rppz3u3A2Zl5DvAd4BrwOR6D+4G3AF+rL/Q5Tk35bD4M/BywGvil8hlqcp+g+DNW713AHZm5CrijPNbEjgC/nZk/BpwPXF3+GfRZTs0g8K8y8yeAc4ENEXE+M/AcDXYVkZkH6w5PAWqDJy8GbsrMwcx8BNgNnDfb9ZsvMvNLmXmkPLwbWFa+9jlOQWY+kJkPNTjlc5ya84DdmfndzDwM3ETxDDWJzPwa8H/GFF8M3FC+vgG4ZFYrNQ9l5v7MvKd8PQA8AJyJz3JKsnCoPDyh/Epm4Dka7CokIt4fEY8Bmyhb7Cj+Aj5Wd9m+skyT+1Xg1vK1z3F6+Bynxuc1vV6emfuhCCzA6S2uz7wSESuBnwS+ic9yyiKiMyLuBZ4Cbs/MGXmOBrt5JCK+HBH3N/i6GCAzfzczlwPbgF+r3dbgrdp6KvRkz7G85ncpuiC21YoavJXPcZLn2Oi2BmVt/Rwn4fPSnBARC4G/AX5jTA+RmpSZQ+VwqWXAeRFx9kx8zoKZeFPNjMx8fZOX/hXw98C1FP/CX153bhnwxDRXbV6Z7DlGxOXAm4HX5YvrAfkcx5jCn8d6Psep8XlNrycjYmlm7o+IpRQtJ5pERJxAEeq2ZeZnymKf5THKzKcj4qsUY0Cn/TnaYlcREbGq7vDngQfL17cAl0ZEV0ScBawCvjXb9ZsvImID8F+An8/M5+pO+Rynh89xanYAqyLirIg4kWLiyS0trtN8dgtwefn6cuBzLazLvBARAXwMeCAz/6TulM9yCiKiu7bKQkScBLye4vf0tD9HFyiuiIj4G+BHgGHgUeCqzHy8PPe7FOPFjlA0o9867hu1uYjYDXQB3y+L7s7Mq8pzPscmRcQvAH8OdANPA/dm5kXlOZ/jFETEG4EPAp3AxzPz/S2u0rwQEX8NXAi8DHiSogfjs8DNwApgL7AxM8dOsFCdiHgN8HXgPorfLwDvphhn57NsUkScQzE5opOiUe3mzPyDiPghpvk5GuwkSZIqwq5YSZKkijDYSZIkVYTBTpIkqSIMdpIkSRVhsJMkSaoIg52kSomI/xARWfc1EBH/GBG/FhEzuih7RPx+ROSYsoyI35/i+/xGRLxlWisnqS2484SkqtpIsXPD4vL1n1Psw/h7E900A36qrMdU/AbwDeAzk10oSfUMdpKq6t7M3F2+/lJEvJIiMB0V7MrV9U/IzMPTXYnMvHu63/NYRERXZg62uh6SZpZdsZLaxQ5gUUScHhF7IuIvI+JXI+JB4DDwJoCIODki/igiHomIw+X3342IUf+/jIifjIivR8QPIuLxiHgPEGM/tFFXbET8RET8bUR8PyKej4iHIuKa8twe4BXAprru5E/U3bshIu4q73smIj4bET8y5v2/GhHfiIh/ExH/OyIGgc3H/wglzXW22ElqF2cBQ8Ch8vi1wLnAeyk23t5TjsH7IrAaeB/FNkrnA+8BXgr8NkBEvAz4CvDPFPs7DgL/mWJboAlFxHnAV4HdwG9SdNOuAs4pL/kF4AvAPwK/X5b1l/duAP6+/OxfBBYCfwB8IyLOrW0jWHoV8KHy5/gu4HZPUhsw2Emqqs4yqC0C/h3wFuDzmflc0fPKEmBdZv5z7YaI+BXgNcDPZubXyuI7yuuvjYg/ysynKALZKcBFmbm3vPd2in2aJ3MdxV7E52fmc2XZV2onM7PWwva9Bt24f0gR0n4uM4+Un3sX8B2K0Plbdde+DPjXmXlvE3WSVBF2xUqqqgeBFyhaqrYA24BfrTt/d32oK22gCGfbI2JB7Qv4EnACResdFBMi7q6FOoDMfBb4/EQVioiTgZ8GttWFuqZExCnAWuCTtVBXfu4jwD8APzvmlj2GOqn92GInqap+gaKbcwB4NDN/MOb8/gb3nE4xvu2Fcd7zh8rvS4H7G5x/cpI6LaH4B/VUZ8nW7g0a1/ufKepdr9F1kirOYCepqu6vmxXbSDYo+z7wCEXXbSN7yu/7gZc3ON+orN4BYBg4c5Lrxrs3gR9ucO6HKeper9HPJ6ni7IqVpBfdBiwHDmVmb4Ov75XX3QWcHxHLazeWXaX/ZqI3L7tfvwH8ckScNMGlg8Co82VXbx+wMSI66z73FcAFwP/X9E8pqbIMdpL0om3AdooJE78VEa+LiJ8rd634UjlGDuBPgWcp1sf7xYi4hGIc3vNNfMY7Kbp074qIX4mI10bE2yLiz+uu2QX8y4h4c0T0RMTKsvw9FDNo/65cyuSXgNuBZ4D/cXw/uqQqMNhJUikzXwAuAq4HrqRYdmQbxZIm2ynWu6NsuXsd8D3gBuDDFK19H2/iM3ZQTKB4jGI3jC9QLJVSP+7uGuAh4GaK9fd+v7z3Nor19k4rz20FHgBek5lPHOvPLak6ItNhGJIkSVVgi50kSVJFGOwkSZIqwmAnSZJUEQY7SZKkijDYSZIkVYTBTpIkqSIMdpIkSRVhsJMkSaoIg50kSVJF/P+7OauucCK3sAAAAABJRU5ErkJggg=="></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h4 id="Let-us-start-with-linear-regression-first">Let us start with linear regression first<a class="anchor-link" href="#Let-us-start-with-linear-regression-first">&#182;</a></h4></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[171]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="n">linreg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="n">linreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span><span class="c1">#plot the results</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">linreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predictor&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Target&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[172]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE for Linear Regression=&gt;&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">linreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>RMSE for Linear Regression=&gt; 1635.1889668724025</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Now,-let&#8217;s-try-polynomial-regression.">Now, let&#8217;s try polynomial regression.<a class="anchor-link" href="#Now,-let&#8217;s-try-polynomial-regression.">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[189]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># importing libraries for polynomial transform</span><span class="c1">#from sklearn.preprocessing import PolynomialFeatures</span><span class="c1">#polynomial_features= PolynomialFeatures(degree=2)</span><span class="c1">#x_poly = polynomial_features.fit_transform(x)</span><span class="c1">#model = LinearRegression()</span><span class="c1">#model.fit(x_poly, y)</span><span class="c1">#y_poly_pred = model.predict(x_poly)</span><span class="c1"># importing libraries for polynomial transform</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span><span class="c1"># for creating pipeline</span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="c1"># creating pipeline and fitting it on data</span><span class="n">Input</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;polynomial&#39;</span><span class="p">,</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)),(</span><span class="s1">&#39;modal&#39;</span><span class="p">,</span><span class="n">LinearRegression</span><span class="p">())]</span><span class="n">pipe</span><span class="o">=</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">Input</span><span class="p">)</span><span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[189]:</div><div class="output_text output_subarea output_execute_result"><pre>Pipeline(memory=None,     steps=[(&#39;polynomial&#39;, PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), (&#39;modal&#39;, LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,         normalize=False))])</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Fitting-Our-model">Fitting Our model<a class="anchor-link" href="#Fitting-Our-model">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[193]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#plotting predictions</span><span class="kn">import</span> <span class="nn">operator</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span><span class="c1"># sort the values of x before line plot</span><span class="n">sort_axis</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="n">sorted_zip</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_poly_pred</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">sort_axis</span><span class="p">)</span><span class="n">x</span><span class="p">,</span> <span class="n">y_poly_pred</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">sorted_zip</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">linreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Linear Regression&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_poly_pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Polynomial Regression&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predictor&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Target&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[196]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE for Polynomial Regression=&gt;&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">poly_pred</span><span class="p">)))</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>RMSE for Polynomial Regression=&gt; 1690.2443340832644</pre></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="What if">But what if we have more than one predictor?</h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>For 2 predictors, the equation of the polynomial regression becomes:</p><p>two degree polynomial regression</p><p>where,</p><pre><code>      Y is the target,      x1, x2 are the predictors,      0 is the bias,      and, 1, 2, 3, 4, and 5 are the weights in the regression equation</code></pre><p>For n predictors, the equation includes all the possible combinations of different order polynomials. This is known as Multi-dimensional Polynomial Regression.</p><p>But, there is a major issue with multi-dimensional Polynomial Regression  multicollinearity. Multicollinearity is the interdependence between the predictors in a multiple dimensional regression problem. This restricts the model from fitting properly on the dataset.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Advantages-of-using-Polynomial-Regression:">Advantages of using Polynomial Regression:<a class="anchor-link" href="#Advantages-of-using-Polynomial-Regression:">&#182;</a></h2><ul><li>Broad range of function can be fit under it.</li><li>Polynomial basically fits wide range of curvature.</li><li>Polynomial provides the best approximation of the relationship between dependent and independent variable.</li></ul><h2 id="Disadvantages-of-using-Polynomial-Regression">Disadvantages of using Polynomial Regression<a class="anchor-link" href="#Disadvantages-of-using-Polynomial-Regression">&#182;</a></h2><ul><li>These are too sensitive to the outliers.</li><li>The presence of one or two outliers in the data can seriously affect the results of a nonlinear analysis.</li><li>In addition there are unfortunately fewer model validation tools for the detection of outliers in nonlinear regression than there are for linear regression.</li></ul></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><h2 id="practice">Practice</h2>Try to use a polynomial regression with the dataset but this time with degree three (cubic). Does it result in better accuracy?</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># write your code here</span></pre></div>    </div></div></div></div>    </div>  </div></body>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;
&lt;b&gt;Polynomial Regression Full Implementation.
&lt;br&gt;You will use use the most basic and the Polynomial model to predict results.
&lt;/a&gt; &lt;/b&gt;
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Polynomial Regression" scheme="https://massivefile.com/tags/Polynomial-Regression/"/>
    
  </entry>
  
  <entry>
    <title>Null Hypothesis || Evaluating Multiple Features</title>
    <link href="https://massivefile.com/Theory_hypothesis/"/>
    <id>https://massivefile.com/Theory_hypothesis/</id>
    <published>2020-05-02T00:56:53.000Z</published>
    <updated>2020-05-05T23:23:28.955Z</updated>
    
    <content type="html"><![CDATA[<body><b>What is Null Hypothesis ? <br> What is p-value <br> What is Significance-Level ? <br> When to reject Null Hypothesis ? </a> </b><a id="more"></a><h2> What is P-Value ? </h2><br><p>One of the main goals of statistical hypothesis testing is to estimate the P value, which is the probability of obtaining the observed results, or something more extreme, if the null hypothesis were true. If the observed results are unlikely under the null hypothesis, your reject the null hypothesis. </p><br><h2>What is Null Hypothesis ? </h2><p>The null hypothesis is a statement that you want to test. In general, the null hypothesis is that things are the same as each other, or the same as a theoretical expectation. For example, if you measure the size of the feet of male and female chickens, the null hypothesis could be that the average foot size in male chickens is the same as the average foot size in female chickens. If you count the number of male and female chickens born to a set of hens, the null hypothesis could be that the ratio of males to females is equal to a theoretical expectation of a 1:1 ratio.</p><br><h2>What is Alternative Hypothesis ? </h2><br><p>The alternative hypothesis is that things are different from each other, or different from a theoretical expectation. For example, one alternative hypothesis would be that male chickens have a different average foot size than female chickens; another would be that the sex ratio is different from 1:1.</p><br><h2>What is Significance Level</h2><p>The significance level, also denoted as alpha or , is a measure of the strength of the evidence that must be present in your sample before you will reject the null hypothesis and conclude that the effect is statistically significant. The researcher determines the significance level before conducting the experiment.<br>The significance level is the probability of rejecting the null hypothesis when it is true. For example, a significance level of 0.05 indicates a 5% risk of concluding that a difference exists when there is no actual difference. Lower significance levels indicate that you require stronger evidence before you will reject the null hypothesis.<br>Use significance levels during hypothesis testing to help you determine which hypothesis the data support. Compare your p-value to your significance level. If the p-value is less than your significance level, you can reject the null hypothesis and conclude that the effect is statistically significant. In other words, the evidence in your sample is strong enough to be able to reject the null hypothesis at the population level.</p><br><h2>Test the Null Hypothesis </h2><br><p>The primary goal of a statistical test is to determine whether an observed data set is so different from what you would expect under the null hypothesis that you should reject the null hypothesis. For example, let's say you are studying sex determination in chickens. <br>For breeds of chickens that are bred to lay lots of eggs, female chicks are more valuable than male chicks, so if you could figure out a way to manipulate the sex ratio, you could make a lot of chicken farmers very happy. <br>You've fed chocolate to a bunch of female chickens before giving birth (in birds, unlike mammals, the female parent determines the sex of the offspring), and you get 25 female chicks and 23 male chicks. Anyone would look at those numbers and see that they could easily result from chance; there would be no reason to reject the null hypothesis of a 1:1 ratio of females to males. <br>If you got 47 females and 1 male, most people would look at those numbers and see that they would be extremely unlikely to happen due to luck, you would reject the null hypothesis and conclude that chocolate really changed the sex ratio. However, what if you had 31 females and 17 males? That's definitely more females than males, but is it really so unlikely to occur due to chance that you can reject the null hypothesis?<br> To answer that, you need more than common sense, you need to calculate the probability of getting a deviation that large due to chance.</p><br><h2>Calculating the Probablity </h2><br><center><img src='https://lh3.googleusercontent.com/eNkVzVpqjIJ7YbhA8cnGSJxpOCzbMauRyAeARwFswTJZtdenuA45yfwSUJBij7XhD-SQldIQCJpX6FOJbXJXVXbumzM3WVafyIrgSE_IR0_NA-sYw7bsyruRGCTi_aSJCCsTmXIx4g=w2400' /></center><br><p>In the figure above, I used the BINOMDIST function of Excel to calculate the probability of getting each possible number of males, from 0 to 48, under the null hypothesis that 0.5 are male.<br>We have sample size of 48 ie 48 chicks and according to our Null Hypothesis, 24 chicks should be Male and 24 should be female with 5 percent error acceptance.<br>As you can see, the probability of getting 17 males out of 48 total chickens is about 0.015. That seems like a pretty small probability, doesn't it? <br> However, that's the probability of getting exactly 17 males. What you want to know is the probability of getting 17 or fewer males. If you were going to accept 17 males as evidence that the sex ratio was biased, you would also have accepted 16, or 15, or 14, males as evidence for a biased sex ratio. You therefore need to add together the probabilities of all these outcomes. The probability of getting 17 or fewer males out of 48, under the null hypothesis, is 0.030. That means that if you had an infinite number of chickens, half males and half females, and you took a bunch of random samples of 48 chickens, 3.0% of the samples would have 17 or fewer males.<br>This number, 0.030, is the P value. It is defined as the probability of getting the observed result, or a more extreme result, if the null hypothesis is true. So "P=0.030" is a shorthand way of saying "The probability of getting 17 or fewer male chickens out of 48 total chickens, IF the null hypothesis is true that 50% of chickens are male, is 0.030."</p><br><h2>When to reject null hypothesis?</h2><br><p>Use a significance level of 0.05. This means that if the P value is less than 0.05, you reject the null hypothesis; if P is greater than or equal to 0.05, you don't reject the null hypothesis.</p><h2>False positives vs. false negatives</h2><br><p>After you do a statistical test, you are either going to reject or accept the null hypothesis. Rejecting the null hypothesis means that you conclude that the null hypothesis is not true; in our chicken sex example, you would conclude that the true proportion of male chicks, if you gave chocolate to an infinite number of chicken mothers, would be less than 50%.<br>When you reject a null hypothesis, there's a chance that you're making a mistake. The null hypothesis might really be true, and it may be that your experimental results deviate from the null hypothesis purely as a result of chance. In a sample of 48 chickens, it's possible to get 17 male chickens purely by chance; it's even possible (although extremely unlikely) to get 0 male and 48 female chickens purely by chance, even though the true proportion is 50% males. This is why we never say we "prove" something in science; there's always a chance, however miniscule, that our data are fooling us and deviate from the null hypothesis purely due to chance. When your data fool you into rejecting the null hypothesis even though it's true, it's called a "false positive," or a "Type I error." So another way of defining the P value is the probability of getting a false positive like the one you've observed, if the null hypothesis is true.<br>Another way your data can fool you is when you don't reject the null hypothesis, even though it's not true. If the true proportion of female chicks is 51%, the null hypothesis of a 50% proportion is not true, but you're unlikely to get a significant difference from the null hypothesis unless you have a huge sample size. Failing to reject the null hypothesis, even though it's not true, is a "false negative" or "Type II error." This is why we never say that our data shows the null hypothesis to be true; all we can say is that <b><i>"We haven't rejected the null hypothesis"</b></i><br></p><ul><b><h2>Important Points to be noted: </b></h2><li>Most times we take the significance level to be 0.05</li><li>We compare significance level with p-value if the significance level > p-value then we can reject the null hypothesis </li><li>If p value > 0.1 little or no evidence against null hypothesis </li><li>If our Null hypothesis is true then the distribution is mostly a Normal/Gaussian Distribution </ul></li><h2> More On topic</h2><br>Please find Implementation <a href = 'https://massivefile.com/multiple_linear_regression/' , target="_blank">Here </a></body>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;
&lt;b&gt;What is Null Hypothesis ? &lt;br&gt; What is p-value &lt;br&gt; What is Significance-Level ? &lt;br&gt; When to reject Null Hypothesis ? &lt;/a&gt; &lt;/b&gt;
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Null Hypothesis" scheme="https://massivefile.com/tags/Null-Hypothesis/"/>
    
  </entry>
  
  <entry>
    <title>R Squared Intution || Evaluating Model Features</title>
    <link href="https://massivefile.com/Theory_RSquared/"/>
    <id>https://massivefile.com/Theory_RSquared/</id>
    <published>2020-05-02T00:56:53.000Z</published>
    <updated>2020-05-05T23:23:34.577Z</updated>
    
    <content type="html"><![CDATA[<body><b>What is R Squared ? <br> What is Adjusted R-Squared ? <br> How to calculate R Squared ?<br> How to Calculate Adjusted R Squared ?<br> Which Method is Better ?</b><a id="more"></a><h2>What is R Squared ? </h2><br><p>R-squared is a goodness-of-fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively. R-squared measures the strength of the relationship between your model and the dependent variable on a convenient 0  100% scale.<br>Image of a large R-squared.After fitting a linear regression model, you need to determine how well the model fits the data. Does it do a good job of explaining changes in the dependent variable? There are a several key goodness-of-fit statistics for regression analysis. In this post, well examine R-squared (R2 ), highlight some of its limitations, and discover some surprises. For instance, small R-squared values are not always a problem, and high R-squared values are not necessarily good!Linear regression identifies the equation that produces the smallest difference between all of the observed values and their fitted values. To be precise, linear regression finds the smallest sum of squared residuals that is possible for the dataset.<br>Statisticians say that a regression model fits the data well if the differences between the observations and the predicted values are small and unbiased. Unbiased in this context means that the fitted values are not systematically too high or too low anywhere in the observation space.<br>However, before assessing numeric measures of goodness-of-fit, like R-squared, you should evaluate the residual plots. Residual plots can expose a biased model far more effectively than the numeric output by displaying problematic patterns in the residuals. If your model is biased, you cannot trust the results.</p><h2>R-squared and the Goodness-of-Fit</h2><p>R-squared evaluates the scatter of the data points around the fitted regression line. It is also called the coefficient of determination, or the coefficient of multiple determination for multiple regression. For the same data set, higher R-squared values represent smaller differences between the observed data and the fitted values.<br>R-squared is the percentage of the dependent variable variation that a linear model explains.<br><br>Formulae:<center><b> 1- (Sum of Errors / Total Sum of errors)<br></center></b><br><br><br>R-squared is always between 0 and 100%:<br>0% represents a model that does not explain any of the variation in the response variable around its mean. The mean of the dependent variable predicts the dependent variable as well as the regression model.100% represents a model that explains all of the variation in the response variable around its mean.Usually, the larger the R2, the better the regression model fits your observations. However, this guideline has important caveats that Ill discuss in both this post and the next post.<h2>What are the limitations of R Squared ?</h2><br><p>R2 increases with every predictor added to a model. As R2 always increases and never decreases, it can appear to be a better fit with the more terms you add to the model. This can be completely misleading.<br>Similarly, if your model has too many terms and too many high-order polynomials you can run into the problem of over-fitting the data. When you over-fit data, a misleadingly high R2 value can lead to misleading projections.</p><br><h2>What is Adjusted R Squared ?</h2><br><p>R2 shows how well terms (data points) fit a curve or line. Adjusted R2 also indicates how well terms fit a curve or line, but adjusts for the number of terms in a model. If you add more and more useless variables to a model, adjusted r-squared will decrease. If you add more useful variables, adjusted r-squared will increase.Adjusted R2 will always be less than or equal to R2.<br><br>Formulae:<br><center>Adjusted R Squared = 1  [((1  R2) * (n  1)) / (n  k  1)]</center><br>Where:<br>n  Number of points in your data set.<br>k  Number of independent variables in the model, excluding the constant</p><br>Fortunately, if you have a low R-squared value but the independent variables are statistically significant, you can still draw important conclusions about the relationships between the variables. Statistically significant coefficients continue to represent the mean change in the dependent variable given a one-unit shift in the independent variable. Clearly, being able to draw conclusions like this is vital.</p><br><h2>Which Method is Better ?</h2><p>Both R2 and the adjusted R2 give you an idea of how many data points fall within the line of the regression equation. However, there is one main difference between R2 and the adjusted R2: R2 assumes that every single variable explains the variation in the dependent variable. The adjusted R2 tells you the percentage of variation explained by only the independent variables that actually affect the dependent variable.<br>The adjusted R2 will penalize you for adding independent variables (K in the equation) that do not fit the model. Why? In regression analysis, it can be tempting to add more variables to the data as you think of them. Some of those variables will be significant, but you cant be sure that significance is just by chance. The adjusted R2 will compensate for this by that penalizing you for those extra variables.<br>While values are usually positive, they can be negative as well. This could happen if your R2 is zero; After the adjustment, the value can dip below zero. This usually indicates that your model is a poor fit for your data. Other problems with your model can also cause sub-zero values, such as not putting a constant term in your model.<br></p><h2> More On topic</h2><br>Please find Implementation <a href = 'https://massivefile.com/multiple_linear_regression/' , target="_blank">Here </a></body>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;
&lt;b&gt;What is R Squared ? &lt;br&gt; What is Adjusted R-Squared ? &lt;br&gt; How to calculate R Squared ?&lt;br&gt; How to Calculate Adjusted R Squared ?&lt;br&gt; Which Method is Better ?&lt;/b&gt;
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="R Squared" scheme="https://massivefile.com/tags/R-Squared/"/>
    
  </entry>
  
  <entry>
    <title>Standardization and Normalization || Feature Scaling</title>
    <link href="https://massivefile.com/Standardization_Normalization/"/>
    <id>https://massivefile.com/Standardization_Normalization/</id>
    <published>2020-04-26T00:56:53.000Z</published>
    <updated>2020-05-05T23:23:16.870Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Feature-Scaling"><a href="#Feature-Scaling" class="headerlink" title="Feature Scaling"></a>Feature Scaling</h4><h5 id="We-have-2-important-parts-in-feature-scaling"><a href="#We-have-2-important-parts-in-feature-scaling" class="headerlink" title="We have 2 important parts in feature scaling"></a>We have 2 important parts in feature scaling</h5><ul><li>Standardization <li>Normalization</ul><a id="more"></a><p>What is Standardization and Normalization ?<br>Why are they Used ?</p><p>The terms normalization and standardization are sometimes used interchangeably,<br>but they usually refer to different things. </p><p><b>Standardization</b> rescales data to have a mean () of 0 and standard deviation () of 1 (unit variance).<br>Formulae for Standardization is<br>$X_{changed} = \frac{X - \mu}{\sigma} $<br>For most applications standardization is recommended.</p><p><b>Normalization</b> usually means to scale a variable to have a values between 0 and 1,<br>while standardization transforms data to have a mean of zero and a standard deviation of 1. </p><p>Normalization rescales the values into a range of [0,1].<br>This might be useful in some cases where all parameters need to have the same positive scale.<br>However, the outliers from the data set are lost.<br>Formulae for normalization is<br>$ X_{changed} = \frac{X - X_{min}}{X_{max}-X_{min}} $</p><p>We must standardize the data only after the split and the scaler should be only be fitted to the x_train set because if we do that we get the mean and standard of the values in the x_test which should be hidden to us. So we will only fit the scaler to the test set and then we will transform the scaler to x_test</p><h2 id="One-Very-Important-Question-is"><a href="#One-Very-Important-Question-is" class="headerlink" title="One Very Important Question is"></a>One Very Important Question is</h2><h4 id="Do-we-have-to-apply-standardization-to-the-dummy-variables-to-the-matrix-of-features"><a href="#Do-we-have-to-apply-standardization-to-the-dummy-variables-to-the-matrix-of-features" class="headerlink" title="Do we have to apply/standardization to the dummy variables to the matrix of features ? "></a><b>Do we have to apply/standardization to the dummy variables to the matrix of features ? <br></b></h4><p><b>Answer is no<br></b></p><p>Simply as the goal of Standardization is to transform your data and get them in the range generally (-3 , +3) But here we have mostly the data in 0s and 1s after we have converted them using ColumnTransformer, OneHotEncoder and LabelEncoder.<br><br>And there is nothing extra to be done here. <br><br>Moreever here standardization will convert the values to -3 and +3 which will worsen out understanding of the data as we will not be able to understand the nonsense numerical values.<br>Feature Scaling on the dataset makes the model better but when we do the same on the dummy variabe it makes the data not redable and we can not relate the country to the salary etc.<br>So feature Scaling should be applyed to the model but not to the dummy variable as they are already encoded before using ColumnTransformer, OneHotEncoder and LabelEncoder.</p><h3 id="Therefore-we-should-only-apply-feature-scaling-to-the-non-dummy-values-ie-the-values-that-are-numbers"><a href="#Therefore-we-should-only-apply-feature-scaling-to-the-non-dummy-values-ie-the-values-that-are-numbers" class="headerlink" title="Therefore we should only apply feature scaling to the non dummy values ie the values that are numbers"></a>Therefore we should only apply feature scaling to the non dummy values ie the values that are numbers</h3>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;Feature-Scaling&quot;&gt;&lt;a href=&quot;#Feature-Scaling&quot; class=&quot;headerlink&quot; title=&quot;Feature Scaling&quot;&gt;&lt;/a&gt;Feature Scaling&lt;/h4&gt;&lt;h5 id=&quot;We-have-2-important-parts-in-feature-scaling&quot;&gt;&lt;a href=&quot;#We-have-2-important-parts-in-feature-scaling&quot; class=&quot;headerlink&quot; title=&quot;We have 2 important parts in feature scaling&quot;&gt;&lt;/a&gt;We have 2 important parts in feature scaling&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;Standardization 
&lt;li&gt;Normalization
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Standardization and Normalization" scheme="https://massivefile.com/tags/Standardization-and-Normalization/"/>
    
      <category term="Feature Scaling" scheme="https://massivefile.com/tags/Feature-Scaling/"/>
    
  </entry>
  
  <entry>
    <title>Setting Up Machine Learning Model</title>
    <link href="https://massivefile.com/setting_up_machine_lerarning_model/"/>
    <id>https://massivefile.com/setting_up_machine_lerarning_model/</id>
    <published>2020-04-26T00:56:53.000Z</published>
    <updated>2020-05-05T23:22:55.298Z</updated>
    
    <content type="html"><![CDATA[<body><p><i><b>Note - These are my notes on DeepLearning Specialization Course 2 Part:<br>Setting Up Machine Learning Model || Improving Deep Neural Networks (Week 1 - Part 1)<br></i></b><a id="more"></a></p>  <div tabindex="-1" id="notebook" class="border-box-sizing">    <div class="container" id="notebook-container"><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1 id="Table-of-Contents">Table of Contents<a class="anchor-link" href="#Table-of-Contents">&#182;</a></h1><p><p><div class="lev1 toc-item"><a href="#Setting-up-your-machine-Learning-Application" data-toc-modified-id="Setting-up-your-machine-Learning-Application-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Setting up your machine Learning Application</a></div><div class="lev2 toc-item"><a href="#Train-/-Dev-/-Test-sets" data-toc-modified-id="Train-/-Dev-/-Test-sets-11"><span class="toc-item-num">1.1&nbsp;&nbsp;</span>Train / Dev / Test sets</a></div><div class="lev2 toc-item"><a href="#Bias-/-Variance" data-toc-modified-id="Bias-/-Variance-12"><span class="toc-item-num">1.2&nbsp;&nbsp;</span>Bias / Variance</a></div><div class="lev2 toc-item"><a href="#Basic-Recipe-for-Machine-Learning" data-toc-modified-id="Basic-Recipe-for-Machine-Learning-13"><span class="toc-item-num">1.3&nbsp;&nbsp;</span>Basic Recipe for Machine Learning</a></div><div class="lev1 toc-item"><a href="#Regularizing-your-neural-network" data-toc-modified-id="Regularizing-your-neural-network-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Regularizing your neural network</a></div><div class="lev2 toc-item"><a href="#Regularization" data-toc-modified-id="Regularization-21"><span class="toc-item-num">2.1&nbsp;&nbsp;</span>Regularization</a></div><div class="lev2 toc-item"><a href="#Why-regularization-reduces-overfitting?" data-toc-modified-id="Why-regularization-reduces-overfitting?-22"><span class="toc-item-num">2.2&nbsp;&nbsp;</span>Why regularization reduces overfitting?</a></div><div class="lev2 toc-item"><a href="#Dropout-Regularization" data-toc-modified-id="Dropout-Regularization-23"><span class="toc-item-num">2.3&nbsp;&nbsp;</span>Dropout Regularization</a></div><div class="lev2 toc-item"><a href="#Understanding-Dropout" data-toc-modified-id="Understanding-Dropout-24"><span class="toc-item-num">2.4&nbsp;&nbsp;</span>Understanding Dropout</a></div><div class="lev2 toc-item"><a href="#Other-regularization-methods" data-toc-modified-id="Other-regularization-methods-25"><span class="toc-item-num">2.5&nbsp;&nbsp;</span>Other regularization methods</a></div><div class="lev1 toc-item"><a href="#Setting-up-your-optimization-problem" data-toc-modified-id="Setting-up-your-optimization-problem-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Setting up your optimization problem</a></div><div class="lev2 toc-item"><a href="#Normalizing-inputs" data-toc-modified-id="Normalizing-inputs-31"><span class="toc-item-num">3.1&nbsp;&nbsp;</span>Normalizing inputs</a></div><div class="lev2 toc-item"><a href="#Vanishing-/-Exploding-gradients" data-toc-modified-id="Vanishing-/-Exploding-gradients-32"><span class="toc-item-num">3.2&nbsp;&nbsp;</span>Vanishing / Exploding gradients</a></div><div class="lev2 toc-item"><a href="#Weight-Initialization-for-Deep-Networks" data-toc-modified-id="Weight-Initialization-for-Deep-Networks-33"><span class="toc-item-num">3.3&nbsp;&nbsp;</span>Weight Initialization for Deep Networks</a></div><div class="lev2 toc-item"><a href="#Numerical-approximation-of-gradients" data-toc-modified-id="Numerical-approximation-of-gradients-34"><span class="toc-item-num">3.4&nbsp;&nbsp;</span>Numerical approximation of gradients</a></div><div class="lev2 toc-item"><a href="#Gradient-Checking" data-toc-modified-id="Gradient-Checking-35"><span class="toc-item-num">3.5&nbsp;&nbsp;</span>Gradient Checking</a></div><div class="lev2 toc-item"><a href="#Gradient-Checking-Implementation-Notes" data-toc-modified-id="Gradient-Checking-Implementation-Notes-36"><span class="toc-item-num">3.6&nbsp;&nbsp;</span>Gradient Checking Implementation Notes</a></div></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1 id="Setting-up-your-machine-Learning-Application">Setting up your machine Learning Application<a class="anchor-link" href="#Setting-up-your-machine-Learning-Application">&#182;</a></h1></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Train-/-Dev-/-Test-sets">Train / Dev / Test sets<a class="anchor-link" href="#Train-/-Dev-/-Test-sets">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/zhNfPDO.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/M2sJUEW.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/3ZE2tkh.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Bias-/-Variance">Bias / Variance<a class="anchor-link" href="#Bias-/-Variance">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/zUwoWUf.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Basic-Recipe-for-Machine-Learning">Basic Recipe for Machine Learning<a class="anchor-link" href="#Basic-Recipe-for-Machine-Learning">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/9JBOjZn.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1 id="Regularizing-your-neural-network">Regularizing your neural network<a class="anchor-link" href="#Regularizing-your-neural-network">&#182;</a></h1></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Regularization">Regularization<a class="anchor-link" href="#Regularization">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/oQeoTQB.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/KBOdujA.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Why-regularization-reduces-overfitting?">Why regularization reduces overfitting?<a class="anchor-link" href="#Why-regularization-reduces-overfitting?">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/86HoIQn.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/cXX9dOd.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Dropout-Regularization">Dropout Regularization<a class="anchor-link" href="#Dropout-Regularization">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/dNacOCr.png" alt=""><img src="https://i.imgur.com/KD7pcKH.png" alt=""><img src="https://i.imgur.com/QuZ5UNB.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Understanding-Dropout">Understanding Dropout<a class="anchor-link" href="#Understanding-Dropout">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/hW8BZwj.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Other-regularization-methods">Other regularization methods<a class="anchor-link" href="#Other-regularization-methods">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/BVmNSMM.png" alt=""><img src="https://i.imgur.com/SntfgkV.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1 id="Setting-up-your-optimization-problem">Setting up your optimization problem<a class="anchor-link" href="#Setting-up-your-optimization-problem">&#182;</a></h1></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Normalizing-inputs">Normalizing inputs<a class="anchor-link" href="#Normalizing-inputs">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/a2ZdeSg.png" alt=""><img src="https://i.imgur.com/Ph78qBk.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Vanishing-/-Exploding-gradients">Vanishing / Exploding gradients<a class="anchor-link" href="#Vanishing-/-Exploding-gradients">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/GzjU43b.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Weight-Initialization-for-Deep-Networks">Weight Initialization for Deep Networks<a class="anchor-link" href="#Weight-Initialization-for-Deep-Networks">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/uWl9XI9.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Numerical-approximation-of-gradients">Numerical approximation of gradients<a class="anchor-link" href="#Numerical-approximation-of-gradients">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/Z1DBfT1.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Gradient-Checking">Gradient Checking<a class="anchor-link" href="#Gradient-Checking">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/MLWOkP2.png" alt=""><img src="https://i.imgur.com/4ndm620.png" alt=""></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Gradient-Checking-Implementation-Notes">Gradient Checking Implementation Notes<a class="anchor-link" href="#Gradient-Checking-Implementation-Notes">&#182;</a></h2></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><img src="https://i.imgur.com/dwjrd88g.png" alt=""></p></div></div></div>    </div>  </div><h5>Credits - <a href='https://www.coursera.org/' target=_blank >Coursera</a>,  <a href = 'https://en.wikipedia.org/wiki/Andrew_Ng' title="Andrew_Ng" target=_blank>Credits to the teacher</a> , <a href ='https://www.coursera.org/specializations/deep-learning?' target=_blank>Deeplearning.ai Course</a><h5></body>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;


&lt;p&gt;&lt;i&gt;&lt;b&gt;Note - These are my notes on DeepLearning Specialization Course 2 Part:&lt;br&gt;Setting Up Machine Learning Model || Improving Deep Neural Networks (Week 1 - Part 1)&lt;br&gt;&lt;/i&gt;&lt;/b&gt;
    
    </summary>
    
    
      <category term="Improving Deep Neural Networks" scheme="https://massivefile.com/categories/Improving-Deep-Neural-Networks/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Setting Up Machine Learning Model" scheme="https://massivefile.com/tags/Setting-Up-Machine-Learning-Model/"/>
    
  </entry>
  
  <entry>
    <title>Data Preprocessing || Feature Scaling (With Code Implementation)</title>
    <link href="https://massivefile.com/data_preprocessing_feature/"/>
    <id>https://massivefile.com/data_preprocessing_feature/</id>
    <published>2020-04-26T00:56:53.000Z</published>
    <updated>2020-05-05T23:21:07.048Z</updated>
    
    <content type="html"><![CDATA[<body>  <div tabindex="-1" id="notebook" class="border-box-sizing">    <div class="container" id="notebook-container"><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><b>This Blog Will Be Focusing On The Preprocessing The Data Mostly EDA, Finding Missing Values, Filling and Feature Scaling</p></b><p><b>TABLE OF CONTENTS</b></p><p><ul>    <li> Importing Libraries </li>    <li> Creating Dataset </li>    <li> EDA on Dataset </li>    <li> Find Missing Values </li><a id="more"></a>    <li> Replace The Missing Values </li>    <li> Visualizing Data </li>    <li> Categorical variables </li>    <li> Splitting the dataset to train and test dataset</li>    <li> Feature Scaling </li></p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Importing-Libraries">Importing Libraries<a class="anchor-link" href="#Importing-Libraries">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[1]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span><span class="kn">import</span> <span class="nn">random</span> </pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Creating-Dataset">Creating Dataset<a class="anchor-link" href="#Creating-Dataset">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[2]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Country&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;France&#39;</span><span class="p">,</span> <span class="s1">&#39;Spain&#39;</span><span class="p">,</span> <span class="s1">&#39;Germany&#39;</span><span class="p">,</span> <span class="s1">&#39;Spain&#39;</span><span class="p">,</span> <span class="s1">&#39;Germany&#39;</span><span class="p">,</span> <span class="s1">&#39;France&#39;</span><span class="p">,</span> <span class="s1">&#39;Spain&#39;</span><span class="p">,</span> <span class="s1">&#39;Germany&#39;</span><span class="p">,</span> <span class="s1">&#39;Spain&#39;</span><span class="p">,</span> <span class="s1">&#39;France&#39;</span><span class="p">],</span> <span class="s1">&#39;Age&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">44</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">38</span><span class="p">,</span> <span class="mi">40</span> <span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">48</span> <span class="p">,</span> <span class="mi">50</span> <span class="p">,</span> <span class="mi">37</span><span class="p">],</span> <span class="s1">&#39;Salary&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">72000</span><span class="p">,</span> <span class="mi">48000</span><span class="p">,</span> <span class="mi">54000</span><span class="p">,</span> <span class="mi">61000</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">58000</span><span class="p">,</span> <span class="mi">52000</span><span class="p">,</span> <span class="mi">79000</span><span class="p">,</span> <span class="mi">83000</span><span class="p">,</span> <span class="mi">67000</span><span class="p">],</span> <span class="s1">&#39;Purchased&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;No&#39;</span><span class="p">,</span><span class="s1">&#39;Yes&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span> <span class="p">]})</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="EDA-on-Dataset">EDA on Dataset<a class="anchor-link" href="#EDA-on-Dataset">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[3]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">())</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 10 entries, 0 to 9Data columns (total 4 columns): #   Column     Non-Null Count  Dtype  ---  ------     --------------  -----   0   Country    10 non-null     object  1   Age        9 non-null      float64 2   Salary     9 non-null      float64 3   Purchased  10 non-null     object dtypes: float64(2), object(2)memory usage: 448.0+ bytesNone</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[4]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>   Country   Age   Salary Purchased0   France  44.0  72000.0        No1    Spain  27.0  48000.0       Yes2  Germany  30.0  54000.0        No3    Spain  38.0  61000.0        No</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[5]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>             Age        Salarycount   9.000000      9.000000mean   38.777778  63777.777778std     7.693793  12265.579662min    27.000000  48000.00000025%    35.000000  54000.00000050%    38.000000  61000.00000075%    44.000000  72000.000000max    50.000000  83000.000000</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Find-Missing-Values">Find Missing Values<a class="anchor-link" href="#Find-Missing-Values">&#182;</a></h2><h3 id="Missing-Values:-We-Have-Some-Missing-Values.-We-will-find-them-first.">Missing Values: We Have Some Missing Values. We will find them first.<a class="anchor-link" href="#Missing-Values:-We-Have-Some-Missing-Values.-We-will-find-them-first.">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[6]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">missingno</span> <span class="k">as</span> <span class="nn">mp</span><span class="n">mp</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="c1">#will plot the missing value chart</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[6]:</div><div class="output_text output_subarea output_execute_result"><pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a204dd910&gt;</pre></div></div><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[7]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span> <span class="c1">#will print the total of null values</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>Country      0Age          1Salary       1Purchased    0dtype: int64</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Replace-The-Missing-Values">Replace The Missing Values<a class="anchor-link" href="#Replace-The-Missing-Values">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[8]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="c1">#replace the missing values with the mean of the values</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Let-us-visualize-again-and-check-if-the-missing-values-are-filled-or-not">Let us visualize again and check if the missing values are filled or not<a class="anchor-link" href="#Let-us-visualize-again-and-check-if-the-missing-values-are-filled-or-not">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[9]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">mp</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="c1">#will plot the missing value chart</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[9]:</div><div class="output_text output_subarea output_execute_result"><pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a241a1150&gt;</pre></div></div><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h5 id="We-can-also-use-imputer-to-do-the-same-task">We can also use imputer to do the same task<a class="anchor-link" href="#We-can-also-use-imputer-to-do-the-same-task">&#182;</a></h5><p>Here is the Code for the same: <br><br>from sklearn.impute import SimpleImputer<br>imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean',verbose=0)<br><br>imputer = imputer.fit(X.iloc[:, 1:3])<br>X.iloc[:, 1:3] = imputer.transform(X.iloc[:, 1:3])<br><br>imputer = imputer.fit(df.iloc[: , 1:3])<br><br>df.iloc[:,1:3] = imputer.transform(df.iloc[:, 1:3])<br></p><p>.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Deviding-the-dataset-first-to-dependent-and-indepandent-values">Deviding the dataset first to dependent and indepandent values<a class="anchor-link" href="#Deviding-the-dataset-first-to-dependent-and-indepandent-values">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[10]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span> <span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># independent variable</span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span> <span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># dependent variable</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[11]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>[[&#39;France&#39; 44.0 72000.0] [&#39;Spain&#39; 27.0 48000.0] [&#39;Germany&#39; 30.0 54000.0] [&#39;Spain&#39; 38.0 61000.0] [&#39;Germany&#39; 40.0 63777.77777777778] [&#39;France&#39; 35.0 58000.0] [&#39;Spain&#39; 38.77777777777778 52000.0] [&#39;Germany&#39; 48.0 79000.0] [&#39;Spain&#39; 50.0 83000.0] [&#39;France&#39; 37.0 67000.0]]</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[12]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>[[&#39;No&#39;] [&#39;Yes&#39;] [&#39;No&#39;] [&#39;No&#39;] [&#39;Yes&#39;] [&#39;Yes&#39;] [&#39;No&#39;] [&#39;Yes&#39;] [&#39;No&#39;] [&#39;Yes&#39;]]</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>..</p><h2 id="Categorical-variables">Categorical variables<a class="anchor-link" href="#Categorical-variables">&#182;</a></h2><h4 id="Now-we-will-take-care-of-categorical-variables">Now we will take care of categorical variables<a class="anchor-link" href="#Now-we-will-take-care-of-categorical-variables">&#182;</a></h4><h4 id="we-will-import-three-libraries-for-the-same">we will import three libraries for the same<a class="anchor-link" href="#we-will-import-three-libraries-for-the-same">&#182;</a></h4><h4 id="label-encoder-,--one-hot-encoder-and-ColumnTransformer">label encoder ,  one hot encoder and ColumnTransformer<a class="anchor-link" href="#label-encoder-,--one-hot-encoder-and-ColumnTransformer">&#182;</a></h4><h4 id="ColumnTransformer-will-encode-your-labels-to-numberical-variables-ie-here-france-to-0-,-germany-to-1-and-other-to-2">ColumnTransformer will encode your labels to numberical variables ie here france to 0 , germany to 1 and other to 2<a class="anchor-link" href="#ColumnTransformer-will-encode-your-labels-to-numberical-variables-ie-here-france-to-0-,-germany-to-1-and-other-to-2">&#182;</a></h4><h4 id="One-hot-encoder-is-used-to-make-a-sparse-matrix-of-the-numerical-features-encoded-by-Cloumn-Transformer.-It-encodes-into-0-and-1-Sparse-Matrix">One hot encoder is used to make a sparse matrix of the numerical features encoded by Cloumn Transformer. It encodes into 0 and 1 Sparse Matrix<a class="anchor-link" href="#One-hot-encoder-is-used-to-make-a-sparse-matrix-of-the-numerical-features-encoded-by-Cloumn-Transformer.-It-encodes-into-0-and-1-Sparse-Matrix">&#182;</a></h4><p>.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[13]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="n">ct</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span><span class="n">transformers</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;encoder&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(),</span> <span class="p">[</span><span class="mi">0</span><span class="p">])],</span> <span class="n">remainder</span> <span class="o">=</span> <span class="s1">&#39;passthrough&#39;</span><span class="p">)</span> <span class="c1">#creating an instance</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[14]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>[[1.0 0.0 0.0 44.0 72000.0] [0.0 0.0 1.0 27.0 48000.0] [0.0 1.0 0.0 30.0 54000.0] [0.0 0.0 1.0 38.0 61000.0] [0.0 1.0 0.0 40.0 63777.77777777778] [1.0 0.0 0.0 35.0 58000.0] [0.0 0.0 1.0 38.77777777777778 52000.0] [0.0 1.0 0.0 48.0 79000.0] [0.0 0.0 1.0 50.0 83000.0] [1.0 0.0 0.0 37.0 67000.0]]</pre></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[15]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>[[&#39;No&#39;] [&#39;Yes&#39;] [&#39;No&#39;] [&#39;No&#39;] [&#39;Yes&#39;] [&#39;Yes&#39;] [&#39;No&#39;] [&#39;Yes&#39;] [&#39;No&#39;] [&#39;Yes&#39;]]</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>.</p><h4 id="Let-us-take-care-of-y-now">Let us take care of y now<a class="anchor-link" href="#Let-us-take-care-of-y-now">&#182;</a></h4><h4 id="We-will-Use-LabelEncoder-for-this">We will Use LabelEncoder for this<a class="anchor-link" href="#We-will-Use-LabelEncoder-for-this">&#182;</a></h4><h4 id="It-is-preferred-to-use-label-encoder-to-change-the-binary-data-so-we-use-LabelEncoder">It is preferred to use label encoder to change the binary data so we use LabelEncoder<a class="anchor-link" href="#It-is-preferred-to-use-label-encoder-to-change-the-binary-data-so-we-use-LabelEncoder">&#182;</a></h4></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[16]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#it is preferred to use label encoder to change the binary data so we use LabelEncoder</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span><span class="n">y</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span> <span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stderr output_text"><pre>/Users/karan7k/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().  y = column_or_1d(y, warn=True)</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Splitting-the-dataset-into-training-set-and-test-set">Splitting the dataset into training set and test set<a class="anchor-link" href="#Splitting-the-dataset-into-training-set-and-test-set">&#182;</a></h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[17]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="n">x_train</span> <span class="p">,</span> <span class="n">x_test</span> <span class="p">,</span> <span class="n">y_train</span> <span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span> <span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[18]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x_train: &#39;</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;y_train: &#39;</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="p">,</span><span class="s1">&#39;x_test: &#39;</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;y_test: &#39;</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>x_train:  [[1.0 0.0 0.0 37.0 67000.0] [0.0 0.0 1.0 27.0 48000.0] [0.0 0.0 1.0 38.77777777777778 52000.0] [0.0 1.0 0.0 48.0 79000.0] [0.0 0.0 1.0 38.0 61000.0] [1.0 0.0 0.0 44.0 72000.0] [1.0 0.0 0.0 35.0 58000.0]]  y_train:  [[1] [1] [0] [1] [0] [0] [1]]  x_test:  [[0.0 1.0 0.0 30.0 54000.0] [0.0 0.0 1.0 50.0 83000.0] [0.0 1.0 0.0 40.0 63777.77777777778]]  y_test:  [[0] [0] [1]]</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="We-can-also-use-numpy-method-too">We can also use numpy method too<a class="anchor-link" href="#We-can-also-use-numpy-method-too">&#182;</a></h3><h4 id="I-prefer-the-train-test-splt-method">I prefer the train test splt method<a class="anchor-link" href="#I-prefer-the-train-test-splt-method">&#182;</a></h4><h4 id="!-DO-NOT-RUN-THIS-PART-IF-YOU-ARE-USING-ABOVE-METHOD">! DO NOT RUN THIS PART IF YOU ARE USING ABOVE METHOD<a class="anchor-link" href="#!-DO-NOT-RUN-THIS-PART-IF-YOU-ARE-USING-ABOVE-METHOD">&#182;</a></h4></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[19]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># so that we get the same results</span><span class="n">splt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">0.8</span> <span class="c1">#80, 20 split or random</span><span class="n">x_train</span> <span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">splt</span><span class="p">]</span> <span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">splt</span><span class="p">]</span><span class="n">x_test</span> <span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">~</span><span class="n">splt</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="o">~</span><span class="n">splt</span><span class="p">]</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[20]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x_train: &#39;</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;y_train: &#39;</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="p">,</span><span class="s1">&#39;x_test: &#39;</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;y_test: &#39;</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>x_train:  [[0.0 0.0 1.0 27.0 48000.0] [0.0 1.0 0.0 30.0 54000.0] [0.0 0.0 1.0 38.0 61000.0] [0.0 1.0 0.0 40.0 63777.77777777778] [1.0 0.0 0.0 35.0 58000.0] [0.0 0.0 1.0 38.77777777777778 52000.0] [1.0 0.0 0.0 37.0 67000.0]]  y_train:  [[1] [0] [0] [1] [1] [0] [1]]  x_test:  [[1.0 0.0 0.0 44.0 72000.0] [0.0 1.0 0.0 48.0 79000.0] [0.0 0.0 1.0 50.0 83000.0]]  y_test:  [[0] [1] [0]]</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Feature-Scaling">Feature Scaling<a class="anchor-link" href="#Feature-Scaling">&#182;</a></h2><h4 id="We-have-2-important-parts-in-feature-scaling">We have 2 important parts in feature scaling<a class="anchor-link" href="#We-have-2-important-parts-in-feature-scaling">&#182;</a></h4><ul><li>Standardization <li>Normalization</ul><p>The terms normalization and standardization are sometimes used interchangeably, but they usually refer to different things.</p><p><b>Standardization</b> rescales data to have a mean () of 0 and standard deviation () of 1 (unit variance).Formulae for Standardization is $X_{changed} = \frac{X - \mu}{\sigma} $For most applications standardization is recommended.</p><p><b>Normalization</b> usually means to scale a variable to have a values between 0 and 1, while standardization transforms data to have a mean of zero and a standard deviation of 1.</p><p>Normalization rescales the values into a range of [0,1]. This might be useful in some cases where all parameters need to have the same positive scale. However, the outliers from the data set are lost.Formulae for normalization is $ X_{changed} = \frac{X - X_{min}}{X_{max}-X_{min}} $</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[21]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="n">sc</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><b>We must standardize the data only after the split and the scaler should be only be fitted to the x_train set because if we do that we get the mean and standard of the values in the x_test which should be hidden to us. So we will only fit the scaler to the test set and then we will transform the scaler to x_test</b>&lt;/p&gt;</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h4><b>Do we have to apply/standardization to the dummy variables(Country Column here) to the matrix of features ? <br></b></h4><p><b>Answer is no<br></b></p><p>Simply as the goal of Standardization is to transform your data and get them in the range generally (-3 , +3) But here we have mostly the data in 0s and 1s after we have converted them using ColumnTransformer, OneHotEncoder and LabelEncoder.<br></p><p>And there is nothing extra to be done here. <br>Moreever here standardization will convert the values to -3 and +3 which will worsen out understanding of the data as we will not be able to understand the nonsense numerical values.<br><br></p><p>Feature Scaling on the dataset makes the model better but when we do the same on the dummy variabe it makes the data not redable and we can not relate the country to the salary etc.<br>So feature Scaling should be applyed to the model but not to the dummy variable as they are already encoded before using ColumnTransformer, OneHotEncoder and LabelEncoder.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Transforming-the-non-dummy-values-in-train-set-after-fitting">Transforming the non dummy values in train set after fitting<a class="anchor-link" href="#Transforming-the-non-dummy-values-in-train-set-after-fitting">&#182;</a></h3><h4 id="Therefore-we-should-only-apply-feature-scaling-to-the-non-dummy-values-ie-the-values-that-are-numbers">Therefore we should only apply feature scaling to the non dummy values ie the values that are numbers<a class="anchor-link" href="#Therefore-we-should-only-apply-feature-scaling-to-the-non-dummy-values-ie-the-values-that-are-numbers">&#182;</a></h4></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[22]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_train</span><span class="p">[:</span> <span class="p">,</span> <span class="mi">3</span><span class="p">:]</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:])</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[23]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>[[0.0 0.0 1.0 -1.8060709482255894 -1.5457062438816012] [0.0 1.0 0.0 -1.13807210436133 -0.5878751616074286] [0.0 0.0 1.0 0.6432581459433618 0.5295944343791061] [0.0 1.0 0.0 1.0885907085195348 0.9730347502467791] [1.0 0.0 0.0 -0.02474069792089762 0.0506788932420198] [0.0 0.0 1.0 0.8164430313896515 -0.9071521890321528] [1.0 0.0 0.0 0.42059186465527537 1.4874255166532786]]</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Transforming-the-non-dummy-values-in-test-set">Transforming the non dummy values in test set<a class="anchor-link" href="#Transforming-the-non-dummy-values-in-test-set">&#182;</a></h3><h5 id="As-discussed-we-will-transform-the-test-set-also">As discussed we will transform the test set also<a class="anchor-link" href="#As-discussed-we-will-transform-the-test-set-also">&#182;</a></h5><h5 id="We-will-not-fit-the-test-dataset-as-we-want-that-dataset-to-be-unknown,-Therefore-we-will-only-transform-this-dataset">We will not fit the test dataset as we want that dataset to be unknown, Therefore we will only transform this dataset<a class="anchor-link" href="#We-will-not-fit-the-test-dataset-as-we-want-that-dataset-to-be-unknown,-Therefore-we-will-only-transform-this-dataset">&#182;</a></h5></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[24]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_test</span><span class="p">[:</span> <span class="p">,</span> <span class="mi">3</span><span class="p">:]</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:])</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[25]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>[[1.0 0.0 0.0 1.9792558336718808 2.285618085215089] [0.0 1.0 0.0 2.8699209588242267 3.4030876812016237] [0.0 0.0 1.0 3.3152535214003995 4.041641736051072]]</pre></div></div></div></div></div>    </div>  </div></body>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;
  &lt;div tabindex=&quot;-1&quot; id=&quot;notebook&quot; class=&quot;border-box-sizing&quot;&gt;
    &lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;&lt;p&gt;&lt;b&gt;This Blog Will Be Focusing On The Preprocessing The Data Mostly EDA, Finding Missing Values, Filling and Feature Scaling&lt;/p&gt;&lt;/b&gt;
&lt;p&gt;&lt;b&gt;TABLE OF CONTENTS&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;ul&gt;
    &lt;li&gt; Importing Libraries &lt;/li&gt;
    &lt;li&gt; Creating Dataset &lt;/li&gt;
    &lt;li&gt; EDA on Dataset &lt;/li&gt;
    &lt;li&gt; Find Missing Values &lt;/li&gt;
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Feature Scaling" scheme="https://massivefile.com/tags/Feature-Scaling/"/>
    
      <category term="Data Preprocessing" scheme="https://massivefile.com/tags/Data-Preprocessing/"/>
    
  </entry>
  
  <entry>
    <title>Simple Linear regression</title>
    <link href="https://massivefile.com/simple_linear_regression/"/>
    <id>https://massivefile.com/simple_linear_regression/</id>
    <published>2020-04-26T00:56:53.000Z</published>
    <updated>2020-05-05T23:23:09.145Z</updated>
    
    <content type="html"><![CDATA[<body><i><b>Note - Simple Linear Regression Full Implementation with the dataset EDA and Other Techniques.  You will use use the most basic and the Simple Linear model to predict the car consumption fuel results.Please Download the FuelConsumption.Csv dataset from <a href= "https://www.kaggle.com/anderas/car-consume" target="_blank">Kaggle</a> </i></b><a id="more"></a>  <div tabindex="-1" id="notebook" class="border-box-sizing">    <div class="container" id="notebook-container"><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1><center>Simple Linear Regression</center></h1><p><h4>About this Notebook</h4>In this notebook, we learn how to use scikit-learn to implement simple linear regression. We download a dataset that is related to fuel consumption and Carbon dioxide emission of cars. Then, we split our data into training and test sets, create a model using training set, evaluate your model using test set, and finally use model to predict unknown value.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h1>Table of contents</h1><p><div class="alert alert-block alert-info" style="margin-top: 20px">    <ol>        <li><a href="#understanding_data">Understanding the Data</a></li>        <li><a href="#reading_data">Reading the data in</a></li>        <li><a href="#data_exploration">Data Exploration</a></li>        <li><a href="#simple_regression">Simple Regression Model</a></li>    </ol></div><br></p><hr></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Importing-Needed-packages">Importing Needed packages<a class="anchor-link" href="#Importing-Needed-packages">&#182;</a></h3></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[1]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span><span class="kn">import</span> <span class="nn">pylab</span> <span class="k">as</span> <span class="nn">pl</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="o">%</span><span class="k">matplotlib</span> inline</pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h3 id="Downloading-Data">Downloading Data<a class="anchor-link" href="#Downloading-Data">&#182;</a></h3><p>To download the data, we will use !wget to download it from IBM Object Storage.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[2]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget -O FuelConsumption.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/FuelConsumptionCo2.csv</pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>/bin/sh: wget: command not found</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="understanding_data">Understanding the Data</h2><h3 id="FuelConsumption.csv:"><code>FuelConsumption.csv</code>:<a class="anchor-link" href="#FuelConsumption.csv:">&#182;</a></h3><p>We have downloaded a fuel consumption dataset, <strong><code>FuelConsumption.csv</code></strong>, which contains model-specific fuel consumption ratings and estimated carbon dioxide emissions for new light-duty vehicles for retail sale in Canada. <span class="exturl" data-url="aHR0cDovL29wZW4uY2FuYWRhLmNhL2RhdGEvZW4vZGF0YXNldC85OGYxYTEyOS1mNjI4LTRjZTQtYjI0ZC02ZjE2YmYyNGRkNjQ=">Dataset source<i class="fa fa-external-link-alt"></i></span></p><ul><li><strong>MODELYEAR</strong> e.g. 2014</li><li><strong>MAKE</strong> e.g. Acura</li><li><strong>MODEL</strong> e.g. ILX</li><li><strong>VEHICLE CLASS</strong> e.g. SUV</li><li><strong>ENGINE SIZE</strong> e.g. 4.7</li><li><strong>CYLINDERS</strong> e.g 6</li><li><strong>TRANSMISSION</strong> e.g. A6</li><li><strong>FUEL CONSUMPTION in CITY(L/100 km)</strong> e.g. 9.9</li><li><strong>FUEL CONSUMPTION in HWY (L/100 km)</strong> e.g. 8.9</li><li><strong>FUEL CONSUMPTION COMB (L/100 km)</strong> e.g. 9.2</li><li><strong>CO2 EMISSIONS (g/km)</strong> e.g. 182   --&gt; low --&gt; 0</li></ul></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="reading_data">Reading the data in</h2></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[3]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;FuelConsumption.csv&quot;</span><span class="p">)</span><span class="c1"># take a look at the dataset</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[3]:</div><div class="output_html rendered_html output_subarea output_execute_result"><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>MODELYEAR</th>      <th>MAKE</th>      <th>MODEL</th>      <th>VEHICLECLASS</th>      <th>ENGINESIZE</th>      <th>CYLINDERS</th>      <th>TRANSMISSION</th>      <th>FUELTYPE</th>      <th>FUELCONSUMPTION_CITY</th>      <th>FUELCONSUMPTION_HWY</th>      <th>FUELCONSUMPTION_COMB</th>      <th>FUELCONSUMPTION_COMB_MPG</th>      <th>CO2EMISSIONS</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>2014</td>      <td>ACURA</td>      <td>ILX</td>      <td>COMPACT</td>      <td>2.0</td>      <td>4</td>      <td>AS5</td>      <td>Z</td>      <td>9.9</td>      <td>6.7</td>      <td>8.5</td>      <td>33</td>      <td>196</td>    </tr>    <tr>      <th>1</th>      <td>2014</td>      <td>ACURA</td>      <td>ILX</td>      <td>COMPACT</td>      <td>2.4</td>      <td>4</td>      <td>M6</td>      <td>Z</td>      <td>11.2</td>      <td>7.7</td>      <td>9.6</td>      <td>29</td>      <td>221</td>    </tr>    <tr>      <th>2</th>      <td>2014</td>      <td>ACURA</td>      <td>ILX HYBRID</td>      <td>COMPACT</td>      <td>1.5</td>      <td>4</td>      <td>AV7</td>      <td>Z</td>      <td>6.0</td>      <td>5.8</td>      <td>5.9</td>      <td>48</td>      <td>136</td>    </tr>    <tr>      <th>3</th>      <td>2014</td>      <td>ACURA</td>      <td>MDX 4WD</td>      <td>SUV - SMALL</td>      <td>3.5</td>      <td>6</td>      <td>AS6</td>      <td>Z</td>      <td>12.7</td>      <td>9.1</td>      <td>11.1</td>      <td>25</td>      <td>255</td>    </tr>    <tr>      <th>4</th>      <td>2014</td>      <td>ACURA</td>      <td>RDX AWD</td>      <td>SUV - SMALL</td>      <td>3.5</td>      <td>6</td>      <td>AS6</td>      <td>Z</td>      <td>12.1</td>      <td>8.7</td>      <td>10.6</td>      <td>27</td>      <td>244</td>    </tr>  </tbody></table></div></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><h2 id="data_exploration">Data Exploration</h2>Lets first have a descriptive exploration on our data.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[4]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># summarize the data</span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[4]:</div><div class="output_html rendered_html output_subarea output_execute_result"><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>MODELYEAR</th>      <th>ENGINESIZE</th>      <th>CYLINDERS</th>      <th>FUELCONSUMPTION_CITY</th>      <th>FUELCONSUMPTION_HWY</th>      <th>FUELCONSUMPTION_COMB</th>      <th>FUELCONSUMPTION_COMB_MPG</th>      <th>CO2EMISSIONS</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>1067.0</td>      <td>1067.000000</td>      <td>1067.000000</td>      <td>1067.000000</td>      <td>1067.000000</td>      <td>1067.000000</td>      <td>1067.000000</td>      <td>1067.000000</td>    </tr>    <tr>      <th>mean</th>      <td>2014.0</td>      <td>3.346298</td>      <td>5.794752</td>      <td>13.296532</td>      <td>9.474602</td>      <td>11.580881</td>      <td>26.441425</td>      <td>256.228679</td>    </tr>    <tr>      <th>std</th>      <td>0.0</td>      <td>1.415895</td>      <td>1.797447</td>      <td>4.101253</td>      <td>2.794510</td>      <td>3.485595</td>      <td>7.468702</td>      <td>63.372304</td>    </tr>    <tr>      <th>min</th>      <td>2014.0</td>      <td>1.000000</td>      <td>3.000000</td>      <td>4.600000</td>      <td>4.900000</td>      <td>4.700000</td>      <td>11.000000</td>      <td>108.000000</td>    </tr>    <tr>      <th>25%</th>      <td>2014.0</td>      <td>2.000000</td>      <td>4.000000</td>      <td>10.250000</td>      <td>7.500000</td>      <td>9.000000</td>      <td>21.000000</td>      <td>207.000000</td>    </tr>    <tr>      <th>50%</th>      <td>2014.0</td>      <td>3.400000</td>      <td>6.000000</td>      <td>12.600000</td>      <td>8.800000</td>      <td>10.900000</td>      <td>26.000000</td>      <td>251.000000</td>    </tr>    <tr>      <th>75%</th>      <td>2014.0</td>      <td>4.300000</td>      <td>8.000000</td>      <td>15.550000</td>      <td>10.850000</td>      <td>13.350000</td>      <td>31.000000</td>      <td>294.000000</td>    </tr>    <tr>      <th>max</th>      <td>2014.0</td>      <td>8.400000</td>      <td>12.000000</td>      <td>30.200000</td>      <td>20.500000</td>      <td>25.800000</td>      <td>60.000000</td>      <td>488.000000</td>    </tr>  </tbody></table></div></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Lets select some features to explore more.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[5]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">cdf</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;ENGINESIZE&#39;</span><span class="p">,</span><span class="s1">&#39;CYLINDERS&#39;</span><span class="p">,</span><span class="s1">&#39;FUELCONSUMPTION_COMB&#39;</span><span class="p">,</span><span class="s1">&#39;CO2EMISSIONS&#39;</span><span class="p">]]</span><span class="n">cdf</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[5]:</div><div class="output_html rendered_html output_subarea output_execute_result"><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>ENGINESIZE</th>      <th>CYLINDERS</th>      <th>FUELCONSUMPTION_COMB</th>      <th>CO2EMISSIONS</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>2.0</td>      <td>4</td>      <td>8.5</td>      <td>196</td>    </tr>    <tr>      <th>1</th>      <td>2.4</td>      <td>4</td>      <td>9.6</td>      <td>221</td>    </tr>    <tr>      <th>2</th>      <td>1.5</td>      <td>4</td>      <td>5.9</td>      <td>136</td>    </tr>    <tr>      <th>3</th>      <td>3.5</td>      <td>6</td>      <td>11.1</td>      <td>255</td>    </tr>    <tr>      <th>4</th>      <td>3.5</td>      <td>6</td>      <td>10.6</td>      <td>244</td>    </tr>    <tr>      <th>5</th>      <td>3.5</td>      <td>6</td>      <td>10.0</td>      <td>230</td>    </tr>    <tr>      <th>6</th>      <td>3.5</td>      <td>6</td>      <td>10.1</td>      <td>232</td>    </tr>    <tr>      <th>7</th>      <td>3.7</td>      <td>6</td>      <td>11.1</td>      <td>255</td>    </tr>    <tr>      <th>8</th>      <td>3.7</td>      <td>6</td>      <td>11.6</td>      <td>267</td>    </tr>  </tbody></table></div></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>we can plot each of these features:</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[6]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">viz</span> <span class="o">=</span> <span class="n">cdf</span><span class="p">[[</span><span class="s1">&#39;CYLINDERS&#39;</span><span class="p">,</span><span class="s1">&#39;ENGINESIZE&#39;</span><span class="p">,</span><span class="s1">&#39;CO2EMISSIONS&#39;</span><span class="p">,</span><span class="s1">&#39;FUELCONSUMPTION_COMB&#39;</span><span class="p">]]</span><span class="n">viz</span><span class="o">.</span><span class="n">hist</span><span class="p">()</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Now, lets plot each of these features vs the Emission, to see how linear is their relation:</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[7]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cdf</span><span class="o">.</span><span class="n">FUELCONSUMPTION_COMB</span><span class="p">,</span> <span class="n">cdf</span><span class="o">.</span><span class="n">CO2EMISSIONS</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;FUELCONSUMPTION_COMB&quot;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Emission&quot;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[8]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cdf</span><span class="o">.</span><span class="n">ENGINESIZE</span><span class="p">,</span> <span class="n">cdf</span><span class="o">.</span><span class="n">CO2EMISSIONS</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Engine size&quot;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Emission&quot;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYUAAAEHCAYAAABBW1qbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2de5Qdd3HnPzUP2RoJEB4JVljWDAFjIpNg7AHMKsk6lnkJDnZygDU7YK3xiUDyZg0sAbzeDSFZ5ZDHBszuSqDgh4wmOCyQxcdoIX4mCzEQ2cjGsmAtsGQLa7EE2FjI2Eiu/aP7zvT0dN9+3O7bd2a+n3P63L7Vj1v3SvOr/lXVr8rcHSGEEAKgr2kFhBBC9A4yCkIIISaRURBCCDGJjIIQQohJZBSEEEJMIqMghBBikoE6b25m+4DHgePAMXcfM7OTgL8FRoF9wFvd/admZsCVwFrgKPBv3f2udvdfunSpj46O1qa/EELMRe68887D7r4s6VitRiHkt939cOT9h4Bb3P2jZvah8P0HgdcDp4bbK4Et4Wsqo6Oj7Ny5sx6thRBijmJm+9OONeE+Oh/YFu5vAy6IyK/zgG8AS8xseQP6CSHEvKVuo+DA35vZnWa2PpQ9190PAoSvzwnlJwMPRa49EMqEEEJ0ibrdR6vd/WEzew5wk5l9t825liCbUYMjNC7rAVauXFmNlkIIIYCaZwru/nD4+gjwd8ArgB+13ELh6yPh6QeAUyKXrwAeTrjnVncfc/exZcsS4yRCCCFKUptRMLNFZvaM1j7wGuBe4AZgXXjaOuBL4f4NwEUWcDbwWMvNJIQQojvUOVN4LvA1M7sb+BbwZXf/CvBR4NVmdj/w6vA9wA7gB8Be4K+BjTXqJoSYZUxMwOgo9PUFrxMTTWs0N6ktpuDuPwBemiD/MbAmQe7ApXXpI4SYvUxMwPr1cPRo8H7//uA9wPh4c3rNRbSiWQjR81xxxZRBaHH0aCAX1SKjIIToeR58sJhclEdGQQjR86RlnysrvXpkFIQQPc+mTTA0NF02NBTIRbXIKAghep7xcdi6FUZGwCx43bpVQeY66EZBPCGE6JjxcRmBbqCZghBCiElkFIQQQkwioyCEEGISGQUhhBCTyCgIIYSYREZBCCHEJDIKQgghJpFREEIIMYmMghBCiElkFIQQQkwioyCEEGKS2o2CmfWb2bfN7Mbw/bVm9oCZ7Qq3M0K5mdknzGyvmd1jZmfWrZsQQojpdKMg3mXAHuCZEdkfuPvnY+e9Hjg13F4JbAlfhRBCdIlaZwpmtgJ4A/DpHKefD1znAd8AlpjZ8jr1E0IIMZ263UcfBz4APB2TbwpdRB8zsxNC2cnAQ5FzDoQyIYQQXaI2o2BmbwQecfc7Y4cuB14MvBw4Cfhg65KE23jCfdeb2U4z23no0KEqVRZCiHlPnTOF1cCbzGwfcD1wrpltd/eDoYvoSeAa4BXh+QeAUyLXrwAejt/U3be6+5i7jy1btqxG9YUQYv5Rm1Fw98vdfYW7jwIXAre6+9tbcQIzM+AC4N7wkhuAi8IspLOBx9z9YF36CSGEmEkT7TgnzGwZgbtoF/DuUL4DWAvsBY4CFzegmxBCzGu6snjN3W939zeG++e6+6+5+0vc/e3ufiSUu7tf6u4vCI/v7IZuQojZwcQEjI5CX1/wOjHRtEZzE61oFkJksnEjDAyAWfC6cWN3P39iAtavh/37wT14Xb9ehqEOZBSEEG3ZuBG2bIHjx4P3x48H77tpGK64Ao4enS47ejSQi2ox9xlZn7OGsbEx37lTXiYh6qSvL3g6j2MGT8dXIM1hHeYSZnanu48lHdNMQQjRlrTnxm4+T65cWUwuyiOjIIToeTZtgqGh6bKhoUAuqkVGQQjR84yPw9atMDISuIxGRoL34+NNazb3kFEQQrRlw4Zi8roYH4d9+4IYwr59Mgh1IaMgxCyn7vz9zZsDA9DfH7zv7w/eb95c/p5ac9C7yCgIUTN15vgn5e9ffDEsXVrtgLt5Mxw7FnzGsWOdGwStOehdlJIqRI20cvzjdPqk3WJ0NBhU2zE01Fv+9zSdR0YCt5Con3YpqTIKQtTIwMDUoq8o/f3BE3enpOXvx+mlAVdrDppH6xSEaIgkg9BOXpS8efoPPtjZ52S5wIrECLTmoLeRURCiRiypdVQbeVGS8veT6GTAzSpzUTRGoDUHvY2MghA1UsVq4HZP6fH8/eFhWLBg+vWdDrif/GR7edG6RFpz0NvIKIh5TdPVP7PIU4wumr9/+DBccsn09NF16zobcLMMW5prqp3LSmsOehcZBTFv6Ub1z9bgnFceZ+vWYvKJCdi2bfp32rat3nRPxQjmFjIKYt5SdMAtw/r1xeRxigaqmygxrRjB3KJ2o2Bm/Wb2bTO7MXz/fDP7ppndb2Z/a2YLQvkJ4fu94fHRunUT85u6M4Og89XARWcaZVw5WWSVuRgfD1xUVbqsRHN0Y6ZwGbAn8v7PgI+5+6nAT4FLQvklwE/d/YXAx8LzhKiNTl07eelkNXDRmUYdrpwsw9aEy0rUR61GwcxWAG8APh2+N+Bc4PPhKduAC8L988P3hMfXhOcLUQuduna6werVQQA8ysBAIE8izZWzdm1ntYbaGTZ1RZtb1D1T+DjwAaC1TnEYeNTdW2s5DwAnh/snAw8BhMcfC88XohbqKPRWNVdcMXPl87Fj0wfc6MKxK64IXDfRdM9164In97pqDdXhshLNUZtRMLM3Ao+4+51RccKpnuNY9L7rzWynme08dOhQBZqK+UyVhd7qIGvATVo4tm1bMGNopXvu2FHvk7yyj+YWdc4UVgNvMrN9wPUEbqOPA0vMrDUhXgE8HO4fAE4BCI8/C/hJ/KbuvtXdx9x9bNmyZTWqL0TzZA24eVw3dT/J15V9dPrpwWyntZ1+emf3E/mozSi4++XuvsLdR4ELgVvdfRy4DXhzeNo64Evh/g3he8Ljt/psrtYnRAVkDbh5Bvy6n+TrWKF8+ulw333TZffdJ8PQDZpYp/BB4H1mtpcgZnBVKL8KGA7l7wM+1IBuQvQUWQNungG/G+sIql6hHDcIWfL5QldW4Lv7rN3OOussF6JJtm93HxlxNwtet2/v/ucPDbkHEYVgGxqaqUfTehYl+n3i23xlw4bk32PDhuL3AnZ6yriqFc1ClKQXOojldd3En+RB7TBnG91YgQ8qcyFEaWZrfn4dxqzqoPCqVcXk84FurMAHGQUhStNUfn508DWDt789e4CPrmVYt664MTvvvOmfed55U8fqCArv3j3TAKxaFcjnK91agS+jIERJmsjPz7PGPz7Ax2cGaU+Wab2ezzsPbrlluuyWW6YMQ11B4d27p3vP57NBgO6twJdREKIkvVwdNDpbSXJzJZH2xBk3CFlyUQ/dWoEvoyBESXq5g1h0tpLXnVW1b1pUTzdW4MsoCDHHiM9W8rqzRkbq0UfMLmQUhChJL6SkRkmbrSS5uZJYuzZZvmZNMbmY3cgoCNGGaNZOPJ+/iZTUdv2S01YTx91cabGDHTuS5TffPNMArFkTyKF7WTGiO8goCJFC1kygqZTU+JrWDRuySx9EF689/fTM49Be75tvnv6ZLYMA1WXFdKWEg8gmbanzbNhU5kLUychIclmBkZHg+PBw8vHh4Xr12rDBvb+/fSmIdqUPsr5XGdasmX6vNWuKf6eqSjiIbFCZCyGK04vNYzZuhC1bsjOFtmxJL2FRdSrtxATcccd02R13TP/cdm446F4JB5GDNGsxGzbNFESdZD1RmyUfN6tWj2gxu3azg7St7gJ5ab9Tf39w/+Fh9wUL2uukAnjdBc0UhChO1hN1WqrnSSdVV2wuHtcow9GjcNll03WC9qWu25W1iJO2Evr48UDnH/8Ynnpqpk7RgLyC1T1EmrWYDZtmCqJu2j1RJ5WtHhzMfiouQtpTeKdbO53i8YGsOEFZHaIzqqKfKTqDNjMF87KPHz3A2NiY79y5s2k1xDxmYiJ44n3wwWDmcORI8GQcZ2RkqmR1Efr6ys8QsujvD2YKK1cGs5/WbCGrvlJ/fzB7aa2mzVOPKYnobzI6mjzjKPu7ifaY2Z3uPpZ0TO4jITog3qfgJzO6ige0C063S8Wss7hey72zfz+885353VzHjweB7JaeZVw88cB2Lwb15yu1GQUzO9HMvmVmd5vZbjP7SCi/1sweMLNd4XZGKDcz+4SZ7TWze8zszLp0E6IuFi0qJo9nE8UH3Be+sHodk3jqqSDuUIRWZtBpp2WfOzgIw8Ppq66bqDgrkqlzpvAkcK67vxQ4A3idmZ0dHvsDdz8j3HaFstcDp4bbemBLjboJUQnxVMsjR5LPS5NnpWLefnuHChag5fbKW76iZcj27Ek/p2UErrkGDh9OD2z3csXZ+UZtRiGMZ7T+FAbDrZ139HzguvC6bwBLzGx5XfoJ0SlJK56LktVNq916hFY4dvv27BIWw8NT52SRVNYiidZntYt5pBmBOL1ccXa+UWtMwcz6zWwX8Ahwk7t/Mzy0KXQRfczMTghlJwMPRS4/EMqE6BpFSi3k7VPQjqxUzDypml//Ohw4EAzOTz8d6B1laAiuvHIq9jE8nHzPqDxa1mLDhuTzq27uEo/PyCA0Q61Gwd2Pu/sZwArgFWb2EuBy4MXAy4GTgA+Gpyc9w8x4BjGz9Wa208x2Hjp0qCbNxXwky78fp8zMIE6aP74lTxt4jx+fWkMQ1dk9qLO/ePH0J26YcnPBTGMzOBgYjiSymruceGLydWly0dt0LSXVzD4M/Nzd/zIiOwd4v7u/0cw+Bdzu7p8Nj30POMfdD6bdUympokoGBpLdNf39wUCb9/wk+vrS751UoC56/saNwcBepAlOVOeWmys6qxkchGc+M8iWiqekFmXp0uQ03OHhII4geo9GUlLNbJmZLQn3FwLnAd9txQnMzIALgHvDS24ALgqzkM4GHmtnEISomiz/fl55EmmVSfPIo9228hLVLcnN9ctfBgO5e+B6+vrX8987Tloabppc9DYD2aeUZjmwzcz6CYzP59z9RjO71cyWEbiLdgHvDs/fAawF9gJHgYtr1E2IGfT3pw/0rQDtqlVTDeRHRvK7kLrd1SzqHsrK9W+5yaBce8e0mZRKVMxO6sw+usfdX+buv+7uL3H3Pw7l57r7r4Wyt7cylMKso0vd/QXhcfmFRO1EA8t5nvzvuw9OPz3YT0qj7Ev5i+rWeoMW0VhE3lz/shVJkwxCO7nobbSiWZQmqxxyr+uQVoY6K23zvvuC16Q0yjQXT1XrDZYsaX88HgSG/O04i7jDxBwmrSjSbNhUEK85korBdVL4rQkd0hrV9PcHx8uUcy56TdHzyzajyVN+u/W9i6Ky17MPVBBPVE0vFDDrVId2MwL37ONJFM1gKvoZRe+fRGuGFCc+w8hLmd9JNEvH2UdhJtF/NLOtZnZ1a6tWTTGb6IUCZp3qkLUwbNWq5ONRedx9dc45yddUtdCrikyo1atnxj76+gJ5GdIWt6XJRW+TN6bwJeBZwM3AlyObmKf0QgGzPDq0izlkNZzfvXumYYhmHyWVubjjjpnXrFmT/gSe9pSdJq+iGc0VV8xMhX366elNb+L0QvxIdIk0v1J0A3blOa/bm2IKzTEbYgp5dNywYSq20N9frFF8WgOcuN++3e/SrZhClKJtRLN+x6zYjOg9aBNTyGsU/guwNs+53dxkFJqlkwG1Ktp1Rsvqsdzp/Yv0TE77zDI6dvq7F/3MrPMVaJ59tDMKed1HlwE3mtkvzOzxcPtZLVMXMSuYmIBt26bXCdq2rbfcCp3GHJLcQ+vXT33HIq6ytM8sUzI6usL52LHiweG1a4vJs37Hoi4w0eOkWYvZsGmm0BxVPIV3SpZbY9GiZB0XLcp3/6zvuH37zH7M7dI9k2Yb7t2fcTUxU2g34xLdh07dR8E9eBPwl+H2xrzX1bnJKDRHUb90HooOHHW7NbKu377dfXBwuryvL9tQxOMe8XsMDrb/7knnF6HqmEKe3yn+mWYyDE3SsVEAPgrcArwz3G4CPprn2jo3GYXmqHqmUCZwnTW41W0U0n6D4eEp45YWhG39TsPD6fdIIm4QyhiGMv927Qx21u+UZiQXLMivs6iWKozCPUBf5H0/cE+ea+vcZBSao+rso7SBqp3bpemZQp4n7qx7FNWx0+/knuz2WrCg/L9d3cZZVE87o1Ck9lG06sqzykcxxFyg6vaJacHM48eD4SMe5IXm+/rmWSdRxbqCOgie7dLfF+Hd7y4mFz1OmrWIbsDbgP3AtcA24AHgwjzX1rlppjB3SHvqz3JxdOLWyCLr+jyzpSZmClmB6zqSBNp9pmYKvQcVBZqXEwSbzwf+Rd7r6txkFOYO27cHQdo8hiFvpk4e9047o7JqVfL1q1blu969ehdXVkwhz+K2OpIE2rFmTfLnrVlTz+eJbEobBeDF4euZSVu7a7uxySjMHdIGszxbmmFYvDj5/MWLg+N5fOtxwxA1CHnoNHMniXbZR2mGta8v/+9SB3HDIIPQLJ0Yha3h620J263tru3GJqPQLFXmnqdl6eSdOSSRNeAWzfzJS/x32bChPhdX0e/s3n4lttYRzA8qcR8V3YATgW8BdwO7gY+E8ucD3wTuB/4WWBDKTwjf7w2Pj2Z9hoxCc1SdfVTWILQbQOvol5BF0d+lCaOQ5/fsdh0r0V3aGYW8pbPfYmbPCPf/k5l90cxelnHZk8C57v5S4AzgdWZ2NvBnwMfc/VTgp8Al4fmXAD919xcCHwvPEz1KUjP4o0fbV9psRyfZOGnXVlFmuihV/y5FyVNyIs9v3U2dRW+RNyX1P7v742b2G8BrCTKQPtnugtAgHQnfDoabA+cCnw/l24ALwv3zw/eEx9eYqXpKr5LWsD5vI/s4nfQbSLt28eL28uHh5ONp8jykpdbu319d2eloX+mBgeB9i2DSPZOoPK3nQ5xu9sYQvUNeo9B6tnoDsMXdvwQsyLrIzPrNbBfwCMEq6O8Dj7p7q0fUAeDkcP9k4CGA8PhjQAd/nqJOqs6/T2r8ksTixVOf0d8f9CrYsSN5wP35z5Pv0ZJfeSUMDk4/NjgYyPMSH6AXLUo/1z0wDhdfXN4wxPtKHz8evI8ahiz27s13Xjd7Y4geIs2vFN2AG4FPEQzqSwj8/3fnuTa8fglBcPo3gb0R+SnAd8L93cCKyLHvA8MJ91oP7AR2rly5sg53m8hBHt91kUB03nUKMHXP4eGZ2UNFM3s6CZanZUwNDGR/h1Ywu5txkqwezZ3EFFTwbnZBBWUuhoDfBU4N3y8HXpPn2sg9Pgz8AXAYGAhlrwK+Gu5/FXhVuD8Qnmft7qlAc3NkZe5UGXAtulVZ53/hwunXLVw4dSxtgG4NjFkDcJ7fscjvVMXvWGZQL1PUTzRLO6OQ1320HPiyu99vZucAbyHILEol7Ou8JNxfCJwH7AlnDG8OT1tH0OoT4IbwPeHxW0PlRQ/y6KPt5U0GXDvxhUfdQWbwxBPTjz/xxFRpjbSAtTvs2zez5WUSv/hFMXndPP10oHuRciWXXQa//OV02S9/GcjF7COvUfgCcNzMXghcRZBW+jcZ1ywHbjOze4B/Bm5y9xuBDwLvM7O9BDGDq8LzrwKGQ/n7gA8V+iZzjKp74rYLTpYhK7On0wY3nVDWFx7316fRMhRVxFWy4h6zgR//uJhc9DhpU4joBtwVvn4A+P1w/9t5rq1zm6vuo6rXAFTR1zdOlhujaH2dqlxHnawWLrKALu/v2om7p8zv3unvV4aq7yfqhwpiCt8kKIp3L/D8UHZvnmvr3OaqUai6YFkdjdWzBoJuxxSqWC1cZvDMKj6XFTOo2iik/d/JE2AuW3qirpXhoj7aGYW87qOLCYLCm9z9ATN7PrC9uvmKiFK166WJRVxVl9bOoowvvCwLF07tr14NK1YE33HFiuB9lCrSXqNs2NBenlZO/Nxzp6fyPu95089ZswZuvrmcTldeCQtiCeoLFpT/jqJh0qzFbNjm6kyh6ievPEXSilK1y6CT2kdpn1n0d8zzNB39zfLOhtqla5apIJo1O0mqvVSlOzIJpaTOLuigIN7nwtfvEHRfa23fQZ3XaqNqo9BpA/skqjYKnRiEtM8sOuDm/azWIJynHWfWAFlHvCdOHf0TxOymnVGw4HgyZrbc3Q+a2UjKLKNkUYNqGBsb8507dzapQi309QV/tnHM8qU51n2/1rVptPkvlcozngFHjmSfV+QzBwaSXWT9/XDsWP7z065P+13jDA2lu86K6ghBltTWrcF1/f1BmY/Nm9M/v45/fzG7MbM73X0s6VjbmIK7Hwxf94cG4KfA45FN1ECeNo9N3q8O6kjBLBpLyVt/qXV93t+v3fqMojqWKXPRjX//qlOoRYOkTSGiG/Au4EfAPoJWnA8AP8hzbZ3bXHUfVd1YvQrfd5xecx+1tmgTnDJZV1F/fdrWuj7pdy36uxTVscx3qjrFudv3F9VDBSmp9wNL85zbzW0uG4WqywZkDfhFP7OMUSjbT7msYSjjr48ahbTAc/T6+HdKC+qnDdpFdSxrjOsMBCtmMfuowih8BRjKc243t7lqFJr4I6u6Bk+cTtpSltlaZGXqRMlqCZp1fZnfpaiOdaw56ZRu93wWndPOKLQNNLcIG+pcQ7CI7cmI6+nfV+bHKoECzdVRNHCc5/yJicCX/uCDwXdK8pOPjATrC6runJHjv/UMqgieL16cHB9ZtKizQHqL00+H++6bKV+1Cnbv7vz+ZRgdTe6j0fq3Fb1H6UBzhE8BtwLfAO6MbKIG4ouPsuS9yMREELjdvz8YUNMCp2Wb8vQq8SKAWfKifO97xeTdIG3B3KZNzegjOiOvUTjm7u9z92vcfVtrq1WzeUy8MmeWvAqq7kKWVCU1iU7acKaxalX198xL2oyi3UyjSOZOE6vTs+j26nVRL3mNwm1mtt7MlpvZSa2tVs3mMWkuojpzyqsuVZB3BlD1YNaJGyVPf+OqmZgIOrG1ZlRZndmq7nhXFePjU+XCu1VuRNRDXqPwb4DLgX9iynU095z5c4j40+fGje2fRsfH4eqrpz/tXX11+T/uvINUJ/2Qo7TCm3GDUOQp/N3vLiavgqK9CNLWUnTS41qIaaRFoGfDNlezj8qmHbbIkz/f19dZWmKWjnmzhPJUC82zJaValsmfL5IJVOZ36fT8KnSsA9U+ml3QQe2jD0T23xI79qftru3GJqOQTN5+x3XWPkrL1+/UiGRt0UV+TaT2dsMo9BpavDb7aGcUstxHF0b2L48de11FkxURo9Ogb15/fp3dvYrEP/ryOjFz8NRTU66XJrq/Ff23qzrA3wRNtl4V1ZP152gp+0nvpx80O8XMbjOzPWa228wuC+V/ZGY/NLNd4bY2cs3lZrbXzL5nZq8t9E3mEPOtPn0w8ayOVhvIJmo+Ff23mwv/1k22XhU1kDaFCGYYQRvO+H7S+4RrlwNnhvvPAP4vsAr4I+D9CeevAu4GTiDoAf19oL/dZ8xV95F7Zz7avK6WeD+FKmsf5elNUOfW+j5NuDWK/tvNdn+8ylzMPmjjPhrIsBkvNbOfEcwKFob7hO9PzDA2B4FWldXHzWwPcHKbS84Hrnf3J4EHzGwv8ArgjgwdRUne9a6p/dZis5YbYP/+qYyWMhlIVT/9l6Gld2tV9cqVwYKqutMlx8eLfUbR83uNTZum/98BLV6b1aRZiyo3YBR4EHgmwUxhH0GznquBZ4fn/Hfg7ZFrrgLe3O6+c3WmsH37zCdts/xPkFlP0UkZK0Wf9rKe0tNqKXVzpjBfaWLmMdtnO/MNOq191Almthj4B4L+zl80s+cChwEH/gRY7u7vNLP/Adzh7tvD664Cdrj7F2L3Ww+sB1i5cuVZ++danQTghBOCgGmcBQvgySdnyuOUqeFTtN5S1mcsXTrl22+CXpipNEF8xgftm/yI+UkVtY/KfvAg8AVgwt2/CODuP3L34+7+NPDXBC4igAPAKZHLVwAPx+/p7lvdfczdx5YtW1an+o2RZBDayaug6qDsT35SXhdRHmUCiU6pzSiYmRG4gPa4+19F5Msjp/0OcG+4fwNwoZmdYGbPB04FvlWXfmI6VRc1O0lFUBpBmUCiU+qcKawG3gGcG0s//XMz+46Z3QP8NvBeAHffDXwOuI+gf8Ol7t5gma+5iVnQFzjevrFbRc36+uqtJTTfmQ2tV0Vvk5V9VBp3/xrJaxl2tLlmE6CchZpp9fWF9g3f23HiifCLXyTLId195B7EKOo0DLNp4VfVKBNIdEqtMQXRDHlLR2/dOrU/MQEXXTS9WudFF6UXkPuVX2kvb+qJdXBwdi38qhqVsRadIqNQA0Uqc9ZBUmeuJKJlq9/1rplZRk8/PX0tQ57PaMnXrk0+nibvhMWLpwbAa67RAKgy1qITanMfzVeqXgQWp6+vnkVYaXWQytZH2pHiJEyTd8ITT9Tba0KI+YRmChVTd0pgy7Wzfn3nM5A6/frdzIJpsuuYEHMNGYWK6dZgWIWhqXOBVzdjCk13HRNiLiGjUDHdHAx7Ofc8a91DlQO5uo4JUR0yChXTzQBrL+eeZ2XBnHZa+Xu3DEp/P2zYUD6tVggxk9prH9XJ2NiY79zZW62i02r+DA/D4cP57pHH19+unk2RWEHrn7/q2kdZDAyUiwXkrf8khEinsdpH85G0InBVFYerK/e8203rywaHf/M3q9VDCDEdpaTOMupKvWy5YLZuDQbs/v7AV1+Xa6a/v5xhuP32ylURQkTQTKEhNm4MXChptYiaYPNmOHYscP8cO1avr75scFjpp0LUi2YKFWOW7ptvsXHjVO0hqKYWUbfJ8z3bEZ+Z5EXpp0LUi2YKJWhXxiItyBqVR2sORUmTd4sis5df/dVi8iSiM5PnPS/fNUo/FaJeNFMoSBVlLNKejJt0jRSdvezZk3yfNHkWg4Ptj9cd4xBCBCgltSCjo4EhiDMyEhQfy5OqmZaO2d8fPDl3mu5ZJiU1S6cin1Hmv1TV9xNCpKOU1ApJawldpFX0OecUk9fFwoVT+03PXtJiBYohCNFdZBQKUsXgtWtXMXldPPHE1H7R77V4cTF5Fk0bJSFEQJ09mk8xs3fefC4AAA/QSURBVNvMbI+Z7Tazy0L5SWZ2k5ndH74+O5SbmX3CzPaa2T1mdmZdunVCFYNX3QvcypAWwE2Tf/KTgcspysBAIC/DyEgxuRCiHuqcKRwD/oO7/ypwNnCpma0CPgTc4u6nAreE7wFeD5wabuuBLTNv2TyzYfBasqT4NZs3B3WE8tYVGh+Ha6+dXtvo2mvLr7LuZs0oIUQ6tRkFdz/o7neF+48De4CTgfOBbeFp24ALwv3zges84BvAEjNbXpd+ZZkNg9ejj5a7rujitSo7fHWzKY8QIp2uxBTMbBR4GfBN4LnufhACwwE8JzztZOChyGUHQllPkTZIbd0arFsQ5ehmUx4hRDq1D2Nmthj4AvAed/9Zu1MTZDOSEc1svZntNLOdhw4dqkrN3KRlGR0/3p3Uyab6PtdNN/tQCCHSqdUomNkggUGYcPcvhuIftdxC4esjofwAcErk8hXAw/F7uvtWdx9z97Fly5bVp3wKTadIVtmOs5fIasojhOgOdWYfGXAVsMfd/ypy6AZgXbi/DvhSRH5RmIV0NvBYy83US/RKimSVfZ/L0q7cR1HGx2HduumB7nXrqi0PLoTIps6ZwmrgHcC5ZrYr3NYCHwVebWb3A68O3wPsAH4A7AX+GuiBuqG9TZq/fdGifNcXWfkcp1XuY//+amYvExNBOmvL6B4/HryfS7MhIWYDKnNRkE4G0tZPnVXSIe9ntEprxDnvPLjlluzrFy2CI0fyfVacrHIfRTnxxOSOaiecAL/4RfH7CSHSUZmLOUg7f/utt+a7x89/Xv7zq84WSmuxqdabQnQXGYVZRp52nN2Y/ClbSIi5iUpnzzLqasdZlE2bppcQB2ULCTEX0ExhDtJJ3CMv4+PBbCVa5qLd7CWLNWuKyYUQ9aBAc0GaDjRX2U9heBgOH853bjeIB8jXrIGbb25OHyHmKgo0zzPyFud761vr1aMoL3rR9HUKL3pRs/oIMR+RUZiDJK0OTuK66+rXJS+tdqDRdQpbtrTvEy2EqB4ZhTlI3N+fRicpqVWzdWsxuRCiHmQU5ijRstazAXVeE6I3kFFogLQyFC151Zk4abOFbmQpCSFmFzIKXSLaDS1rkN67N/l4mlwIIapCRqFLPOtZU/tp9YZa8rSeDWnyLNLSWHspG3k2tDkVYj4go9Al1EGsPeqnIERvIKOQwMaNMDAQuHMGBqpJizzppM7vMZepeoW0EKIcqn0Uo5Uv36KVLw/Zjex7lTVrkktp91oJifFxGQEhmkYzhRhZ+fLDw+Xu+5OflLuuCm6+eaYBUAkJIUQSMgoxsvLly5aGaLqk9M03B4Hl1iaDIIRIos4ezVeb2SNmdm9E9kdm9sNYe87WscvNbK+Zfc/MXluXXtC+t3Cr9k6clnzHjuKfNzg4PWCalZK6YEHy8TS5EEJURZ0zhWuB1yXIP+buZ4TbDgAzWwVcCJweXrPZzFKG587I6i28fn3ydS15mSyiuBHIShG9+uqZ15gFciGEqJPajIK7/yOQ15N+PnC9uz/p7g8Ae4FX1KHXFVdMbwwDwfsrrgj2N2+GDRumV+vcsGEqyJzmBurvDwbupJnGU09N3R+yc/LHx+Ezn5meifOZzygIK4SonyZiCv/OzO4J3UvPDmUnAw9FzjkQyionT2/h1athxYpgQF6xInjfIi2fftu2oM5QWq2h6P3z5ORHaxft2yeDIIToDt02CluAFwBnAAeB/xrKk7zsiU4WM1tvZjvNbOehQ4cKK5BWUrolz3IvJeXTr1sXzAT6+oItiegMI09Ofru4Rx46vV4IMU9x99o2YBS4N+sYcDlweeTYV4FXZd3/rLPO8qL09UVzcKa2vr7g+MhI8vH+fnez4Pj27VP3277dfWgo+ZrWNjQ0/Zosku5Z5B7bt7svWDD9+gULiukghJi7ADs9ZVyttR2nmY0CN7r7S8L3y939YLj/XuCV7n6hmZ0O/A1BHOF5wC3Aqe7etnBymXacWa0u+/qyawINDU092Y+OJtck6u8PXD8rVwZuoSLun7R7jowErqQsli6FH/94przX2m8KIZqhkXacZvZZ4A7gNDM7YGaXAH9uZt8xs3uA3wbeC+Duu4HPAfcBXwEuzTIIZclKOc2zniAamE6LUbTiC2XiAXniHu1IMggteZWlO4QQc486s4/e5u7L3X3Q3Ve4+1Xu/g53/zV3/3V3f1Nr1hCev8ndX+Dup7n7/65Lr6yU07Vrk4/HaQ3QaUakk8VqaXWSqqqfpFaXQog05t2K5qyU07yL01qDfpoRyWtc6iBvKQ61uhRCxJl3RgECA3DsWBA7OHZseqG7PC6aaPpomhEps/K5RVqdpLz1k668MlhFnYVaXQoh4sxLo9COrMVp8fTRTv3/RXTI65IaH4drrplKeU0jLb4ihJi/yCjEyFqcFg8clx3A260jqKLhTHTxW1qJ7HPOyX8/IcT8QEYhRtFmL2UG8DIL5DppOKOez0KIvMgoJFCkxESZATyr/lLV1OHiEkLMTWQUShB3/UCxOkVJC9Oi8qyZRFHqSJsVQsxNZBQKUsWAnbWAruqZRBUxCiHE/EBGoSBVDNhZ3d2qdvdUHaMQQsxdBppWYLZRxYA9MpJe2wgCt07S8U7cPePjMgJCiGw0UyhIFf75LHeO3D1CiKaQUShIVWsI2rlz5O4RQjRFraWz66ZM6ewqmJgIYggPPliuNLYQQjRJI6Wz5zJVtMrM6oymzmlCiCaQUaiAogN4Vlpr1esUhBAiL3IfdUhrAI+mqUY7syWR1Vmt085rQgjRjnbuIxmFDikzgKe1/DQLXFJZx4UQohOaasd5tZk9Ymb3RmQnmdlNZnZ/+PrsUG5m9gkz22tm95jZmXXpVTVl1i1kpbWqLIUQoinqjClcC7wuJvsQcIu7nwrcEr4HeD1waritB7bUqFellBnAtU5BCNGr1Nmj+R+BeK+w84Ft4f424IKI/DoP+AawxMyW16VblZQZwLVOQQjRq3S7zMVz3f0ggLsfNLPnhPKTgYci5x0IZQe7rF9hWgN10XULWWUnVJZCCNEEvVL7KKlpZGIE3MzWE7iYWNkjTnYN4EKIuUK31yn8qOUWCl8fCeUHgFMi560AHk66gbtvdfcxdx9btmxZrcoKIcR8o9tG4QZgXbi/DvhSRH5RmIV0NvBYy80khBCie9TmPjKzzwLnAEvN7ADwYeCjwOfM7BLgQeAt4ek7gLXAXuAocHFdegkhhEinNqPg7m9LObQm4VwHLq1LFyGEEPlQ7SMhhBCTzOoyF2Z2CEgoMpGbpcDhitSpC+lYDdKxGqRjNTSt44i7J2bqzGqj0ClmtjOt/kevIB2rQTpWg3Sshl7WUe4jIYQQk8goCCGEmGS+G4WtTSuQA+lYDdKxGqRjNfSsjvM6piCEEGI6832mIIQQIsK8NApJDYB6CTM7xcxuM7M9ZrbbzC5rWqc4ZnaimX3LzO4OdfxI0zqlYWb9ZvZtM7uxaV3SMLN9ZvYdM9tlZs22E0zBzJaY2efN7Lvh/81XNa1TFDM7Lfz9WtvPzOw9TesVx8zeG/7N3GtmnzWzE5vWKcq8dB+Z2W8BRwh6OLykaX3ihMUCl7v7XWb2DOBO4AJ3v69h1SYxMwMWufsRMxsEvgZcFvbD6CnM7H3AGPBMd39j0/okYWb7gDF379n8ejPbBvwfd/+0mS0Ahtz90ab1SsLM+oEfAq90907WMlWKmZ1M8Leyyt2fMLPPATvc/dpmNZtiXs4UUhoA9QzuftDd7wr3Hwf2EPSX6BnChkhHwreD4dZzTxhmtgJ4A/DppnWZzZjZM4HfAq4CcPenetUghKwBvt9LBiHCALDQzAaAIVIqQjfFvDQKswkzGwVeBnyzWU1mErpldhGUQL/J3XtOR+DjwAeAp5tWJAMH/t7M7gx7hvQavwIcAq4JXXGfNrNFTSvVhguBzzatRBx3/yHwlwQFQQ8SVIT++2a1mo6MQg9jZouBLwDvcfefNa1PHHc/7u5nEPS/eIWZ9ZQrzszeCDzi7nc2rUsOVrv7mQT9yi8NXZy9xABwJrDF3V8G/JypHus9RejaehPwP5vWJY6ZPZug/fDzgecBi8zs7c1qNR0ZhR4l9NN/AZhw9y82rU87QjfC7cDrGlYlzmrgTaG//nrgXDPb3qxKybj7w+HrI8DfAa9oVqMZHAAORGaDnycwEr3I64G73P1HTSuSwHnAA+5+yN1/CXwR+JcN6zQNGYUeJAziXgXscfe/alqfJMxsmZktCfcXEvxn/26zWk3H3S939xXuPkrgTrjV3XvqqQzAzBaFCQWELpnXAD2VGefu/w94yMxOC0VrgJ5JfIjxNnrQdRTyIHC2mQ2Ff+drCGKGPcO8NAphA6A7gNPM7EDY9KeXWA28g+DJtpVet7ZppWIsB24zs3uAfyaIKfRsymeP81zga2Z2N/At4Mvu/pWGdUri94GJ8N/8DOBPG9ZnBmY2BLya4Am85whnWp8H7gK+QzAG99Tq5nmZkiqEECKZeTlTEEIIkYyMghBCiElkFIQQQkwioyCEEGISGQUhhBCTyCiIeYOZHY9V0Sy9ItfM/qlK3WL3HjOzT9R1fyHaoZRUMW8wsyPuvrhpPYToZTRTEPOesJfBR8zsrrCnwYtD+TIzuymUf8rM9pvZ0vDYkfD1HDO7PdJnYCJcqYqZnWVm/xAWuftqWBI9/tlvCevq321m/xi5543h/o7IzOYxM1sXFiL8CzP7ZzO7x8ze1a3fSsx9ZBTEfGJhzH30ryPHDocF6bYA7w9lHyYojXEmQT2ilSn3fRnwHmAVQTXR1WHtqv8GvNndzwKuBjYlXPuHwGvd/aUERdym4e5rw6KDlwD7gf8V7j/m7i8HXg78npk9P//PIEQ6A00rIEQXeSIcYJNolUW4E/jdcP83gN8BcPevmNlPU679lrsfAAhLiY8CjwIvAW4KJw79BKWS43wduDZstpJYmiGcnXwGeKu7P2ZmrwF+3czeHJ7yLOBU4IEU/YTIjYyCEAFPhq/Hmfq7sILXRq83YLe7t21Z6e7vNrNXEjQC2mVm04xW2EHseuCP3b1VJM+A33f3r+bUT4jcyH0kRDpfA94KED6dP7vAtd8DllnYx9jMBs3s9PhJZvYCd/+mu/8hcBg4JXbKR4F73P36iOyrwIbQRYWZvajHG96IWYRmCmI+sTB077T4iru3S0v9CPDZMPbwDwTun8fzfJC7PxW6dz5hZs8i+Fv7OLA7dupfmNmpBE//twB3A/8qcvz9wO6I3n9I0Fp0FLgrDGofAi7Io5cQWSglVYgUzOwE4Li7Hwuf+Le0iUkIMSfQTEGIdFYCnzOzPuAp4Pca1keI2tFMQQghxCQKNAshhJhERkEIIcQkMgpCCCEmkVEQQggxiYyCEEKISWQUhBBCTPL/AT6K+ZU1YglXAAAAAElFTkSuQmCC"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="Practice">Practice<a class="anchor-link" href="#Practice">&#182;</a></h2><p>plot <strong>CYLINDER</strong> vs the Emission, to see how linear is their relation:</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[9]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># write your code here</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>Double-click <strong>here</strong> for the solution.</p><!-- Your answer is below:plt.scatter(cdf.CYLINDERS, cdf.CO2EMISSIONS, color='blue')plt.xlabel("Cylinders")plt.ylabel("Emission")plt.show()--></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h4 id="Creating-train-and-test-dataset">Creating train and test dataset<a class="anchor-link" href="#Creating-train-and-test-dataset">&#182;</a></h4><p>Train/Test Split involves splitting the dataset into training and testing sets respectively, which are mutually exclusive. After which, you train with the training set and test with the testing set. This will provide a more accurate evaluation on out-of-sample accuracy because the testing dataset is not part of the dataset that have been used to train the data. It is more realistic for real world problems.</p><p>This means that we know the outcome of each data point in this dataset, making it great to test with! And since this data has not been used to train the model, the model has no knowledge of the outcome of these data points. So, in essence, it is truly an out-of-sample testing.</p><p>Lets split our dataset into train and test sets, 80% of the entire data for training, and the 20% for testing. We create a mask to select random rows using <strong>np.random.rand()</strong> function:</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[10]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">msk</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">0.8</span><span class="n">train</span> <span class="o">=</span> <span class="n">cdf</span><span class="p">[</span><span class="n">msk</span><span class="p">]</span><span class="n">test</span> <span class="o">=</span> <span class="n">cdf</span><span class="p">[</span><span class="o">~</span><span class="n">msk</span><span class="p">]</span></pre></div>    </div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><h2 id="simple_regression">Simple Regression Model</h2>Linear Regression fits a linear model with coefficients $\theta = (\theta_1, ..., \theta_n)$ to minimize the 'residual sum of squares' between the independent x in the dataset, and the dependent y by the linear approximation.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h4 id="Train-data-distribution">Train data distribution<a class="anchor-link" href="#Train-data-distribution">&#182;</a></h4></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[11]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">ENGINESIZE</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">CO2EMISSIONS</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Engine size&quot;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Emission&quot;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h4 id="Modeling">Modeling<a class="anchor-link" href="#Modeling">&#182;</a></h4><p>Using sklearn package to model data.</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[12]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span><span class="n">regr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span><span class="n">train_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="s1">&#39;ENGINESIZE&#39;</span><span class="p">]])</span><span class="n">train_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="s1">&#39;CO2EMISSIONS&#39;</span><span class="p">]])</span><span class="n">regr</span><span class="o">.</span><span class="n">fit</span> <span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span><span class="c1"># The coefficients</span><span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Coefficients: &#39;</span><span class="p">,</span> <span class="n">regr</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span><span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Intercept: &#39;</span><span class="p">,</span><span class="n">regr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>Coefficients:  [[39.18749203]]Intercept:  [125.2222036]</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>As mentioned before, <strong>Coefficient</strong> and <strong>Intercept</strong> in the simple linear regression, are the parameters of the fit line. Given that it is a simple linear regression, with only 2 parameters, and knowing that the parameters are the intercept and slope of the line, sklearn can estimate them directly from our data. Notice that all of the data must be available to traverse and calculate the parameters.</p></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h4 id="Plot-outputs">Plot outputs<a class="anchor-link" href="#Plot-outputs">&#182;</a></h4></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>we can plot the fit line over the data:</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[13]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">ENGINESIZE</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">CO2EMISSIONS</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">regr</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">train_x</span> <span class="o">+</span> <span class="n">regr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Engine size&quot;</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Emission&quot;</span><span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt output_prompt">Out[13]:</div><div class="output_text output_subarea output_execute_result"><pre>Text(0, 0.5, &#39;Emission&#39;)</pre></div></div><div class="output_area">    <div class="prompt"></div><div class="output_png output_subarea "><img src="data:image/png;base64,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"></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h4 id="Evaluation">Evaluation<a class="anchor-link" href="#Evaluation">&#182;</a></h4><p>we compare the actual values and predicted values to calculate the accuracy of a regression model. Evaluation metrics provide a key role in the development of a model, as it provides insight to areas that require improvement.</p><p>There are different model evaluation metrics, lets use MSE here to calculate the accuracy of our model based on the test set:</p><ul>    <li> Mean absolute error: It is the mean of the absolute value of the errors. This is the easiest of the metrics to understand since its just average error.</li>    <li> Mean Squared Error (MSE): Mean Squared Error (MSE) is the mean of the squared error. Its more popular than Mean absolute error because the focus is geared more towards large errors. This is due to the squared term exponentially increasing larger errors in comparison to smaller ones.</li>    <li> Root Mean Squared Error (RMSE): This is the square root of the Mean Square Error. </li>    <li> R-squared is not error, but is a popular metric for accuracy of your model. It represents how close the data are to the fitted regression line. The higher the R-squared, the better the model fits your data. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).</li></ul></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In&nbsp;[14]:</div><div class="inner_cell">    <div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span><span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s1">&#39;ENGINESIZE&#39;</span><span class="p">]])</span><span class="n">test_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s1">&#39;CO2EMISSIONS&#39;</span><span class="p">]])</span><span class="n">test_y_hat</span> <span class="o">=</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean absolute error: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">test_y_hat</span> <span class="o">-</span> <span class="n">test_y</span><span class="p">)))</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual sum of squares (MSE): </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">test_y_hat</span> <span class="o">-</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2-score: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test_y_hat</span> <span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="p">)</span></pre></div>    </div></div></div><div class="output_wrapper"><div class="output"><div class="output_area">    <div class="prompt"></div><div class="output_subarea output_stream output_stdout output_text"><pre>Mean absolute error: 23.01Residual sum of squares (MSE): 899.65R2-score: 0.75</pre></div></div></div></div></div>    </div>  </div></body><h5>Credits - <a href='https://www.google.com/' target=_blank >google</a>,  <a href = 'https://www.coursera.org/' target=_blank>Coursera</a> , <a href ='https://www.ibm.com/in-en' target=_blank>IBM</a><h5>   </html>]]></content>
    
    <summary type="html">
    
      &lt;body&gt;
&lt;i&gt;&lt;b&gt;Note - Simple Linear Regression Full Implementation with the dataset EDA and Other Techniques.
  You will use use the most basic and the Simple Linear model to predict the car consumption fuel results.
Please Download the FuelConsumption.Csv dataset from &lt;a href= &quot;https://www.kaggle.com/anderas/car-consume&quot; target=&quot;_blank&quot;&gt;Kaggle&lt;/a&gt; &lt;/i&gt;&lt;/b&gt;
    
    </summary>
    
    
      <category term="ML From Scratch" scheme="https://massivefile.com/categories/ML-From-Scratch/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Simple Linear Regression" scheme="https://massivefile.com/tags/Simple-Linear-Regression/"/>
    
  </entry>
  
  <entry>
    <title>Quiz 1 || Regularization</title>
    <link href="https://massivefile.com/quiz5/"/>
    <id>https://massivefile.com/quiz5/</id>
    <published>2020-04-25T00:56:53.000Z</published>
    <updated>2020-05-05T23:22:35.982Z</updated>
    
    <content type="html"><![CDATA[<p><b><i>title: Quiz 1|| Deeplearnig (Course - 1 Week - 1) Improving Deep Neural Networks (Week 1)<br>Note - Quiz on the notes on DeepLearning </b></i></p><a id="more"></a><iframe src="https://drive.google.com/file/d/1DtvdJ1Z7Uasyn72J_Tx3WHF2DCcdzEM_/preview" width="680" height="480"></iframe>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;b&gt;&lt;i&gt;title: Quiz 1|| Deeplearnig (Course - 1 Week - 1) Improving Deep Neural Networks (Week 1)&lt;br&gt;Note - Quiz on the notes on DeepLearning &lt;/b&gt;&lt;/i&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Quiz" scheme="https://massivefile.com/categories/Quiz/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Quiz" scheme="https://massivefile.com/tags/Quiz/"/>
    
  </entry>
  
  <entry>
    <title>Regularization || Improving Deep Neural Networks</title>
    <link href="https://massivefile.com/regularizarion_all_info/"/>
    <id>https://massivefile.com/regularizarion_all_info/</id>
    <published>2020-04-20T00:56:53.000Z</published>
    <updated>2020-05-05T23:22:50.850Z</updated>
    
    <content type="html"><![CDATA[<p><i><b>Note - These are my notes on DeepLearning Specialization Part:<br>Regularization || Deeplearning (Course - 2 Week - 1) || Improving Deep Neural Networks(Week 1)</b></i></p><a id="more"></a><h3><b>Introduction: </b></h3>If you suspect your neural network is over fitting your data. That is you have a high variance problem, one of the first things you should try per probably regularization. The other way to address high variance, is to get more training data that's also quite reliable. But you can't always get more training data, or it could be expensive to get more data. But adding regularization will often help to prevent overfitting, or to reduce the errors in your network. So let's see how regularization works. Let's develop these ideas using logistic regression. Recall that for logistic regression, you try to minimize the cost function J, which is defined as this cost function.In other words, instead of simply aiming to minimize loss (empirical risk minimization):Because here, you're using the Euclidean normals, or else the L2 norm with the prime to vector w. Now, why do you regularize just the parameter w? Why don't we add something here about b as well? In practice, you could do this, but I usually just omit this. Because if you look at your parameters, w is usually a pretty high dimensional parameter vector, especially with a high variance problem. Maybe w just has a lot of parameters, so you aren't fitting all the parameters well, whereas b is just a single number. So almost all the parameters are in w rather b. And if you add this last term, in practice, it won't make much of a difference, because b is just one parameter over a very large number of parameters. In practice, I usually just don't bother to include it. But you can if you want. <b>So L2 regularization is the most common type of regularization. </b>You might have also heard of some people talk about L1 regularization. And that's when you add, instead of this L2 norm, you instead add a term that is lambda/m of sum over of this. And this is also called the L1 norm of the parameter vector w, so the little subscript 1 down there, right? And I guess whether you put m or 2m in the denominator, is just a scaling constant. <b>L1 Regularization</b>If you use L1 regularization, then w will end up being sparse. And what that means is that the w vector will have a lot of zeros in it. And some people say that this can help with compressing the model, because the set of parameters are zero, and you need less memory to store the model. Although, I find that, in practice, L1 regularization to make your model sparse, helps only a little bit. So I don't think it's used that much, at least not for the purpose of compressing your model. And when people train your networks, L2 regularization is just used much much more often. Sorry, just fixing up some of the notation here. So one last detail. Lambda here is called the regularization, Parameter.<p>And usually, you set this using your development set, or using [INAUDIBLE] cross validation. When you a variety of values and see what does the best, in terms of trading off between doing well in your training set versus also setting that two normal of your parameters to be small. Which helps prevent over fitting. So lambda is another hyper parameter that you might have to tune. And by the way, for the programming exercises, lambda is a reserved keyword in the Python programming language. So in the programming exercise, well have lambd,<br>]without the a, so as not to clash with the reserved keyword in Python. So we use lambd to represent the lambda regularization parameter.</p><p>$$<br>\text{minimize(Loss(Data|Model))}<br>$$<br>well now minimize loss+complexity, which is called structural risk minimization:</p><p>$$\text{minimize(Loss(Data|Model) + complexity(Model))}$$<br>Our training optimization algorithm is now a function of two terms: the loss term, which measures how well the model fits the data, and the regularization term, which measures model complexity.</p><p>Model complexity as a function of the weights of all the features in the model.<br>Model complexity as a function of the total number of features with nonzero weights. (A later module covers this approach.)<br>If model complexity is a function of weights, a feature weight with a high absolute value is more complex than a feature weight with a low absolute value.</p><p>We can quantify complexity using the L2 regularization formula, which defines the regularization term as the sum of the squares of all the feature weights:</p><p>$$<br>L_2 \text{ regularization term} = ||\boldsymbol w||_2^2 = {w_1^2 + w_2^2 +  + w_n^2}<br>$$</p><p>In this formula, weights close to zero have little effect on model complexity, while outlier weights can have a huge impact.</p><p>For example, a linear model with the following weights:</p><p>$$<br>{w_1 = 0.2, w_2 = 0.5, w_3 = 5, w_4 = 1, w_5 = 0.25, w_6 = 0.75}<br>$$</p><p>Has an L2 regularization term of 26.915:</p><p>$$<br>w_1^2 + w_2^2 + \boldsymbol{w_3^2} + w_4^2 + w_5^2 + w_6^2$$ $$= 0.2^2 + 0.5^2 + \boldsymbol{5^2} + 1^2 + 0.25^2 + 0.75^2$$ $$= 0.04 + 0.25 + \boldsymbol{25} + 1 + 0.0625 + 0.5625<br>$$<br>$$<br>= 26.915$$<br>But (w_3) (bolded above), with a squared value of 25, contributes nearly all the complexity. The sum of the squares of all five other weights adds just 1.915 to the L2 regularization term.</p><h3><b>Lambda Introduction</b></h3>Model developers tune the overall impact of the regularization term by multiplying its value by a scalar known as lambda (also called the regularization rate). That is, model developers aim to do the following:<p>$$ \text{minimize(Loss(Data|Model)} + \lambda \text{ complexity(Model))} $$<br>Performing L2 regularization has the following effect on a model</p><p>Encourages weight values toward 0 (but not exactly 0)<br>Encourages the mean of the weights toward 0, with a normal (bell-shaped or Gaussian) distribution.<br>Increasing the lambda value strengthens the regularization effect. For example, the histogram of weights for a high value of lambda<br>Some of your training examples of the losses of the individual predictions in the different examples, where you recall that w and b in the logistic regression, are the parameters. So w is an x-dimensional parameter vector, and b is a real number. And so to add regularization to the logistic regression, what you do is add to it this thing, lambda, which is called the regularization parameter. Ill say more about that in a second. But lambda/2m times the norm of w squared. So here, the norm of w squared is just equal to sum from j equals 1 to nx of wj squared, or this can also be written w transpose w, its just a square Euclidean norm of the prime to vector w. And this is called L2 regularization.</p><p>When choosing a lambda value, the goal is to strike the right balance between simplicity and training-data fit:</p><p>If your lambda value is too high, your model will be simple, but you run the risk of underfitting your data. Your model wont learn enough about the training data to make useful predictions.</p><p>If your lambda value is too low, your model will be more complex, and you run the risk of overfitting your data. Your model will learn too much about the particularities of the training data, and wont be able to generalize to new data.</p><p>Note: Setting lambda to zero removes regularization completely. In this case, training focuses exclusively on minimizing loss, which poses the highest possible overfitting risk.<br>The ideal value of lambda produces a model that generalizes well to new, previously unseen data. Unfortunately, that ideal value of lambda is data-dependent, so youll need to do some tuning.</p><p><b>L2 Regularization and lambda (Regularization Parameter): relation </b><br>Theres a close connection between learning rate and lambda. Strong L2 regularization values tend to drive feature weights closer to 0. Lower learning rates (with early stopping) often produce the same effect because the steps away from 0 arent as large. Consequently, tweaking learning rate and lambda simultaneously may have confounding effects.</p><p>Early stopping means ending training before the model fully reaches convergence. In practice, we often end up with some amount of implicit early stopping when training in an online (continuous) fashion. That is, some new trends just havent had enough data yet to converge.</p><p>As noted, the effects from changes to regularization parameters can be confounded with the effects from changes in learning rate or number of iterations. One useful practice (when training across a fixed batch of data) is to give yourself a high enough number of iterations that early stopping doesnt play into things.</p><h3><b>Implementing L2 Regularisation in a Neural Network</b></h3>So this is how you implement L2 regularization for logistic regression. How about a neural network? In a neural network, you have a cost function<b>(J)</b> that's a function of all of your parameters, w[1], b[1] through w[L], b[L], where capital L is the number of layers in your neural network. And so the cost function is this, sum of the losses, summed over your m training examples. <center><img src='https://lh3.googleusercontent.com/sWOu6Am4oV1_G_Wj-TsBgIfSxa93f76O4d2HNImLm6aHzOjbjfovcgTZlLUdhgtp8HiENZ88QB0gJLgRc5c4Dmkujw3XzX7fbjzAWdN65-OUSOwQAoQGF23IGobJ5hYodUvTegUlCg=w2400' /></a></center>And says at regularization, you add lambda over 2m of sum over all of your parameters W, your parameter matrix is w, of their, that's called the squared norm. Where this norm of a matrix, meaning the squared norm is defined as the sum of the i sum of j, of each of the elements of that matrix, squared. And if you want the indices of this summation. This is sum from i=1 through n[l-1]. Sum from j=1 through n[l], because w is an n[l-1] by n[l] dimensional matrix, where these are the number of units in layers [l-1] in layer l. So this matrix norm, it turns out is called the Frobenius norm of the matrix, denoted with a F in the subscript. So for arcane linear algebra technical reasons, this is not called the l2 normal of a matrix. Instead, it's called the Frobenius norm of a matrix. I know it sounds like it would be more natural to just call the l2 norm of the matrix, but for really arcane reasons that you don't need to know, by convention, this is called the Frobenius norm. It just means the sum of square of elements of a matrix. So how do you implement gradient descent with this? Previously, we would complete dw using backprop, where backprop would give us the partial derivative of J with respect to w, or really w for any given [l]. And then you update w[l], as w[l]- the learning rate times d. So this is before we added this extra regularization term to the objective. Now that we've added this regularization term to the objective, what you do is you take dw and you add to it, lambda/m times w. And then you just compute this update, same as before. And it turns out that with this new definition of dw[l], this new dw[l] is still a correct definition of the derivative of your cost function, with respect to your parameters, now that you've added the extra regularization term at the end.<h4><b>L2 Norm ~ Weight Deacy</b></h4>And it's for this reason that L2 regularization is sometimes also called weight decay. So if I take this definition of dw[l] and just plug it in here, then you see that the update is w[l] = w[l] times the learning rate alpha times the thing from backprop,+lambda of m times w[l]. Throw the minus sign there. And so this is equal to $$ (w[l]- alpha * lambda / m) * (w[l]- alpha) $$ times the thing you got from backpop.And so this term shows that whatever the matrix w[l] is, you're going to make it a little bit smaller, right? This is actually as if you're taking the matrix w and you're multiplying it by $$ 1-alpha*lambda/m$$ . You're really taking the matrix w and subtracting $$ alpha*lambda/m $$ with L2 Regularization penalty . Like you're multiplying matrix w by this number, which is going to be a little bit less than 1. So this is why L2 norm regularization is also called weight decay. Because it's just like the ordinally gradient descent, where you update w by subtracting alpha times the original gradient you got from backprop. But now you're also multiplying w by this thing, which is a little bit less than 1. So the alternative name for L2 regularization is weight decay. I'm not really going to use that name, but the intuition for it's called weight decay is that this first term here, is equal to this. So you're just multiplying the weight metrics by a number slightly less than 1. So that's how you implement L2 regularization in neural network.Now, one question that he has asked me is, why does regularization prevent over-fitting? Let's look at the next Section, and gain some intuition for how regularization prevents over-fitting.<h3><b>How do regularization Prevent Overfitting?</b></h3>Why does regularization help with overfitting? Why does it help with reducing variance problems? Let's go through a couple examples to gain some intuition about how it works. So, recall that high bias, high variance. And I just write pictures from our earlier section that looks something like this. <center><img src='https://lh3.googleusercontent.com/FHNMcPVOi2k8SROzVlvatlBSoHm_Z-D8Z1BSPmXesbCG7ZNoXs3h8sXC7MI6QBnpjgHGIFNpEMFBnRHnJEQdzfF2NbOcra3FRZvzyPxpWkSdFgJ-_0mrZfTE9SAnGycgDRbn356kcQ=w2400' /></a></center>Now, let's see a fitting large and deep neural network. I know I haven't drawn this one too large or too deep, unless you think some neural network and this currently overfitting. So you have some cost function like J of W, B equals sum of the losses. <p>$$\text{minimize(Loss(Data|Model)} + \lambda \text{ complexity(Model))}$$</p><p>So what we did for regularization was add this extra term that penalizes the weight matrices from being too large. So that was the Frobenius norm. So why is it that shrinking the L two norm or the Frobenius norm or the parameters might cause less overfitting? One piece of intuition is that if you crank regularisation lambda to be really, really big, theyll be really incentivized to set the weight matrices W to be reasonably close to zero. So one piece of intuition is maybe it set the weight to be so close to zero for a lot of hidden units thats basically zeroing out a lot of the impact of these hidden units. And if thats the case, then this much simplified neural network becomes a much smaller neural network. In fact, it is almost like a logistic regression unit, but stacked most probably as deep. And so that will take you from this overfitting case much closer to the left to other high bias case. But hopefully therell be an intermediate value of lambda that results in a result closer to this just right case in the middle.<br>But the intuition is that by cranking up lambda to be really big theyll set W close to zero, which in practice this isnt actually what happens. We can think of it as zeroing out or at least reducing the impact of a lot of the hidden units so you end up with what might feel like a simpler network.<br>They get closer and closer as if youre just using logistic regression.<br>The intuition of completely zeroing out of a bunch of hidden units isnt quite right.<br>It turns out that what actually happens is theyll still use all the hidden units, but each of them would just have a much smaller effect. But you do end up with a simpler network and as if you have a smaller network that is therefore less prone to overfitting.<br>So a lot of this intuition helps better when you implement regularization in the program exercise, you actually see some of these variance reduction results yourself. </p><h3>Another Intution with TanH as activation Function instead of Sigmoid </h3>Here's another attempt at additional intuition for why regularization helps prevent overfitting. And for this, I'm going to assume that we're using the tanh activation function which looks like this.<center><img src='https://lh3.googleusercontent.com/rFlM7K_gswGP0l-ma4cZZ-1gVYJ6bfy2oCvPMzZBWhgkT6dJi5UROEHNv_n1TQkU2LOplBtZRLj2kaAbHCa0dXQUM1R7jrZRvbDFSrPgPscN9mH22rpbpnN0WgD27ajYmtbSrUTQxQ=w2400' /></a></center>This is a g of z equals tanh of z. So if that's the case, notice that so long as Z is quite small, so if Z takes on only a smallish range of parameters, maybe around here, then you're just using the linear regime of the tanh function. Is only if Z is allowed to wander up to larger values or smaller values like so, that the activation function starts to become less linear. <h3>Takeaway:</h3>So the intuition you might take away from this is that if lambda, the regularization parameter, is large, then you have that your parameters will be relatively small, because they are penalized being large into a cos function. And so if the blades W are small then because Z is equal to W and then technically is plus b, but if W tends to be very small, then Z will also be relatively small. And in particular, if Z ends up taking relatively small values, just in this whole range, then G of Z will be roughly linear. So it's as if every layer will be roughly linear. As if it is just linear regression. And we saw in course one that if every layer is linear then your whole network is just a linear network. And so even a very deep network, with a deep network with a linear activation function is at the end they are only able to compute a linear function. So it's not able to fit those very very complicated decision. Very non-linear decision boundaries that allow it to really overfit right to data sets like we saw on the overfitting high variance case on the previous slide. <h4><b>So just to summarize</b></h4> If the regularization becomes very large, the parameters W very small, so Z will be relatively small, kind of ignoring the effects of b for now, so Z will be relatively small or, really, <center><a href='https://photos.google.com/share/AF1QipM2Xp4gWyc88SkPOjkiyF9p0HCmee0RykiqXJIrcXLLmGpDjhO94h6AOF8fmTeVJQ?key=MVJNVGZnTmQ2TXY1aUgwOVk4eXN0aEN1eEVEX1l3&source=ctrlq.org' target="_blank" rel="noopener"><img src='https://lh3.googleusercontent.com/JfTz4qNmxAanFm5Jw4LFySSbPwQAlS831GBSwisc_YZYKn92wzaCkKWy5f_bYV4j7_cJ28rGeYlq5k7BJlzhT4LF2jkur3oUnPV3JlhrrARUjpzGSpK3BzAv40OPX9GfHTEfSERhKQ=w2400' /></a></center>I should say it takes on a small range of values. And so the activation function if is tanh, say, will be relatively linear. And so your whole neural network will be computing something not too far from a big linear function which is therefore pretty simple function rather than a very complex highly non-linear function. And so is also much less able to overfit. And again, when you enter in regularization for yourself in the program exercise, you'll be able to see some of these effects yourself. <h4><b>Tip</b></h4> Before wrapping up our def discussion on regularization, I just want to give you one implementational tip. Which is that, when implanting regularization, we took our definition of the cost function J and we actually modified it by adding this extra term that penalizes the weight being too large. And so if you implement gradient descent, one of the steps to debug gradient descent is to plot the cost function J as a function of the number of elevations of gradient descent and you want to see that the cost function J decreases monotonically after every elevation of gradient descent. And if you're implementing regularization then please remember that J now has this new definition. If you plot the old definition of J, just this first term, then you might not see a decrease monotonically. So to debug gradient descent make sure that you're plotting this new definition of J that includes this second term as well. Otherwise you might not see J decrease monotonically on every single elevation. So that's it for L two regularization which is actually a regularization technique that I use the most in training deep learning modules. In deep learning there is another sometimes used regularization technique called dropout regularization. Let's take a look at that in the next section.<h3><b>Dropout Regularization</b></h3> In addition to L2 regularization, another very powerful regularization techniques is called "dropout." Let's see how that works. Let's say you train a neural network like the one on the left and there's over-fitting. Here's what you do with dropout. Let me make a copy of the neural network. <center><img src='https://lh3.googleusercontent.com/Fi03rYl86k7FWsqUCAFCc79c-F9M_wbUn6ByFbjv3zvcRw5r9ZT9lmlBbXdgqellkC2nRZjkllmH6kLV2fVcCFkB3N32jRimkeMwZH2Wa47DdHOe4sJDFYECd6ltKQrQDoT_SkMs8Q=w2400' /></a></center> With dropout, what we're going to do is go through each of the layers of the network and set some probability of eliminating a node in neural network. Let's say that for each of these layers, we're going to- for each node, toss a coin and have a 0.5 chance of keeping each node and 0.5 chance of removing each node. So, after the coin tosses, maybe we'll decide to eliminate those nodes, then what you do is actually remove all the outgoing things from that no as well. So you end up with a much smaller, really much diminished network. And then you do back propagation training. There's one example on this much diminished network. And then on different examples, you would toss a set of coins again and keep a different set of nodes and then dropout or eliminate different than nodes. And so for each training example, you would train it using one of these neural based networks. So, maybe it seems like a slightly crazy technique. They just go around coding those are random, but this actually works. But you can imagine that because you're training a much smaller network on each example or maybe just give a sense for why you end up able to regularize the network, because these much smaller networks are being trained. <h3>Implementing Dropout</h3>Let's look at how you implement dropout. There are a few ways of implementing dropout. I'm going to show you the most common one, which is technique called inverted dropout. For the sake of completeness, let's say we want to illustrate this with layer l=3. So, in the code I'm going to write- there will be a bunch of 3s here. I'm just illustrating how to represent dropout in a single layer. So, what we are going to do is set a vector d and d^3 is going to be the dropout vector for the layer 3. <h3><b>Inverted Dropout</b></h3>That's what the 3 is to be np.random.rand(a). And this is going to be the same shape as a3. And when I see if this is less than some number, which I'm going to call keep.prob. And so, keep.prob is a number. It was 0.5 on the previous time, and maybe now I'll use 0.8 in this example,<center><img src='https://lh3.googleusercontent.com/XOvtoZLjKVzuCa6Sg5VPg-Y3Q1B9iIuhdcaSV9BuLVFHtUx9XxR7UNrO_KxG7RPya0Db5xOv5cC0qFGB6DWdS6o9REhLWRkqkOgMDSPQjNaszGNfbaFRcEzVqfubH0vnwyT1ZYpEcQ=w2400' /></a></center> and there will be the probability that a given hidden unit will be kept. So keep.prob = 0.8, then this means that there's a 0.2 chance of eliminating any hidden unit. So, what it does is it generates a random matrix. And this works as well if you have factorized. So d3 will be a matrix. Therefore, each example have a each hidden unit there's a 0.8 chance that the corresponding d3 will be one, and a 20% chance there will be zero. So, this random numbers being less than 0.8 it has a 0.8 chance of being one or be true, and 20% or 0.2 chance of being false, of being zero. And then what you are going to do is take your activations from the third layer, let me just call it a3 in this low example. So, a3 has the activations you computate. And you can set a3 to be equal to the old a3, times- There is element wise multiplication. Or you can also write this as a3* = d3. But what this does is for every element of d3 that's equal to zero. And there was a 20% chance of each of the elements being zero, just multiply operation ends up zeroing out, the corresponding element of d3. If you do this in python, technically d3 will be a boolean array where value is true and false, rather than one and zero. But the multiply operation works and will interpret the true and false values as one and zero.If you try this yourself in python, you'll see. Then finally, we're going to take a3 and scale it up by dividing by 0.8 or really dividing by our keep.prob parameter. So, let me explain what this final step is doing. Let's say for the sake of argument that you have 50 units or 50 neurons in the third hidden layer. So maybe a3 is 50 by one dimensional or if you- factorization maybe it's 50 by m dimensional. So, if you have a 80% chance of keeping them and 20% chance of eliminating them. This means that on average, you end up with 10 units shut off or 10 units zeroed out. And so now, if you look at the value of z^4, z^4 is going to be equal to $$ w^4 * a^3 + b^4 $$. And so, on expectation, this will be reduced by 20%. By which I mean that 20% of the elements of a3 will be zeroed out. So, in order to not reduce the expected value of z^4, what you do is you need to take this, and divide it by 0.8 because this will correct or just a bump that back up by roughly 20% that you need. So it's not changed the expected value of a3. And, so this line here is what's called the inverted dropout technique. And its effect is that, no matter what you set to keep.prob to, whether it's 0.8 or 0.9 or even one, if it's set to one then there's no dropout, because it's keeping everything or 0.5 or whatever, this inverted dropout technique by dividing by the keep.prob, it ensures that the expected value of a3 remains the same. And it turns out that at test time, when you trying to evaluate a neural network, which we'll talk about on the next slide, this inverted dropout technique, there is there is line to are due to the green box at dropping out. This makes test time easier because you have less of a scaling problem. By far the most common implementation of dropouts today as far as I know is inverted dropouts. I recommend you just implement this. But there were some early iterations of dropout that missed this divide by keep.prob line, and so at test time the average becomes more and more complicated. But again, people tend not to use those other versions. So, what you do is you use the d vector, and you'll notice that for different training examples, you zero out different hidden units. And in fact, if you make multiple passes through the same training set, then on different pauses through the training set, you should randomly zero out different hidden units. So, it's not that for one example, you should keep zeroing out the same hidden units is that, on iteration one of grade and descent, you might zero out some hidden units. And on the second iteration of great descent where you go through the training set the second time, maybe you'll zero out a different pattern of hidden units. And the vector d or d3, for the third layer, is used to decide what to zero out, both in for prob as well as in that prob. We are just showing for prob here. Now, having trained the algorithm at test time, here's what you would do. At test time, you're given some x or which you want to make a prediction. And using our standard notation, I'm going to use a^0, the activations of the zeroes layer to denote just test example x. So what we're going to do is not to use dropout at test time in particular which is in a sense. $$ Z^1= w^1.a^0 + b^1. a^1 = g^1(z^1 Z). Z^2 = w^2.a^1 + b^2. a^2 =... $$ And so on. Until you get to the last layer and that you make a prediction y^. But notice that the test time you're not using dropout explicitly and you're not tossing coins at random, you're not flipping coins to decide which hidden units to eliminate. And that's because when you are making predictions at the test time, you don't really want your output to be random. If you are implementing dropout at test time, that just add noise to your predictions. <h4><b>Introspect Results:</b></h4>In theory, one thing you could do is run a prediction process many times with different hidden units randomly dropped out and have it across them. But that's computationally inefficient and will give you roughly the same result; very, very similar results to this different procedure as well. And just to mention, the inverted dropout thing, you remember the step on the previous line when we divided by the cheap.prob. The effect of that was to ensure that even when you don't see men dropout at test time to the scaling, the expected value of these activations don't change. So, you don't need to add in an extra funny scaling parameter at test time. That's different than when you have that training time. So that's dropouts. And when you implement this in week's premier exercise, you gain more firsthand experience with it as well. But why does it really work? What I want to do the next section is give you some better intuition about what dropout really is doing. Let's go on to the next section.<h2><b>Understanding Dropout</b></h2>Drop out does this seemingly crazy thing of randomly knocking out units on your network. Why does it work so well with a regularizer? Let's gain some better intuition. In the previous section, I gave this intuition that drop-out randomly knocks out units in your network. So it's as if on every iteration you're working with a smaller neural network, and so using a smaller neural network seems like it should have a regularizing effect. <h4><b>Why Does Dropout Work ? </b></h4>Here's a second intuition which is, let's look at it from the perspective of a single unit. Let's say this one. Now, for this unit to do his job as for inputs and it needs to generate some meaningful output. Now with drop out, the inputs can get randomly eliminated. Sometimes those two units will get eliminated, sometimes a different unit will get eliminated. <center><img src='https://lh3.googleusercontent.com/i8iTmh22B_C9MbDioL-Qk4WH5QS0AikkJxkoiQ11nth8Sqp_AOepqSh0r43xboelt8q0cEYRLamafiDycm-ZVlz1K8TklSB-lCKs1wqXa6_j8E3qyZ5DKxv8FpJBJgcJhF9mMHeseA=w2400' /></a></center>So, what this means is that this unit, which I'm circling in purple, it can't rely on any one feature because any one feature could go away at random or any one of its own inputs could go away at random. Some particular would be reluctant to put all of its bets on, say, just this input, right? The weights, we're reluctant to put too much weight on any one input because it can go away. So this unit will be more motivated to spread out this way and give you a little bit of weight to each of the four inputs to this unit. And by spreading all the weights, this will tend to have an effect of shrinking the squared norm of the weights. And so, similar to what we saw with L2 regularization, the effect of implementing drop out is that it shrinks the weights and does some of those outer regularization that helps prevent over-fitting. But it turns out that drop out can formally be shown to be an adaptive form without a regularization. But L2 penalty on different weights are different, depending on the size of the activations being multiplied that way. But to summarize, it is possible to show that drop out has a similar effect to L2 regularization. Only to L2 regularization applied to different ways can be a little bit different and even more adaptive to the scale of different inputs. One more detail for when you're implementing drop out. Here's a network where you have three input features. This is seven hidden units here, seven, three, two, one. So, one of the parameters we had to choose was the cheap prop which has a chance of keeping a unit in each layer. So, it is also feasible to vary key prop by layer. So for the first layer, your matrix W1 will be three by seven. Your second weight matrix will be seven by seven. W3 will be seven by three and so on. And so W2 is actually the biggest weight matrix, because they're actually the largest set of parameters would be in W2 which is seven by seven. So to prevent, to reduce over-fitting of that matrix, maybe for this layer, I guess this is layer two, you might have a key prop that's relatively low, say zero point five, whereas for different layers where you might worry less about over-fitting, you could have a higher key prop, maybe just zero point seven. And if a layers we don't worry about over-fitting at all, you can have a key prop of one point zero. <h4><b>For clarity</b></h4>These numbers I'm drawing on the purple boxes, These could be different key props for different layers. Notice that the key prop of one point zero means that you're keeping every unit and so, you're really not using drop out for that layer. But for layers where you're more worried about over-fitting, really the layers with a lot of parameters, you can set the key prop to be smaller to apply a more powerful form of drop out. It's kind of like cranking up the regularization parameter lambda of L2 regularization where you try to regularize some layers more than others. And technically, you can also apply drop out to the input layer, where you can have some chance of just maxing out one or more of the input features. Although in practice, usually don't do that that often. And so, a key prop of one point zero was quite common for the input there. You can also use a very high value, maybe zero point nine, but it's much less likely that you want to eliminate half of the input features. So usually key prop, if you apply the law, will be a number close to one if you even apply drop out at all to the input there. So just to summarize, if you're more worried about some layers overfitting than others, you can set a lower key prop for some layers than others. <h3><b>Downside of Dropout</b></h3>The downside is, this gives you even more hyper parameters to search for using cross-validation. One other alternative might be to have some layers where you apply drop out and some layers where you don't apply drop out and then just have one hyper parameter, which is a key prop for the layers for which you do apply drop outs. And before we wrap up, just a couple implementational tips. Many of the first successful implementations of drop outs were to computer vision. So in computer vision, the input size is so big, inputting all these pixels that you almost never have enough data. And so drop out is very frequently used by computer vision. And there's some computer vision researchers that pretty much always use it, almost as a default. But really the thing to remember is that drop out is a regularization technique, it helps prevent over-fitting. And so, unless my algorithm is over-fitting, I wouldn't actually bother to use drop out. So it's used somewhat less often than other application areas. There's just with computer vision, you usually just don't have enough data, so you're almost always overfitting, which is why there tends to be some computer vision researchers who swear by drop out. But their intuition doesn't always generalize I think to other disciplines. One big downside of drop out is that the cost function J is no longer well-defined. On every iteration, you are randomly killing off a bunch of nodes. And so, if you are double checking the performance of grade and dissent, it's actually harder to double check that you have a well defined cost function J that is going downhill on every iteration. Because the cost function J that you're optimizing is actually less. Less well defined, or is certainly hard to calculate. <p>So you lose this debugging tool to will a plot, a graph like this. So what I usually do is turn off drop out, you will set key prop equals one, and I run my code and make sure that it is monotonically decreasing J, and then turn on drop out and hope that I didnt introduce bugs into my code during drop out. Because you need other ways, I guess, but not plotting these figures to make sure that your code is working to greatness and its working even with drop outs. So with that, theres still a few more regularization techniques that are worth your knowing. Lets talk about a few more such techniques in the next section.</p><h2><b>Other regularization methods</b></h2>In addition to L2 regularization and drop out regularization there are few other techniques to reducing over fitting in your neural network. <h3><b>Data Augmentation</b></h3>Let's take a look. Let's say you fitting a CAD crossfire. If you are over fitting getting more training data can help, but getting more training data can be expensive and sometimes you just can't get more data. But what you can do is augment your training set by taking image like this. <center><img src='https://lh3.googleusercontent.com/4gwG300GPm8Cl3rC1VcXzQV2SI8EQvbHqIni5OZXEZDmndgwIhtlL9fe9tted-xq-4fVXpeFjR9Y_8PflUvDKfhILCTJAIBBq1-bq_QghBiU7ZzDgmoyvMPQzDYW2N0EhutB9k8Z6A=w2400' /></a></center> And for example, flipping it horizontally and adding that also with your training set. So now instead of just this one example in your training set, you can add this to your training example. So by flipping the images horizontally, you could double the size of your training set. Because you're training set is now a bit redundant this isn't as good as if you had collected an additional set of brand new independent examples. But you could do this Without needing to pay the expense of going out to take more pictures of cats. And then other than flipping horizontally, you can also take random crops of the image. So here we're rotated and sort of randomly zoom into the image and this still looks like a cat. So by taking random distortions and translations of the image you could augment your data set and make additional fake training examples. Again, these extra fake training examples they don't add as much information as they were to call they get a brand new independent example of a cat. But because you can do this, almost for free, other than for some confrontational costs. This can be an inexpensive way to give your algorithm more data and therefore sort of regularize it and reduce over fitting. And by synthesizing examples like this what you're really telling your algorithm is that If something is a cat then flipping it horizontally is still a cat. Notice I didn't flip it vertically, because maybe we don't want upside down cats, right? And then also maybe randomly zooming in to part of the image it's probably still a cat. For optical character recognition you can also bring your data set by taking digits and imposing random rotations and distortions to it. So If you add these things to your training set, these are also still digit force.For illustration I applied a very strong distortion. So this look very wavy for, in practice you don't need to distort the four quite as aggressively, but just a more subtle distortion than what I'm showing here, to make this example clearer for you, right? But a more subtle distortion is usually used in practice, because this looks like really warped fours. So data augmentation can be used as a regularization technique, in fact similar to regularization. <h3><b>Early Stopping</b></h3>There's one other technique that is often used called early stopping. So what you're going to do is as you run gradient descent you're going to plot your, either the training error, you'll use 01 classification error on the training set. Or just plot the cost function J optimizing, and that should decrease monotonically, like so, all right? Because as you trade, hopefully, you're trading around your cost function J should decrease.<center><b><img src='https://lh3.googleusercontent.com/V29kERc26WxVJlGBykQSvR-n57e3dU5xGPY2X41EfK140hD15n9cZjQ2o0aSNsvrJKcRMSLdPuPxdjDSBgwdjkEiYTc2d1Hfqwda3Sqqh14cfmUxwJu7hZyBHMIZo0nddy79CS3kMw=w2400' /></a></b></center>So with early stopping, what you do is you plot this, and you also plot your dev set error.And again, this could be a classification error in a development sense, or something like the cost function, like the logistic loss or the log loss of the dev set. Now what you find is that your dev set error will usually go down for a while, and then it will increase from there. So what early stopping does is, you will say well, it looks like your neural network was doing best around that iteration, so we just want to stop trading on your neural network halfway and take whatever value achieved this dev set error. So why does this work? Well when you've haven't run many iterations for your neural network yet your parameters w will be close to zero. Because with random initialization you probably initialize w to small random values so before you train for a long time, w is still quite small. And as you iterate, as you train, w will get bigger and bigger and bigger until here maybe you have a much larger value of the parameters w for your neural network. So what early stopping does is by stopping halfway you have only a mid-size rate w. <p>And so similar to L2 regularization by picking a neural network with smaller norm for your parameters w, hopefully your neural network is over fitting less. And the term early stopping refers to the fact that youre just stopping the training of your neural network earlier. </p><h3><b>Downside of early stopping</h3></b></h3>I sometimes use early stopping when training a neural network. But it does have one downside, let me explain. I think of the machine learning process as comprising several different steps. One, is that you want an algorithm to optimize the cost function j and we have various tools to do that, such as grade intersect. And then we'll talk later about other algorithms, like momentum and RMS prop and Atom and so on. But after optimizing the cost function j, you also wanted to not over-fit. And we have some tools to do that such as your regularization, getting more data and so on. Now in machine learning, we already have so many hyper-parameters it surge over. It's already very complicated to choose among the space of possible algorithms. And so I find machine learning easier to think about when you have one set of tools for optimizing the cost function J, and when you're focusing on authorizing the cost function J. All you care about is finding w and b, so that J(w,b) is as small as possible. You just don't think about anything else other than reducing this. And then it's completely separate task to not over fit, in other words, to reduce variance. And when you're doing that, you have a separate set of tools for doing it. And this principle is sometimes called orthogonalization. And there's this idea, that you want to be able to think about one task at a time. I'll say more about orthorganization in a later section, so if you don't fully get the concept yet, don't worry about it. But, to me the main downside of early stopping is that this couples these two tasks. So you no longer can work on these two problems independently, because by stopping gradient decent early, you're sort of breaking whatever you're doing to optimize cost function J, because now you're not doing a great job reducing the cost function J. You've sort of not done that that well. And then you also simultaneously trying to not over fit. So instead of using different tools to solve the two problems, you're using one that kind of mixes the two. And this just makes the set ofthings you could try are more complicated to think about. Rather than using early stopping, one alternative is just use L2 regularization then you can just train the neural network as long as possible. I find that this makes the search space of hyper parameters easier to decompose, and easier to search over. But the downside of this though is that you might have to try a lot of values of the regularization parameter lambda. And so this makes searching over many values of lambda more computationally expensive. And the advantage of early stopping is that running the gradient descent process just once, you get to try out values of small w, mid-size w, and large w, without needing to try a lot of values of the L2 regularization hyperparameter lambda. <p>If this concept doesnt completely make sense to you yet, dont worry about it. Were going to talk about it in greater detail in a later section, I think this will make a bit more sense. Despite its disadvantages, many people do use it. I personally prefer to just use L2 regularization and try different values of lambda. Thats assuming you can afford the computation to do so. But early stopping does let you get a similar effect without needing to explicitly try lots of different values of lambda. So youve now seen how to use data augmentation as well as if you wish early stopping in order to reduce variance or prevent over fitting your neural network. Next lets talk about some techniques for setting up your optimization problem to make your training go quickly.</p><h5>Credits - <a href='https://www.coursera.org/' target=_blank >Coursera</a>,  <a href = 'https://en.wikipedia.org/wiki/Andrew_Ng' title="Andrew_Ng" target=_blank>Credits to the teacher</a> , <a href ='https://www.coursera.org/specializations/deep-learning?' target=_blank>Deeplearning.ai Course</a><h5>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;i&gt;&lt;b&gt;Note - These are my notes on DeepLearning Specialization Part:&lt;br&gt;Regularization || Deeplearning (Course - 2 Week - 1) || Improving Deep Neural Networks(Week 1)&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Improving Deep Neural Networks" scheme="https://massivefile.com/categories/Improving-Deep-Neural-Networks/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Regularization" scheme="https://massivefile.com/tags/Regularization/"/>
    
  </entry>
  
  <entry>
    <title>Setting Up Optimisation (Normalization | Vanishing/Exploding Gradients , Weight Initialization , Gradient Checking)</title>
    <link href="https://massivefile.com/SettingUpOptimisation/"/>
    <id>https://massivefile.com/SettingUpOptimisation/</id>
    <published>2020-04-18T00:56:53.000Z</published>
    <updated>2020-05-05T23:22:59.945Z</updated>
    
    <content type="html"><![CDATA[<p><i><b>Note - These are my notes on DeepLearning Specialization Course 2 Part:<br>Setting Up Optimisation (Normalization | Vanishing/Exploding Gradients , Weight Initialization , Gradient Checking || Improving Deep Neural Networks (Week 1 - Part 1)<br></i></b><a id="more"></a></p><h3><b>Introduction: </b></h3>When training a neural network, one of the techniques that will speed up your training is if you normalize your inputs. Let's see what that means. Let's see if a training sets with two input features. So the input features x are two dimensional, and here's a scatter plot of your training set.<center><img src='https://lh3.googleusercontent.com/9OxDjLP6PApTrbdaOtPMTsOBqC77w1d7NxUMG_58trd9ohPA1DTFjRMR_c9wzrP3VUmCqVPk4xcRKNXVbDdzYG58GEam1OLOWvUtu9CfLWRh4nBHUoQW4Wm72kGbpF3aD4SlMlEQMw=w2400' /></center> <p>Normalizing your inputs corresponds to two steps. The first is to subtract out or to zero out the mean. So you set mu = 1 over M sum over I of Xi. So this is a vector, and then X gets set as X- mu for every training example, so this means you just move the training set until it has 0 mean. And then the second step is to normalize the variances. So notice here that the feature X1 has a much larger variance than the feature X2 here. So what we do is set sigma = 1 over m sum of Xi**2.<br>I guess this is a element y squaring. And so now sigma squared is a vector with the variances of each of the features, and notice weve already subtracted out the mean, so Xi squared, element y squared is just the variances. And you take each example and divide it by this vector sigma squared. And so in pictures, you end up with this. Where now the variance of X1 and X2 are both equal to one.</p><p>And one tip, if you use this to scale your training data, then use the same mu and sigma squared to normalize your test set, right? In particular, you dont want to normalize the training set and the test set differently. Whatever this value is and whatever this value is, use them in these two formulas so that you scale your test set in exactly the same way, rather than estimating mu and sigma squared separately on your training set and test set. Because you want your data, both training and test examples, to go through the same transformation defined by the same mu and sigma squared calculated on your training data.<br><b><h3>So, why do we do Normalization?</h3></b><br>Why do we want to normalize the input features? Recall that a cost function is defined as written on the top right. It turns out that if you use unnormalized input features, its more likely that your cost function will look like this, its a very squished out bowl, very elongated cost function, where the minimum youre trying to find is maybe over there. But if your features are on very different scales, say the feature X1 ranges from 1 to 1,000, and the feature X2 ranges from 0 to 1, then it turns out that the ratio or the range of values for the parameters w1 and w2 will end up taking on very different values. And so maybe these axes should be w1 and w2, but Ill plot w and b, then your cost function can be a very elongated bowl like that. </p><center><img src='https://lh3.googleusercontent.com/QmNrK_RkPKU6RVMKeVydmkTHzL-IK540_a7N_eXvGPBvtO2_LBiQp_-koFsgtg-oN6slWtaSM5iQFUmTTgg6MHNeCNzbil34FFbdI0iH0Ym5NoELeoNcZ-D8EWgs3XeQQQ0i-kDKPw=w2400' /></center>So if you part the contours of this function, you can have a very elongated function like that. Whereas if you normalize the features, then your cost function will on average look more symmetric. And if you're running gradient descent on the cost function like the one on the left, then you might have to use a very small learning rate because if you're here that gradient descent might need a lot of steps to oscillate back and forth before it finally finds its way to the minimum. Whereas if you have a more spherical contours, then wherever you start gradient descent can pretty much go straight to the minimum. You can take much larger steps with gradient descent rather than needing to oscillate around like like the picture on the left. Of course in practice w is a high-dimensional vector, and so trying to plot this in 2D doesn't convey all the intuitions correctly. But the rough intuition that your cost function will be more round and easier to optimize when your features are all on similar scales. Not from one to 1000, zero to one, but mostly from minus one to one or of about similar variances of each other. That just makes your cost function J easier and faster to optimize. In practice if one feature, say X1, ranges from zero to one, and X2 ranges from minus one to one, and X3 ranges from one to two, these are fairly similar ranges, so this will work just fine. It's when they're on dramatically different ranges like ones from 1 to a 1000, and the another from 0 to 1, that that really hurts your authorization algorithm. But by just setting all of them to a 0 mean and say, variance 1, like we did in the last slide, that just guarantees that all your features on a similar scale and will usually help your learning algorithm run faster. So, if your input features came from very different scales, maybe some features are from 0 to 1, some from 1 to 1,000, then it's important to normalize your features. If your features came in on similar scales, then this step is less important. Although performing this type of normalization pretty much never does any harm, so I'll often do it anyway if I'm not sure whether or not it will help with speeding up training for your algebra.<p>So thats it for normalizing your input features. Next, lets keep talking about ways to speed up the training of your new network.<br>When training a neural network, one of the techniques</p><h2><b>Vanishing / Exploding gradients</b></h2><p>One of the problems of training neural network, especially very deep neural networks, is data vanishing and exploding gradients. What that means is that when youre training a very deep network your derivatives or your slopes can sometimes get either very, very big or very, very small, maybe even exponentially small, and this makes training difficult. In this Topic you see what this problem of exploding and vanishing gradients really means, as well as how you can use careful choices of the random weight initialization to significantly reduce this problem. Unless youre training a very deep neural network like this, to save space on the slide, Ive drawn it as if you have only two hidden units per layer, but it could be more as well. But this neural network will have parameters W1, W2, W3 and so on up to WL. <center><img src='https://lh3.googleusercontent.com/Q3W0fEM_mFd1V-qLMWT2svKLYl3lbOuSNk9ph1X8G6cwIVq9J-kIwVoq08hBnjJOgiDpzfzZcwIahtiu2Mzd50rUmy5ZNE7cB8NxwjDijZdGjHBryf2OibhL-SjmamUpemehoaqhQQ=w2400' /></center> For the sake of simplicity, lets say were using an activation function G of Z equals Z, so linear activation function. And lets ignore B, lets say B of L equals zero. So in that case you can show that the output Y will be WL times WL minus one times WL minus two, dot, dot, dot down to the W3, W2, W1 times X. But if you want to just check my math, W1 times X is going to be Z1, because B is equal to zero. So Z1 is equal to, I guess, W1 times X and then plus B which is zero. But then A1 is equal to G of Z1.<br>But because we use linear activation function, this is just equal to Z1. So this first term W1X is equal to A1. And then by the reasoning you can figure out that W2 times W1 times X is equal to A2, because thats going to be G of Z2, is going to be G of W2 times A1 which you can plug that in here. So this thing is going to be equal to A2, and then this thing is going to be A3 and so on until the protocol of all these matrices gives you Y-hat, not Y. Now, lets say that each of you weight matrices WL is just a little bit larger than one times the identity. So its 1.5_1.5_0_0. </p><p>Technically, the last one has different dimensions so maybe this is just the rest of these weight matrices. Then Y-hat will be, ignoring this last one with different dimension, this 1.5_0_0_1.5 matrix to the power of L minus 1 times X, because we assume that each one of these matrices is equal to this thing. Its really 1.5 times the identity matrix, then you end up with this calculation. And so Y-hat will be essentially 1.5 to the power of L, to the power of L minus 1 times X, and if L was large for very deep neural network, Y-hat will be very large. In fact, it just grows exponentially, it grows like 1.5 to the number of layers. And so if you have a very deep neural network, the value of Y will explode. Now, conversely, if we replace this with 0.5, so something less than 1, then this becomes 0.5 to the power of L. This matrix becomes 0.5 to the L minus one times X, again ignoring WL. And so each of your matrices are less than 1, then lets say X1, X2 were one one, then the activations will be one half, one half, one fourth, one fourth, one eighth, one eighth, and so on until this becomes one over two to the L. So the activation values will decrease exponentially as a function of the def, as a function of the number of layers L of the network. So in the very deep network, the activations end up decreasing exponentially. </p><center><img src='https://lh3.googleusercontent.com/Q3W0fEM_mFd1V-qLMWT2svKLYl3lbOuSNk9ph1X8G6cwIVq9J-kIwVoq08hBnjJOgiDpzfzZcwIahtiu2Mzd50rUmy5ZNE7cB8NxwjDijZdGjHBryf2OibhL-SjmamUpemehoaqhQQ=w2400' /></center>So the intuition I hope you can take away from this is that at the weights W, if they're all just a little bit bigger than one or just a little bit bigger than the identity matrix, then with a very deep network the activations can explode. And if W is just a little bit less than identity. So this maybe here's 0.9, 0.9, then you have a very deep network, the activations will decrease exponentially. And even though I went through this argument in terms of activations increasing or decreasing exponentially as a function of L, a similar argument can be used to show that the derivatives or the gradients the computer is going to send will also increase exponentially or decrease exponentially as a function of the number of layers. With some of the modern neural networks, L equals 150. Microsoft recently got great results with 152 layer neural network. But with such a deep neural network, if your activations or gradients increase or decrease exponentially as a function of L, then these values could get really big or really small. And this makes training difficult, especially if your gradients are exponentially smaller than L, then gradient descent will take tiny little steps. It will take a long time for gradient descent to learn anything. To summarize, you've seen how deep networks suffer from the problems of vanishing or exploding gradients. In fact, for a long time this problem was a huge barrier to training deep neural networks. It turns out there's a partial solution that doesn't completely solve this problem but it helps a lot which is careful choice of how you initialize the weights. To see that, let's go to the next Topic.One of the problems of training neural network, especially very deep neural networks, is data vanishing<h3><b>Weight Initialization for Deep Networks</b></h3>In the last paragraph you saw how very deep neural networks can have the problems of vanishing and exploding gradients. It turns out that a partial solution to this, doesn't solve it entirely but helps a lot, is better or more careful choice of the random initialization for your neural network. <h4><b>Single Neuron</b></h4>To understand this, let's start with the example of initializing the ways for a single neuron, and then we're go on to generalize this to a deep network. Let's go through this with an example with just a single neuron, and then we'll talk about the deep net later. So with a single neuron, you might input four features, x1 through x4, and then you have some a=g(z) and then it outputs some y. And later on for a deeper net, you know these inputs will be right, some layer a(l), but for now let's just call this x for now. <center><img src='https://lh3.googleusercontent.com/USFAtdNm0RCsytlythdEzQqlTQeNrFTMj5XPbfpS4tWNlw35ylqQknNdWPVaappekVIwfv7t9FAoPPWpWv-8QXOtGxPmKvEulSc2nqxI_gVlpiMxEgclAVFliY-P5nVQ5da-VKkqnw=w2400' /></center>So z is going to be equal to w1x1 + w2x2 +... + I guess WnXn. And let's set b=0 so, you know, let's just ignore b for now. So in order to make z not blow up and not become too small, you notice that the larger n is, the smaller you want Wi to be, right? Because z is the sum of the WiXi. And so if you're adding up a lot of these terms, you want each of these terms to be smaller. One reasonable thing to do would be to set the variance of Wi to be equal to 1 over n, where n is the number of input features that's going into a neuron. So in practice, what you can do is set the weight matrix W for a certain layer to be np.random.randn you know, and then whatever the shape of the matrix is for this out here, and then times square root of 1 over the number of features that I fed into each neuron in layer l. So there's going to be n(l-1) because that's the number of units that I'm feeding into each of the units in layer l. <h4><b>Using RElu Activation Function:</b></h4>It turns out that if you're using a ReLu activation function that, rather than 1 over n it turns out that, set in the variance of 2 over n works a little bit better. So you often see that in initialization, especially if you're using a ReLu activation function. So if gl(z) is ReLu(z), oh and it depends on how familiar you are with random variables. It turns out that something, a Gaussian random variable and then multiplying it by a square root of this, that sets the variance to be quoted this way, to be 2 over n. And the reason I went from n to this n superscript l-1 was, in this example with logistic regression which is at n input features, but the more general case layer l would have n(l-1) inputs each of the units in that layer. So if the input features of activations are roughly mean 0 and standard variance and variance 1 then this would cause z to also take on a similar scale. And this doesn't solve, but it definitely helps reduce the vanishing, exploding gradients problem, because it's trying to set each of the weight matrices w, you know, so that it's not too much bigger than 1 and not too much less than 1 so it doesn't explode or vanish too quickly. I've just mention some other variants. The version we just described is assuming a ReLu activation function and this by a paper by [inaudible]. <h4><b>Using TanH Activation Function: </b></h4>A few other variants, if you are using a TanH activation function then there's a paper that shows that instead of using the constant 2, it's better use the constant 1 and so 1 over this instead of 2. And so you multiply it by the square root of this. So this square root term will replace this term and you use this if you're using a TanH activation function. This is called Xavier initialization. And another version we're taught by Yoshua Bengio and his colleagues, you might see in some papers, but is to use this formula, which you know has some other theoretical justification, but I would say if you're using a ReLu activation function, which is really the most common activation function, I would use this formula. If you're using TanH you could try this version instead, and some authors will also use this. But in practice I think all of these formulas just give you a starting point. It gives you a default value to use for the variance of the initialization of your weight matrices. If you wish the variance here, this variance parameter could be another thing that you could tune with your hyperparameters. So you could have another parameter that multiplies into this formula and tune that multiplier as part of your hyperparameter surge. Sometimes tuning the hyperparameter has a modest size effect. <center><img src='https://lh3.googleusercontent.com/USFAtdNm0RCsytlythdEzQqlTQeNrFTMj5XPbfpS4tWNlw35ylqQknNdWPVaappekVIwfv7t9FAoPPWpWv-8QXOtGxPmKvEulSc2nqxI_gVlpiMxEgclAVFliY-P5nVQ5da-VKkqnw=w2400' /></center>It's not one of the first hyperparameters I would usually try to tune, but I've also seen some problems where tuning this helps a reasonable amount. But this is usually lower down for me in terms of how important it is relative to the other hyperparameters you can tune. So I hope that gives you some intuition about the problem of vanishing or exploding gradients as well as choosing a reasonable scaling for how you initialize the weights. Hopefully that makes your weights not explode too quickly and not decay to zero too quickly, so you can train a reasonably deep network without the weights or the gradients exploding or vanishing too much. When you train deep networks, this is another trick that will help you make your neural networks trained much more quickly.<h4><b>Numerical approximation of gradients</b></h4>When you implement back propagation you'll find that there's a test called creating checking that can really help you make sure that your implementation of back prop is correct. Because sometimes you write all these equations and you're just not 100% sure if you've got all the details right and internal back propagation. So in order to build up to gradient and checking, let's first talk about how to numerically approximate computations of gradients and in the next Topic, we'll talk about how you can implement gradient checking to make sure the implementation of backdrop is correct. So lets take the function f and replot it here and remember this is f of theta equals theta cubed, and let's again start off to some value of theta. Let's say theta equals 1. Now instead of just nudging theta to the right to get theta plus epsilon, we're going to nudge it to the right and nudge it to the left to get theta minus epsilon, as was theta plus epsilon. So this is 1, this is 1.01, this is 0.99 where, again, epsilon is same as before, it is 0.01. It turns out that rather than taking this little triangle and computing the height over the width, you can get a much better estimate of the gradient if you take this point, f of theta minus epsilon and this point, and you instead compute the height over width of this bigger triangle. So for technical reasons which I won't go into, the height over width of this bigger green triangle gives you a much better approximation to the derivative at theta. And you saw it yourself, taking just this lower triangle in the upper right is as if you have two triangles, right? This one on the upper right and this one on the lower left. And you're kind of taking both of them into account by using this bigger green triangle. So rather than a one sided difference, you're taking a two sided difference. <center><img src='https://lh3.googleusercontent.com/ZXRr2_3cQYJLeXZ_Phe9zhE7DKQvVXUdIu_YFbSymXPziknQV_UvkQn3L0z5etZUc-c9uRmnMXZVCWpwnJ2KEcAokMrEx7vgPS0LWUvUvUIP-Ln3cXbdt4acFNttc2QBumTfC-CocA=w2400' /></center>So let's work out the math. This point here is F of theta plus epsilon. This point here is F of theta minus epsilon. So the height of this big green triangle is f of theta plus epsilon minus f of theta minus epsilon. And then the width, this is 1 epsilon, this is 2 epsilon. So the width of this green triangle is 2 epsilon. So the height of the width is going to be first the height, so that's F of theta plus epsilon minus F of theta minus epsilon divided by the width. So that was 2 epsilon which we write that down here.And this should hopefully be close to g of theta. So plug in the values, remember f of theta is theta cubed. So theta plus epsilon is 1.01. So I take a cube of that minus 0.99 theta cube of that divided by 2 times 0.01. Feel free to practice in the calculator. You should get that this is 3.0001. <center><img src='https://lh3.googleusercontent.com/KHzqEvI8T5YKBV4GgCXppFjMXhZthr2mCvQAODoROrh2M5xtnpdvdC3_RGEG7qFRUTRy2pxxzYLz-FfcTGQC23i-QhFvGTT_3S24bZmV5ihyZFdCKuMmWBPjEMMZswP5cOll-ioWYg=w2400' /></center> So this two sided difference way of approximating the derivative you find that this is extremely close to 3. And so this gives you a much greater confidence that g of theta is probably a correct implementation of the derivative of F.<h4><b>Single Sided Difference:</b></h4>When you use this method for grading, checking and back propagation, this turns out to run twice as slow as you were to use a one-sided defferense. It turns out that in practice I think it's worth it to use this other method because it's just much more accurate. The little bit of optional theory for those of you that are a little bit more familiar of Calculus, it turns out that, and it's okay if you don't get what I'm about to say here. But it turns out that the formal definition of a derivative is for very small values of epsilon is f of theta plus epsilon minus f of theta minus epsilon over 2 epsilon. And the formal definition of derivative is in the limits of exactly that formula on the right as epsilon those as 0. And the definition of unlimited is something that you learned if you took a Calculus class but I won't go into that here. And it turns out that for a non zero value of epsilon, you can show that the error of this approximation is on the order of epsilon squared, and remember epsilon is a very small number. So if epsilon is 0.01 which it is here then epsilon squared is 0.0001. The big O notation means the error is actually some constant times this, but this is actually exactly our approximation error. So the big O constant happens to be 1. Whereas in contrast if we were to use this formula, the other one, then the error is on the order of epsilon. And again, when epsilon is a number less than 1, then epsilon is actually much bigger than epsilon squared which is why this formula here is actually much less accurate approximation than this formula on the left. Which is why when doing gradient checking, we rather use this two-sided difference when you compute f of theta plus epsilon minus f of theta minus epsilon and then divide by 2 epsilon rather than just one sided difference which is less accurate.<center><<img src='https://lh3.googleusercontent.com/KHzqEvI8T5YKBV4GgCXppFjMXhZthr2mCvQAODoROrh2M5xtnpdvdC3_RGEG7qFRUTRy2pxxzYLz-FfcTGQC23i-QhFvGTT_3S24bZmV5ihyZFdCKuMmWBPjEMMZswP5cOll-ioWYg=w2400' /></center>If you didn't understand my last two comments, all of these things are on here. Don't worry about it. That's really more for those of you that are a bit more familiar with Calculus, and with numerical approximations. <h4><b>TakeAway:</b></h4>But the takeaway is that this two-sided difference formula is much more accurate. And so that's what we're going to use when we do gradient checking in the next Topic.So you've seen how by taking a two sided difference, you can numerically verify whether or not a function g, g of theta that someone else gives you is a correct implementation of the derivative of a function f. Let's now see how we can use this to verify whether or not your back propagation implementation is correct or if there might be a bug in there that you need to go and tease out<h5>Credits - <a href='https://www.coursera.org/' target=_blank >Coursera</a>,  <a href = 'https://en.wikipedia.org/wiki/Andrew_Ng' title="Andrew_Ng" target=_blank>Credits to the teacher</a> , <a href ='https://www.coursera.org/specializations/deep-learning?' target=_blank>Deeplearning.ai Course</a><h5>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;i&gt;&lt;b&gt;Note - These are my notes on DeepLearning Specialization Course 2 Part:&lt;br&gt;Setting Up Optimisation (Normalization | Vanishing/Exploding Gradients , Weight Initialization , Gradient Checking || Improving Deep Neural Networks (Week 1 - Part 1)&lt;br&gt;&lt;/i&gt;&lt;/b&gt;
    
    </summary>
    
    
      <category term="Improving Deep Neural Networks" scheme="https://massivefile.com/categories/Improving-Deep-Neural-Networks/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Setting Up Optimisation Problem" scheme="https://massivefile.com/tags/Setting-Up-Optimisation-Problem/"/>
    
      <category term="Normalization" scheme="https://massivefile.com/tags/Normalization/"/>
    
      <category term="Vanishing / Exploding gradients" scheme="https://massivefile.com/tags/Vanishing-Exploding-gradients/"/>
    
  </entry>
  
  <entry>
    <title>Building your Deep Neural Network Step by Step</title>
    <link href="https://massivefile.com/Building_your_Deep_Neural_Network/"/>
    <id>https://massivefile.com/Building_your_Deep_Neural_Network/</id>
    <published>2020-04-16T00:56:53.000Z</published>
    <updated>2020-05-05T23:20:59.933Z</updated>
    
    <content type="html"><![CDATA[<p><i><b>Note - These are my notes on DeepLearning Specialization Part:<br>Building your Deep Neural Network Step by Step || (Course- 1 Week - 4) || Neural Networks and Deep Learning (Week 4)</i></b></p><a id="more"></a><h1 id="Building-your-Deep-Neural-Network-Step-by-Step"><a href="#Building-your-Deep-Neural-Network-Step-by-Step" class="headerlink" title="Building your Deep Neural Network: Step by Step"></a>Building your Deep Neural Network: Step by Step</h1><p>Welcome to your week 4 assignment (part 1 of 2)! You have previously trained a 2-layer Neural Network (with a single hidden layer). This week, you will build a deep neural network, with as many layers as you want!</center></p><ul><li>In this notebook, you will implement all the functions required to build a deep neural network.</li><li>In the next assignment, you will use these functions to build a deep neural network for image classification.</li></ul><p><strong>After this assignment you will be able to:</strong></p><ul><li>Use non-linear units like ReLU to improve your model</li><li>Build a deeper neural network (with more than 1 hidden layer)</li><li>Implement an easy-to-use neural network class</li></ul><p><strong>Notation</strong>:</p><ul><li>Superscript $[l]$ denotes a quantity associated with the $l^{th}$ layer. <ul><li>Example: $a^{[L]}$ is the $L^{th}$ layer activation. $W^{[L]}$ and $b^{[L]}$ are the $L^{th}$ layer parameters.</li></ul></li><li>Superscript $(i)$ denotes a quantity associated with the $i^{th}$ example. <ul><li>Example: $x^{(i)}$ is the $i^{th}$ training example.</li></ul></li><li>Lowerscript $i$ denotes the $i^{th}$ entry of a vector.<ul><li>Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the $l^{th}$ layers activations).</li></ul></li></ul><p>Lets get started!</p><h2 id="1-Packages"><a href="#1-Packages" class="headerlink" title="1. Packages"></a>1. Packages</h2><p>Lets first import all the packages that you will need during this assignment. </p><ul><li>numpy is the main package for scientific computing with Python. </li><li>matplotlib is a library to plot graphs in Python. </li><li><code>dnn_utils</code> provides some necessary functions for this notebook. </li><li><code>testCases</code> provides some test cases to assess the correctness of your functions </li><li>np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work. Please dont change the seed.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np;</span><br><span class="line"><span class="keyword">import</span> h5py;</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt;</span><br><span class="line"><span class="keyword">from</span> testCases_v3 <span class="keyword">import</span> *;</span><br><span class="line"><span class="keyword">from</span> dnn_utils_v2 <span class="keyword">import</span> sigmoid, sigmoid_backward, relu, relu_backward;</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">5.0</span>, <span class="number">4.0</span>); <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span>;</span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span>;</span><br><span class="line"></span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>You can get the support code from here.</p><p>the <code>sigmoid</code> function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(Z)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the sigmoid activation in numpy</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    Z -- numpy array of any shape</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    A -- output of sigmoid(z), same shape as Z</span></span><br><span class="line"><span class="string">    cache -- returns Z as well, useful during backpropagation</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    A = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-Z));</span><br><span class="line">    cache = Z;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> A, cache;</span><br></pre></td></tr></table></figure><p>the <code>sigmoid_backward</code> function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_backward</span><span class="params">(dA, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward propagation for a single SIGMOID unit.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    dA -- post-activation gradient, of any shape</span></span><br><span class="line"><span class="string">    cache -- 'Z' where we store for computing backward propagation efficiently</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    dZ -- Gradient of the cost with respect to Z</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    Z = cache;</span><br><span class="line"></span><br><span class="line">    s = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-Z));</span><br><span class="line">    dZ = dA * s * (<span class="number">1</span> - s);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> (dZ.shape == Z.shape);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dZ;</span><br></pre></td></tr></table></figure><p>the <code>relu</code> function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(Z)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the RELU function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    Z -- Output of the linear layer, of any shape</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    A -- Post-activation parameter, of the same shape as Z</span></span><br><span class="line"><span class="string">    cache -- a python dictionary containing "A" ; stored for computing the backward pass efficiently</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    A = np.maximum(<span class="number">0</span>,Z);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span>(A.shape == Z.shape);</span><br><span class="line"></span><br><span class="line">    cache = Z; </span><br><span class="line">    <span class="keyword">return</span> A, cache;</span><br></pre></td></tr></table></figure><p>the <code>relu_backward</code> function</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu_backward</span><span class="params">(dA, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward propagation for a single RELU unit.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    dA -- post-activation gradient, of any shape</span></span><br><span class="line"><span class="string">    cache -- 'Z' where we store for computing backward propagation efficiently</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    dZ -- Gradient of the cost with respect to Z</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    Z = cache;</span><br><span class="line">    dZ = np.array(dA, copy = <span class="literal">True</span>); <span class="comment"># just converting dz to a correct object.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># When z &lt;= 0, you should set dz to 0 as well. </span></span><br><span class="line">    dZ[Z &lt;= <span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> (dZ.shape == Z.shape);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dZ;</span><br></pre></td></tr></table></figure><h2 id="2-Outline-of-the-Assignment"><a href="#2-Outline-of-the-Assignment" class="headerlink" title="2. Outline of the Assignment"></a>2. Outline of the Assignment</h2><p>To build your neural network, you will be implementing several helper functions. These helper functions will be used in the next assignment to build a two-layer neural network and an L-layer neural network. Each small helper function you will implement will have detailed instructions that will walk you through the necessary steps. Here is an outline of this assignment, you will:</p><ul><li><p>Initialize the parameters for a two-layer network and for an L-layer neural network.</p></li><li><p>Implement the forward propagation module (shown in purple in the figure below). </p><ul><li>Complete the LINEAR part of a layers forward propagation step (resulting in Z[l]).</li><li>We give you the ACTIVATION function (relu/sigmoid).</li><li>Combine the previous two steps into a new [LINEAR-&gt;ACTIVATION] forward function.</li><li>Stack the [LINEAR-&gt;RELU] forward function L-1 time (for layers 1 through L-1) and add a [LINEAR-&gt;SIGMOID] at the end (for the final layer L). This gives you a new L_model_forward function.</li></ul></li><li><p>Compute the loss.</p></li><li><p>Implement the backward propagation module (denoted in red in the figure below). </p><ul><li>Complete the LINEAR part of a layers backward propagation step.</li><li>We give you the gradient of the ACTIVATE function (relu_backward/sigmoid_backward)</li><li>Combine the previous two steps into a new [LINEAR-&gt;ACTIVATION] backward function.</li><li>Stack [LINEAR-&gt;RELU] backward L-1 times and add [LINEAR-&gt;SIGMOID] backward in a new L_model_backward function</li></ul></li><li><p>Finally update the parameters.</p></li></ul><p><strong>Note</strong> that for every forward function, there is a corresponding backward function. That is why at every step of your forward module you will be storing some values in a cache. The cached values are useful for computing gradients. In the backpropagation module you will then use the cache to calculate the gradients. This assignment will show you exactly how to carry out each of these steps.</p><h2 id="3-Initialization"><a href="#3-Initialization" class="headerlink" title="3. Initialization"></a>3. Initialization</h2><p>You will write two helper functions that will initialize the parameters for your model. The first function will be used to initialize parameters for a two layer model. The second one will generalize this initialization process to L layers.</p><h3 id="3-1-2-layer-Neural-Network"><a href="#3-1-2-layer-Neural-Network" class="headerlink" title="3.1 2-layer Neural Network"></a>3.1 2-layer Neural Network</h3><p><strong>Exercise</strong>: Create and initialize the parameters of the 2-layer neural network.</p><p><strong>Instructions</strong>: </p><ul><li>The models structure is: LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID. </li><li>Use random initialization for the weight matrices. Use <code>np.random.randn(shape)*0.01</code> with the correct shape. </li><li>Use zero initialization for the biases. Use <code>np.zeros(shape)</code>.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: initialize_parameters</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">(n_x, n_h, n_y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Argument:</span></span><br><span class="line"><span class="string">    n_x -- size of the input layer</span></span><br><span class="line"><span class="string">    n_h -- size of the hidden layer</span></span><br><span class="line"><span class="string">    n_y -- size of the output layer</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters:</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (n_h, n_x)</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (n_h, 1)</span></span><br><span class="line"><span class="string">                    W2 -- weight matrix of shape (n_y, n_h)</span></span><br><span class="line"><span class="string">                    b2 -- bias vector of shape (n_y, 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 4 lines of code)</span></span><br><span class="line">    W1 = np.random.randn(n_h, n_x) * <span class="number">0.01</span>;</span><br><span class="line">    b1 = np.zeros((n_h, <span class="number">1</span>));</span><br><span class="line">    W2 = np.random.randn(n_y, n_h) * <span class="number">0.01</span>;</span><br><span class="line">    b2 = np.zeros((n_y, <span class="number">1</span>));</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span>(W1.shape == (n_h, n_x));</span><br><span class="line">    <span class="keyword">assert</span>(b1.shape == (n_h, <span class="number">1</span>));</span><br><span class="line">    <span class="keyword">assert</span>(W2.shape == (n_y, n_h));</span><br><span class="line">    <span class="keyword">assert</span>(b2.shape == (n_y, <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">    parameters = &#123;<span class="string">"W1"</span>: W1,</span><br><span class="line">                  <span class="string">"b1"</span>: b1,</span><br><span class="line">                  <span class="string">"W2"</span>: W2,</span><br><span class="line">                  <span class="string">"b2"</span>: b2&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = initialize_parameters(<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>);</span><br><span class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]));</span><br><span class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]));</span><br><span class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]));</span><br><span class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]));</span><br></pre></td></tr></table></figure><pre><code>W1 = [[ 0.01624345 -0.00611756 -0.00528172] [-0.01072969  0.00865408 -0.02301539]]b1 = [[0.] [0.]]W2 = [[ 0.01744812 -0.00761207]]b2 = [[0.]]</code></pre><h3 id="3-2-L-layer-Neural-Network"><a href="#3-2-L-layer-Neural-Network" class="headerlink" title="3.2 L-layer Neural Network"></a>3.2 L-layer Neural Network</h3><p>The initialization for a deeper L-layer neural network is more complicated because there are many more weight matrices and bias vectors. When completing the <code>initialize_parameters_deep</code>, you should make sure that your dimensions match between each layer. Recall that $n^{[l]}$ is the number of units in layer $l$. Thus for example if the size of our input $X$ is $(12288,209)$ (with $m=209$ examples) then:</p><p>| |Shape of W|Shape of b|Activation|Shape of Activation|<br>||-|||<br>|Layer 1|(n[1],12288)|(n[1],1)|Z[1]=W[1]X+b[1]|(n[1],209)|<br>|Layer 2|(n[2],n[1]) |(n[2],1)|Z[2]=W[2]A[1]+b[2]|(n[2],209)|<br>|$\vdots$|$\vdots$|$\vdots$|$\vdots$|$\vdots$|<br>|Layer L-1|(n[L1],n[L2])|(n[L1],1)|Z[L1]=W[L1]A[L2]+b[L1]|(n[L1],209)|<br>|Layer L|(n[L],n[L1])|(n[L],1)|Z[L]=W[L]A[L1]+b[L]|(n[L],209)|<br>The initialization for a deeper L-layer neural network is more complicated because there are many more weight matrices and bias vectors. When completing the <code>initialize_parameters_deep</code>, you should make sure that your dimensions match between each layer. Recall that $n^{[l]}$ is the number of units in layer $l$. Thus for example if the size of our input $X$ is $(12288, 209)$ (with $m=209$ examples) then:</p><table style="width:100%"><pre><code>&lt;tr&gt;    &lt;td&gt;  &lt;/td&gt;     &lt;td&gt; **Shape of W** &lt;/td&gt;     &lt;td&gt; **Shape of b**  &lt;/td&gt;     &lt;td&gt; **Activation** &lt;/td&gt;    &lt;td&gt; **Shape of Activation** &lt;/td&gt; &lt;tr&gt;&lt;tr&gt;    &lt;td&gt; **Layer 1** &lt;/td&gt;     &lt;td&gt; $(n^{[1]},12288)$ &lt;/td&gt;     &lt;td&gt; $(n^{[1]},1)$ &lt;/td&gt;     &lt;td&gt; $Z^{[1]} = W^{[1]}  X + b^{[1]} $ &lt;/td&gt;     &lt;td&gt; $(n^{[1]},209)$ &lt;/td&gt; &lt;tr&gt;&lt;tr&gt;    &lt;td&gt; **Layer 2** &lt;/td&gt;     &lt;td&gt; $(n^{[2]}, n^{[1]})$  &lt;/td&gt;     &lt;td&gt; $(n^{[2]},1)$ &lt;/td&gt;     &lt;td&gt;$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$ &lt;/td&gt;     &lt;td&gt; $(n^{[2]}, 209)$ &lt;/td&gt; &lt;tr&gt;   &lt;tr&gt;    &lt;td&gt; $\vdots$ &lt;/td&gt;     &lt;td&gt; $\vdots$  &lt;/td&gt;     &lt;td&gt; $\vdots$  &lt;/td&gt;     &lt;td&gt; $\vdots$&lt;/td&gt;     &lt;td&gt; $\vdots$  &lt;/td&gt; &lt;tr&gt;</code></pre>   <tr>        <td> **Layer L-1** </td>         <td> $(n^{[L-1]}, n^{[L-2]})$ </td>         <td> $(n^{[L-1]}, 1)$  </td>         <td>$Z^{[L-1]} =  W^{[L-1]} A^{[L-2]} + b^{[L-1]}$ </td>         <td> $(n^{[L-1]}, 209)$ </td>     <tr>   <tr>        <td> **Layer L** </td>         <td> $(n^{[L]}, n^{[L-1]})$ </td>         <td> $(n^{[L]}, 1)$ </td>        <td> $Z^{[L]} =  W^{[L]} A^{[L-1]} + b^{[L]}$</td>        <td> $(n^{[L]}, 209)$  </td>     <tr></table><p>Then $WX+b$ will be:</p>$$WX + b = \begin{bmatrix}    (ja + kd + lg) + s  & (jb + ke + lh) + s  & (jc + kf + li)+ s\\    (ma + nd + og) + t & (mb + ne + oh) + t & (mc + nf + oi) + t\\    (pa + qd + rg) + u & (pb + qe + rh) + u & (pc + qf + ri)+ u\end{bmatrix}\tag{2}$$<p><strong>Exercise</strong>: Implement initialization for an L-layer Neural Network.</p><p><strong>Instructions</strong>: </p><ul><li><p>The models structure is [LINEAR -&gt; RELU]  (L-1) -&gt; LINEAR -&gt; SIGMOID. I.e., it has L1 layers using a ReLU activation function followed by an output layer with a sigmoid activation function. </p></li><li><p>Use random initialization for the weight matrices. Use <code>np.random.rand(shape) * 0.01</code>. </p></li><li><p>Use zeros initialization for the biases. Use <code>np.zeros(shape)</code>. </p></li><li><p>We will store $n^{[l]}$, the number of units in different layers, in a variable <code>layer_dims</code>. For example, the <code>layer_dims</code> for the Planar Data classification model from last week would have been [2,4,1]: There were two inputs, one hidden layer with 4 hidden units, and an output layer with 1 output unit. Thus means <code>W1</code>s shape was (4,2), <code>b1</code> was (4,1), <code>W2</code> was (1,4) and <code>b2</code> was (1,1). Now you will generalize this to L layers! </p></li><li><p>Here is the implementation for L=1 (one layer neural network). It should inspire you to implement the general case (L-layer neural network).</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> L == <span class="number">1</span>:</span><br><span class="line">parameters[<span class="string">"W"</span> + str(L)] = np.random.randn(layer_dims[<span class="number">1</span>], layer_dims[<span class="number">0</span>]) * <span class="number">0.01</span>;</span><br><span class="line">parameters[<span class="string">"b"</span> + str(L)] = np.zeros((layer_dims[<span class="number">1</span>], <span class="number">1</span>));</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: initialize_parameters_deep</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters_deep</span><span class="params">(layer_dims)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    layer_dims -- python array (list) containing the dimensions of each layer in our network</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL":</span></span><br><span class="line"><span class="string">                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])</span></span><br><span class="line"><span class="string">                    bl -- bias vector of shape (layer_dims[l], 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="number">3</span>);</span><br><span class="line">    parameters = &#123;&#125;;</span><br><span class="line">    L = len(layer_dims);     <span class="comment"># number of layers in the network</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L):</span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">        parameters[<span class="string">"W"</span> + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - <span class="number">1</span>]) * <span class="number">0.01</span>;</span><br><span class="line">        parameters[<span class="string">"b"</span> + str(l)] = np.zeros((layer_dims[l], <span class="number">1</span>));</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span>(parameters[<span class="string">'W'</span> + str(l)].shape == (layer_dims[l], layer_dims[l<span class="number">-1</span>]));</span><br><span class="line">        <span class="keyword">assert</span>(parameters[<span class="string">'b'</span> + str(l)].shape == (layer_dims[l], <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = initialize_parameters_deep([<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>]);</span><br><span class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]));</span><br><span class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]));</span><br><span class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]));</span><br><span class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]));</span><br></pre></td></tr></table></figure><pre><code>W1 = [[ 0.01788628  0.0043651   0.00096497 -0.01863493 -0.00277388] [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218] [-0.01313865  0.00884622  0.00881318  0.01709573  0.00050034] [-0.00404677 -0.0054536  -0.01546477  0.00982367 -0.01101068]]b1 = [[0.] [0.] [0.] [0.]]W2 = [[-0.01185047 -0.0020565   0.01486148  0.00236716] [-0.01023785 -0.00712993  0.00625245 -0.00160513] [-0.00768836 -0.00230031  0.00745056  0.01976111]]b2 = [[0.] [0.] [0.]]</code></pre><h2 id="4-Forward-propagation-module"><a href="#4-Forward-propagation-module" class="headerlink" title="4 Forward propagation module"></a>4 Forward propagation module</h2><h3 id="4-1-Linear-Forward"><a href="#4-1-Linear-Forward" class="headerlink" title="4.1 Linear Forward"></a>4.1 Linear Forward</h3><p>Now that you have initialized your parameters, you will do the forward propagation module. You will start by implementing some basic functions that you will use later when implementing the model. You will complete three functions in this order:</p><ul><li>LINEAR</li><li>LINEAR -&gt; ACTIVATION where ACTIVATION will be either ReLU or Sigmoid.</li><li>[LINEAR -&gt; RELU]  (L-1) -&gt; LINEAR -&gt; SIGMOID (whole model)</li></ul><p>The linear forward module (vectorized over all the examples) computes the following equations:<br>$$Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}\tag{3}$$</p><p>where $A^{[0]}=X$.</p><p><strong>Exercise</strong>: Build the linear part of forward propagation.</p><p><strong>Reminder</strong>:<br>The mathematical representation of this unit is $Z^{[l]}=W^{[l]}A^{[l1]}+b^{[l]}$. You may also find <code>np.dot()</code> useful. If your dimensions dont match, printing <code>W.shape</code> may help.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: linear_forward</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_forward</span><span class="params">(A, W, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the linear part of a layer's forward propagation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    A -- activations from previous layer (or input data): (size of previous layer, number of examples)</span></span><br><span class="line"><span class="string">    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)</span></span><br><span class="line"><span class="string">    b -- bias vector, numpy array of shape (size of the current layer, 1)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    Z -- the input of the activation function, also called pre-activation parameter </span></span><br><span class="line"><span class="string">    cache -- a python dictionary containing "A", "W" and "b" ; stored for computing the backward pass efficiently</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">    Z = np.dot(W, A) + b;</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span>(Z.shape == (W.shape[<span class="number">0</span>], A.shape[<span class="number">1</span>]));</span><br><span class="line">    cache = (A, W, b);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Z, cache;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A, W, b = linear_forward_test_case();</span><br><span class="line">Z, linear_cache = linear_forward(A, W, b);</span><br><span class="line">print(<span class="string">"Z = "</span> + str(Z));</span><br></pre></td></tr></table></figure><pre><code>Z = [[ 3.26295337 -1.23429987]]</code></pre><p>linear_forward_test_case:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_forward_test_case</span><span class="params">()</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">1</span>);</span><br><span class="line">    A = np.random.randn(<span class="number">3</span>,<span class="number">2</span>);</span><br><span class="line">    W = np.random.randn(<span class="number">1</span>,<span class="number">3</span>);</span><br><span class="line">    b = np.random.randn(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> A, W, b;</span><br></pre></td></tr></table></figure><h3 id="4-2-Linear-Activation-Forward"><a href="#4-2-Linear-Activation-Forward" class="headerlink" title="4.2 Linear-Activation Forward"></a>4.2 Linear-Activation Forward</h3><p>In this notebook, you will use two activation functions:</p><ul><li><strong>Sigmoid</strong>: $\sigma(Z) = \sigma(W A + b) = \frac{1}{ 1 + e^{-(W A + b)} }$ We have provided you with the <code>sigmoid</code> function. This function returns two items: the activation value <code>a</code> and a <code>cache</code> that contains <code>Z</code> (its what we will feed in to the corresponding backward function). To use it you could just call:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A, activation_cache = sigmoid(Z);</span><br></pre></td></tr></table></figure><ul><li><strong>ReLU</strong>: The mathematical formula for ReLu is <code>A=RELU(Z)=max(0,Z)</code>. We have provided you with the relu function. This function returns two items: the activation value <code>A</code> and a <code>cache</code> that contains <code>Z</code> (its what we will feed in to the corresponding backward function). To use it you could just call:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A, activation_cache = relu(Z);</span><br></pre></td></tr></table></figure><p>For more convenience, you are going to group two functions (Linear and Activation) into one function (LINEAR-&gt;ACTIVATION). Hence, you will implement a function that does the LINEAR forward step followed by an ACTIVATION forward step.</p><p><strong>Exercise</strong>: Implement the forward propagation of the LINEAR-&gt;ACTIVATION layer. Mathematical relation is:<br>$A^{[l]} = g(Z^{[l]}) = g(W^{[l]}A^{[l-1]} +b^{[l]})$ where the activation <code>g</code> can be <code>sigmoid()</code> or <code>relu()</code>. Use <code>linear_forward()</code> and the correct activation function.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: linear_activation_forward</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_activation_forward</span><span class="params">(A_prev, W, b, activation)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the forward propagation for the LINEAR-&gt;ACTIVATION layer</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)</span></span><br><span class="line"><span class="string">    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)</span></span><br><span class="line"><span class="string">    b -- bias vector, numpy array of shape (size of the current layer, 1)</span></span><br><span class="line"><span class="string">    activation -- the activation to be used in this layer, stored as a text string: "sigmoid" or "relu"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    A -- the output of the activation function, also called the post-activation value </span></span><br><span class="line"><span class="string">    cache -- a python dictionary containing "linear_cache" and "activation_cache";</span></span><br><span class="line"><span class="string">             stored for computing the backward pass efficiently</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> activation == <span class="string">"sigmoid"</span>:</span><br><span class="line">        <span class="comment"># Inputs: "A_prev, W, b". Outputs: "A, activation_cache".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">        Z, linear_cache = linear_forward(A_prev, W, b); <span class="comment"># Z, (W, A_prev, B)</span></span><br><span class="line">        A, activation_cache = sigmoid(Z); <span class="comment"># A, (Z)</span></span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> activation == <span class="string">"relu"</span>:</span><br><span class="line">        <span class="comment"># Inputs: "A_prev, W, b". Outputs: "A, activation_cache".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">        Z, linear_cache = linear_forward(A_prev, W, b); </span><br><span class="line">        A, activation_cache = relu(Z);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> (A.shape == (W.shape[<span class="number">0</span>], A_prev.shape[<span class="number">1</span>]));</span><br><span class="line">    cache = (linear_cache, activation_cache); <span class="comment">#, ((W, A_prev, B) ,(Z))</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> A, cache;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">A_prev, W, b = linear_activation_forward_test_case();</span><br><span class="line"></span><br><span class="line">A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = <span class="string">"sigmoid"</span>);</span><br><span class="line">print(<span class="string">"With sigmoid: A = "</span> + str(A));</span><br><span class="line"></span><br><span class="line">A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = <span class="string">"relu"</span>);</span><br><span class="line">print(<span class="string">"With ReLU: A = "</span> + str(A));</span><br></pre></td></tr></table></figure><pre><code>With sigmoid: A = [[0.96890023 0.11013289]]With ReLU: A = [[3.43896131 0.        ]]</code></pre><p>linear_activation_forward_test_case function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_activation_forward_test_case</span><span class="params">()</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">2</span>)</span><br><span class="line">    A_prev = np.random.randn(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">    W = np.random.randn(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    b = np.random.randn(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> A_prev, W, b</span><br></pre></td></tr></table></figure><p><strong>Note</strong>: In deep learning, the [LINEAR-&gt;ACTIVATION] computation is counted as a single layer in the neural network, not two layers.</p><h3 id="4-3-L-Layer-Model"><a href="#4-3-L-Layer-Model" class="headerlink" title="4.3 L-Layer Model"></a>4.3 L-Layer Model</h3><p>For even more convenience when implementing the L-layer Neural Net, you will need a function that replicates the previous one (<code>linear_activation_forward</code> with RELU) L1 times, then follows that with one <code>linear_activation_forward</code> with SIGMOID.</p><p><strong>Exercise</strong>: Implement the forward propagation of the above model.</p><p><strong>Instruction</strong>: In the code below, the variable <code>AL</code> will denote $A^{[L]} = \sigma(Z^{[L]}) = \sigma(W^{[L]} A^{[L-1]} + b^{[L]})$. (This is sometimes also called <code>Yhat</code>, i.e., this is $\hat{Y}$.)</p><p><strong>Tips</strong>: </p><ul><li>Use the functions you had previously written </li><li>Use a for loop to replicate [LINEAR-&gt;RELU] (L-1) times </li><li>Dont forget to keep track of the caches in the <code>caches</code> list. To add a new value <code>c</code> to a list, you can use <code>list.append(c)</code>.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: L_model_forward</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_model_forward</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement forward propagation for the [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID computation</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- data, numpy array of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    parameters -- output of initialize_parameters_deep()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    AL -- last post-activation value</span></span><br><span class="line"><span class="string">    caches -- list of caches containing:</span></span><br><span class="line"><span class="string">                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)</span></span><br><span class="line"><span class="string">                the cache of linear_sigmoid_forward() (there is one, indexed L-1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    caches = []</span><br><span class="line">    A = X</span><br><span class="line">    L = len(parameters) // <span class="number">2</span>                  <span class="comment"># number of layers in the neural network</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Implement [LINEAR -&gt; RELU]*(L-1). Add "cache" to the "caches" list.</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L):</span><br><span class="line">        A_prev = A </span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">        A, linear_activation_cache = linear_activation_forward(A_prev, parameters[<span class="string">"W"</span> + str(l)], parameters[<span class="string">"b"</span> + str(l)], <span class="string">"relu"</span>);</span><br><span class="line">        caches.append(linear_activation_cache);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Implement LINEAR -&gt; SIGMOID. Add "cache" to the "caches" list.</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">    AL, linear_activation_cache = linear_activation_forward(A, parameters[<span class="string">"W"</span> + str(L)], parameters[<span class="string">"b"</span> + str(L)], <span class="string">"sigmoid"</span>);</span><br><span class="line">    caches.append(linear_activation_cache);</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span>(AL.shape == (<span class="number">1</span>,X.shape[<span class="number">1</span>]));</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> AL, caches;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X, parameters = L_model_forward_test_case_2hidden();</span><br><span class="line">AL, caches = L_model_forward(X, parameters);</span><br><span class="line">print(<span class="string">"AL = "</span> + str(AL));</span><br><span class="line">print(<span class="string">"Length of caches list = "</span> + str(len(caches)));</span><br></pre></td></tr></table></figure><pre><code>AL = [[0.03921668 0.70498921 0.19734387 0.04728177]]Length of caches list = 3</code></pre><p>L_model_forward_test_case function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_model_forward_test_case</span><span class="params">()</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">1</span>);</span><br><span class="line">    X = np.random.randn(<span class="number">4</span>,<span class="number">2</span>);</span><br><span class="line">    W1 = np.random.randn(<span class="number">3</span>,<span class="number">4</span>);</span><br><span class="line">    b1 = np.random.randn(<span class="number">3</span>,<span class="number">1</span>);</span><br><span class="line">    W2 = np.random.randn(<span class="number">1</span>,<span class="number">3</span>);</span><br><span class="line">    b2 = np.random.randn(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">    parameters = &#123;<span class="string">"W1"</span>: W1,</span><br><span class="line">                  <span class="string">"b1"</span>: b1,</span><br><span class="line">                  <span class="string">"W2"</span>: W2,</span><br><span class="line">                  <span class="string">"b2"</span>: b2&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, parameters;</span><br></pre></td></tr></table></figure><p>Great! Now you have a full forward propagation that takes the input $X$ and outputs a row vector $A^{[L]}$ containing your predictions. It also records all intermediate values in <code>caches</code>. Using $A^{[L]}$, you can compute the cost of your predictions.</p><h2 id="5-Cost-function"><a href="#5-Cost-function" class="headerlink" title="5. Cost function"></a>5. Cost function</h2><p>Now you will implement forward and backward propagation. You need to compute the cost, because you want to check if your model is actually learning.</p><p><strong>Exercise</strong>: Compute the cross-entropy cost $J$, using the following formula:<br>$$-\frac{1}{m} \sum\limits_{i = 1}^{m} (y^{(i)}\log\left(a^{[L] (i)}\right) + (1-y^{(i)})\log\left(1- a^{<a href="i">L</a>}\right)) \tag{4}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: compute_cost</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(AL, Y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the cost function defined by equation (7).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    cost -- cross-entropy cost</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    m = Y.shape[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute loss from aL and y.</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 1 lines of code)</span></span><br><span class="line">    cost = <span class="number">-1</span> / m * (np.dot(Y, np.log(AL).T) + np.dot(<span class="number">1</span> - Y, np.log(<span class="number">1</span> - AL).T));</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    cost = np.squeeze(cost);      <span class="comment"># To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).</span></span><br><span class="line">    <span class="comment">#assert(isinstance(cost, float));</span></span><br><span class="line">    <span class="keyword">assert</span>(cost.shape == ());</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Y, AL = compute_cost_test_case();</span><br><span class="line">print(<span class="string">"cost = "</span> + str(compute_cost(AL, Y)));</span><br></pre></td></tr></table></figure><pre><code>cost = 0.41493159961539694</code></pre><p>compute_cost_test_case function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost_test_case</span><span class="params">()</span>:</span> </span><br><span class="line">    Y = np.asarray([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]]);</span><br><span class="line">    aL = np.array([[<span class="number">.8</span>,<span class="number">.9</span>,<span class="number">0.4</span>]]); </span><br><span class="line">    <span class="keyword">return</span> Y, aL;</span><br></pre></td></tr></table></figure><h2 id="6-Backward-propagation-module"><a href="#6-Backward-propagation-module" class="headerlink" title="6. Backward propagation module"></a>6. Backward propagation module</h2><p>Just like with forward propagation, you will implement helper functions for backpropagation. Remember that back propagation is used to calculate the gradient of the loss function with respect to the parameters.</p><p>The purple blocks represent the forward propagation, and the red blocks represent the backward propagation.</p>{% raw %}$$\frac{d \mathcal{L}(a^{[2]},y)}{{dz^{[1]}}} = \frac{d\mathcal{L}(a^{[2]},y)}{{da^{[2]}}}\frac{{da^{[2]}}}{{dz^{[2]}}}\frac{{dz^{[2]}}}{{da^{[1]}}}\frac{{da^{[1]}}}{{dz^{[1]}}} \tag{5}$${% endraw %}<p>In order to calculate the gradient $dW^{[1]} = \frac{\partial L}{\partial W^{[1]}}$, you use the previous chain rule and you do $dW^{[1]} = dz^{[1]} \times \frac{\partial z^{[1]} }{\partial W^{[1]}}$, . During the backpropagation, at each step you multiply your current gradient by the gradient corresponding to the specific layer to get the gradient you wanted. Equivalently, in order to calculate the gradient $db^{[1]} = \frac{\partial L}{\partial b^{[1]}}$, you use the previous chain rule and you do $db^{[1]} = dz^{[1]} \times \frac{\partial z^{[1]} }{\partial b^{[1]}}$. This is why we talk about <strong>backpropagation</strong>. </p><p>Now, similar to forward propagation, you are going to build the backward propagation in three steps: </p><ul><li>LINEAR backward </li><li>LINEAR -&gt; ACTIVATION backward where ACTIVATION computes the derivative of either the ReLU or sigmoid activation </li><li>[LINEAR -&gt; RELU]  (L-1) -&gt; LINEAR -&gt; SIGMOID backward (whole model)</li></ul><h3 id="6-1-Linear-backward"><a href="#6-1-Linear-backward" class="headerlink" title="6.1 Linear backward"></a>6.1 Linear backward</h3><p>For layer l, the linear part is: $Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$, (followed by an activation).<br>Suppose you have already calculated the derivative $dZ^{[l]} = \frac{\partial \mathcal{L} }{\partial Z^{[l]}}$. You want to get $(dW^{[l]}, db^{[l]} dA^{[l-1]})$.</p><p>The three outputs $(dW^{[l]}, db^{[l]}, dA^{[l]})$, are computed using the input $dZ^{[l]}$. Here are the formulas you need:<br>$$dW^{[l]} = \frac{\partial \mathcal{L} }{\partial W^{[l]}} = \frac{1}{m} dZ^{[l]} A^{[l-1] T} \tag{5}$$</p><p>$$db^{[l]} = \frac{\partial \mathcal{L} }{\partial b^{[l]}} = \frac{1}{m} \sum_{i = 1}^{m} dZ^{<a href="i">l</a>}\tag{6}$$</p><p>$$dA^{[l-1]} = \frac{\partial \mathcal{L} }{\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]} \tag{7}$$</p><p><strong>Exercise</strong>: Use the 3 formulas above to implement <code>linear_backward()</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: linear_backward</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_backward</span><span class="params">(dZ, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the linear portion of backward propagation for a single layer (layer l)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    dZ -- Gradient of the cost with respect to the linear output (of current layer l)</span></span><br><span class="line"><span class="string">    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev</span></span><br><span class="line"><span class="string">    dW -- Gradient of the cost with respect to W (current layer l), same shape as W</span></span><br><span class="line"><span class="string">    db -- Gradient of the cost with respect to b (current layer l), same shape as b</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    A_prev, W, b = cache;</span><br><span class="line">    m = A_prev.shape[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 3 lines of code)</span></span><br><span class="line">    dW = <span class="number">1</span> / m * np.dot(dZ, A_prev.T);</span><br><span class="line">    db = <span class="number">1</span> / m * np.sum(dZ, axis = <span class="number">1</span>, keepdims = <span class="literal">True</span>);</span><br><span class="line">    dA_prev = np.dot(W.T, dZ);</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> (dA_prev.shape == A_prev.shape);</span><br><span class="line">    <span class="keyword">assert</span> (dW.shape == W.shape);</span><br><span class="line">    <span class="keyword">assert</span> (db.shape == b.shape);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dA_prev, dW, db;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set up some test inputs</span></span><br><span class="line">dZ, linear_cache = linear_backward_test_case();</span><br><span class="line">dA_prev, dW, db = linear_backward(dZ, linear_cache);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dA_prev = "</span>+ str(dA_prev));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dW = "</span> + str(dW));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"db = "</span> + str(db));</span><br></pre></td></tr></table></figure><pre><code>dA_prev = [[ 0.51822968 -0.19517421] [-0.40506361  0.15255393] [ 2.37496825 -0.89445391]]dW = [[-0.10076895  1.40685096  1.64992505]]db = [[0.50629448]]</code></pre><p>linear_backward_test_case function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_backward_test_case</span><span class="params">()</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">1</span>);</span><br><span class="line">    dZ = np.random.randn(<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">    A = np.random.randn(<span class="number">3</span>,<span class="number">2</span>);</span><br><span class="line">    W = np.random.randn(<span class="number">1</span>,<span class="number">3</span>);</span><br><span class="line">    b = np.random.randn(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">    linear_cache = (A, W, b);</span><br><span class="line">    <span class="keyword">return</span> dZ, linear_cache;</span><br></pre></td></tr></table></figure><h3 id="6-2-Linear-Activation-backward"><a href="#6-2-Linear-Activation-backward" class="headerlink" title="6.2 Linear-Activation backward"></a>6.2 Linear-Activation backward</h3><p>Next, you will create a function that merges the two helper functions: <code>linear_backward</code> and the backward step for the activation <code>linear_activation_backward</code>.</p><p>To help you implement <code>linear_activation_backward</code>, we provided two backward functions: </p><ul><li><code>sigmoid_backward</code>: Implements the backward propagation for SIGMOID unit. You can call it as follows:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dZ = sigmoid_backward(dA, activation_cache)</span><br></pre></td></tr></table></figure><ul><li><code>relu_backward</code>: Implements the backward propagation for RELU unit. You can call it as follows:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dZ = relu_backward(dA, activation_cache)</span><br></pre></td></tr></table></figure><p>If g(.) is the activation function,<br><code>sigmoid_backward</code> and <code>relu_backward</code> compute:</p><p>$$dZ^{[l]} = dA^{[l]} * g(Z^{[l]}) \tag{8}$$</p><p><strong>Exercise</strong>: Implement the backpropagation for the LINEAR-&gt;ACTIVATION layer.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: linear_activation_backward</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_activation_backward</span><span class="params">(dA, cache, activation)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward propagation for the LINEAR-&gt;ACTIVATION layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    dA -- post-activation gradient for current layer l </span></span><br><span class="line"><span class="string">    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently</span></span><br><span class="line"><span class="string">    activation -- the activation to be used in this layer, stored as a text string: "sigmoid" or "relu"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev</span></span><br><span class="line"><span class="string">    dW -- Gradient of the cost with respect to W (current layer l), same shape as W</span></span><br><span class="line"><span class="string">    db -- Gradient of the cost with respect to b (current layer l), same shape as b</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    linear_cache, activation_cache = cache</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> activation == <span class="string">"relu"</span>:</span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">        dZ = relu_backward(dA, activation_cache);</span><br><span class="line">        dA_prev, dW, db = linear_backward(dZ, linear_cache);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> activation == <span class="string">"sigmoid"</span>:</span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">        dZ = sigmoid_backward(dA, activation_cache);</span><br><span class="line">        dA_prev, dW, db = linear_backward(dZ, linear_cache);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dA_prev, dW, db;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">AL, linear_activation_cache = linear_activation_backward_test_case();</span><br><span class="line"></span><br><span class="line">dA_prev, dW, db = linear_activation_backward(AL, linear_activation_cache, activation = <span class="string">"sigmoid"</span>);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"sigmoid:"</span>);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dA_prev = "</span>+ str(dA_prev));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dW = "</span> + str(dW));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"db = "</span> + str(db) + <span class="string">"\n"</span>);</span><br><span class="line"></span><br><span class="line">dA_prev, dW, db = linear_activation_backward(AL, linear_activation_cache, activation = <span class="string">"relu"</span>);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"relu:"</span>);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dA_prev = "</span>+ str(dA_prev));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dW = "</span> + str(dW));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"db = "</span> + str(db));</span><br></pre></td></tr></table></figure><pre><code>sigmoid:dA_prev = [[ 0.11017994  0.01105339] [ 0.09466817  0.00949723] [-0.05743092 -0.00576154]]dW = [[ 0.10266786  0.09778551 -0.01968084]]db = [[-0.05729622]]relu:dA_prev = [[ 0.44090989  0.        ] [ 0.37883606  0.        ] [-0.2298228   0.        ]]dW = [[ 0.44513824  0.37371418 -0.10478989]]db = [[-0.20837892]]</code></pre><p><code>linear_activation_backward_test_case</code> function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_activation_backward_test_case</span><span class="params">()</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">2</span>);</span><br><span class="line">    dA = np.random.randn(<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">    A = np.random.randn(<span class="number">3</span>,<span class="number">2</span>);</span><br><span class="line">    W = np.random.randn(<span class="number">1</span>,<span class="number">3</span>);</span><br><span class="line">    b = np.random.randn(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">    Z = np.random.randn(<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">    linear_cache = (A, W, b);</span><br><span class="line">    activation_cache = Z;</span><br><span class="line">    linear_activation_cache = (linear_cache, activation_cache);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dA, linear_activation_cache;</span><br></pre></td></tr></table></figure><h3 id="6-3-L-Model-Backward"><a href="#6-3-L-Model-Backward" class="headerlink" title="6.3 L-Model Backward"></a>6.3 L-Model Backward</h3><p>Now you will implement the backward function for the whole network. Recall that when you implemented the <code>L_model_forward function</code>, at each iteration, you stored a cache which contains <strong>(X,W,b, and z)</strong>. In the back propagation module, you will use those variables to compute the gradients. Therefore, in the <code>L_model_backward</code> function, you will iterate through all the hidden layers backward, starting from layer L. On each step, you will use the cached values for layer l to backpropagate through layer l. Figure 5 below shows the backward pass.</p><p><strong>Initializing backpropagation</strong>: </p><p>To backpropagate through this network, we know that the output is, $A^{[L]} = \sigma(Z^{[L]})$ . Your code thus needs to compute $= \frac{\partial \mathcal{L}}{\partial A^{[L]}}$.<br>To do so, use this formula (derived using calculus which you dont need in-depth knowledge of):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dAL = - (np.divide(Y, AL) - np.divide(<span class="number">1</span> - Y, <span class="number">1</span> - AL)) <span class="comment"># derivative of cost with respect to AL</span></span><br></pre></td></tr></table></figure><p>You can then use this post-activation gradient <code>dAL</code> to keep going backward. As seen in Figure 5, you can now feed in <code>dAL</code> into the LINEAR-&gt;SIGMOID backward function you implemented (which will use the cached values stored by the <code>L_model_forward</code> function). After that, you will have to use a for loop to iterate through all the other layers using the LINEAR-&gt;RELU backward function. You should store each <code>dA</code>, <code>dW</code>, and <code>db</code> in the grads dictionary. To do so, use this formula :<br>$$grads[dW + str(l)] = dW^{[l]}\tag{9}$$</p><p>For example, for <code>l=3</code> this would store $dW^{[l]}$ in <code>grads[&quot;dW3&quot;]</code>.</p><p><strong>Exercise</strong>: Implement backpropagation for the [LINEAR-&gt;RELU]  (L-1) -&gt; LINEAR -&gt; SIGMOID model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: L_model_backward</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_model_backward</span><span class="params">(AL, Y, caches)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward propagation for the [LINEAR-&gt;RELU] * (L-1) -&gt; LINEAR -&gt; SIGMOID group</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    AL -- probability vector, output of the forward propagation (L_model_forward())</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (containing 0 if non-cat, 1 if cat)</span></span><br><span class="line"><span class="string">    caches -- list of caches containing:</span></span><br><span class="line"><span class="string">                every cache of linear_activation_forward() with "relu" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)</span></span><br><span class="line"><span class="string">                the cache of linear_activation_forward() with "sigmoid" (it's caches[L-1])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    grads -- A dictionary with the gradients</span></span><br><span class="line"><span class="string">             grads["dA" + str(l)] = ... </span></span><br><span class="line"><span class="string">             grads["dW" + str(l)] = ...</span></span><br><span class="line"><span class="string">             grads["db" + str(l)] = ... </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    grads = &#123;&#125;;</span><br><span class="line">    L = len(caches); <span class="comment"># the number of layers</span></span><br><span class="line">    m = AL.shape[<span class="number">1</span>];</span><br><span class="line">    Y = Y.reshape(AL.shape); <span class="comment"># after this line, Y is the same shape as AL</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initializing the backpropagation</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line of code)</span></span><br><span class="line">    dAL = - (np.divide(Y, AL) - np.divide(<span class="number">1</span> - Y, <span class="number">1</span> - AL));</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Lth layer (SIGMOID -&gt; LINEAR) gradients. Inputs: "AL, Y, caches". Outputs: "grads["dAL"], grads["dWL"], grads["dbL"]</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">    dA_prev, dW, db = linear_activation_backward(dAL, caches[L - <span class="number">1</span>], <span class="string">"sigmoid"</span>);</span><br><span class="line">    grads[<span class="string">"dA"</span> + str(L)], grads[<span class="string">"dW"</span> + str(L)], grads[<span class="string">"db"</span> + str(L)] = dA_prev, dW, db;</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> reversed(range(L<span class="number">-1</span>)):</span><br><span class="line">        <span class="comment"># lth layer: (RELU -&gt; LINEAR) gradients.</span></span><br><span class="line">        <span class="comment"># Inputs: "grads["dA" + str(l + 2)], caches". Outputs: "grads["dA" + str(l + 1)] , grads["dW" + str(l + 1)] , grads["db" + str(l + 1)] </span></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 5 lines)</span></span><br><span class="line">        dA = dA_prev;</span><br><span class="line">        dA_prev, dW, db = linear_activation_backward(dA, caches[l], <span class="string">"relu"</span>);</span><br><span class="line">        grads[<span class="string">"dA"</span> + str(l + <span class="number">1</span>)] = dA_prev;</span><br><span class="line">        grads[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] = dW;</span><br><span class="line">        grads[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] = db;</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> grads;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">AL, Y_assess, caches = L_model_backward_test_case();</span><br><span class="line">grads = L_model_backward(AL, Y_assess, caches);</span><br><span class="line">print_grads(grads);</span><br></pre></td></tr></table></figure><pre><code>dW1 = [[0.41010002 0.07807203 0.13798444 0.10502167] [0.         0.         0.         0.        ] [0.05283652 0.01005865 0.01777766 0.0135308 ]]db1 = [[-0.22007063] [ 0.        ] [-0.02835349]]dA1 = [[ 0.12913162 -0.44014127] [-0.14175655  0.48317296] [ 0.01663708 -0.05670698]]</code></pre><p><code>L_model_backward_test_case</code> function in <code>testCases_v3.py</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_model_backward_test_case</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    X = np.random.rand(3,2)</span></span><br><span class="line"><span class="string">    Y = np.array([[1, 1]])</span></span><br><span class="line"><span class="string">    parameters = &#123;'W1': np.array([[ 1.78862847,  0.43650985,  0.09649747]]), 'b1': np.array([[ 0.]])&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    aL, caches = (np.array([[ 0.60298372,  0.87182628]]), [((np.array([[ 0.20445225,  0.87811744],</span></span><br><span class="line"><span class="string">           [ 0.02738759,  0.67046751],</span></span><br><span class="line"><span class="string">           [ 0.4173048 ,  0.55868983]]),</span></span><br><span class="line"><span class="string">    np.array([[ 1.78862847,  0.43650985,  0.09649747]]),</span></span><br><span class="line"><span class="string">    np.array([[ 0.]])),</span></span><br><span class="line"><span class="string">   np.array([[ 0.41791293,  1.91720367]]))])</span></span><br><span class="line"><span class="string">   """</span></span><br><span class="line">    np.random.seed(<span class="number">3</span>)</span><br><span class="line">    AL = np.random.randn(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    Y = np.array([[<span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">    A1 = np.random.randn(<span class="number">4</span>,<span class="number">2</span>)</span><br><span class="line">    W1 = np.random.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">    b1 = np.random.randn(<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">    Z1 = np.random.randn(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">    linear_cache_activation_1 = ((A1, W1, b1), Z1)</span><br><span class="line"></span><br><span class="line">    A2 = np.random.randn(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">    W2 = np.random.randn(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    b2 = np.random.randn(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    Z2 = np.random.randn(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">    linear_cache_activation_2 = ((A2, W2, b2), Z2)</span><br><span class="line"></span><br><span class="line">    caches = (linear_cache_activation_1, linear_cache_activation_2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> AL, Y, caches</span><br></pre></td></tr></table></figure><h3 id="6-4-Update-Parameters"><a href="#6-4-Update-Parameters" class="headerlink" title="6.4 Update Parameters"></a>6.4 Update Parameters</h3><p>In this section you will update the parameters of the model, using gradient descent:<br>$$W^{[l]} = W^{[l]} - \alpha \text{ } dW^{[l]} \tag{10}$$</p><p>$$b^{[l]} = b^{[l]} - \alpha \text{ } db^{[l]} \tag{11}$$</p><p>where $$ is the learning rate. After computing the updated parameters, store them in the parameters dictionary.</p><p><strong>Exercise</strong>: Implement update_parameters() to update your parameters using gradient descent.</p><p><strong>Instructions</strong>:<br>Update parameters using gradient descent on every $W^{[l]}$ and $b^{[l]}$ for $l=1,2,,L$.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: update_parameters</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, grads, learning_rate)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Update parameters using gradient descent</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters </span></span><br><span class="line"><span class="string">    grads -- python dictionary containing your gradients, output of L_model_backward</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your updated parameters </span></span><br><span class="line"><span class="string">                  parameters["W" + str(l)] = ... </span></span><br><span class="line"><span class="string">                  parameters["b" + str(l)] = ...</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    L = len(parameters) // <span class="number">2</span> <span class="comment"># number of layers in the neural network</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update rule for each parameter. Use a for loop.</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 3 lines of code)</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line">        parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)] -= learning_rate * grads[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)];</span><br><span class="line">        parameters[<span class="string">"b"</span> + str(l + <span class="number">1</span>)] -= learning_rate * grads[<span class="string">"db"</span> + str(l + <span class="number">1</span>)];</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> parameters;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">parameters, grads = update_parameters_test_case();</span><br><span class="line">parameters = update_parameters(parameters, grads, <span class="number">0.1</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"W1 = "</span>+ str(parameters[<span class="string">"W1"</span>]));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"b1 = "</span>+ str(parameters[<span class="string">"b1"</span>]));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"W2 = "</span>+ str(parameters[<span class="string">"W2"</span>]));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"b2 = "</span>+ str(parameters[<span class="string">"b2"</span>]));</span><br></pre></td></tr></table></figure><pre><code>W1 = [[-0.59562069 -0.09991781 -2.14584584  1.82662008] [-1.76569676 -0.80627147  0.51115557 -1.18258802] [-1.0535704  -0.86128581  0.68284052  2.20374577]]b1 = [[-0.04659241] [-1.28888275] [ 0.53405496]]W2 = [[-0.55569196  0.0354055   1.32964895]]b2 = [[-0.84610769]]</code></pre><p><code>update_parameters_test_case</code> function in <code>testCases_v3.py</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters_test_case</span><span class="params">()</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">2</span>)</span><br><span class="line">    W1 = np.random.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">    b1 = np.random.randn(<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">    W2 = np.random.randn(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    b2 = np.random.randn(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    parameters = &#123;<span class="string">"W1"</span>: W1,</span><br><span class="line">                  <span class="string">"b1"</span>: b1,</span><br><span class="line">                  <span class="string">"W2"</span>: W2,</span><br><span class="line">                  <span class="string">"b2"</span>: b2&#125;</span><br><span class="line">    np.random.seed(<span class="number">3</span>)</span><br><span class="line">    dW1 = np.random.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">    db1 = np.random.randn(<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">    dW2 = np.random.randn(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    db2 = np.random.randn(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    grads = &#123;<span class="string">"dW1"</span>: dW1,</span><br><span class="line">             <span class="string">"db1"</span>: db1,</span><br><span class="line">             <span class="string">"dW2"</span>: dW2,</span><br><span class="line">             <span class="string">"db2"</span>: db2&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters, grads</span><br></pre></td></tr></table></figure><h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><p>Congrats on implementing all the functions required for building a deep neural network!</p><p>We know it was a long assignment but going forward it will only get better. The next part of the assignment is easier.</p><p>In the next assignment you will put all these together to build two models: </p><ul><li>A two-layer neural network </li><li>An L-layer neural network</li></ul><p>You will in fact use these models to classify cat vs non-cat images!</p><h1 id="Part-2Deep-Neural-Network-for-Image-Classification-Application"><a href="#Part-2Deep-Neural-Network-for-Image-Classification-Application" class="headerlink" title="Part 2Deep Neural Network for Image Classification: Application"></a>Part 2Deep Neural Network for Image Classification: Application</h1><h2 id="1-Packages-1"><a href="#1-Packages-1" class="headerlink" title="1. Packages"></a>1. Packages</h2><p>Lets first import all the packages that you will need during this assignment. </p><ul><li>numpy is the fundamental package for scientific computing with Python. </li><li>matplotlib is a library to plot graphs in Python. </li><li>h5py is a common package to interact with a dataset that is stored on an H5 file. </li><li>PIL and scipy are used here to test your model with your own picture at the end. </li><li><code>dnn_app_utils</code> provides the functions implemented in the Building your Deep Neural Network: Step by Step assignment to this notebook. </li><li>np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span><br><span class="line"><span class="keyword">from</span> dnn_app_utils_v2 <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">5.0</span>, <span class="number">4.0</span>) <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></span><br><span class="line"></span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>The autoreload extension is already loaded. To reload it, use:  %reload_ext autoreload</code></pre><h2 id="2-Dataset"><a href="#2-Dataset" class="headerlink" title="2. Dataset"></a>2. Dataset</h2><p>You will use the same Cat vs non-Cat dataset as in Logistic Regression as a Neural Network (Assignment 2). The model you had built had 70% test accuracy on classifying cats vs non-cats images. Hopefully, your new model will perform a better!</p><p>Problem Statement: You are given a dataset (data.h5) containing: </p><ul><li>a training set of m_train images labelled as cat (1) or non-cat (0) </li><li>a test set of m_test images labelled as cat and non-cat </li><li>each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB).</li></ul><p>Lets get more familiar with the dataset. Load the data by running the cell below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_x_orig, train_y, test_x_orig, test_y, classes = load_data();</span><br></pre></td></tr></table></figure><p>The following code will show you an image in the dataset. Feel free to change the index and re-run the cell multiple times to see other images.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example of a picture</span></span><br><span class="line">index = <span class="number">10</span>;</span><br><span class="line">plt.imshow(train_x_orig[index]);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"y = "</span> + str(train_y[<span class="number">0</span>,index]) + <span class="string">". It's a "</span> + classes[train_y[<span class="number">0</span>,index]].decode(<span class="string">"utf-8"</span>) +  <span class="string">" picture."</span>);</span><br></pre></td></tr></table></figure><pre><code>y = 0. It&apos;s a non-cat picture.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Explore your dataset </span></span><br><span class="line">m_train = train_x_orig.shape[<span class="number">0</span>];</span><br><span class="line">num_px = train_x_orig.shape[<span class="number">1</span>];</span><br><span class="line">m_test = test_x_orig.shape[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Number of training examples: "</span> + str(m_train));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Number of testing examples: "</span> + str(m_test));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Each image is of size: ("</span> + str(num_px) + <span class="string">", "</span> + str(num_px) + <span class="string">", 3)"</span>);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"train_x_orig shape: "</span> + str(train_x_orig.shape));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"train_y shape: "</span> + str(train_y.shape));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"test_x_orig shape: "</span> + str(test_x_orig.shape));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"test_y shape: "</span> + str(test_y.shape));</span><br></pre></td></tr></table></figure><pre><code>Number of training examples: 209Number of testing examples: 50Each image is of size: (64, 64, 3)train_x_orig shape: (209, 64, 64, 3)train_y shape: (1, 209)test_x_orig shape: (50, 64, 64, 3)test_y shape: (1, 50)</code></pre><p>As usual, you reshape and standardize the images before feeding them to the network. The code is given in the cell below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Reshape the training and test examples </span></span><br><span class="line">train_x_flatten = train_x_orig.reshape(train_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T;   <span class="comment"># The "-1" makes reshape flatten the remaining dimensions</span></span><br><span class="line">test_x_flatten = test_x_orig.reshape(test_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Standardize data to have feature values between 0 and 1.</span></span><br><span class="line">train_x = train_x_flatten / <span class="number">255.</span>;</span><br><span class="line">test_x = test_x_flatten / <span class="number">255.</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"train_x's shape: "</span> + str(train_x.shape));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"test_x's shape: "</span> + str(test_x.shape));</span><br></pre></td></tr></table></figure><pre><code>train_x&apos;s shape: (12288, 209)test_x&apos;s shape: (12288, 50)</code></pre><p>$12288$ equals $64643$ which is the size of one reshaped image vector.</p><h2 id="3-Architecture-of-your-model"><a href="#3-Architecture-of-your-model" class="headerlink" title="3. Architecture of your model"></a>3. Architecture of your model</h2><p>Now that you are familiar with the dataset, it is time to build a deep neural network to distinguish cat images from non-cat images.</p><p>You will build two different models: </p><ul><li>A 2-layer neural network </li><li>An L-layer deep neural network</li></ul><p>You will then compare the performance of these models, and also try out different values for L.</p><p>Lets look at the two architectures.</p><h3 id="3-1-2-layer-neural-network"><a href="#3-1-2-layer-neural-network" class="headerlink" title="3.1 2-layer neural network"></a>3.1 2-layer neural network</h3><p>The model can be summarized as: <strong>INPUT -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID -&gt; OUTPUT</strong></p><p>Detailed Architecture of figure 2: </p><ul><li>The input is a $(64,64,3)$ image which is flattened to a vector of size $(12288,1)$. </li><li>The corresponding vector: $[x_0,x_1,,x_{12287}]^T$ is then multiplied by the weight matrix $W^{[1]}$ of size $(n^{[1]},12288)$. </li><li>You then add a bias term and take its relu to get the following vector: $[a^{[1]}<em>0,a^{[1]}_1,,a^{[1]}</em>{n^{[1]}1}]^T$. </li><li>You then repeat the same process. </li><li>You multiply the resulting vector by $W^{[2]}$ and add your intercept (bias). </li><li>Finally, you take the sigmoid of the result. If it is greater than $0.5$, you classify it to be a cat.</li></ul><h3 id="3-2-L-layer-deep-neural-network"><a href="#3-2-L-layer-deep-neural-network" class="headerlink" title="3.2 L-layer deep neural network"></a>3.2 L-layer deep neural network</h3><p>It is hard to represent an L-layer deep neural network with the above representation. However, here is a simplified network representation:<br>The model can be summarized as: <strong>[LINEAR -&gt; RELU]  (L-1) -&gt; LINEAR -&gt; SIGMOID</strong></p><p>Detailed Architecture of figure 3: </p><ul><li>The input is a $(64,64,3)$ image which is flattened to a vector of size $(12288,1)$. </li><li>The corresponding vector: $[x_0,x_1,,x_{12287}]^T$ is then multiplied by the weight matrix $W^{[1]}$ and then you add the intercept $b^{[l]}$. The result is called the linear unit. </li><li>Next, you take the relu of the linear unit. This process could be repeated several times for each $(W^{[l]},b^{[l]})$ depending on the model architecture. </li><li>Finally, you take the sigmoid of the final linear unit. If it is greater than $0.5$, you classify it to be a cat.</li></ul><h3 id="3-3-General-methodology"><a href="#3-3-General-methodology" class="headerlink" title="3.3 General methodology"></a>3.3 General methodology</h3><p>As usual you will follow the Deep Learning methodology to build the model: </p><ol><li>Initialize parameters / Define hyperparameters </li><li>Loop for num_iterations: <ol><li>Forward propagation </li><li>Compute cost function </li><li>Backward propagation </li><li>Update parameters (using parameters, and grads from backprop) </li></ol></li><li>Use trained parameters to predict labels</li></ol><p>Lets now implement those two models!</p><h2 id="4-Two-layer-neural-network"><a href="#4-Two-layer-neural-network" class="headerlink" title="4. Two-layer neural network"></a>4. Two-layer neural network</h2><p><strong>Question</strong>: Use the helper functions you have implemented in the previous assignment to build a 2-layer neural network with the following </p><p><strong>structure</strong>: LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID. The functions you may need and their inputs are:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">(n_x, n_h, n_y)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> parameters </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_activation_forward</span><span class="params">(A_prev, W, b, activation)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> A, cache</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(AL, Y)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> cost</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_activation_backward</span><span class="params">(dA, cache, activation)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> dA_prev, dW, db</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, grads, learning_rate)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### CONSTANTS DEFINING THE MODEL ####</span></span><br><span class="line">n_x = <span class="number">12288</span>;    <span class="comment"># num_px * num_px * 3</span></span><br><span class="line">n_h = <span class="number">7</span>;</span><br><span class="line">n_y = <span class="number">1</span>;</span><br><span class="line">layers_dims = (n_x, n_h, n_y);</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#GRADED FUNCTION: two_layer_model</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">two_layer_model</span><span class="params">(X, Y, layers_dims, learning_rate = <span class="number">0.0075</span>, num_iterations = <span class="number">3000</span>, print_cost=False)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements a two-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input data, of shape (n_x, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    layers_dims -- dimensions of the layers (n_x, n_h, n_y)</span></span><br><span class="line"><span class="string">    num_iterations -- number of iterations of the optimization loop</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate of the gradient descent update rule</span></span><br><span class="line"><span class="string">    print_cost -- If set to True, this will print the cost every 100 iterations </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- a dictionary containing W1, W2, b1, and b2</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="number">1</span>);</span><br><span class="line">    grads = &#123;&#125;;</span><br><span class="line">    costs = [];                              <span class="comment"># to keep track of the cost</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>];                           <span class="comment"># number of examples</span></span><br><span class="line">    (n_x, n_h, n_y) = layers_dims;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize parameters dictionary, by calling one of the functions you'd previously implemented</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">    parameters = initialize_parameters(n_x, n_h, n_y);</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get W1, b1, W2 and b2 from the dictionary parameters.</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>];</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>];</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>];</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loop (gradient descent)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID. Inputs: "X, W1, b1". Output: "A1, cache1, A2, cache2".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">        A1, cache1 = linear_activation_forward(X, W1, b1, <span class="string">"relu"</span>);</span><br><span class="line">        A2, cache2 = linear_activation_forward(A1, W2, b2, <span class="string">"sigmoid"</span>);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute cost</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">        cost = compute_cost(A2, Y);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initializing backward propagation</span></span><br><span class="line">        dA2 = - (np.divide(Y, A2) - np.divide(<span class="number">1</span> - Y, <span class="number">1</span> - A2));</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backward propagation. Inputs: "dA2, cache2, cache1". Outputs: "dA1, dW2, db2; also dA0 (not used), dW1, db1".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, <span class="string">"sigmoid"</span>);</span><br><span class="line">        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, <span class="string">"relu"</span>);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2</span></span><br><span class="line">        grads[<span class="string">'dW1'</span>] = dW1;</span><br><span class="line">        grads[<span class="string">'db1'</span>] = db1;</span><br><span class="line">        grads[<span class="string">'dW2'</span>] = dW2;</span><br><span class="line">        grads[<span class="string">'db2'</span>] = db2;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update parameters.</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 1 line of code)</span></span><br><span class="line">        parameters = update_parameters(parameters, grads, learning_rate);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Retrieve W1, b1, W2, b2 from parameters</span></span><br><span class="line">        W1 = parameters[<span class="string">"W1"</span>];</span><br><span class="line">        b1 = parameters[<span class="string">"b1"</span>];</span><br><span class="line">        W2 = parameters[<span class="string">"W2"</span>];</span><br><span class="line">        b2 = parameters[<span class="string">"b2"</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print the cost every 100 training example</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Cost after iteration &#123;&#125;: &#123;&#125;"</span>.format(i, np.squeeze(cost)));</span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            costs.append(cost);</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot the cost</span></span><br><span class="line"></span><br><span class="line">    plt.plot(np.squeeze(costs));</span><br><span class="line">    plt.ylabel(<span class="string">'cost'</span>);</span><br><span class="line">    plt.xlabel(<span class="string">'iterations (per tens)'</span>);</span><br><span class="line">    plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate));</span><br><span class="line">    plt.show();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters;</span><br></pre></td></tr></table></figure><p>Run the cell below to train your parameters. See if your model runs. The cost should be decreasing. It may take up to 5 minutes to run 2500 iterations. Check if the Cost after iteration 0 matches the expected output below, if not click on the black square button on the upper bar of the notebook to stop the cell and try to find your error.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameters = two_layer_model(train_x, train_y, layers_dims = (n_x, n_h, n_y), num_iterations = <span class="number">2500</span>, print_cost = <span class="literal">True</span>);</span><br></pre></td></tr></table></figure><pre><code>Cost after iteration 0: 0.693049735659989Cost after iteration 100: 0.6464320953428849Cost after iteration 200: 0.6325140647912678Cost after iteration 300: 0.6015024920354665Cost after iteration 400: 0.5601966311605748Cost after iteration 500: 0.5158304772764729Cost after iteration 600: 0.4754901313943325Cost after iteration 700: 0.43391631512257495Cost after iteration 800: 0.4007977536203886Cost after iteration 900: 0.35807050113237976Cost after iteration 1000: 0.33942815383664127Cost after iteration 1100: 0.3052753636196264Cost after iteration 1200: 0.2749137728213016Cost after iteration 1300: 0.2468176821061484Cost after iteration 1400: 0.19850735037466102Cost after iteration 1500: 0.1744831811255665Cost after iteration 1600: 0.17080762978096942Cost after iteration 1700: 0.11306524562164715Cost after iteration 1800: 0.09629426845937152Cost after iteration 1900: 0.0834261795972687Cost after iteration 2000: 0.07439078704319087Cost after iteration 2100: 0.06630748132267934Cost after iteration 2200: 0.05919329501038172Cost after iteration 2300: 0.053361403485605585Cost after iteration 2400: 0.04855478562877019</code></pre><p>Good thing you built a vectorized implementation! Otherwise it might have taken 10 times longer to train this.</p><p>Now, you can use the trained parameters to classify images from the dataset. To see your predictions on the training and test sets, run the cell below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions_train = predict(train_x, train_y, parameters);</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 0.9999999999999998</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions_test = predict(test_x, test_y, parameters);</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 0.72</code></pre><p>the <code>prediction</code> function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(X, y, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    This function is used to predict the results of a  L-layer neural network.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- data set of examples you would like to label</span></span><br><span class="line"><span class="string">    parameters -- parameters of the trained model</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    p -- predictions for the given dataset X</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    n = len(parameters) // <span class="number">2</span> <span class="comment"># number of layers in the neural network</span></span><br><span class="line">    p = np.zeros((<span class="number">1</span>,m))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Forward propagation</span></span><br><span class="line">    probas, caches = L_model_forward(X, parameters)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># convert probas to 0/1 predictions</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, probas.shape[<span class="number">1</span>]):</span><br><span class="line">        <span class="keyword">if</span> probas[<span class="number">0</span>,i] &gt; <span class="number">0.5</span>:</span><br><span class="line">            p[<span class="number">0</span>,i] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            p[<span class="number">0</span>,i] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Accuracy: "</span>  + str(np.sum((p == y)/m)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> p</span><br></pre></td></tr></table></figure><p><strong>Note</strong>: You may notice that running the model on fewer iterations (say 1500) gives better accuracy on the test set. This is called early stopping and we will talk about it in the next course. Early stopping is a way to prevent overfitting.</p><p>Congratulations! It seems that your 2-layer neural network has better performance (72%) than the logistic regression implementation (70%, assignment week 2). Lets see if you can do even better with an L-layer model.</p><h2 id="5-L-layer-Neural-Network"><a href="#5-L-layer-Neural-Network" class="headerlink" title="5. L-layer Neural Network"></a>5. L-layer Neural Network</h2><p><strong>Question</strong>: Use the helper functions you have implemented previously to build an L-layer neural network with the following structure: [LINEAR -&gt; RELU](L-1) -&gt; LINEAR -&gt; SIGMOID. The functions you may need and their inputs are:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters_deep</span><span class="params">(layer_dims)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> parameters </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_model_forward</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> AL, caches</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(AL, Y)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> cost</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_model_backward</span><span class="params">(AL, Y, caches)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> grads</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, grads, learning_rate)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### CONSTANTS ###</span></span><br><span class="line">layers_dims = [<span class="number">12288</span>, <span class="number">20</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">1</span>] <span class="comment">#  5-layer model</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: L_layer_model</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_layer_model</span><span class="params">(X, Y, layers_dims, learning_rate = <span class="number">0.0075</span>, num_iterations = <span class="number">3000</span>, print_cost=False)</span>:</span><span class="comment">#lr was 0.009</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements a L-layer neural network: [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate of the gradient descent update rule</span></span><br><span class="line"><span class="string">    num_iterations -- number of iterations of the optimization loop</span></span><br><span class="line"><span class="string">    print_cost -- if True, it prints the cost every 100 steps</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    costs = []                         <span class="comment"># keep track of cost</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Parameters initialization.</span></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    parameters = initialize_parameters_deep(layers_dims);</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loop (gradient descent)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward propagation: [LINEAR -&gt; RELU]*(L-1) -&gt; LINEAR -&gt; SIGMOID.</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">        AL, caches =L_model_forward(X, parameters);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute cost.</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">        cost = compute_cost(AL, Y);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backward propagation.</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">        grads = L_model_backward(AL, Y, caches);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update parameters.</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">        parameters = update_parameters(parameters, grads, learning_rate);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print the cost every 100 training example</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Cost after iteration %i: %f"</span> %(i, cost));</span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            costs.append(cost);</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot the cost</span></span><br><span class="line">    plt.plot(np.squeeze(costs));</span><br><span class="line">    plt.ylabel(<span class="string">'cost'</span>);</span><br><span class="line">    plt.xlabel(<span class="string">'iterations (per tens)'</span>);</span><br><span class="line">    plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate));</span><br><span class="line">    plt.show();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters;</span><br></pre></td></tr></table></figure><p>You will now train the model as a 5-layer neural network.</p><p>Run the cell below to train your model. The cost should decrease on every iteration. It may take up to 5 minutes to run 2500 iterations. Check if the Cost after iteration 0 matches the expected output below, if not click on the black square button on the upper bar of the notebook to stop the cell and try to find your error.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = <span class="number">2500</span>, print_cost = <span class="literal">True</span>);</span><br></pre></td></tr></table></figure><pre><code>Cost after iteration 0: 0.771749Cost after iteration 100: 0.672053Cost after iteration 200: 0.648263Cost after iteration 300: 0.611507Cost after iteration 400: 0.567047Cost after iteration 500: 0.540138Cost after iteration 600: 0.527930Cost after iteration 700: 0.465477Cost after iteration 800: 0.369126Cost after iteration 900: 0.391747Cost after iteration 1000: 0.315187Cost after iteration 1100: 0.272700Cost after iteration 1200: 0.237419Cost after iteration 1300: 0.199601Cost after iteration 1400: 0.189263Cost after iteration 1500: 0.161189Cost after iteration 1600: 0.148214Cost after iteration 1700: 0.137775Cost after iteration 1800: 0.129740Cost after iteration 1900: 0.121225Cost after iteration 2000: 0.113821Cost after iteration 2100: 0.107839Cost after iteration 2200: 0.102855Cost after iteration 2300: 0.100897Cost after iteration 2400: 0.092878</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pred_train = predict(train_x, train_y, parameters);</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 0.9856459330143539</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pred_test = predict(test_x, test_y, parameters);</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 0.8</code></pre><p>Congrats! It seems that your 5-layer neural network has better performance $(80%) $than your 2-layer neural network $(72%)$ on the same test set.</p><p>This is good performance for this task. Nice job!</p><p>Though in the next course on Improving deep neural networks you will learn how to obtain even higher accuracy by systematically searching for better hyperparameters (learning_rate, layers_dims, num_iterations, and others youll also learn in the next course).</p><h2 id="6-Results-Analysis"><a href="#6-Results-Analysis" class="headerlink" title="6. Results Analysis"></a>6. Results Analysis</h2><p>First, lets take a look at some images the L-layer model labeled incorrectly. This will show a few mislabeled images.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print_mislabeled_images(classes, test_x, test_y, pred_test);</span><br></pre></td></tr></table></figure><p>A few type of images the model tends to do poorly on include: </p><ul><li>Cat body in an unusual position </li><li>Cat appears against a background of a similar color </li><li>Unusual cat color and species </li><li>Camera Angle </li><li>Brightness of the picture </li><li>Scale variation (cat is very large or small in image)</li></ul><h2 id="7-Test-with-your-own-image-optional-ungraded-exercise"><a href="#7-Test-with-your-own-image-optional-ungraded-exercise" class="headerlink" title="7. Test with your own image (optional/ungraded exercise)"></a>7. Test with your own image (optional/ungraded exercise)</h2><p>Congratulations on finishing this assignment. You can use your own image and see the output of your model. To do that: </p><ol><li>Click on File in the upper bar of this notebook, then click Open to go on your Coursera Hub. </li><li>Add your image to this Jupyter Notebooks directory, in the images folder </li><li>Change your images name in the following code </li><li>Run the code and check if the algorithm is right (1 = cat, 0 = non-cat)!</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## START CODE HERE ##</span></span><br><span class="line">my_image = <span class="string">"1.png"</span>; <span class="comment"># change this to the name of your image file </span></span><br><span class="line">my_label_y = [<span class="number">1</span>]; <span class="comment"># the true class of your image (1 -&gt; cat, 0 -&gt; non-cat)</span></span><br><span class="line"><span class="comment">## END CODE HERE ##</span></span><br><span class="line"></span><br><span class="line">fname = <span class="string">"images/"</span> + my_image;</span><br><span class="line">image = np.array(ndimage.imread(fname, flatten=<span class="literal">False</span>));</span><br><span class="line">my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px * num_px * <span class="number">3</span>,<span class="number">1</span>));</span><br><span class="line">my_predicted_image = predict(my_image, my_label_y, parameters);</span><br><span class="line"></span><br><span class="line">plt.imshow(image);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"y = "</span> + str(np.squeeze(my_predicted_image)) + <span class="string">", your L-layer model predicts a \""</span> + classes[int(np.squeeze(my_predicted_image)),].decode(<span class="string">"utf-8"</span>) +  <span class="string">"\" picture."</span>);</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 1.0y = 1.0, your L-layer model predicts a &quot;cat&quot; picture.</code></pre><h5>Credits - <a href='https://www.coursera.org/' target=_blank >Coursera</a>,  <a href = 'https://en.wikipedia.org/wiki/Andrew_Ng' title="Andrew_Ng" target=_blank>Credits to the teacher</a> , <a href ='https://www.coursera.org/specializations/deep-learning?' target=_blank>Deeplearning.ai Course</a><h5>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;i&gt;&lt;b&gt;Note - These are my notes on DeepLearning Specialization Part:&lt;br&gt;Building your Deep Neural Network Step by Step || (Course- 1 Week - 4) || Neural Networks and Deep Learning (Week 4)&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Assignment" scheme="https://massivefile.com/categories/Assignment/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Assignment" scheme="https://massivefile.com/tags/Assignment/"/>
    
      <category term="Building your Deep Neural Network Step by Step" scheme="https://massivefile.com/tags/Building-your-Deep-Neural-Network-Step-by-Step/"/>
    
  </entry>
  
  <entry>
    <title>Deep Neural Network Application</title>
    <link href="https://massivefile.com/Deep_Neural_Network_Application/"/>
    <id>https://massivefile.com/Deep_Neural_Network_Application/</id>
    <published>2020-04-15T00:56:53.000Z</published>
    <updated>2020-05-05T23:21:15.817Z</updated>
    
    <content type="html"><![CDATA[<p><i><b>Note - These are my notes on DeepLearning Specialization Part:<br>Deep Neural Network Application  || (Course- 1 Week - 4) || Neural Networks and Deep Learning (Week 4)</i></b></p><a id="more"></a><h1 id="Deep-Neural-Network-for-Image-Classification-Application"><a href="#Deep-Neural-Network-for-Image-Classification-Application" class="headerlink" title="Deep Neural Network for Image Classification: Application"></a>Deep Neural Network for Image Classification: Application</h1><p>When you finish this, you will have finished the last programming assignment of Week 4, and also the last programming assignment of this course!<br>You will use use the functions youd implemented in the previous assignment to build a deep network, and apply it to cat vs non-cat classification. Hopefully, you will see an improvement in accuracy relative to your previous logistic regression implementation.<br><strong>After this assignment you will be able to:</strong></p><ul><li>Build and apply a deep neural network to supervised learning. </li></ul><p>Lets get started!</p><h2 id="1-Packages"><a href="#1-Packages" class="headerlink" title="1 - Packages"></a>1 - Packages</h2><p>Lets first import all the packages that you will need during this assignment. </p><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cubnVtcHkub3Jn">numpy<i class="fa fa-external-link-alt"></i></span> is the fundamental package for scientific computing with Python.</li><li><span class="exturl" data-url="aHR0cHM6Ly9tYXRwbG90bGliLm9yZw==">matplotlib<i class="fa fa-external-link-alt"></i></span> is a library to plot graphs in Python.</li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuaDVweS5vcmc=">h5py<i class="fa fa-external-link-alt"></i></span> is a common package to interact with a dataset that is stored on an H5 file.</li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cucHl0aG9ud2FyZS5jb20vcHJvZHVjdHMvcGlsLw==">PIL<i class="fa fa-external-link-alt"></i></span> and <span class="exturl" data-url="aHR0cHM6Ly93d3cuc2NpcHkub3JnLw==">scipy<i class="fa fa-external-link-alt"></i></span> are used here to test your model with your own picture at the end.</li><li>dnn_app_utils provides the functions implemented in the Building your Deep Neural Network: Step by Step assignment to this notebook.</li><li>np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span><br><span class="line"><span class="keyword">import</span> skimage</span><br><span class="line"><span class="keyword">from</span> dnn_app_utils_v2 <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">5.0</span>, <span class="number">4.0</span>) <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></span><br><span class="line"></span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="2-Dataset"><a href="#2-Dataset" class="headerlink" title="2 - Dataset"></a>2 - Dataset</h2><p>You will use the same Cat vs non-Cat dataset as in Logistic Regression as a Neural Network (Assignment 2). The model you had built had 70% test accuracy on classifying cats vs non-cats images. Hopefully, your new model will perform a better!</p><p><strong>Problem Statement</strong>: You are given a dataset (data.h5) containing:<br>    - a training set of m_train images labelled as cat (1) or non-cat (0)<br>    - a test set of m_test images labelled as cat and non-cat<br>    - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB).</p><p>Lets get more familiar with the dataset. Load the data by running the cell below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_x_orig, train_y, test_x_orig, test_y, classes = load_data()</span><br></pre></td></tr></table></figure><p>The following code will show you an image in the dataset. Feel free to change the index and re-run the cell multiple times to see other images. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example of a picture</span></span><br><span class="line">index = <span class="number">10</span></span><br><span class="line">plt.imshow(train_x_orig[index])</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"y = "</span> + str(train_y[<span class="number">0</span>,index]) + <span class="string">". It's a "</span> + classes[train_y[<span class="number">0</span>,index]].decode(<span class="string">"utf-8"</span>) +  <span class="string">" picture."</span>)</span><br></pre></td></tr></table></figure><pre><code>y = 0. It&apos;s a non-cat picture.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Explore your dataset </span></span><br><span class="line">m_train = train_x_orig.shape[<span class="number">0</span>]</span><br><span class="line">num_px = train_x_orig.shape[<span class="number">1</span>]</span><br><span class="line">m_test = test_x_orig.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Number of training examples: "</span> + str(m_train))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Number of testing examples: "</span> + str(m_test))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Each image is of size: ("</span> + str(num_px) + <span class="string">", "</span> + str(num_px) + <span class="string">", 3)"</span>)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"train_x_orig shape: "</span> + str(train_x_orig.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"train_y shape: "</span> + str(train_y.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"test_x_orig shape: "</span> + str(test_x_orig.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"test_y shape: "</span> + str(test_y.shape))</span><br></pre></td></tr></table></figure><pre><code>Number of training examples: 209Number of testing examples: 50Each image is of size: (64, 64, 3)train_x_orig shape: (209, 64, 64, 3)train_y shape: (1, 209)test_x_orig shape: (50, 64, 64, 3)test_y shape: (1, 50)</code></pre><p>As usual, you reshape and standardize the images before feeding them to the network. The code is given in the cell below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Reshape the training and test examples </span></span><br><span class="line">train_x_flatten = train_x_orig.reshape(train_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T   <span class="comment"># The "-1" makes reshape flatten the remaining dimensions</span></span><br><span class="line">test_x_flatten = test_x_orig.reshape(test_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># Standardize data to have feature values between 0 and 1.</span></span><br><span class="line">train_x = train_x_flatten/<span class="number">255.</span></span><br><span class="line">test_x = test_x_flatten/<span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"train_x's shape: "</span> + str(train_x.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"test_x's shape: "</span> + str(test_x.shape))</span><br></pre></td></tr></table></figure><pre><code>train_x&apos;s shape: (12288, 209)test_x&apos;s shape: (12288, 50)</code></pre><p>$12,288$ equals $64 \times 64 \times 3$ which is the size of one reshaped image vector.</p><h2 id="3-Architecture-of-your-model"><a href="#3-Architecture-of-your-model" class="headerlink" title="3 - Architecture of your model"></a>3 - Architecture of your model</h2><p>Now that you are familiar with the dataset, it is time to build a deep neural network to distinguish cat images from non-cat images.</p><p>You will build two different models:</p><ul><li>A 2-layer neural network</li><li>An L-layer deep neural network</li></ul><p>You will then compare the performance of these models, and also try out different values for $L$. </p><p>Lets look at the two architectures.</p><h3 id="3-1-2-layer-neural-network"><a href="#3-1-2-layer-neural-network" class="headerlink" title="3.1 - 2-layer neural network"></a>3.1 - 2-layer neural network</h3><ul><li>The input is a (64,64,3) image which is flattened to a vector of size $(12288,1)$. </li><li>The corresponding vector: $[x_0,x_1,,x_{12287}]^T$ is then multiplied by the weight matrix $W^{[1]}$ of size $(n^{[1]}, 12288)$.</li><li>You then add a bias term and take its relu to get the following vector: $[a_0^{[1]}, a_1^{[1]},, a_{n^{[1]}-1}^{[1]}]^T$.</li><li>You then repeat the same process.</li><li>You multiply the resulting vector by $W^{[2]}$ and add your intercept (bias). </li><li>Finally, you take the sigmoid of the result. If it is greater than 0.5, you classify it to be a cat.</li></ul><h3 id="3-2-L-layer-deep-neural-network"><a href="#3-2-L-layer-deep-neural-network" class="headerlink" title="3.2 - L-layer deep neural network"></a>3.2 - L-layer deep neural network</h3><p>It is hard to represent an L-layer deep neural network with the above representation. However, here is a simplified network representation:</p><p><u>Detailed Architecture of figure 3</u>:</p><ul><li>The input is a (64,64,3) image which is flattened to a vector of size (12288,1).</li><li>The corresponding vector: $[x_0,x_1,,x_{12287}]^T$ is then multiplied by the weight matrix $W^{[1]}$ and then you add the intercept $b^{[1]}$. The result is called the linear unit.</li><li>Next, you take the relu of the linear unit. This process could be repeated several times for each $(W^{[l]}, b^{[l]})$ depending on the model architecture.</li><li>Finally, you take the sigmoid of the final linear unit. If it is greater than 0.5, you classify it to be a cat.</li></ul><h3 id="3-3-General-methodology"><a href="#3-3-General-methodology" class="headerlink" title="3.3 - General methodology"></a>3.3 - General methodology</h3><p>As usual you will follow the Deep Learning methodology to build the model:<br>    1. Initialize parameters / Define hyperparameters<br>    2. Loop for num_iterations:<br>        a. Forward propagation<br>        b. Compute cost function<br>        c. Backward propagation<br>        d. Update parameters (using parameters, and grads from backprop)<br>    4. Use trained parameters to predict labels</p><p>Lets now implement those two models!</p><h2 id="4-Two-layer-neural-network"><a href="#4-Two-layer-neural-network" class="headerlink" title="4 - Two-layer neural network"></a>4 - Two-layer neural network</h2><p><strong>Question</strong>:  Use the helper functions you have implemented in the previous assignment to build a 2-layer neural network with the following structure: <em>LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</em>. The functions you may need and their inputs are:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">(n_x, n_h, n_y)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> parameters </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_activation_forward</span><span class="params">(A_prev, W, b, activation)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> A, cache</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(AL, Y)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> cost</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_activation_backward</span><span class="params">(dA, cache, activation)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> dA_prev, dW, db</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, grads, learning_rate)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### CONSTANTS DEFINING THE MODEL ####</span></span><br><span class="line">n_x = <span class="number">12288</span>     <span class="comment"># num_px * num_px * 3</span></span><br><span class="line">n_h = <span class="number">7</span></span><br><span class="line">n_y = <span class="number">1</span></span><br><span class="line">layers_dims = (n_x, n_h, n_y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: two_layer_model</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">two_layer_model</span><span class="params">(X, Y, layers_dims, learning_rate = <span class="number">0.0075</span>, num_iterations = <span class="number">3000</span>, print_cost=False)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements a two-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input data, of shape (n_x, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    layers_dims -- dimensions of the layers (n_x, n_h, n_y)</span></span><br><span class="line"><span class="string">    num_iterations -- number of iterations of the optimization loop</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate of the gradient descent update rule</span></span><br><span class="line"><span class="string">    print_cost -- If set to True, this will print the cost every 100 iterations </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- a dictionary containing W1, W2, b1, and b2</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    grads = &#123;&#125;</span><br><span class="line">    costs = []                              <span class="comment"># to keep track of the cost</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]                           <span class="comment"># number of examples</span></span><br><span class="line">    (n_x, n_h, n_y) = layers_dims</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize parameters dictionary, by calling one of the functions you'd previously implemented</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">    parameters = initialize_parameters(n_x, n_h, n_y)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get W1, b1, W2 and b2 from the dictionary parameters.</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop (gradient descent)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID. Inputs: "X, W1, b1". Output: "A1, cache1, A2, cache2".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">        A1, cache1 = linear_activation_forward(X, W1, b1, activation=<span class="string">'relu'</span>)</span><br><span class="line">        A2, cache2 = linear_activation_forward(A1, W2, b2, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute cost</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">        cost = compute_cost(A2, Y)</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Initializing backward propagation</span></span><br><span class="line">        dA2 = - (np.divide(Y, A2) - np.divide(<span class="number">1</span> - Y, <span class="number">1</span> - A2))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Backward propagation. Inputs: "dA2, cache2, cache1". Outputs: "dA1, dW2, db2; also dA0 (not used), dW1, db1".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, activation=<span class="string">'relu'</span>)</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2</span></span><br><span class="line">        grads[<span class="string">'dW1'</span>] = dW1</span><br><span class="line">        grads[<span class="string">'db1'</span>] = db1</span><br><span class="line">        grads[<span class="string">'dW2'</span>] = dW2</span><br><span class="line">        grads[<span class="string">'db2'</span>] = db2</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Update parameters.</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 1 line of code)</span></span><br><span class="line">        parameters = update_parameters(parameters, grads, learning_rate=learning_rate)</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Retrieve W1, b1, W2, b2 from parameters</span></span><br><span class="line">        W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">        b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">        W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">        b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Print the cost every 100 training example</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Cost after iteration &#123;&#125;: &#123;&#125;"</span>.format(i, np.squeeze(cost)))</span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            costs.append(cost)</span><br><span class="line">       </span><br><span class="line">    <span class="comment"># plot the cost</span></span><br><span class="line"></span><br><span class="line">    plt.plot(np.squeeze(costs))</span><br><span class="line">    plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'iterations (per tens)'</span>)</span><br><span class="line">    plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><p>Run the cell below to train your parameters. See if your model runs. The cost should be decreasing. It may take up to 5 minutes to run 2500 iterations. Check if the Cost after iteration 0 matches the expected output below, if not click on the square () on the upper bar of the notebook to stop the cell and try to find your error.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameters = two_layer_model(train_x, train_y, layers_dims = (n_x, n_h, n_y), num_iterations = <span class="number">2500</span>, print_cost=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><pre><code>Cost after iteration 0: 0.693049735659989Cost after iteration 100: 0.6464320953428849Cost after iteration 200: 0.6325140647912678Cost after iteration 300: 0.6015024920354665Cost after iteration 400: 0.5601966311605747Cost after iteration 500: 0.515830477276473Cost after iteration 600: 0.47549013139433266Cost after iteration 700: 0.43391631512257495Cost after iteration 800: 0.4007977536203886Cost after iteration 900: 0.3580705011323798Cost after iteration 1000: 0.3394281538366413Cost after iteration 1100: 0.3052753636196265Cost after iteration 1200: 0.2749137728213018Cost after iteration 1300: 0.24681768210614863Cost after iteration 1400: 0.1985073503746611Cost after iteration 1500: 0.17448318112556635Cost after iteration 1600: 0.17080762978096914Cost after iteration 1700: 0.11306524562164712Cost after iteration 1800: 0.0962942684593716Cost after iteration 1900: 0.08342617959726877Cost after iteration 2000: 0.07439078704319092Cost after iteration 2100: 0.06630748132267941Cost after iteration 2200: 0.05919329501038178Cost after iteration 2300: 0.05336140348560562Cost after iteration 2400: 0.04855478562877025</code></pre><p><strong>Expected Output</strong>:</p><table>     <tr>        <td> **Cost after iteration 0**</td>        <td> 0.6930497356599888 </td>    </tr>    <tr>        <td> **Cost after iteration 100**</td>        <td> 0.6464320953428849 </td>    </tr>    <tr>        <td> **...**</td>        <td> ... </td>    </tr>    <tr>        <td> **Cost after iteration 2400**</td>        <td> 0.048554785628770206 </td>    </tr></table><p>Good thing you built a vectorized implementation! Otherwise it might have taken 10 times longer to train this.</p><p>Now, you can use the trained parameters to classify images from the dataset. To see your predictions on the training and test sets, run the cell below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions_train = predict(train_x, train_y, parameters)</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 0.9999999999999998</code></pre><p><strong>Expected Output</strong>:</p><table>     <tr>        <td> **Accuracy**</td>        <td> 1.0 </td>    </tr></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions_test = predict(test_x, test_y, parameters)</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 0.72</code></pre><p><strong>Expected Output</strong>:</p><table>     <tr>        <td> **Accuracy**</td>        <td> 0.72 </td>    </tr></table><p><strong>Note</strong>: You may notice that running the model on fewer iterations (say 1500) gives better accuracy on the test set. This is called early stopping and we will talk about it in the next course. Early stopping is a way to prevent overfitting. </p><p>Congratulations! It seems that your 2-layer neural network has better performance (72%) than the logistic regression implementation (70%, assignment week 2). Lets see if you can do even better with an $L$-layer model.</p><h2 id="5-L-layer-Neural-Network"><a href="#5-L-layer-Neural-Network" class="headerlink" title="5 - L-layer Neural Network"></a>5 - L-layer Neural Network</h2><p><strong>Question</strong>: Use the helper functions you have implemented previously to build an $L$-layer neural network with the following structure: <em>[LINEAR -&gt; RELU]$\times$(L-1) -&gt; LINEAR -&gt; SIGMOID</em>. The functions you may need and their inputs are:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters_deep</span><span class="params">(layer_dims)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> parameters </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_model_forward</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> AL, caches</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(AL, Y)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> cost</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_model_backward</span><span class="params">(AL, Y, caches)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> grads</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, grads, learning_rate)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### CONSTANTS ###</span></span><br><span class="line">layers_dims = [<span class="number">12288</span>, <span class="number">20</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">1</span>] <span class="comment">#  5-layer model</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: L_layer_model</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_layer_model</span><span class="params">(X, Y, layers_dims, learning_rate = <span class="number">0.0075</span>, num_iterations = <span class="number">3000</span>, print_cost=False)</span>:</span><span class="comment">#lr was 0.009</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements a L-layer neural network: [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate of the gradient descent update rule</span></span><br><span class="line"><span class="string">    num_iterations -- number of iterations of the optimization loop</span></span><br><span class="line"><span class="string">    print_cost -- if True, it prints the cost every 100 steps</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    costs = []                         <span class="comment"># keep track of cost</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Parameters initialization.</span></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    parameters = initialize_parameters_deep(layers_dims)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop (gradient descent)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward propagation: [LINEAR -&gt; RELU]*(L-1) -&gt; LINEAR -&gt; SIGMOID.</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">        AL, caches = L_model_forward(X, parameters)</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute cost.</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">        cost = compute_cost(AL, Y)</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Backward propagation.</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">        grads = L_model_backward(AL, Y, caches)</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># Update parameters.</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 1 line of code)</span></span><br><span class="line">        parameters = update_parameters(parameters, grads, learning_rate=learning_rate)</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">                </span><br><span class="line">        <span class="comment"># Print the cost every 100 training example</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Cost after iteration %i: %f"</span> %(i, cost))</span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            costs.append(cost)</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># plot the cost</span></span><br><span class="line">    plt.plot(np.squeeze(costs))</span><br><span class="line">    plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'iterations (per tens)'</span>)</span><br><span class="line">    plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><p>You will now train the model as a 5-layer neural network. </p><p>Run the cell below to train your model. The cost should decrease on every iteration. It may take up to 5 minutes to run 2500 iterations. Check if the Cost after iteration 0 matches the expected output below, if not click on the square () on the upper bar of the notebook to stop the cell and try to find your error.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = <span class="number">2500</span>, print_cost = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><pre><code>Cost after iteration 0: 0.771749Cost after iteration 100: 0.672053Cost after iteration 200: 0.648263Cost after iteration 300: 0.611507Cost after iteration 400: 0.567047Cost after iteration 500: 0.540138Cost after iteration 600: 0.527930Cost after iteration 700: 0.465477Cost after iteration 800: 0.369126Cost after iteration 900: 0.391747Cost after iteration 1000: 0.315187Cost after iteration 1100: 0.272700Cost after iteration 1200: 0.237419Cost after iteration 1300: 0.199601Cost after iteration 1400: 0.189263Cost after iteration 1500: 0.161189Cost after iteration 1600: 0.148214Cost after iteration 1700: 0.137775Cost after iteration 1800: 0.129740Cost after iteration 1900: 0.121225Cost after iteration 2000: 0.113821Cost after iteration 2100: 0.107839Cost after iteration 2200: 0.102855Cost after iteration 2300: 0.100897Cost after iteration 2400: 0.092878</code></pre><p><strong>Expected Output</strong>:</p><table>     <tr>        <td> **Cost after iteration 0**</td>        <td> 0.771749 </td>    </tr>    <tr>        <td> **Cost after iteration 100**</td>        <td> 0.672053 </td>    </tr>    <tr>        <td> **...**</td>        <td> ... </td>    </tr>    <tr>        <td> **Cost after iteration 2400**</td>        <td> 0.092878 </td>    </tr></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pred_train = predict(train_x, train_y, parameters)</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 0.9856459330143539</code></pre><table>    <tr>    <td>    **Train Accuracy**    </td>    <td>    0.985645933014    </td>    </tr></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pred_test = predict(test_x, test_y, parameters)</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 0.8</code></pre><p><strong>Expected Output</strong>:</p><table>     <tr>        <td> **Test Accuracy**</td>        <td> 0.8 </td>    </tr></table><p>Congrats! It seems that your 5-layer neural network has better performance (80%) than your 2-layer neural network (72%) on the same test set. </p><p>This is good performance for this task. Nice job! </p><p>Though in the next course on Improving deep neural networks you will learn how to obtain even higher accuracy by systematically searching for better hyperparameters (learning_rate, layers_dims, num_iterations, and others youll also learn in the next course). </p><h2 id="6-Results-Analysis"><a href="#6-Results-Analysis" class="headerlink" title="6) Results Analysis"></a>6) Results Analysis</h2><p>First, lets take a look at some images the L-layer model labeled incorrectly. This will show a few mislabeled images. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print_mislabeled_images(classes, test_x, test_y, pred_test)</span><br></pre></td></tr></table></figure><p><strong>A few type of images the model tends to do poorly on include:</strong> </p><ul><li>Cat body in an unusual position</li><li>Cat appears against a background of a similar color</li><li>Unusual cat color and species</li><li>Camera Angle</li><li>Brightness of the picture</li><li>Scale variation (cat is very large or small in image) </li></ul><h2 id="7-Test-with-your-own-image-optional-ungraded-exercise"><a href="#7-Test-with-your-own-image-optional-ungraded-exercise" class="headerlink" title="7) Test with your own image (optional/ungraded exercise)"></a>7) Test with your own image (optional/ungraded exercise)</h2><p>Congratulations on finishing this assignment. You can use your own image and see the output of your model. To do that:<br>    1. Click on File in the upper bar of this notebook, then click Open to go on your Coursera Hub.<br>    2. Add your image to this Jupyter Notebooks directory, in the images folder<br>    3. Change your images name in the following code<br>    4. Run the code and check if the algorithm is right (1 = cat, 0 = non-cat)!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## START CODE HERE ##</span></span><br><span class="line">my_image = <span class="string">"my_image.jpg"</span> <span class="comment"># change this to the name of your image file </span></span><br><span class="line">my_label_y = [<span class="number">1</span>] <span class="comment"># the true class of your image (1 -&gt; cat, 0 -&gt; non-cat)</span></span><br><span class="line"><span class="comment">## END CODE HERE ##</span></span><br><span class="line"></span><br><span class="line">fname = <span class="string">"images/"</span> + my_image</span><br><span class="line">image = np.array(plt.imread(fname))</span><br><span class="line">my_image = skimage.transform.resize(image, output_shape=(num_px,num_px)).reshape((num_px*num_px*<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line">my_predicted_image = predict(my_image, my_label_y, parameters)</span><br><span class="line"></span><br><span class="line">plt.imshow(image)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"y = "</span> + str(np.squeeze(my_predicted_image)) + <span class="string">", your L-layer model predicts a \""</span> + classes[int(np.squeeze(my_predicted_image)),].decode(<span class="string">"utf-8"</span>) +  <span class="string">"\" picture."</span>)</span><br></pre></td></tr></table></figure><pre><code>/Users/abanihi/opt/miniconda3/envs/pangeo/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, &apos;constant&apos;, will be changed to &apos;reflect&apos; in skimage 0.15.  warn(&quot;The default mode, &apos;constant&apos;, will be changed to &apos;reflect&apos; in &quot;/Users/abanihi/opt/miniconda3/envs/pangeo/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.  warn(&quot;Anti-aliasing will be enabled by default in skimage 0.15 to &quot;Accuracy: 1.0y = 1.0, your L-layer model predicts a &quot;cat&quot; picture.</code></pre><p><strong>References</strong>:</p><ul><li>for auto-reloading external module: <span class="exturl" data-url="aHR0cHM6Ly9zdGFja292ZXJmbG93LmNvbS9xdWVzdGlvbnMvMTkwNzk5My9hdXRvcmVsb2FkLW9mLW1vZHVsZXMtaW4taXB5dGhvbg==">https://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython<i class="fa fa-external-link-alt"></i></span></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%load_ext version_information</span><br><span class="line">%version_information numpy, PIL, matplotlib, scipy, skimage</span><br></pre></td></tr></table></figure><table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.6 64bit [GCC 4.2.1 Compatible Apple LLVM 6.1.0 (clang-602.0.53)]</td></tr><tr><td>IPython</td><td>7.0.1</td></tr><tr><td>OS</td><td>Darwin 17.7.0 x86_64 i386 64bit</td></tr><tr><td>numpy</td><td>1.15.1</td></tr><tr><td>PIL</td><td>5.3.0</td></tr><tr><td>matplotlib</td><td>3.0.0</td></tr><tr><td>scipy</td><td>1.1.0</td></tr><tr><td>skimage</td><td>0.14.1</td></tr><tr><td colspan='2'>Sun Oct 14 21:16:14 2018 MDT</td></tr></table><h5>Credits - <a href='https://www.coursera.org/' target=_blank >Coursera</a>,  <a href = 'https://en.wikipedia.org/wiki/Andrew_Ng' title="Andrew_Ng" target=_blank>Credits to the teacher</a> , <a href ='https://www.coursera.org/specializations/deep-learning?' target=_blank>Deeplearning.ai Course</a><h5>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;i&gt;&lt;b&gt;Note - These are my notes on DeepLearning Specialization Part:&lt;br&gt;Deep Neural Network Application  || (Course- 1 Week - 4) || Neural Networks and Deep Learning (Week 4)&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Assignment" scheme="https://massivefile.com/categories/Assignment/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Assignment" scheme="https://massivefile.com/tags/Assignment/"/>
    
      <category term="Deep Neural Network Application" scheme="https://massivefile.com/tags/Deep-Neural-Network-Application/"/>
    
  </entry>
  
  <entry>
    <title>Quiz 4 || Neural Networks and Deep Learning</title>
    <link href="https://massivefile.com/quiz4/"/>
    <id>https://massivefile.com/quiz4/</id>
    <published>2020-04-14T18:30:00.000Z</published>
    <updated>2020-05-05T23:22:30.090Z</updated>
    
    <content type="html"><![CDATA[<p><b><i>title: Quiz 4|| Deeplearnig (Course - 1 Week - 4) Neural Networks and Deep Learning (Week 4)<br>Note - Quiz on the notes on DeepLearning </b></i></p><a id="more"></a><iframe src="https://drive.google.com/file/d/1jnPSkG8QQoT6PwWJtDDojc4_X4ivoARi/preview" width="640" height="480"></iframe>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;b&gt;&lt;i&gt;title: Quiz 4|| Deeplearnig (Course - 1 Week - 4) Neural Networks and Deep Learning (Week 4)&lt;br&gt;Note - Quiz on the notes on DeepLearning &lt;/b&gt;&lt;/i&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Quiz" scheme="https://massivefile.com/categories/Quiz/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Quiz" scheme="https://massivefile.com/tags/Quiz/"/>
    
  </entry>
  
  <entry>
    <title>Planar data classification with one hidden layer</title>
    <link href="https://massivefile.com/Planar_data_classification_with_one_hidden_layer/"/>
    <id>https://massivefile.com/Planar_data_classification_with_one_hidden_layer/</id>
    <published>2020-04-14T00:56:53.000Z</published>
    <updated>2020-05-05T23:22:03.042Z</updated>
    
    <content type="html"><![CDATA[<p><i><b>Note - These are my notes on DeepLearning Specialization Part:<br>Planar data classification with one hidden layer || (Course- 1 Week - 3) || Neural Networks and Deep Learning (Week 3)</i></b><a id="more"></a></p><h1 id="Table-of-Contents"><a href="#Table-of-Contents" class="headerlink" title="Table of Contents "></a>Table of Contents </center></h1> <p><div class="lev1 toc-item"><a href="#Planar-data-classification-with-one-hidden-layer" data-toc-modified-id="Planar-data-classification-with-one-hidden-layer-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Planar data classification with one hidden layer</a></div><div class="lev2 toc-item"><a href="#1---Packages" data-toc-modified-id="1---Packages-11"><span class="toc-item-num">1.1&nbsp;&nbsp;</span>1 - Packages</a></div><div class="lev2 toc-item"><a href="#2---Dataset" data-toc-modified-id="2---Dataset-12"><span class="toc-item-num">1.2&nbsp;&nbsp;</span>2 - Dataset</a></div><div class="lev2 toc-item"><a href="#3---Simple-Logistic-Regression" data-toc-modified-id="3---Simple-Logistic-Regression-13"><span class="toc-item-num">1.3&nbsp;&nbsp;</span>3 - Simple Logistic Regression</a></div><div class="lev2 toc-item"><a href="#4---Neural-Network-model" data-toc-modified-id="4---Neural-Network-model-14"><span class="toc-item-num">1.4&nbsp;&nbsp;</span>4 - Neural Network model</a></div><div class="lev3 toc-item"><a href="#4.1---Defining-the-neural-network-structure" data-toc-modified-id="4.1---Defining-the-neural-network-structure-141"><span class="toc-item-num">1.4.1&nbsp;&nbsp;</span>4.1 - Defining the neural network structure</a></div><div class="lev3 toc-item"><a href="#4.2---Initialize-the-model's-parameters" data-toc-modified-id="4.2---Initialize-the-model's-parameters-142"><span class="toc-item-num">1.4.2&nbsp;&nbsp;</span>4.2 - Initialize the model's parameters</a></div><div class="lev3 toc-item"><a href="#4.3---The-Loop" data-toc-modified-id="4.3---The-Loop-143"><span class="toc-item-num">1.4.3&nbsp;&nbsp;</span>4.3 - The Loop</a></div><div class="lev3 toc-item"><a href="#4.4---Integrate-parts-4.1,-4.2-and-4.3-in-nn_model()" data-toc-modified-id="4.4---Integrate-parts-4.1,-4.2-and-4.3-in-nn_model()-144"><span class="toc-item-num">1.4.4&nbsp;&nbsp;</span>4.4 - Integrate parts 4.1, 4.2 and 4.3 in nn_model()</a></div><div class="lev3 toc-item"><a href="#4.5-Predictions" data-toc-modified-id="4.5-Predictions-145"><span class="toc-item-num">1.4.5&nbsp;&nbsp;</span>4.5 Predictions</a></div><div class="lev3 toc-item"><a href="#4.6---Tuning-hidden-layer-size-(optional/ungraded-exercise)" data-toc-modified-id="4.6---Tuning-hidden-layer-size-(optional/ungraded-exercise)-146"><span class="toc-item-num">1.4.6&nbsp;&nbsp;</span>4.6 - Tuning hidden layer size (optional/ungraded exercise)</a></div><div class="lev2 toc-item"><a href="#5)-Performance-on-other-datasets" data-toc-modified-id="5)-Performance-on-other-datasets-15"><span class="toc-item-num">1.5&nbsp;&nbsp;</span>5) Performance on other datasets</a></div><h1 id="Planar-data-classification-with-one-hidden-layer"><a href="#Planar-data-classification-with-one-hidden-layer" class="headerlink" title="Planar data classification with one hidden layer"></a>Planar data classification with one hidden layer</h1><p>Welcome to your week 3 programming assignment. Its time to build your first neural network, which will have a hidden layer. You will see a big difference between this model and the one you implemented using logistic regression. </p><p><strong>You will learn how to:</strong></p><ul><li>Implement a 2-class classification neural network with a single hidden layer</li><li>Use units with a non-linear activation function, such as tanh </li><li>Compute the cross entropy loss </li><li>Implement forward and backward propagation</li></ul><h2 id="1-Packages"><a href="#1-Packages" class="headerlink" title="1 - Packages"></a>1 - Packages</h2><p>Lets first import all the packages that you will need during this assignment.</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cubnVtcHkub3Jn">numpy<i class="fa fa-external-link-alt"></i></span> is the fundamental package for scientific computing with Python.</li><li><span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS8=">sklearn<i class="fa fa-external-link-alt"></i></span> provides simple and efficient tools for data mining and data analysis. </li><li><span class="exturl" data-url="aHR0cHM6Ly9tYXRwbG90bGliLm9yZw==">matplotlib<i class="fa fa-external-link-alt"></i></span> is a library for plotting graphs in Python.</li><li>testCases provides some test examples to assess the correctness of your functions</li><li>planar_utils provide various useful functions used in this assignment</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Package imports</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> testCases <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets</span><br><span class="line"><span class="keyword">import</span> sklearn.linear_model</span><br><span class="line"><span class="keyword">from</span> planar_utils <span class="keyword">import</span> plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>) <span class="comment"># set a seed so that the results are consistent</span></span><br></pre></td></tr></table></figure><h2 id="2-Dataset"><a href="#2-Dataset" class="headerlink" title="2 - Dataset"></a>2 - Dataset</h2><p>First, lets get the dataset you will work on. The following code will load a flower 2-class dataset into variables <code>X</code> and <code>Y</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X, Y = load_planar_dataset()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.shape, Y.shape</span><br></pre></td></tr></table></figure><pre><code>((2, 400), (1, 400))</code></pre><p>Visualize the dataset using matplotlib. The data looks like a flower with some red (label y=0) and some blue (y=1) points. Your goal is to build a model to fit this data. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualize the data:</span></span><br><span class="line">plt.scatter(X[<span class="number">0</span>, :], X[<span class="number">1</span>, :], c=Y[<span class="number">0</span>, :], s=<span class="number">40</span>, cmap=plt.cm.Spectral);</span><br></pre></td></tr></table></figure><p>You have:<br>    - a numpy-array (matrix) X that contains your features (x1, x2)<br>    - a numpy-array (vector) Y that contains your labels (red:0, blue:1).</p><p>Lets first get a better sense of what our data is like. </p><p><strong>Exercise</strong>: How many training examples do you have? In addition, what is the <code>shape</code> of the variables <code>X</code> and <code>Y</code>? </p><p><strong>Hint</strong>: How do you get the shape of a numpy array? <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnNjaXB5Lm9yZy9kb2MvbnVtcHkvcmVmZXJlbmNlL2dlbmVyYXRlZC9udW1weS5uZGFycmF5LnNoYXBlLmh0bWw=">(help)<i class="fa fa-external-link-alt"></i></span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### START CODE HERE ### ( 3 lines of code)</span></span><br><span class="line">shape_X = X.shape</span><br><span class="line">shape_Y = Y.shape</span><br><span class="line">m =  Y.size <span class="comment"># training set size</span></span><br><span class="line"><span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">'The shape of X is: '</span> + str(shape_X))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'The shape of Y is: '</span> + str(shape_Y))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'I have m = %d training examples!'</span> % (m))</span><br></pre></td></tr></table></figure><pre><code>The shape of X is: (2, 400)The shape of Y is: (1, 400)I have m = 400 training examples!</code></pre><p><strong>Expected Output</strong>:</p><table style="width:20%">  <tr>    <td>**shape of X**</td>    <td> (2, 400) </td>   </tr>  <tr>    <td>**shape of Y**</td>    <td>(1, 400) </td>   </tr><pre><code>&lt;tr&gt;&lt;td&gt;**m**&lt;/td&gt;&lt;td&gt; 400 &lt;/td&gt; </code></pre>  </tr></table><h2 id="3-Simple-Logistic-Regression"><a href="#3-Simple-Logistic-Regression" class="headerlink" title="3 - Simple Logistic Regression"></a>3 - Simple Logistic Regression</h2><p>Before building a full neural network, lets first see how logistic regression performs on this problem. You can use sklearns built-in functions to do that. Run the code below to train a logistic regression classifier on the dataset.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train the logistic regression classifier</span></span><br><span class="line">clf = sklearn.linear_model.LogisticRegressionCV(cv=<span class="number">5</span>);</span><br><span class="line">clf.fit(X.T, Y.T.ravel());</span><br></pre></td></tr></table></figure><p>You can now plot the decision boundary of these models. Run the code below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot the decision boundary for logistic regression</span></span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: clf.predict(x), X, Y)</span><br><span class="line">plt.title(<span class="string">"Logistic Regression"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print accuracy</span></span><br><span class="line">LR_predictions = clf.predict(X.T)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'Accuracy of logistic regression: %d '</span> % float((np.dot(Y,LR_predictions) + np.dot(<span class="number">1</span>-Y,<span class="number">1</span>-LR_predictions))/float(Y.size)*<span class="number">100</span>) +</span><br><span class="line">       <span class="string">'% '</span> + <span class="string">"(percentage of correctly labelled datapoints)"</span>)</span><br></pre></td></tr></table></figure><pre><code>Accuracy of logistic regression: 47 % (percentage of correctly labelled datapoints)</code></pre><p><strong>Expected Output</strong>:</p><table style="width:20%">  <tr>    <td>**Accuracy**</td>    <td> 47% </td>   </tr></table><p><strong>Interpretation</strong>: The dataset is not linearly separable, so logistic regression doesnt perform well. Hopefully a neural network will do better. Lets try this now! </p><h2 id="4-Neural-Network-model"><a href="#4-Neural-Network-model" class="headerlink" title="4 - Neural Network model"></a>4 - Neural Network model</h2><p>Logistic regression did not work well on the flower dataset. You are going to train a Neural Network with a single hidden layer.</p><p><strong>Here is our model</strong>:<br><strong>Mathematically</strong>:</p><p>For one example $x^{(i)}$:<br>$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1] (i)}\tag{1}$$<br>$$a^{[1] (i)} = \tanh(z^{[1] (i)})\tag{2}$$<br>$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2] (i)}\tag{3}$$<br>$$\hat{y}^{(i)} = a^{[2] (i)} = \sigma(z^{ [2] (i)})\tag{4}$$<br>$$y^{(i)}_{prediction} = \begin{cases} 1 &amp; \mbox{if } a^{<a href="i">2</a>} &gt; 0.5 \ 0 &amp; \mbox{otherwise } \end{cases}\tag{5}$$</p><p>Given the predictions on all the examples, you can also compute the cost $J$ as follows:<br>$$J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \large\left(\small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right)  \large  \right) \small \tag{6}$$</p><p><strong>Reminder</strong>: The general methodology to build a Neural Network is to:<br>    1. Define the neural network structure ( # of input units,  # of hidden units, etc).<br>    2. Initialize the models parameters<br>    3. Loop:<br>        - Implement forward propagation<br>        - Compute loss<br>        - Implement backward propagation to get the gradients<br>        - Update parameters (gradient descent)</p><p>You often build helper functions to compute steps 1-3 and then merge them into one function we call <code>nn_model()</code>. Once youve built <code>nn_model()</code> and learnt the right parameters, you can make predictions on new data.</p><h3 id="4-1-Defining-the-neural-network-structure"><a href="#4-1-Defining-the-neural-network-structure" class="headerlink" title="4.1 - Defining the neural network structure"></a>4.1 - Defining the neural network structure</h3><p><strong>Exercise</strong>: Define three variables:<br>    - n_x: the size of the input layer<br>    - n_h: the size of the hidden layer (set this to 4)<br>    - n_y: the size of the output layer</p><p><strong>Hint</strong>: Use shapes of X and Y to find n_x and n_y. Also, hard code the hidden layer size to be 4.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: layer_sizes</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layer_sizes</span><span class="params">(X, Y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input dataset of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    Y -- labels of shape (output size, number of examples)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    n_x -- the size of the input layer</span></span><br><span class="line"><span class="string">    n_h -- the size of the hidden layer</span></span><br><span class="line"><span class="string">    n_y -- the size of the output layer</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 3 lines of code)</span></span><br><span class="line">    n_x = X.shape[<span class="number">0</span>] <span class="comment"># size of input layer</span></span><br><span class="line">    n_h = <span class="number">4</span></span><br><span class="line">    n_y = Y.shape[<span class="number">0</span>] <span class="comment"># size of output layer</span></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> (n_x, n_h, n_y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_assess, Y_assess = layer_sizes_test_case()</span><br><span class="line">(n_x, n_h, n_y) = layer_sizes(X_assess, Y_assess)</span><br><span class="line">print(<span class="string">"The size of the input layer is: n_x = "</span> + str(n_x))</span><br><span class="line">print(<span class="string">"The size of the hidden layer is: n_h = "</span> + str(n_h))</span><br><span class="line">print(<span class="string">"The size of the output layer is: n_y = "</span> + str(n_y))</span><br></pre></td></tr></table></figure><pre><code>The size of the input layer is: n_x = 5The size of the hidden layer is: n_h = 4The size of the output layer is: n_y = 2</code></pre><p><strong>Expected Output</strong> (these are not the sizes you will use for your network, they are just used to assess the function youve just coded).</p><table style="width:20%">  <tr>    <td>**n_x**</td>    <td> 5 </td>   </tr><pre><code>&lt;tr&gt;&lt;td&gt;**n_h**&lt;/td&gt;&lt;td&gt; 4 &lt;/td&gt; </code></pre>  </tr><pre><code>&lt;tr&gt;&lt;td&gt;**n_y**&lt;/td&gt;&lt;td&gt; 2 &lt;/td&gt; </code></pre>  </tr></table><h3 id="4-2-Initialize-the-models-parameters"><a href="#4-2-Initialize-the-models-parameters" class="headerlink" title="4.2 - Initialize the models parameters"></a>4.2 - Initialize the models parameters</h3><p><strong>Exercise</strong>: Implement the function <code>initialize_parameters()</code>.</p><p><strong>Instructions</strong>:</p><ul><li>Make sure your parameters sizes are right. Refer to the neural network figure above if needed.</li><li>You will initialize the weights matrices with random values. <ul><li>Use: <code>np.random.randn(a,b) * 0.01</code> to randomly initialize a matrix of shape (a,b).</li></ul></li><li>You will initialize the bias vectors as zeros. <ul><li>Use: <code>np.zeros((a,b))</code> to initialize a matrix of shape (a,b) with zeros.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: initialize_parameters</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">(n_x, n_h, n_y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Argument:</span></span><br><span class="line"><span class="string">    n_x -- size of the input layer</span></span><br><span class="line"><span class="string">    n_h -- size of the hidden layer</span></span><br><span class="line"><span class="string">    n_y -- size of the output layer</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    params -- python dictionary containing your parameters:</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (n_h, n_x)</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (n_h, 1)</span></span><br><span class="line"><span class="string">                    W2 -- weight matrix of shape (n_y, n_h)</span></span><br><span class="line"><span class="string">                    b2 -- bias vector of shape (n_y, 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    np.random.seed(<span class="number">2</span>) <span class="comment"># we set up a seed so that your output matches ours although the initialization is random.</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 4 lines of code)</span></span><br><span class="line">    W1 = np.random.randn(n_h, n_x) * <span class="number">0.01</span></span><br><span class="line">    b1 = np.zeros((n_h, <span class="number">1</span>))</span><br><span class="line">    W2 = np.random.randn(n_y, n_h) * <span class="number">0.01</span></span><br><span class="line">    b2 = np.zeros((n_y, <span class="number">1</span>))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">assert</span> (W1.shape == (n_h, n_x))</span><br><span class="line">    <span class="keyword">assert</span> (b1.shape == (n_h, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">assert</span> (W2.shape == (n_y, n_h))</span><br><span class="line">    <span class="keyword">assert</span> (b2.shape == (n_y, <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    parameters = &#123;<span class="string">"W1"</span>: W1,</span><br><span class="line">                  <span class="string">"b1"</span>: b1,</span><br><span class="line">                  <span class="string">"W2"</span>: W2,</span><br><span class="line">                  <span class="string">"b2"</span>: b2&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">n_x, n_h, n_y = initialize_parameters_test_case()</span><br><span class="line"></span><br><span class="line">parameters = initialize_parameters(n_x, n_h, n_y)</span><br><span class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]))</span><br><span class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]))</span><br><span class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]))</span><br><span class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]))</span><br></pre></td></tr></table></figure><pre><code>W1 = [[-0.00416758 -0.00056267] [-0.02136196  0.01640271] [-0.01793436 -0.00841747] [ 0.00502881 -0.01245288]]b1 = [[0.] [0.] [0.] [0.]]W2 = [[-0.01057952 -0.00909008  0.00551454  0.02292208]]b2 = [[0.]]</code></pre><p><strong>Expected Output</strong>:</p><table style="width:90%">  <tr>    <td>**W1**</td>    <td> [[-0.00416758 -0.00056267] [-0.02136196  0.01640271] [-0.01793436 -0.00841747] [ 0.00502881 -0.01245288]] </td>   </tr>  <tr>    <td>**b1**</td>    <td> [[ 0.] [ 0.] [ 0.] [ 0.]] </td>   </tr>  <tr>    <td>**W2**</td>    <td> [[-0.01057952 -0.00909008  0.00551454  0.02292208]]</td>   </tr>  <tr>    <td>**b2**</td>    <td> [[ 0.]] </td>   </tr></table><h3 id="4-3-The-Loop"><a href="#4-3-The-Loop" class="headerlink" title="4.3 - The Loop"></a>4.3 - The Loop</h3><p><strong>Question</strong>: Implement <code>forward_propagation()</code>.</p><p><strong>Instructions</strong>:</p><ul><li>Look above at the mathematical representation of your classifier.</li><li>You can use the function <code>sigmoid()</code>. It is built-in (imported) in the notebook.</li><li>You can use the function <code>np.tanh()</code>. It is part of the numpy library.</li><li>The steps you have to implement are:<ol><li>Retrieve each parameter from the dictionary parameters (which is the output of <code>initialize_parameters()</code>) by using <code>parameters[&quot;..&quot;]</code>.</li><li>Implement Forward Propagation. Compute $Z^{[1]}, A^{[1]}, Z^{[2]}$ and $A^{[2]}$ (the vector of all your predictions on all the examples in the training set).</li></ol></li><li>Values needed in the backpropagation are stored in <code>cache</code>. The <code>cache</code> will be given as an input to the backpropagation function.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: forward_propagation</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Argument:</span></span><br><span class="line"><span class="string">    X -- input data of size (n_x, m)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters (output of initialization function)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    A2 -- The sigmoid output of the second activation</span></span><br><span class="line"><span class="string">    cache -- a dictionary containing "Z1", "A1", "Z2" and "A2"</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># Retrieve each parameter from the dictionary "parameters"</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 4 lines of code)</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line">    <span class="comment">#print(W1.shape, b1.shape, W2.shape, b2.shape)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Implement Forward Propagation to calculate A2 (probabilities)</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 4 lines of code)</span></span><br><span class="line">    Z1 = np.dot(W1, X) + b1</span><br><span class="line">    A1 = np.tanh(Z1)</span><br><span class="line">    Z2 = np.dot(W2, A1) + b2</span><br><span class="line">    A2 = sigmoid(Z2)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">assert</span>(A2.shape == (<span class="number">1</span>, X.shape[<span class="number">1</span>]))</span><br><span class="line">    </span><br><span class="line">    cache = &#123;<span class="string">"Z1"</span>: Z1,</span><br><span class="line">             <span class="string">"A1"</span>: A1,</span><br><span class="line">             <span class="string">"Z2"</span>: Z2,</span><br><span class="line">             <span class="string">"A2"</span>: A2&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> A2, cache</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X_assess, parameters = forward_propagation_test_case()</span><br><span class="line"></span><br><span class="line">A2, cache = forward_propagation(X_assess, parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note: we use the mean here just to make sure that your output matches ours. </span></span><br><span class="line">print(np.mean(cache[<span class="string">'Z1'</span>]) ,np.mean(cache[<span class="string">'A1'</span>]),np.mean(cache[<span class="string">'Z2'</span>]),np.mean(cache[<span class="string">'A2'</span>]))</span><br></pre></td></tr></table></figure><pre><code>-0.0004997557777419913 -0.0004969633532317802 0.0004381874509591466 0.500109546852431</code></pre><p><strong>Expected Output</strong>:</p><table style="width:55%">  <tr>    <td> -0.000499755777742 -0.000496963353232 0.000438187450959 0.500109546852 </td>   </tr></table><p>Now that you have computed $A^{[2]}$ (in the Python variable <code>A2</code>), which contains $a^{<a href="i">2</a>}$ for every example, you can compute the cost function as follows:</p><p>$$J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \large{(} \small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right) \large{)} \small\tag{13}$$</p><p><strong>Exercise</strong>: Implement <code>compute_cost()</code> to compute the value of the cost $J$.</p><p><strong>Instructions</strong>:</p><ul><li>There are many ways to implement the cross-entropy loss. To help you, we give you how we would have implemented<br>$$<br>\sum\limits_{i=0}^{m}  y^{(i)}\log(a^{<a href="i">2</a>})<br>$$:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">logprobs = np.multiply(np.log(A2),Y)</span><br><span class="line">cost = - np.sum(logprobs)                <span class="comment"># no need to use a for loop!</span></span><br></pre></td></tr></table></figure></li></ul><p>(you can use either <code>np.multiply()</code> and then <code>np.sum()</code> or directly <code>np.dot()</code>).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: compute_cost</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(A2, Y, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Computes the cross-entropy cost given in equation (13)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    Y -- "true" labels vector of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters W1, b1, W2 and b2</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    cost -- cross-entropy cost given equation (13)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    m = Y.shape[<span class="number">1</span>] <span class="comment"># number of example</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve W1 and W2 from parameters</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute the cross-entropy cost</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">    logprobs = np.multiply(np.log(A2), Y) + np.multiply((<span class="number">1</span>-Y), np.log(<span class="number">1</span>-A2))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    cost = <span class="number">-1</span>/m * np.sum(logprobs) </span><br><span class="line">    </span><br><span class="line">    cost = np.squeeze(cost)     <span class="comment"># makes sure cost is the dimension we expect. </span></span><br><span class="line">                                <span class="comment"># E.g., turns [[17]] into 17 </span></span><br><span class="line">    <span class="keyword">assert</span>(isinstance(cost, float))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A2, Y_assess, parameters = compute_cost_test_case()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"cost = "</span> + str(compute_cost(A2, Y_assess, parameters)))</span><br></pre></td></tr></table></figure><pre><code>cost = 0.6929198937761265</code></pre><p><strong>Expected Output</strong>:</p><table style="width:20%">  <tr>    <td>**cost**</td>    <td> 0.692919893776 </td>   </tr></table><p>Using the cache computed during forward propagation, you can now implement backward propagation.</p><p><strong>Question</strong>: Implement the function <code>backward_propagation()</code>.</p><p><strong>Instructions</strong>:<br>Backpropagation is usually the hardest (most mathematical) part in deep learning. To help you, here again is the slide from the lecture on backpropagation. Youll want to use the six equations on the right of this slide, since you are building a vectorized implementation.  </p><!--$\frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } = \frac{1}{m} (a^{[2](i)} - y^{(i)})$$\frac{\partial \mathcal{J} }{ \partial W_2 } = \frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } a^{[1] (i) T} $$\frac{\partial \mathcal{J} }{ \partial b_2 } = \sum_i{\frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)}}}$$\frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)} } =  W_2^T \frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $$\frac{\partial \mathcal{J} }{ \partial W_1 } = \frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)} }  X^T $$\frac{\partial \mathcal{J} _i }{ \partial b_1 } = \sum_i{\frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)}}}$- Note that $*$ denotes elementwise multiplication.- The notation you will use is common in deep learning coding:    - dW1 = $\frac{\partial \mathcal{J} }{ \partial W_1 }$    - db1 = $\frac{\partial \mathcal{J} }{ \partial b_1 }$    - dW2 = $\frac{\partial \mathcal{J} }{ \partial W_2 }$    - db2 = $\frac{\partial \mathcal{J} }{ \partial b_2 }$!--><ul><li>Tips:<ul><li>To compute dZ1 youll need to compute $g^{[1]}(Z^{[1]})$. Since $g^{[1]}(.)$ is the tanh activation function, if $a = g^{[1]}(z)$ then $g^{[1]}(z) = 1-a^2$. So you can compute<br>$g^{[1]}(Z^{[1]})$ using <code>(1 - np.power(A1, 2))</code>.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: backward_propagation</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation</span><span class="params">(parameters, cache, X, Y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward propagation using the instructions above.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing our parameters </span></span><br><span class="line"><span class="string">    cache -- a dictionary containing "Z1", "A1", "Z2" and "A2".</span></span><br><span class="line"><span class="string">    X -- input data of shape (2, number of examples)</span></span><br><span class="line"><span class="string">    Y -- "true" labels vector of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    grads -- python dictionary containing your gradients with respect to different parameters</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># First, retrieve W1 and W2 from the dictionary "parameters".</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Retrieve also A1 and A2 from dictionary "cache".</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">    A1 = cache[<span class="string">"A1"</span>]</span><br><span class="line">    A2 = cache[<span class="string">"A2"</span>]</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward propagation: calculate dW1, db1, dW2, db2. </span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 6 lines of code, corresponding to 6 equations on slide above)</span></span><br><span class="line">    dZ2= A2 - Y</span><br><span class="line">    dW2 = (<span class="number">1</span>/m) * np.dot(dZ2, A1.T)</span><br><span class="line">    db2 = (<span class="number">1</span>/m) * np.sum(dZ2, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    dZ1 = np.multiply(np.dot(W2.T, dZ2), (<span class="number">1</span> - np.power(A1, <span class="number">2</span>)))</span><br><span class="line">    dW1 = (<span class="number">1</span>/m) * np.dot(dZ1, X.T)</span><br><span class="line">    db1 = (<span class="number">1</span>/m) * np.sum(dZ1, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    grads = &#123;<span class="string">"dW1"</span>: dW1,</span><br><span class="line">             <span class="string">"db1"</span>: db1,</span><br><span class="line">             <span class="string">"dW2"</span>: dW2,</span><br><span class="line">             <span class="string">"db2"</span>: db2&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> grads</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">parameters, cache, X_assess, Y_assess = backward_propagation_test_case()</span><br><span class="line"></span><br><span class="line">grads = backward_propagation(parameters, cache, X_assess, Y_assess)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dW1 = "</span>+ str(grads[<span class="string">"dW1"</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"db1 = "</span>+ str(grads[<span class="string">"db1"</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dW2 = "</span>+ str(grads[<span class="string">"dW2"</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"db2 = "</span>+ str(grads[<span class="string">"db2"</span>]))</span><br></pre></td></tr></table></figure><pre><code>dW1 = [[ 0.01018708 -0.00708701] [ 0.00873447 -0.0060768 ] [-0.00530847  0.00369379] [-0.02206365  0.01535126]]db1 = [[-0.00069728] [-0.00060606] [ 0.000364  ] [ 0.00151207]]dW2 = [[ 0.00363613  0.03153604  0.01162914 -0.01318316]]db2 = [[0.06589489]]</code></pre><p><strong>Expected output</strong>:</p><table style="width:80%">  <tr>    <td>**dW1**</td>    <td> [[ 0.01018708 -0.00708701] [ 0.00873447 -0.0060768 ] [-0.00530847  0.00369379] [-0.02206365  0.01535126]] </td>   </tr>  <tr>    <td>**db1**</td>    <td>  [[-0.00069728] [-0.00060606] [ 0.000364  ] [ 0.00151207]] </td>   </tr>  <tr>    <td>**dW2**</td>    <td> [[ 0.00363613  0.03153604  0.01162914 -0.01318316]] </td>   </tr>  <tr>    <td>**db2**</td>    <td> [[ 0.06589489]] </td>   </tr></table>  <p><strong>Question</strong>: Implement the update rule. Use gradient descent. You have to use (dW1, db1, dW2, db2) in order to update (W1, b1, W2, b2).</p><p><strong>General gradient descent rule</strong>: $ \theta = \theta - \alpha \frac{\partial J }{ \partial \theta }$ where $\alpha$ is the learning rate and $\theta$ represents a parameter.</p><p><strong>Illustration</strong>: The gradient descent algorithm with a good learning rate (converging) and a bad learning rate (diverging). Images courtesy of Adam Harley.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: update_parameters</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, grads, learning_rate = <span class="number">1.2</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Updates parameters using the gradient descent update rule given above</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters </span></span><br><span class="line"><span class="string">    grads -- python dictionary containing your gradients </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your updated parameters </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># Retrieve each parameter from the dictionary "parameters"</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 4 lines of code)</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve each gradient from the dictionary "grads"</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 4 lines of code)</span></span><br><span class="line">    dW1 = grads[<span class="string">"dW1"</span>]</span><br><span class="line">    db1 = grads[<span class="string">"db1"</span>]</span><br><span class="line">    dW2 = grads[<span class="string">"dW2"</span>]</span><br><span class="line">    db2 = grads[<span class="string">"db2"</span>]</span><br><span class="line">    <span class="comment">## END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Update rule for each parameter</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 4 lines of code)</span></span><br><span class="line">    W1 = W1 - learning_rate * dW1</span><br><span class="line">    b1 = b1 - learning_rate * db1</span><br><span class="line">    W2 = W2 - learning_rate * dW2</span><br><span class="line">    b2 = b2 - learning_rate * db2</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    parameters = &#123;<span class="string">"W1"</span>: W1,</span><br><span class="line">                  <span class="string">"b1"</span>: b1,</span><br><span class="line">                  <span class="string">"W2"</span>: W2,</span><br><span class="line">                  <span class="string">"b2"</span>: b2&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">parameters, grads = update_parameters_test_case()</span><br><span class="line">parameters = update_parameters(parameters, grads)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]))</span><br><span class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]))</span><br><span class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]))</span><br><span class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]))</span><br></pre></td></tr></table></figure><pre><code>W1 = [[-0.00643025  0.01936718] [-0.02410458  0.03978052] [-0.01653973 -0.02096177] [ 0.01046864 -0.05990141]]b1 = [[-1.02420756e-06] [ 1.27373948e-05] [ 8.32996807e-07] [-3.20136836e-06]]W2 = [[-0.01041081 -0.04463285  0.01758031  0.04747113]]b2 = [[0.00010457]]</code></pre><p><strong>Expected Output</strong>:</p><table style="width:80%">  <tr>    <td>**W1**</td>    <td> [[-0.00643025  0.01936718] [-0.02410458  0.03978052] [-0.01653973 -0.02096177] [ 0.01046864 -0.05990141]]</td>   </tr>  <tr>    <td>**b1**</td>    <td> [[ -1.02420756e-06] [  1.27373948e-05] [  8.32996807e-07] [ -3.20136836e-06]]</td>   </tr>  <tr>    <td>**W2**</td>    <td> [[-0.01041081 -0.04463285  0.01758031  0.04747113]] </td>   </tr>  <tr>    <td>**b2**</td>    <td> [[ 0.00010457]] </td>   </tr></table>  <h3 id="4-4-Integrate-parts-4-1-4-2-and-4-3-in-nn-model"><a href="#4-4-Integrate-parts-4-1-4-2-and-4-3-in-nn-model" class="headerlink" title="4.4 - Integrate parts 4.1, 4.2 and 4.3 in nn_model()"></a>4.4 - Integrate parts 4.1, 4.2 and 4.3 in nn_model()</h3><p><strong>Question</strong>: Build your neural network model in <code>nn_model()</code>.</p><p><strong>Instructions</strong>: The neural network model has to use the previous functions in the right order.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: nn_model</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_model</span><span class="params">(X, Y, n_h, num_iterations = <span class="number">10000</span>, print_cost=False)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- dataset of shape (2, number of examples)</span></span><br><span class="line"><span class="string">    Y -- labels of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    n_h -- size of the hidden layer</span></span><br><span class="line"><span class="string">    num_iterations -- Number of iterations in gradient descent loop</span></span><br><span class="line"><span class="string">    print_cost -- if True, print the cost every 1000 iterations</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    np.random.seed(<span class="number">3</span>)</span><br><span class="line">    n_x = layer_sizes(X, Y)[<span class="number">0</span>]</span><br><span class="line">    n_y = layer_sizes(X, Y)[<span class="number">2</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: "n_x, n_h, n_y". Outputs = "W1, b1, W2, b2, parameters".</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 5 lines of code)</span></span><br><span class="line">    parameters = initialize_parameters(n_x, n_h, n_y)</span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop (gradient descent)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</span><br><span class="line">         </span><br><span class="line">        <span class="comment">### START CODE HERE ### ( 4 lines of code)</span></span><br><span class="line">        <span class="comment"># Forward propagation. Inputs: "X, parameters". Outputs: "A2, cache".</span></span><br><span class="line">        A2, cache = forward_propagation(X, parameters)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Cost function. Inputs: "A2, Y, parameters". Outputs: "cost".</span></span><br><span class="line">        cost = compute_cost(A2, Y, parameters)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># Backpropagation. Inputs: "parameters, cache, X, Y". Outputs: "grads".</span></span><br><span class="line">        grads = backward_propagation(parameters, cache, X, Y)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># Gradient descent parameter update. Inputs: "parameters, grads". Outputs: "parameters".</span></span><br><span class="line">        parameters = update_parameters(parameters, grads)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Print the cost every 1000 iterations</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Cost after iteration %i: %f"</span> %(i, cost))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X_assess, Y_assess = nn_model_test_case()</span><br><span class="line"></span><br><span class="line">parameters = nn_model(X_assess, Y_assess, <span class="number">4</span>, num_iterations=<span class="number">10000</span>, print_cost=<span class="literal">False</span>)</span><br><span class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]))</span><br><span class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]))</span><br><span class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]))</span><br><span class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]))</span><br></pre></td></tr></table></figure><pre><code>/Users/abanihi/opt/miniconda3/envs/pangeo/lib/python3.6/site-packages/ipykernel/__main__.py:26: RuntimeWarning: divide by zero encountered in log/Users/abanihi/devel/personal/deep-learning-specialization-coursera/01-Neural-Networks-and-Deep-Learning/week3/Programming-Assignments/planar_utils.py:34: RuntimeWarning: overflow encountered in exp  s = 1/(1+np.exp(-x))W1 = [[-4.18491249  5.33220652] [-7.52991891  1.24304481] [-4.19257906  5.32654053] [ 7.52989842 -1.24305585]]b1 = [[ 2.32930709] [ 3.79453736] [ 2.33008777] [-3.79456804]]W2 = [[-6033.83651818 -6008.12961806 -6033.10073783  6008.06596049]]b2 = [[-52.66626424]]</code></pre><p><strong>Expected Output</strong>:</p><table style="width:90%">  <tr>    <td>**W1**</td>    <td> [[-4.18494056  5.33220609] [-7.52989382  1.24306181] [-4.1929459   5.32632331] [ 7.52983719 -1.24309422]]</td>   </tr>  <tr>    <td>**b1**</td>    <td> [[ 2.32926819] [ 3.79458998] [ 2.33002577] [-3.79468846]]</td>   </tr>  <tr>    <td>**W2**</td>    <td> [[-6033.83672146 -6008.12980822 -6033.10095287  6008.06637269]] </td>   </tr>  <tr>    <td>**b2**</td>    <td> [[-52.66607724]] </td>   </tr></table>  <h3 id="4-5-Predictions"><a href="#4-5-Predictions" class="headerlink" title="4.5 Predictions"></a>4.5 Predictions</h3><p><strong>Question</strong>: Use your model to predict by building predict().<br>Use forward propagation to predict results.</p><p><strong>Reminder</strong>: predictions = $y_{prediction} = \mathbb 1 \textfalse = \begin{cases}<br>      1 &amp; \text{if}\ activation &gt; 0.5 \<br>      0 &amp; \text{otherwise}<br>    \end{cases}$  </p><p>As an example, if you would like to set the entries of a matrix X to 0 and 1 based on a threshold you would do: <code>X_new = (X &gt; threshold)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: predict</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(parameters, X)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Using the learned parameters, predicts a class for each example in X</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters </span></span><br><span class="line"><span class="string">    X -- input data of size (n_x, m)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    predictions -- vector of predictions of our model (red: 0 / blue: 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### ( 2 lines of code)</span></span><br><span class="line">    A2, cache = forward_propagation(X, parameters)</span><br><span class="line">    predictions = (A2 &gt; <span class="number">0.5</span>)  <span class="comment"># Vectorized</span></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> predictions</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">parameters, X_assess = predict_test_case()</span><br><span class="line"></span><br><span class="line">predictions = predict(parameters, X_assess)</span><br><span class="line">print(<span class="string">"predictions mean = "</span> + str(np.mean(predictions)))</span><br></pre></td></tr></table></figure><pre><code>predictions mean = 0.6666666666666666</code></pre><p><strong>Expected Output</strong>: </p><table style="width:40%">  <tr>    <td>**predictions mean**</td>    <td> 0.666666666667 </td>   </tr></table><p>It is time to run the model and see how it performs on a planar dataset. Run the following code to test your model with a single hidden layer of $n_h$ hidden units.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Build a model with a n_h-dimensional hidden layer</span></span><br><span class="line">parameters = nn_model(X, Y, n_h = <span class="number">4</span>, num_iterations = <span class="number">10000</span>, print_cost=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the decision boundary</span></span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict(parameters, x.T), X, Y)</span><br><span class="line">plt.title(<span class="string">"Decision Boundary for hidden layer size "</span> + str(<span class="number">4</span>))</span><br></pre></td></tr></table></figure><pre><code>Cost after iteration 0: 0.693048Cost after iteration 1000: 0.288083Cost after iteration 2000: 0.254385Cost after iteration 3000: 0.233864Cost after iteration 4000: 0.226792Cost after iteration 5000: 0.222644Cost after iteration 6000: 0.219731Cost after iteration 7000: 0.217504Cost after iteration 8000: 0.219456Cost after iteration 9000: 0.218558Text(0.5, 1.0, &apos;Decision Boundary for hidden layer size 4&apos;)</code></pre><p><strong>Expected Output</strong>:</p><table style="width:40%">  <tr>    <td>**Cost after iteration 9000**</td>    <td> 0.218607 </td>   </tr></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Print accuracy</span></span><br><span class="line">predictions = predict(parameters, X)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'Accuracy: %d'</span> % float((np.dot(Y,predictions.T) + np.dot(<span class="number">1</span>-Y,<span class="number">1</span>-predictions.T))/float(Y.size)*<span class="number">100</span>) + <span class="string">'%'</span>)</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 90%</code></pre><p><strong>Expected Output</strong>: </p><table style="width:15%">  <tr>    <td>**Accuracy**</td>    <td> 90% </td>   </tr></table><p>Accuracy is really high compared to Logistic Regression. The model has learnt the leaf patterns of the flower! Neural networks are able to learn even highly non-linear decision boundaries, unlike logistic regression. </p><p>Now, lets try out several hidden layer sizes.</p><h3 id="4-6-Tuning-hidden-layer-size-optional-ungraded-exercise"><a href="#4-6-Tuning-hidden-layer-size-optional-ungraded-exercise" class="headerlink" title="4.6 - Tuning hidden layer size (optional/ungraded exercise)"></a>4.6 - Tuning hidden layer size (optional/ungraded exercise)</h3><p>Run the following code. It may take 1-2 minutes. You will observe different behaviors of the model for various hidden layer sizes.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This may take about 2 minutes to run</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">32</span>))</span><br><span class="line">hidden_layer_sizes = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">20</span>, <span class="number">50</span>]</span><br><span class="line"><span class="keyword">for</span> i, n_h <span class="keyword">in</span> enumerate(hidden_layer_sizes):</span><br><span class="line">    plt.subplot(<span class="number">5</span>, <span class="number">2</span>, i+<span class="number">1</span>)</span><br><span class="line">    plt.title(<span class="string">'Hidden Layer of size %d'</span> % n_h)</span><br><span class="line">    parameters = nn_model(X, Y, n_h, num_iterations = <span class="number">5000</span>)</span><br><span class="line">    plot_decision_boundary(<span class="keyword">lambda</span> x: predict(parameters, x.T), X, Y)</span><br><span class="line">    predictions = predict(parameters, X)</span><br><span class="line">    accuracy = float((np.dot(Y,predictions.T) + np.dot(<span class="number">1</span>-Y,<span class="number">1</span>-predictions.T))/float(Y.size)*<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Accuracy for &#123;&#125; hidden units: &#123;&#125; %"</span>.format(n_h, accuracy))</span><br></pre></td></tr></table></figure><pre><code>Accuracy for 1 hidden units: 67.5 %Accuracy for 2 hidden units: 67.25 %Accuracy for 3 hidden units: 90.75 %Accuracy for 4 hidden units: 90.5 %Accuracy for 5 hidden units: 91.25 %Accuracy for 20 hidden units: 90.5 %Accuracy for 50 hidden units: 90.75 %</code></pre><p><strong>Interpretation</strong>:</p><ul><li>The larger models (with more hidden units) are able to fit the training set better, until eventually the largest models overfit the data. </li><li>The best hidden layer size seems to be around n_h = 5. Indeed, a value around here seems to  fits the data well without also incurring noticable overfitting.</li><li>You will also learn later about regularization, which lets you use very large models (such as n_h = 50) without much overfitting. </li></ul><p><strong>Optional questions</strong>:</p><p><strong>Note</strong>: Remember to submit the assignment but clicking the blue Submit Assignment button at the upper-right. </p><p>Some optional/ungraded questions that you can explore if you wish: </p><ul><li>What happens when you change the tanh activation for a sigmoid activation or a ReLU activation?</li><li>Play with the learning_rate. What happens?</li><li>What if we change the dataset? (See part 5 below!)</li></ul><font color='blue'>**You've learnt to:**- Build a complete neural network with a hidden layer- Make a good use of a non-linear unit- Implemented forward propagation and backpropagation, and trained a neural network- See the impact of varying the hidden layer size, including overfitting.</font>Nice work! <h2 id="5-Performance-on-other-datasets"><a href="#5-Performance-on-other-datasets" class="headerlink" title="5) Performance on other datasets"></a>5) Performance on other datasets</h2><p>If you want, you can rerun the whole notebook (minus the dataset part) for each of the following datasets.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Datasets</span></span><br><span class="line">noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure = load_extra_datasets()</span><br><span class="line"></span><br><span class="line">datasets = &#123;<span class="string">"noisy_circles"</span>: noisy_circles,</span><br><span class="line">            <span class="string">"noisy_moons"</span>: noisy_moons,</span><br><span class="line">            <span class="string">"blobs"</span>: blobs,</span><br><span class="line">            <span class="string">"gaussian_quantiles"</span>: gaussian_quantiles&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">### START CODE HERE ### (choose your dataset)</span></span><br><span class="line">dataset = <span class="string">"noisy_moons"</span></span><br><span class="line"><span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">X, Y = datasets[dataset]</span><br><span class="line">X, Y = X.T, Y.reshape(<span class="number">1</span>, Y.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># make blobs binary</span></span><br><span class="line"><span class="keyword">if</span> dataset == <span class="string">"blobs"</span>:</span><br><span class="line">    Y = Y%<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize the data</span></span><br><span class="line">plt.scatter(X[<span class="number">0</span>, :], X[<span class="number">1</span>, :], c=Y.ravel(), s=<span class="number">40</span>, cmap=plt.cm.Spectral);</span><br></pre></td></tr></table></figure><p>Congrats on finishing this Programming Assignment!</p><p>Reference:</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly9zY3MucnllcnNvbi5jYS9+YWhhcmxleS9uZXVyYWwtbmV0d29ya3Mv">https://scs.ryerson.ca/~aharley/neural-networks/<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9jczIzMW4uZ2l0aHViLmlvL25ldXJhbC1uZXR3b3Jrcy1jYXNlLXN0dWR5Lw==">https://cs231n.github.io/neural-networks-case-study/<i class="fa fa-external-link-alt"></i></span></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%load_ext version_information</span><br><span class="line">%version_information numpy, matplotlib, sklearn</span><br></pre></td></tr></table></figure><table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.6 64bit [GCC 4.2.1 Compatible Apple LLVM 6.1.0 (clang-602.0.53)]</td></tr><tr><td>IPython</td><td>7.0.1</td></tr><tr><td>OS</td><td>Darwin 17.7.0 x86_64 i386 64bit</td></tr><tr><td>numpy</td><td>1.15.1</td></tr><tr><td>matplotlib</td><td>3.0.0</td></tr><tr><td>sklearn</td><td>0.20.0</td></tr><tr><td colspan='2'>Sun Oct 14 20:51:09 2018 MDT</td></tr></table><h5>Credits - <a href='https://www.coursera.org/' target=_blank >Coursera</a>,  <a href = 'https://en.wikipedia.org/wiki/Andrew_Ng' title="Andrew_Ng" target=_blank>Credits to the teacher</a> , <a href ='https://www.coursera.org/specializations/deep-learning?' target=_blank>Deeplearning.ai Course</a><h5>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;i&gt;&lt;b&gt;Note - These are my notes on DeepLearning Specialization Part:&lt;br&gt;Planar data classification with one hidden layer || (Course- 1 Week - 3) || Neural Networks and Deep Learning (Week 3)&lt;/i&gt;&lt;/b&gt;
    
    </summary>
    
    
      <category term="Assignment" scheme="https://massivefile.com/categories/Assignment/"/>
    
    
      <category term="2020" scheme="https://massivefile.com/tags/2020/"/>
    
      <category term="Assignment" scheme="https://massivefile.com/tags/Assignment/"/>
    
      <category term="Planar data classification with one hidden layer" scheme="https://massivefile.com/tags/Planar-data-classification-with-one-hidden-layer/"/>
    
  </entry>
  
</feed>
