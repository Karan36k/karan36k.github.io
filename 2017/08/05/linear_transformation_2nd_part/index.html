<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">

<script>
    (function(){
        if(''){
                         If (prompt('Please enter the article password') !== ''){
                                 Alert('Password error!');
                history.back();
            }
        }
    })();
</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"snakecoding.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":"flat","style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":false},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Notes from: Tsinghua University Open Class: Linear Algebra 2-Lecture 5: Linear Transformation 2 ForewordFor a given linear transformation, choose an appropriate basis to make its matrix representation">
<meta property="og:type" content="article">
<meta property="og:title" content="Tsinghua linear-algebra-2 5th-lecture linear-transformation-2nd-part">
<meta property="og:url" content="https://snakecoding.com/2017/08/05/linear_transformation_2nd_part/index.html">
<meta property="og:site_name" content="Machine Learning">
<meta property="og:description" content="Notes from: Tsinghua University Open Class: Linear Algebra 2-Lecture 5: Linear Transformation 2 ForewordFor a given linear transformation, choose an appropriate basis to make its matrix representation">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2017-08-05T14:46:00.000Z">
<meta property="article:modified_time" content="2020-04-09T11:04:43.784Z">
<meta property="article:author" content="Karan">
<meta property="article:tag" content="linear_algebra">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://snakecoding.com/2017/08/05/linear_transformation_2nd_part/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Tsinghua linear-algebra-2 5th-lecture linear-transformation-2nd-part | Machine Learning</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Machine Learning" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Machine Learning</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Data Science</p>
      <a>
        <img class="custom-logo-image" src="/images/custom-logo.jpg" alt="Machine Learning">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">15</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">6</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">87</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="#" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/05/linear_transformation_2nd_part/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Tsinghua linear-algebra-2 5th-lecture linear-transformation-2nd-part
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-05 20:16:00" itemprop="dateCreated datePublished" datetime="2017-08-05T20:16:00+05:30">2017-08-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:43" itemprop="dateModified" datetime="2020-04-09T16:34:43+05:30">2020-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning-Maths/" itemprop="url" rel="index"><span itemprop="name">Machine Learning Maths</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>9.3k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>8 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Notes from: Tsinghua University Open Class: Linear Algebra 2-Lecture 5: Linear Transformation 2</p>
<h2 id="Foreword"><a href="#Foreword" class="headerlink" title="Foreword"></a>Foreword</h2><p>For a given linear transformation, choose an appropriate basis to make its matrix representation as simple as possible, we introduce the matrix representation of linear transformation<br>For the linear transformation $ \ sigma $ from the $ n $ -dimensional vector space $ V $ to the $ m $ -dimensional vector space $ W $, we take a set of bases from $ V $ $ v_1 $ to $ v_n $ A set of bases W from $ w_1 $ to $ w_m $, then the linear transformation $ σ $ acting on $ v_1 $ to $ v_n $ can be linearly represented by $ w_1, …, w_m $, and the coefficients we express are represented by a The matrix $ A $ of n $ is described, so the linear transformation $ σ $ corresponds to the matrix $ A $ of $ m × n $. The matrix representation of the linear transformation depends on the choice of our basis. Generally speaking, if the basis is changed, it will have a different matrix representation for the same linear transformation. Then we hope to find the properties of the linear transformation that are independent of the basis selection. When we use the matrix to study these properties of the linear transformation, we can use the matrix representation as simple as possible under the base.</p>
<h2 id="Identity-transformation-and-basis-transformation"><a href="#Identity-transformation-and-basis-transformation" class="headerlink" title="Identity transformation and basis transformation"></a>Identity transformation and basis transformation</h2><p>The identity transformation is invariant, so the invariant linear transformation corresponds to the identity matrix.</p>
<p>! [identical_linear_transformation] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/1.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/1.png</a>) </p>
<blockquote>
<p>the 9th property of determinant: the determinant of $ AB $ is det $ A $ times det $ B $: $ | AB | = | A || B | $ </p>
</blockquote>
<p>Therefore: because $ (\ sigma_1 , …. , \ sigma_n) $ and $ (\ beta_1 , … , \ beta_n) $ are both base vectors, so they are both full rank and $ n $ dimension, so reversible, then introduce $ P $ reversible. Otherwise $ | \ alpha_1 , … , \ alpha_n | \ ne | \ beta_1 , … , \ beta_n || P | $<br>! [example_identical_linear_transformation] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/2.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/2.png</a>)  </p>
<h2 id="Application-of-base-transformation"><a href="#Application-of-base-transformation" class="headerlink" title="Application of base transformation"></a>Application of base transformation</h2><h3 id="A-256x256-grayscale-image"><a href="#A-256x256-grayscale-image" class="headerlink" title="A 256x256 grayscale image"></a>A 256x256 grayscale image</h3><p>! [256x256_application_of_change_of_basis] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/3.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/3.png</a>) </p>
<p>** Note: $ C ^ N $ is the base of the complex number of $ n $ dimension elements **</p>
<h3 id="Three-of-the-bases-of-the-image"><a href="#Three-of-the-bases-of-the-image" class="headerlink" title="Three of the bases of the image"></a>Three of the bases of the image</h3><p>! [img_basis] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/4.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/4.png</a>) </p>
<p>The wavelet base is good for its inverse, and the Fourier base is good for its inverse. If it is a solid color image of $ 4 \ times4 $, the first components of wavelet base or Fourier base $ w_1 $ and $ \ xi_1 $ are used as the base, which is expressed as $ c_1w_1 = W \ begin {pmatrix} c_1 \ 0 \ 0 \ 0 \ end {pmatrix} $ and $ c_1 \ xi_1 = \ xi \ begin {pmatrix} c_1 \ 0 \ 0 \ 0 \ end {pmatrix} $. For images with more drastic transformations between pixels, you can use $ c (w_3 + w_4) $ in wavelet basis and $ c \ xi_3 $ in Fourier basis.</p>
<h3 id="jpeg"><a href="#jpeg" class="headerlink" title="jpeg"></a>jpeg</h3><p>! [jpeg_process] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/5.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/5.png</a>) </p>
<p>The image itself is represented by the coefficient matrix $ c $, so the so-called compressed and transmitted image is also compressed and transmitted this matrix $ c $. What compression does is use as little information (data) as possible to represent the original information (data). This process will lose some unimportant information (data). Corresponding to the non-zero element comparison of $ c $ on the matrix Less (this requires that a smaller number of basis vectors can be used to approximate the original matrix, the less the better). Because $ c = W ^ {-1} x $, it is also important to be able to quickly calculate the inverse of the base, and wavelet bases and Fourier bases fit this feature.</p>
<h2 id="Linear-transformation-of-matrix-under-different-bases"><a href="#Linear-transformation-of-matrix-under-different-bases" class="headerlink" title="Linear transformation of matrix under different bases"></a>Linear transformation of matrix under different bases</h2><p>! [the_same_linear_transform_of_different_bases] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/6.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/6.png</a>)  </p>
<p>** Theorem: The linear transformation of the $ n $ vector space $ V $$ \ sigma $ under different bases of $ V $ is a similar matrix. **</p>
<p>! [the_same_linear_transform_of_different_bases_at_different_aspects] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/7.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/7.png</a>) </p>
<p>From the above picture:<br>$ I_1 $ and $ I_2 $ are identity transformations<br>$ (\ beta_1 , … , \ beta_n) = I_1 (\ beta_1 , … , \ beta_n) = (\ alpha_1 , … , \ alpha_n) P $<br>$ (\ alpha_1 , … , \ alpha_n) = I_2 (\ alpha_1 , … , \ alpha_n) = (\ beta_1 , … , \ beta_n) P ^ {-1} $<br>Linear transformation compound angle: $ \ sigma = I_2 , \ sigma , I_1 , \ rightarrow , B = P ^ {-1} AP $</p>
<h2 id="The-invariance-of-the-same-linear-transformation-under-different-basis"><a href="#The-invariance-of-the-same-linear-transformation-under-different-basis" class="headerlink" title="The invariance of the same linear transformation under different basis"></a>The invariance of the same linear transformation under different basis</h2><p>When we use the matrix to study the linear transformation, we hope to study the properties of the linear transformation independent of the basis selection. From the above discussion, we know that the linear transformation of this vector space $ V $ to itself under different bases is similar to each other. Therefore, the so-called unrelated property is the invariant property under similar transformation, so it is very important to study similar invariants naturally in linear algebra. We know that for a matrix, the characteristic polynomials, eigenvalues, traces, determinants, the rank of the matrix, etc. are all similar invariants of the matrix. In this way, we call an n-dimensional vector space $ V $ linearly transformed in $ V $ The matrix $ A $ under a set of bases, the characteristic polynomial, eigenvalue, trace determinant of the matrix representing $ A $ is called the linear transformation of the characteristic polynomial, eigenvalue, trace, determinant.<br>! [properties_of_the_same_linear_transformation_of_different_bases] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/8.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/8.png</a>)</p>
<h2 id="Matrix-factorization-and-basis-transformation"><a href="#Matrix-factorization-and-basis-transformation" class="headerlink" title="Matrix factorization and basis transformation"></a>Matrix factorization and basis transformation</h2><p>Given a linear transformation $ σ $ from $ R ^ n $ to $ R ^ m $, its standard basis in $ R ^ n $ $ e_1 $ to $ e_n $ and the standard basis of $ R ^ m $ $ ẽ_1 , …, ẽ_m $ the matrix is ​​$ A $,<br>$ σ $ acting on $ e_1… e_n $ is equal to $ \ tilde {e} _1, …, \ tilde {e} _m $ multiplied by the matrix $ A $, which means that $ σ $ acts on $ e_j $ , Which is equal to the jth column of $ A $, which is $ A $ multiplied by $ e_j $, so this linear transformation can be expressed as any pair of $ n $ -dimensional vector $ v $, then $ σ $ acts on $ v $ is the matrix $ A $ multiplied by $ V $:<br>$$ \ sigma (e_1 , … , e_n) = (\ tilde {e} _1 , … , \ tilde {e} _m) A \ rightarrow \ sigma (e_j) = Ae_j $$</p>
<p>! [input_space_form_of_linear_transformation] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/9.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/9.png</a>)</p>
<p>Then do the base transformation, the first changes the input base, the second changes the output base, and the third input and output base changes.</p>
<p>! [matrix_decomposition_and_basis_transformation] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/10.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/10.png</a>)</p>
<h3 id="Diagonalizing-the-matrix-as-a-linear-transformation"><a href="#Diagonalizing-the-matrix-as-a-linear-transformation" class="headerlink" title="Diagonalizing the matrix as a linear transformation"></a>Diagonalizing the matrix as a linear transformation</h3><p>! [vector_basis_of_linear_transformation] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/11.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/11.png</a>)</p>
<p>From the above, we can get $ \ sigma (x_1 , … , x_n) = (x_1 , … , x_n) \ Lambda = S \ Lambda $, $ x $ is the eigenvector basis, and the other base transformation {id} _1 (S) = S = \ {e } S $<br>The linear transformation of $ σ $ is under the new basis of the eigenvector of A, and its matrix representation is the diagonal matrix of $ \ Lambda $. The matrix of $ σ $ from $ R ^ n $ to $ R ^ n $ under the standard basis is $ A $, and the matrix of $ σ $ under the eigenvector basis is the diagonal matrix $ \ Lambda $. Then input the group of bases of $ x $ and output the group of bases of $ e $, the identity transformation, its matrix representation is $ S $. If you input the base group $ e $ and output the identity transformation of the base group $ x $, its matrix representation is $ S ^ {-1} $.</p>
<h3 id="Singular-value-decomposition-as-a-linear-transformation"><a href="#Singular-value-decomposition-as-a-linear-transformation" class="headerlink" title="Singular value decomposition as a linear transformation"></a>Singular value decomposition as a linear transformation</h3><p>! [SVD_decomposition_as_linear_transformation] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/12.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/12.png</a>)</p>
<h2 id="Linear-transformation-kernel-and-image"><a href="#Linear-transformation-kernel-and-image" class="headerlink" title="Linear transformation kernel and image"></a>Linear transformation kernel and image</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>! [definition_kernel_and_image] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/13.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/13.png</a>)</p>
<h3 id="Zero-degree-and-rank-of-linear-transformation"><a href="#Zero-degree-and-rank-of-linear-transformation" class="headerlink" title="Zero degree and rank of linear transformation"></a>Zero degree and rank of linear transformation</h3><p>! [nullity_and_rank_of_linear_transformation] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/14.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/14.png</a>)</p>
<h4 id="Proof-of-rank-of-linear-transformation"><a href="#Proof-of-rank-of-linear-transformation" class="headerlink" title="Proof of rank of linear transformation"></a>Proof of rank of linear transformation</h4><p>! [proof_nullity_and_rank_of_linear_transformation] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/15.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/15.png</a>)</p>
<p>Note: $ L (\ sigma (v_1), , … \ ,, \ sigma (v_n)) $ symbol meaning: by $ \ sigma (v_1), , … \ ,, \ sigma (v_n) $ Linear Zhang Cheng.</p>
<h4 id="Dimensional-formula-of-linear-transformation"><a href="#Dimensional-formula-of-linear-transformation" class="headerlink" title="Dimensional formula of linear transformation"></a>Dimensional formula of linear transformation</h4><p>! [dim (kernel) + dim (image) = dimV.png] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/16.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/16.png</a>)<br>! [kernel + image! = V.png] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/17.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/17.png</a>) </p>
<h4 id="Single-shot-full-shot-reversible"><a href="#Single-shot-full-shot-reversible" class="headerlink" title="Single shot full shot reversible"></a>Single shot full shot reversible</h4><p>** Single shot double shot full shot learned in middle school **</p>
<p>! [injective_surjective_bijective] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/18.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/18.png</a>)</p>
<p>** Injective, surjective and inverse under linear transformation **</p>
<p>! [injective_surjective_inverse_of_linear_transformation_are_equivalent] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/19.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/19.png</a>)</p>
<p>The first equivalent symbol proof (counter-proof method): If the single shot cannot launch the kernel only $ \ {0 } $, then assume $ \ exists , \ alpha (\ ne0) \ in {ker , \ sigma} $ then $ \ sigma (\ alpha) = 0 $, and because $ \ sigma (0) = 0 $, that is, $ \ sigma (\ alpha , or , 0) = 0 $ contradicts injective. Conversely, if $ \ sigma (v_1) = 0, \ sigma (v_2) = 0 $, according to the definition or nature of the linear transformation: $ \ sigma (v_1-v_2) = 0 \ rightarrow v_1-v_2 \ in ker , \ sigma = \ {0 } \ rightarrow v_1 = v_2 \ rightarrow \ sigma $ is a single shot. Therefore: $ \ sigma $ is a single shot $ \ Leftarrow \ Rightarrow ker , \ sigma = \ {0 } $</p>
<p><strong>example:</strong></p>
<p>! [example_of_injective_surjective_inverse_of_linear_transformation_are_equivalent] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/20.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/20.png</a>)</p>
<h2 id="invariant-subspace"><a href="#invariant-subspace" class="headerlink" title="invariant subspace"></a>invariant subspace</h2><h3 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h3><p>! [definition_of_invariant_subspace] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/21.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/21.png</a>)</p>
<h3 id="The-meaning-of-invariant-subspace"><a href="#The-meaning-of-invariant-subspace" class="headerlink" title="The meaning of invariant subspace"></a>The meaning of invariant subspace</h3><p>! [candy_of_invariant_subspace] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/22.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-5/22.png</a>)</p>
<p>From here, we can see that we want to decompose the large space into the direct sum of invariant subspaces, so that we can take out the appropriate base, so that the linear transformation<br>The matrix representation under this set of bases can become the shape of a diagonal block, then the study of linear transformation is transformed into the study that it is limited to an invariant subspace<br>On this basis, look at the structure of the nilpotent transformation.</p>

    </div>

    
    
    
        <div class="reward-container">
  <div>No one has ever become poor by giving.</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      <div style="display: inline-block;">
        <img src="/images/googlePay.png" alt="Karan Google Pay">
        <p>Google Pay</p>
      </div>
      <div style="display: inline-block;">
        <img src="/images/AmazonPay.png" alt="Karan Amazon Pay">
        <p>Amazon Pay</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/linear-algebra/" rel="tag"><i class="fa fa-tag"></i> linear_algebra</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2017/08/04/linear_transformation_1st_part/" rel="prev" title="Tsinghua linear-algebra-2 4th-lecture linear-transformation-1st-part">
      <i class="fa fa-chevron-left"></i> Tsinghua linear-algebra-2 4th-lecture linear-transformation-1st-part
    </a></div>
      <div class="post-nav-item">
    <a href="/2017/08/06/pseudo_inverse/" rel="next" title="Tsinghua linear-algebra-2 6th-lecture pseudo-inverse">
      Tsinghua linear-algebra-2 6th-lecture pseudo-inverse <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Foreword"><span class="nav-number">1.</span> <span class="nav-text">Foreword</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Identity-transformation-and-basis-transformation"><span class="nav-number">2.</span> <span class="nav-text">Identity transformation and basis transformation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Application-of-base-transformation"><span class="nav-number">3.</span> <span class="nav-text">Application of base transformation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#A-256x256-grayscale-image"><span class="nav-number">3.1.</span> <span class="nav-text">A 256x256 grayscale image</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Three-of-the-bases-of-the-image"><span class="nav-number">3.2.</span> <span class="nav-text">Three of the bases of the image</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#jpeg"><span class="nav-number">3.3.</span> <span class="nav-text">jpeg</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Linear-transformation-of-matrix-under-different-bases"><span class="nav-number">4.</span> <span class="nav-text">Linear transformation of matrix under different bases</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#The-invariance-of-the-same-linear-transformation-under-different-basis"><span class="nav-number">5.</span> <span class="nav-text">The invariance of the same linear transformation under different basis</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Matrix-factorization-and-basis-transformation"><span class="nav-number">6.</span> <span class="nav-text">Matrix factorization and basis transformation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Diagonalizing-the-matrix-as-a-linear-transformation"><span class="nav-number">6.1.</span> <span class="nav-text">Diagonalizing the matrix as a linear transformation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Singular-value-decomposition-as-a-linear-transformation"><span class="nav-number">6.2.</span> <span class="nav-text">Singular value decomposition as a linear transformation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Linear-transformation-kernel-and-image"><span class="nav-number">7.</span> <span class="nav-text">Linear transformation kernel and image</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Definition"><span class="nav-number">7.1.</span> <span class="nav-text">Definition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Zero-degree-and-rank-of-linear-transformation"><span class="nav-number">7.2.</span> <span class="nav-text">Zero degree and rank of linear transformation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Proof-of-rank-of-linear-transformation"><span class="nav-number">7.2.1.</span> <span class="nav-text">Proof of rank of linear transformation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dimensional-formula-of-linear-transformation"><span class="nav-number">7.2.2.</span> <span class="nav-text">Dimensional formula of linear transformation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Single-shot-full-shot-reversible"><span class="nav-number">7.2.3.</span> <span class="nav-text">Single shot full shot reversible</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#invariant-subspace"><span class="nav-number">8.</span> <span class="nav-text">invariant subspace</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Definition-1"><span class="nav-number">8.1.</span> <span class="nav-text">Definition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-meaning-of-invariant-subspace"><span class="nav-number">8.2.</span> <span class="nav-text">The meaning of invariant subspace</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Karan"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Karan</p>
  <div class="site-description" itemprop="description">Refuse to Fall</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">87</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:snakecoding.py@gmail.com" title="Get In Touch → mailto:snakecoding.py@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>Get In Touch</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Karan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">2.4m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">35:43</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '94c94e82b4a09d1d039a',
      clientSecret: 'd5e33f2eef896ccdbb8ea4051d59e215038ff302',
      repo        : 'karan36k.github.io',
      owner       : 'karan36k',
      admin       : ['karan36k'],
      id          : '60b31da70f22a8ca5f894f3691ed05c6',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>
</body>
</html>
