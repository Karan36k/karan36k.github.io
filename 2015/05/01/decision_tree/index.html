<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">

<script>
    (function(){
        if(''){
                         If (prompt('Please enter the article password') !== ''){
                                 Alert('Password error!');
                history.back();
            }
        }
    })();
</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"snakecoding.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":"flat","style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":false},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Decision tree learningDecision tree learning usually includes three aspects: feature selection, decision tree generation and decision tree pruning. The decision tree learning ideas mainly come from: I">
<meta property="og:type" content="article">
<meta property="og:title" content="Decision tree learning">
<meta property="og:url" content="https://snakecoding.com/2015/05/01/decision_tree/index.html">
<meta property="og:site_name" content="Machine Learning">
<meta property="og:description" content="Decision tree learningDecision tree learning usually includes three aspects: feature selection, decision tree generation and decision tree pruning. The decision tree learning ideas mainly come from: I">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2015-05-01T14:46:00.000Z">
<meta property="article:modified_time" content="2020-04-09T10:58:51.514Z">
<meta property="article:author" content="Karan">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://snakecoding.com/2015/05/01/decision_tree/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Decision tree learning | Machine Learning</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Machine Learning" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Machine Learning</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Data Science</p>
      <a>
        <img class="custom-logo-image" src="/images/custom-logo.jpg" alt="Machine Learning">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">15</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">6</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">87</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="#" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2015/05/01/decision_tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Decision tree learning
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2015-05-01 20:16:00" itemprop="dateCreated datePublished" datetime="2015-05-01T20:16:00+05:30">2015-05-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:28:51" itemprop="dateModified" datetime="2020-04-09T16:28:51+05:30">2020-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>8.4k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>8 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Decision-tree-learning"><a href="#Decision-tree-learning" class="headerlink" title="Decision tree learning"></a>Decision tree learning</h2><p>Decision tree learning usually includes three aspects: feature selection, decision tree generation and decision tree pruning. The decision tree learning ideas mainly come from: ID algorithm proposed by Quinlan in 1986, C4.5 algorithm proposed in 1993 and CART algorithm proposed by Breiman and others in 1984.</p>
<h2 id="Feature-selection"><a href="#Feature-selection" class="headerlink" title="Feature selection"></a>Feature selection</h2><p>In order to explain the various mathematical concepts, introduce examples</p>
<p>Table 5.1 Sample data table for loan application (from [Li Hang “Statistical Method”] (<a href="https://book.douban.com/subject/10590856/" target="_blank" rel="noopener">https://book.douban.com/subject/10590856/</a>))</p>
<p>! [img] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/1.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/1.png</a>)</p>
<p>The above table has loan sample training data D consisting of 15 sample data. The data includes 4 characteristics of loan applicants: age, whether they have a job, whether they have a house or not, and credit status. The last column of the category means: whether to agree to grant the loan. This is the final conclusion of the decision tree, that is The target attribute-whether to issue loans, that is, the leaf node at the end of the decision tree is only divided into 2 categories: loan approval and loan approval.</p>
<h3 id="Information-entropy-entropy"><a href="#Information-entropy-entropy" class="headerlink" title="Information entropy (entropy)"></a>Information entropy (entropy)</h3><p>Introduce concepts, for the first concept to be used: information entropy in another blog-[data compression and information entropy] (<a href="http://2.mybrtzl.sinaapp.com/%e8%bd%ac%" target="_blank" rel="noopener">http://2.mybrtzl.sinaapp.com/%e8%bd%ac%</a> e6% 95% b0% e6% 8d% ae% e5% 8e% 8b% e7% bc% a9% e4% b8% 8e% e4% bf% a1% e6% 81% af% e7% 86% b5 /) It explains in detail why information entropy measures uncertainty, and it will not be described in detail below, but directly quoted.</p>
<p>Let D be the division of training data (ie sample data) according to the target category (or target attribute), then the information entropy of D is expressed as:<br>$$ info (D) =-\ sum \ limits_ {i = 1} ^ {m} p_ilog_2 (p_i) $$</p>
<p>Where pi represents the probability of the i-th category appearing in the entire training data, and the number of elements belonging to this category can be divided by the total number of training data (ie, sample data) as an estimate.</p>
<p>Analyze specific issues</p>
<p>In the above table, the target category: whether to issue loans, will be classified into one category, and the remaining six will not be classified into one category. The information entropy for such classification is:</p>
<p>$$ H (D) =-\ frac {9} {15} log_2 \ frac {9} {15}-\ frac {6} {15} log_2 \ frac {6} {15} = 0.971 $$</p>
<p>Note: This information entropy, which is classified according to the target category, is already known when the sample is given. According to probability statistics, it is also called empirical entropy.</p>
<p>Now we assume that the training data D is divided according to the attribute A, then the v subsets (that is, the v branches in the tree) that are split according to the A attribute, these subsets are divided according to the target category (two types of release and no release) Expectation of the entropy corresponding to the classification (ie: the average value of the information entropy of different subsets divided by attribute A):</p>
<p>$$ info_A (D) = \ sum \ limits_ {j = 1} ^ {v} \ frac {| D_j |} {| D |} info (D_j) $$</p>
<p>Note: This is actually the empirical conditional entropy, because the confirmation is the expectation of the entropy that is classified according to the target category under the premise that the A attribute is divided into subsets. See below for information gain calculation.</p>
<h3 id="Information-gain"><a href="#Information-gain" class="headerlink" title="Information gain"></a>Information gain</h3><p>Is the difference between the above two:</p>
<p>$$ gain (A) = info (D) -info_A (D) $$</p>
<p>Analyze specific issues</p>
<p>-According to the age attribute (denoted as A1): youth (D1), middle age (D2), old age (D3)</p>
<p>$$ \ begin {align} g (D, A_1) &amp; = H (D)-[\ frac {5} {15} H (D_1) + \ frac {5} {15} H (D_2) + \ frac { 5} {15} H (D_3)] \ &amp; = 0.971-[\ frac {5} {15} (-\ frac {2} {5} log_2 \ frac {2} {5}-\ frac {3} {5} log_2 \ frac {3} {5}) + \ frac {5} {15} (-\ frac {3} {5} log_2 \ frac {3} {5}-\ frac {2} {5} log_2 \ frac {2} {5}) + \ frac {5} {15} (-\ frac {4} {5} log_2 \ frac {4} {5}-\ frac {1} {5} log_2 \ frac {1} {5})] \ &amp; = 0.971-0.888 \ &amp; = 0.083 \ end {align} $$</p>
<p>-Divided according to whether there is work (marked as A2): there is work (D1), no work (D2)</p>
<p>$$ \ begin {align} g (D, A_2) &amp; = H (D)-[\ frac {5} {15} H (D_1) + \ frac {5} {15} H (D_2)] \ &amp; = 0.971-[\ frac {5} {15} \ times 0+ \ frac {10} {15} (-\ frac {4} {10} log_2 \ frac {4} {10}-\ frac {6} { 10} log_2 \ frac {6} {10})] \ &amp; = 0.324 \ end {align} $$</p>
<p>-According to whether you have your own house (marked as A3): have your own house (D1), no own house (D2)</p>
<p>$$ \ begin {align} g (D, A_3) &amp; = 0.971-[\ frac {6} {15} \ times 0+ \ frac {9} {15} (-\ frac {3} {9} log_2 \ frac {3} {9}-\ frac {6} {9} log_2 \ frac {6} {9})] \ &amp; = 0.971-0.551 \ &amp; = 0.420 \ end {align} $$</p>
<p>-In the same way, according to the last attribute: credit situation, calculate its information gain:</p>
<p>$$ g (D, A_4) = 0.971-0.608 = 0.363 $$</p>
<p>So it can be seen that the information gain metric is: the reduction of information entropy, which is obtained by dividing the original data through a certain attribute. The reduction in information entropy, that is, the increase in certainty, furthermore, the number of categories is decreasing, then the possibility of determining which category is increased, so that it is easier to classify. ID3 algorithm is based on information gain to measure the ability to divide data based on attributes (ie features), and then provide principles for feature (ie attributes) selection.</p>
<p>-### gain ratio</p>
<p>The information gain selection method has a big flaw. It always tends to choose attributes with many attribute values. If we add a name attribute to the above data record, assuming that each person in the 15 records has a different name, then the information Gain will choose the name as the best attribute, because after splitting by name, each group contains only one record, and each record belongs to only one category (either issued or not issued), so the uncertainty is the lowest, that is, the highest purity, (Note: Why is it the highest? You can calculate it based on the derivative. The maximum value is not repeated here.) There are 15 branches under the name as the test split node. But such a classification is meaningless, it does not have any generalization ability. The gain ratio improves on this, it introduces a split message:</p>
<p>$$ SplitInfo_R (D) =-\ sum \ limits_ {j = 1} ^ {k} \ frac {| D_j |} {D} \ times log_2 (\ frac {| D_j |} {D}) $$</p>
<p>Note: Split information is the information entropy divided according to a certain attribute, and the entropy described earlier in this article is all the information entropy classified according to the target attribute.</p>
<p>　　The gain ratio is defined as the ratio of information gain to split information:</p>
<p>　$$ GainRatio (R) = \ frac {Gain (R)} {SplitInfo_R (D)} $$</p>
<p>We find the largest attribute of GainRatio as the best split attribute. If there are many values ​​for an attribute, then SplitInfoR (D) will be large, thus making GainRatio (R) smaller. However, the gain ratio also has shortcomings. SplitInfo (D) may take 0, which does not make sense at this time; and when SplitInfo (D) tends to 0, the value of GainRatio (R) becomes unreliable. The improvement measure is to add one to the denominator Smooth, add an average of all split information here:</p>
<p>$$ GainRatio (R) = \ frac {Gain (R)} {\ overline {SplitInfo (D)} + SplitInfo_R (D)} $$</p>
<p>C4.5 algorithm is to calculate the classification ability of each attribute according to the information gain ratio, and then provide principles for the selection of features (ie attributes).</p>
<p>-### Gini coefficient</p>
<p>Definition (Gini index): In the classification problem, assuming that there are K classes, the probability that the sample point belongs to the Kth class is p (k), then the Gini index of the probability distribution is defined as</p>
<p>$$ [Gini (p) = \ sum \ limits_ {k = 1} ^ {K} p_k (1-p_k) = 1- \ sum \ limits_ {k = 1} ^ {K} p_k ^ 2] $$</p>
<p>For the 2 classification problem, if the probability that the sample belongs to the first category is p, then the Gini index of the probability distribution is:</p>
<p>$$ Gini (p) = 2p (1-p) $$</p>
<p>The Gini index for a given sample set D is:</p>
<p>$$ Gini (D) = 1- \ sum \ limits_ {k = 1} ^ {K} \ left (\ frac {| C_k |} {| D |} \ right) ^ 2 $$</p>
<p>Here, C (k) is the subset of samples belonging to the kth class in D, and K is the number of classes.</p>
<p>If the sample set D is divided into two parts D1 and D2 according to whether the feature A takes a certain possible value α, that is</p>
<p>$$ D_1 = \ {(x, y) \ in D | A (x) = a }, D_2 = D-D_1 $$</p>
<p>Then under the condition of feature A, the Gini index of set D is defined as</p>
<p>$$ Gini (D, A) = \ frac {| D_1 |} {| D |} Gini (D_1) + \ frac {| D_2 |} {D} Gini (D_2) $$</p>
<p>The Gini index Gini (D) represents the uncertainty of the set D, and the Gini index Gini (D, A) represents the uncertainty of the set D after A = α division. The larger the value of the Gini index, the greater the uncertainty of the sample set, which is similar to entropy.</p>
<h2 id="ID3-algorithm"><a href="#ID3-algorithm" class="headerlink" title="ID3 algorithm"></a>ID3 algorithm</h2><p>-### Information gain algorithm</p>
<pre><code>(From [Li Hang &quot;Statistical Methods&quot;] (https://book.douban.com/subject/10590856/))</code></pre><p>! [img] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/2.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/2.png</a>)</p>
<p>-### ID3 algorithm</p>
<pre><code>(From [Li Hang &quot;Statistical Methods&quot;] (https://book.douban.com/subject/10590856/))</code></pre><p>! [img] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/3.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/3.png</a>)</p>
<p>-### Example</p>
<pre><code>(From [Li Hang &quot;Statistical Methods&quot;] (https://book.douban.com/subject/10590856/))</code></pre><p>! [img] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/4.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/4.png</a>)</p>
<h2 id="C4-5-Generation-Algorithm"><a href="#C4-5-Generation-Algorithm" class="headerlink" title="C4.5 Generation Algorithm"></a>C4.5 Generation Algorithm</h2><p>(From [Li Hang “Statistical Methods”] (<a href="https://book.douban.com/subject/10590856/" target="_blank" rel="noopener">https://book.douban.com/subject/10590856/</a>))</p>
<p>! [img] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/5.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/5.png</a>)</p>
<h2 id="CART-generation-algorithm"><a href="#CART-generation-algorithm" class="headerlink" title="CART generation algorithm"></a>CART generation algorithm</h2><p>(From [Li Hang “Statistical Methods”] (<a href="https://book.douban.com/subject/10590856/" target="_blank" rel="noopener">https://book.douban.com/subject/10590856/</a>))</p>
<p>! [img] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/6.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/6.png</a>)</p>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>###! [img] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/7.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/TongJiXueXiFangfa/decision_tree/7.png</a>)</p>

    </div>

    
    
    
        <div class="reward-container">
  <div>No one has ever become poor by giving.</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      <div style="display: inline-block;">
        <img src="/images/googlePay.png" alt="Karan Google Pay">
        <p>Google Pay</p>
      </div>
      <div style="display: inline-block;">
        <img src="/images/AmazonPay.png" alt="Karan Amazon Pay">
        <p>Amazon Pay</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"><i class="fa fa-tag"></i> Machine Learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2015/04/24/perception_learning_algorithm/" rel="prev" title="Perception Learning Algorithm">
      <i class="fa fa-chevron-left"></i> Perception Learning Algorithm
    </a></div>
      <div class="post-nav-item">
    <a href="/2016/01/20/vim_without_widgets/" rel="next" title="Vim without plugins">
      Vim without plugins <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Decision-tree-learning"><span class="nav-number">1.</span> <span class="nav-text">Decision tree learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Feature-selection"><span class="nav-number">2.</span> <span class="nav-text">Feature selection</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Information-entropy-entropy"><span class="nav-number">2.1.</span> <span class="nav-text">Information entropy (entropy)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Information-gain"><span class="nav-number">2.2.</span> <span class="nav-text">Information gain</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ID3-algorithm"><span class="nav-number">3.</span> <span class="nav-text">ID3 algorithm</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#C4-5-Generation-Algorithm"><span class="nav-number">4.</span> <span class="nav-text">C4.5 Generation Algorithm</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CART-generation-algorithm"><span class="nav-number">5.</span> <span class="nav-text">CART generation algorithm</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Example"><span class="nav-number">5.1.</span> <span class="nav-text">Example</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Karan"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Karan</p>
  <div class="site-description" itemprop="description">Refuse to Fall</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">87</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:snakecoding.py@gmail.com" title="Get In Touch → mailto:snakecoding.py@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>Get In Touch</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Karan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">2.4m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">35:43</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '94c94e82b4a09d1d039a',
      clientSecret: 'd5e33f2eef896ccdbb8ea4051d59e215038ff302',
      repo        : 'karan36k.github.io',
      owner       : 'karan36k',
      admin       : ['karan36k'],
      id          : '9b48ca1f16f7dee3c8aa151526a9346a',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>
</body>
</html>
