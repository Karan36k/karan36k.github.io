<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">

<script>
    (function(){
        if(''){
                         If (prompt('Please enter the article password') !== ''){
                                 Alert('Password error!');
                history.back();
            }
        }
    })();
</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"snakecoding.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":true,"sidebar":{"position":"left","display":"post","padding":20,"offset":15,"onmobile":false},"copycode":{"enable":true,"show_result":"flat","style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":false},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Refuse to Fall">
<meta property="og:type" content="website">
<meta property="og:title" content="Machine Learning">
<meta property="og:url" content="https://snakecoding.com/page/20/index.html">
<meta property="og:site_name" content="Machine Learning">
<meta property="og:description" content="Refuse to Fall">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Karan">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://snakecoding.com/page/20/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Machine Learning</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Machine Learning" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Machine Learning</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Data Science</p>
      <a>
        <img class="custom-logo-image" src="/images/custom-logo.jpg" alt="Machine Learning">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">15</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">6</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">87</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="#" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/04/linear_transformation_1st_part/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/04/linear_transformation_1st_part/" class="post-title-link" itemprop="url">Tsinghua linear-algebra-2 4th-lecture linear-transformation-1st-part</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-04 20:16:00" itemprop="dateCreated datePublished" datetime="2017-08-04T20:16:00+05:30">2017-08-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:44" itemprop="dateModified" datetime="2020-04-09T16:34:44+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>8.3k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>8 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Notes from: Tsinghua University Open Class: Linear Algebra 2-Lecture 4: Linear Transformation 1</p>
<h2 id="Foreword"><a href="#Foreword" class="headerlink" title="Foreword"></a>Foreword</h2><p>In the history, British mathematician Arthur Cayley introduced matrix multiplication to describe the composition of linear transformation, so that the matrix became the research object of mathematics. Linear transformation is a map that maintains linear operations between two vector spaces. Linear algebra is a mathematical discipline developed from its central problem (solving linear equations) to study vector spaces, linear transformations, and related mathematical problems. The study of finite dimensional vector space can always be transformed into the study of matrix, which is the core feature of linear algebra.</p>
<h2 id="Definition-of-linear-transformation"><a href="#Definition-of-linear-transformation" class="headerlink" title="Definition of linear transformation"></a>Definition of linear transformation</h2><p>Recall the functions learned in middle school: $ f (x) = 2x \ quad g (x) = x ^ {2} \ quad l (x) = sin (x) $ Maps to a number in the value range. Generalized to map vector to vector mapping such as f is a mapping from $ R ^ {3} $ to $ R ^ {2} $: $ f: \ begin {pmatrix} x \ y \ z \ end {pmatrix} , \ rightarrow , \ begin {pmatrix} 2x \ 3y-z \ end {pmatrix} $, we care about the mapping from vector space to vector space. People find that the set of points on the plane, points in space, matrix polynomial functions, continuous functions, etc. look different, but their respective addition and multiplication satisfy the same properties, so they introduced an abstract concept like vector space Study the concept of vector space uniformly.</p>
<h3 id="Definition-of-Vector-Space"><a href="#Definition-of-Vector-Space" class="headerlink" title="Definition of Vector Space"></a>Definition of Vector Space</h3><p>! [definition_of_vector_space] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMS5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/1.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h3 id="Definition-of-linear-transformation-1"><a href="#Definition-of-linear-transformation-1" class="headerlink" title="Definition of linear transformation"></a>Definition of linear transformation</h3><p>! [definition_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMi5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/2.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h4 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h4><p>! [example1_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMy5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/3.png<i class="fa fa-external-link-alt"></i></span>)<br>! [example2_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvNC5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/4.png<i class="fa fa-external-link-alt"></i></span>)<br>! [example3_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvNS5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/5.png<i class="fa fa-external-link-alt"></i></span>)<br>! [example4_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvNi5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/6.png<i class="fa fa-external-link-alt"></i></span>)<br>! [example5_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvNy5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/7.png<i class="fa fa-external-link-alt"></i></span>)<br>! [example6_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvOC5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/8.png<i class="fa fa-external-link-alt"></i></span>)</p>
<p>** Note that the definition of linear transformation $ T: V , \ rightarrow , W $ gives $ T (0) = 0 $ **</p>
<p>! [example7_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvOS5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/9.png<i class="fa fa-external-link-alt"></i></span>)<br>! [example8_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMTAucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/10.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h3 id="The-nature-of-linear-transformation"><a href="#The-nature-of-linear-transformation" class="headerlink" title="The nature of linear transformation"></a>The nature of linear transformation</h3><p>! [properties_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMTEucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/11.png<i class="fa fa-external-link-alt"></i></span>)</p>
<p>For the first proof: If $ T (0) \ ne0 $ does not satisfy the linear transformation definition $ T (cx) = cT (x) $, for example: $ T (0) = 1 , \ rightarrow , T (0 ) = T (c0) = 1 , \ ne , cT (0) = c $</p>
<p>For the third proof: if $ x_ {1}, , … \ ,, x_ {n} $ is linearly correlated, then there is a number that is not all 0 c_ {n} $ satisfies $ c_ {1} x_ {1} , + , … , + , c_ {n} x_ {n} = 0 $ ie $ T (c_ {1} x_ {1 } , + , c_ {2} x_ {2} , + , … , + , c_ {n} x_ {n}) = T (0) = c_ {1} f (x_ { 1}) , + , … , + , c_ {n} f (x_ {n}) = 0 $, which is $ T (x_ {1}), , … \ ,, T (x_ {n}) $ linear correlation.</p>
<h3 id="Operation-of-linear-transformation"><a href="#Operation-of-linear-transformation" class="headerlink" title="Operation of linear transformation"></a>Operation of linear transformation</h3><h4 id="Addition"><a href="#Addition" class="headerlink" title="Addition"></a>Addition</h4><p>! [addition_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMTIucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/12.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h4 id="Multiplication"><a href="#Multiplication" class="headerlink" title="Multiplication"></a>Multiplication</h4><p>! [scalar_multiplication_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMTMucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/13.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h4 id="product"><a href="#product" class="headerlink" title="product"></a>product</h4><p>** Note: The product of linear transformation is defined as a compound operation of linear transformation **</p>
<p>! [multiplication_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMTQucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/14.png<i class="fa fa-external-link-alt"></i></span>)</p>
<p>** Note: Linear transformation does not satisfy the multiplication commutation law and elimination law, similar to matrix multiplication **</p>
<h4 id="Inverse"><a href="#Inverse" class="headerlink" title="Inverse"></a>Inverse</h4><p>! [inverse_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMTUucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/15.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h4 id="Power"><a href="#Power" class="headerlink" title="Power"></a>Power</h4><p>! [exponential_operation_of_linear_transformation1] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMTYucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/16.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h4 id="Polynomial"><a href="#Polynomial" class="headerlink" title="Polynomial"></a>Polynomial</h4><p>! [polynomial_of_linear_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMTcucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/17.png<i class="fa fa-external-link-alt"></i></span>)</p>
<p>** Note: Since the linear transformation does not satisfy the multiplication commutation law, $ (\ sigma \ tau) ^ {m} = \ underbrace {(\ sigma \ tau) (\ sigma \ tau) , … , (\ sigma \ tau)} _ {m (\ sigma \ tau) multiplication} \ ne \ sigma ^ {m} \ tau ^ {m} $ **</p>
<h2 id="Matrix-representation-of-linear-change"><a href="#Matrix-representation-of-linear-change" class="headerlink" title="Matrix representation of linear change"></a>Matrix representation of linear change</h2><p>! [Matrix representation of linear transformation 1] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMTgucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/18.png<i class="fa fa-external-link-alt"></i></span>) </p>
<p>Due to the output space of $ T (v_ {1}) $, $ T (v_ {2}) $, …, $ T (v_ {3}) , \ epsilon , W $, it can be done as follows:<br>! [Matrix representation of linear transformation 2] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMTkucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/19.png<i class="fa fa-external-link-alt"></i></span>)<br>! [Matrix representation of linear transformation 3] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMjAucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/20.png<i class="fa fa-external-link-alt"></i></span>) </p>
<h3 id="Examples-1"><a href="#Examples-1" class="headerlink" title="Examples"></a>Examples</h3><p>! [Matrix representation of linear transformation-Example 1] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMjEucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/21.png<i class="fa fa-external-link-alt"></i></span>)<br>! [Matrix representation of linear transformation-Example 2] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMjIucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/22.png<i class="fa fa-external-link-alt"></i></span>)<br>! [Matrix representation of linear transformation-Example 3] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMjMucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/23.png<i class="fa fa-external-link-alt"></i></span>)<br>! [Matrix representation of linear transformation-Example 4] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMjQucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/24.png<i class="fa fa-external-link-alt"></i></span>) </p>
<h2 id="Relationship-between-linear-transformation-and-matrix"><a href="#Relationship-between-linear-transformation-and-matrix" class="headerlink" title="Relationship between linear transformation and matrix"></a>Relationship between linear transformation and matrix</h2><h3 id="One-to-one-correspondence"><a href="#One-to-one-correspondence" class="headerlink" title="One to one correspondence"></a>One to one correspondence</h3><p>! [the_relation_between_transformation_and_matrix] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMjUucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/25.png<i class="fa fa-external-link-alt"></i></span>)<br>! [the_inverse_of_transformation_and_matrix] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMjYucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/26.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h3 id="Product-of-linear-transformation-and-product-of-matrix"><a href="#Product-of-linear-transformation-and-product-of-matrix" class="headerlink" title="Product of linear transformation and product of matrix"></a>Product of linear transformation and product of matrix</h3><p>! [the_product_of_transfromation_and_matrices] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMjcucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/27.png<i class="fa fa-external-link-alt"></i></span>)</p>
<p>** Note (extremely important): The product (composite) of the linear transformation here corresponds to the “left product” of the matrix. **</p>
<h3 id="Linear-isomorphism"><a href="#Linear-isomorphism" class="headerlink" title="Linear isomorphism"></a>Linear isomorphism</h3><p>! [linear_isomorphism_between_matrix_and_transformation] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTQvMjgucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-4/28.png<i class="fa fa-external-link-alt"></i></span>)</p>
<p>** Example **: Let linear transformation $ \ tau ,: , R ^ {3} \ rightarrow , R ^ {2} $ be defined as $ \ tau (x, y, z) = (x + y, yz) $, linear transformation $ \ sigma: R ^ {2} , \ rightarrow , R ^ {2} $ is defined as $ \ sigma (u, v) = (2u-v, u) $ $ \ sigma \ tau: R ^ {3} , \ rightarrow , R ^ {2} $ matrix under the standard base of $ R ^ {3} $ and $ R ^ {2} $.</p>
<p>** Solution **: Note that $ \ sigma \ tau = \ sigma (\ tau (x, y, z)) = \ sigma (x + y, yz) = (2x + y + z, x + y) $ </p>
<p>Therefore, the linear change under the standard base $ \ sigma (\ tau (x , y , z)): R ^ {3} \ to , R ^ {2} $:</p>
<p>$$ e_ {1} = (1,0,0) ^ {T}, e_ {2} = (0,1,0) ^ {T}, e_ {3} = (0,0,1) ^ { T} , \ Rightarrow , I_ {3} = (e_ {1} , e_ {2} , e_ {3}) $$</p>
<p>$ \ sigma (\ tau (e_ {1})) = \ sigma (\ tau (, (1,0,0) ,) = \ begin {pmatrix} 2 \ 1 \\ end {pmatrix} \ quad \ sigma ((\ tau (e_ {2})) = \ begin {pmatrix} 1 \ 1 \\ end {pmatrix} \ quad \ sigma (\ tau (e_ {3})) = \ begin {pmatrix } 1 \ 0 \\ end {pmatrix} $</p>
<p>$ \ sigma (\ tau (e_ {1} , e_ {2} , e_ {3})) = \ sigma (\ tau (I_ {3})) = \ underbrace {\ begin {pmatrix} 2 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 0 \ end {pmatrix}} _ {C} $</p>
<p>The first linear change $ \ tau (x, y, z) = (x + y, yz): R ^ {3} , \ to , R ^ {2} $:</p>
<p>$$ \ tau (e_ {1}) = \ tau (1,0,0) = (1 + 0,0 + 0) = (1,0) $$</p>
<p>$$ \ tau (e_ {2}) = \ tau (0,1,0) = (0 + 1,1 + 0) = (1,1) $$</p>
<p>$$ \ tau (e_ {3}) = \ tau (0,0,1) = (0 + 0,0 + 1) = (0,1) $$</p>
<p>$$ \ tau (I_ {3}) = \ tau (e_ {1} , e_ {2} , e_ {3}) = \ begin {pmatrix} 1 &amp; 1 &amp; 0 \ 0 &amp; 1 &amp; -1 \ end {pmatrix} = I_ {2} \ begin {pmatrix} 1 &amp; 1 &amp; 0 \ 0 &amp; 1 &amp; -1 \ end {pmatrix} $$</p>
<p>$$ \ underbrace {\ begin {pmatrix} 1 &amp; 1 &amp; 0 \ 0 &amp; 1 &amp; -1 \ end {pmatrix}} _ {A} \ begin {pmatrix} x \ y \ z \ end {pmatrix} = \ begin {pmatrix} x + y \ yz \ end {pmatrix} $$</p>
<p>The second linear change $ \ sigma (u, v) = (2u-v, u): R ^ {2} , \ to , R ^ {2} $:</p>
<p>$$ \ delta_ {1} = (1,0) ^ {T}, \ delta_ {2} = (0,1) ^ {T} , \ Rightarrow , I_ {2} = (\ delta_ {1} , \ delta_ {2}) $$</p>
<p>$$ \ sigma (\ delta_ {1}) = \ begin {pmatrix} 2 \ 1 \ end {pmatrix}, , \ sigma (\ delta_ {2}) = \ begin {pmatrix} -1 \ 0 \ end {pmatrix} \ Rightarrow \ sigma (\ delta_ {1} , \ delta_ {2}) = I_ {2} \ begin {pmatrix} 2 &amp; -1 \ 1 &amp; 0 \ end {pmatrix} $$</p>
<p>$$ \ underbrace {\ begin {pmatrix} 2 &amp; -1 \ 1 &amp; 0 \ end {pmatrix}} _ {B} \ begin {pmatrix} u \ v \ end {pmatrix} = \ begin {pmatrix} 2u-v \ \ u \ end {pmatrix} $$</p>
<p>Found $ BA = C , \ Rightarrow , \ begin {pmatrix} 2 &amp; -1 \ 1 &amp; 0 \ end {pmatrix} \ begin {pmatrix} 1 &amp; 1 &amp; 0 \ 0 &amp; 1 &amp; -1 \ end {pmatrix} = \ begin {pmatrix} 2 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 0 \ end {pmatrix} $, the compound in line with the linear transformation mentioned above is the left multiplication of the corresponding matrix.</p>
<p>Conclusion: ** Linear transformation on finite dimensional vector space $ \ leftarrow \ rightarrow $ matrix **</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/03/singular_values_decomposition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/03/singular_values_decomposition/" class="post-title-link" itemprop="url">Tsinghua linear-algebra-2 3rd-lecture Singular-Values-Decomposition</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-03 20:16:00" itemprop="dateCreated datePublished" datetime="2017-08-03T20:16:00+05:30">2017-08-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:37" itemprop="dateModified" datetime="2020-04-09T16:34:37+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>6.4k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>6 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Foreword"><a href="#Foreword" class="headerlink" title="Foreword"></a>Foreword</h2><p>Notes from: Tsinghua University Open Class: Linear Algebra 2-Lecture 3: Singular Value Decomposition, ** This article will list each step of the derivation in detail **.</p>
<p>** Summary of Tsinghua University Linear Algebra 2 Open Class Notes **</p>
<p>Lecture 1: [Positive Definite Matrix] (<span class="exturl" data-url="aHR0cHM6Ly9rYXJhbjM2ay5naXRodWIuaW8vMjAxNy8wOC8wMS9wb3NpdGl2ZV9kZWZpbml0ZV9tYXRyaXgv">https://karan36k.github.io/2017/08/01/positive_definite_matrix/<i class="fa fa-external-link-alt"></i></span>)<br>Lecture 2: [Similarity Matrix] ()<br>Lecture 3: [Singular Value Decomposition] (<span class="exturl" data-url="aHR0cHM6Ly9rYXJhbjM2ay5naXRodWIuaW8vMjAxNy8wOC8wMy9zaW5ndWxhcl92YWx1ZXNfZGVjb21wb3NpdGlvbi8=">https://karan36k.github.io/2017/08/03/singular_values_decomposition/<i class="fa fa-external-link-alt"></i></span>)<br>Lecture 4: [Linear Transformation 1] (<span class="exturl" data-url="aHR0cHM6Ly9rYXJhbjM2ay5naXRodWIuaW8vMjAxNy8wOC8wNC9saW5lYXJfdHJhbnNmb3JtYXRpb25fMXN0X3BhcnQv">https://karan36k.github.io/2017/08/04/linear_transformation_1st_part/<i class="fa fa-external-link-alt"></i></span>)<br>Lecture 5: [Linear Transformation 2] (<span class="exturl" data-url="aHR0cHM6Ly9rYXJhbjM2ay5naXRodWIuaW8vMjAxNy8wOC8wNS9saW5lYXJfdHJhbnNmb3JtYXRpb25fMm5kX3BhcnQv">https://karan36k.github.io/2017/08/05/linear_transformation_2nd_part/<i class="fa fa-external-link-alt"></i></span>)<br>Lecture 6: [Pseudo-inverse] (<span class="exturl" data-url="aHR0cHM6Ly9rYXJhbjM2ay5naXRodWIuaW8vMjAxNy8wOC8wNi9wc2V1ZG9faW52ZXJzZS8=">https://karan36k.github.io/2017/08/06/pseudo_inverse/<i class="fa fa-external-link-alt"></i></span>)<br>Lecture 7: [Matrix in Engineering] (<span class="exturl" data-url="aHR0cHM6Ly9rYXJhbjM2ay5naXRodWIuaW8vMjAxNy8wOC8wNy9lbmdpbmVlcmluZ19tYXRyaWNlcy8=">https://karan36k.github.io/2017/08/07/engineering_matrices/<i class="fa fa-external-link-alt"></i></span>)<br>Lecture 8: [Graph and Network] (<span class="exturl" data-url="aHR0cHM6Ly9rYXJhbjM2ay5naXRodWIuaW8vMjAxNy8wOC8wOC9ncmFwaF9hbmRfbmV0d29yay8=">https://karan36k.github.io/2017/08/08/graph_and_network/<i class="fa fa-external-link-alt"></i></span>)<br>Lecture 9: [Markov Matrix and Positive Matrix] (<span class="exturl" data-url="aHR0cHM6Ly9rYXJhbjM2ay5naXRodWIuaW8vMjAxNy8wOC8wNi9NYXJrb3ZfbWF0cml4Lw==">https://karan36k.github.io/2017/08/06/Markov_matrix/<i class="fa fa-external-link-alt"></i></span>)<br>Lecture 10: [Fourier Series] (<span class="exturl" data-url="aHR0cHM6Ly9rYXJhbjM2ay5naXRodWIuaW8vMjAxNy8wOC8wMi9Gb3VyaWVyX3Nlcmllcy8=">https://karan36k.github.io/2017/08/02/Fourier_series/<i class="fa fa-external-link-alt"></i></span>)<br>Lecture 11: [Computer Image] (<span class="exturl" data-url="aHR0cHM6Ly9rYXJhbjM2ay5naXRodWIuaW8vMjAxNy8wOC8xMS9jb21wdXRlcl9ncmFwaGljcy8=">https://karan36k.github.io/2017/08/11/computer_graphics/<i class="fa fa-external-link-alt"></i></span>)<br>Lecture 12: [Complex and Complex Matrix] (<span class="exturl" data-url="aHR0cHM6Ly9rYXJhbjM2ay5naXRodWIuaW8vMjAxNy8wOC8xMi9jb21wbGV4X2FuZF9jb21wbGV4X21hdHJpeC8=">https://karan36k.github.io/2017/08/12/complex_and_complex_matrix/<i class="fa fa-external-link-alt"></i></span>)</p>
<h2 id="Text"><a href="#Text" class="headerlink" title="Text"></a>Text</h2><p>Diagonal matrices are our favorite kind of matrix. For matrices that can be similar to diagonal matrices, the power and exponent can be easily calculated, and for square matrices that cannot be similar to diagonal matrices. In the last lesson we discussed how to find the similar standard form and the Jordan standard form that are as simple as possible. The squares discussed above are all discussed. So how do we diagonalize the m by n matrix?</p>
<p>The most important type of matrix decomposition in linear algebra is singular value decomposition, which answers the above questions. ** Diagonal matrix is ​​our favorite kind of matrix, because given a diagonal matrix, its eigenvalues, determinants, power and exponential functions can be obtained immediately. The operation of the diagonal matrix has many similarities with the operation of the numbers we are familiar with, and an n-order matrix is ​​similar to the diagonal matrix if and only if it has n linearly independent feature vectors. **<br>! [preface_SVD] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvMS5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/1.png<i class="fa fa-external-link-alt"></i></span>)<br>In particular, the real symmetric matrix must be orthogonal to the diagonal matrix, that is to say, to give you a real symmetric matrix, there must be an orthogonal matrix $ Q $ and its column vector is written as $ v_1 $ to $ v_n $, It can satisfy that $ Q ^ TAQ $ is equal to $ \ lambda $, $ \ lambda $ is a diagonal matrix, and its diagonal element is the eigenvalue of $ A $, then the column vector of $ Q $ $ v_i $, which It is the eigenvalue of the matrix $ A $, the eigenvector of $ \ lambda_i $, which means that $ Av_i $ is equal to $ \ lambda_iv_i $. We now have a question about how to “diagonalize” a matrix of $ m \ times n $. So that means in what sense we can try our best. Moving a rectangular array of $ m \ times n $ closer to a diagonal matrix, today we will discuss the singular value decomposition of matrices, which is the most important type of matrix decomposition in linear algebra applications.</p>
<h2 id="AA-T-and-A-TA-features"><a href="#AA-T-and-A-TA-features" class="headerlink" title="$ AA ^ T $ and $ A ^ TA $ features"></a>$ AA ^ T $ and $ A ^ TA $ features</h2><h3 id="Eigenvalues-​​of-AA-T-and-A-TA"><a href="#Eigenvalues-​​of-AA-T-and-A-TA" class="headerlink" title="Eigenvalues ​​of $ AA ^ T $ and $ A ^ TA $"></a>Eigenvalues ​​of $ AA ^ T $ and $ A ^ TA $</h3><p>! [1st_property_of_AAT] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvMi5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/2.png<i class="fa fa-external-link-alt"></i></span>) </p>
<h3 id="AA-T-and-A-TA-non-zero-eigenvalue-sets"><a href="#AA-T-and-A-TA-non-zero-eigenvalue-sets" class="headerlink" title="$ AA ^ T $ and $ A ^ TA $ non-zero eigenvalue sets"></a>$ AA ^ T $ and $ A ^ TA $ non-zero eigenvalue sets</h3><p>! [2nd_property_of_AAT] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvMy5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/3.png<i class="fa fa-external-link-alt"></i></span>) </p>
<h3 id="Feature-vectors-of-A-TA-and-AA-T"><a href="#Feature-vectors-of-A-TA-and-AA-T" class="headerlink" title="Feature vectors of $ A ^ TA $ and $ AA ^ T $"></a>Feature vectors of $ A ^ TA $ and $ AA ^ T $</h3><p>! [orthonormal_eigenvectors_of_AAT] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvNC5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/4.png<i class="fa fa-external-link-alt"></i></span>)</p>
<p>Let $ u_i: = {Av_i \ over \ sigma_i} \ in , R ^ m (1 \ le i \ le r) $, then $ AA ^ Tu_i = A (A ^ T \ frac {Av_i} {\ sigma_i} ) = A \ frac {A ^ TAv_i} {\ sigma_i} = A \ frac {\ sigma_i ^ 2v_i} {\ sigma_i} = {\ sigma_i} ^ 2 {Av_i \ over \ sigma_i} = {\ sigma_i} ^ 2u_i $ , Resulting in: $ AA ^ Tu_i = {\ sigma_i} ^ 2u_i $. And because: $ {u_i} ^ T {u_j} = \ frac {(Av_i) ^ T} {\ sigma_i} {Av_j \ over \ sigma_j} = {v_i ^ T (A ^ TAv_j) \ over \ sigma_i \ sigma_j} = \ frac {\ sigma_j ^ 2 {v_i} ^ Tv_j} {\ sigma_i \ sigma_j} = {\ sigma_j \ over \ sigma_i} v_i ^ Tv_j \ rightarrow u_i ^ Tu_j = \ begin {cases} 0, &amp; i \ ne j \ 1, &amp; i = j \ end {cases} $ Therefore: $ \ {u_i | 1 \ le i \ le r } $ is the unit orthogonal feature vector of $ AA ^ T $.</p>
<p>According to the assumption ($ v_1, , … \ ,, v_n $ is the unit cross base of $ A ^ TA $, $ \ sigma_1 ^ 2, , … \ ,, \ sigma_n ^ 2 $ is $ AA ^ The characteristic value of T $) is obtained as: || Av_i || ^ 2 = \ sigma_i ^ 2 \ rightarrow | Av_i | = \ sigma_i $</p>
<h3 id="SVD-from-AA-T"><a href="#SVD-from-AA-T" class="headerlink" title="SVD from $ AA ^ T $"></a>SVD from $ AA ^ T $</h3><p>$ (1) u_i: = {Av_i \ over \ sigma_i} \ in , R ^ m (1 \ le i \ le r) \ rightarrow Av_i = \ sigma_iu_i \ (2) A ^ TAv_i = {\ sigma_i} ^ 2v_i, (i \ le i \ le r) \ rightarrow A ^ T {Av_i \ over \ sigma_i} = \ sigma_iv_i \ rightarrow A ^ Tu_i = \ sigma_iv_i $</p>
<p>From the above formula: $ U $ is a set of unit orthogonal bases in $ A $ column space, and $ V $ is a set of unit orthogonal bases in $ A ^ T $ column space. $ \ sigma_i $ is the length of $ Av_i $, which is calculated as $ \ begin {pmatrix} \ sigma_1 &amp;&amp;&amp;&amp; \ &amp;. &amp;&amp;&amp; \ &amp;&amp;. &amp;&amp; \ &amp;&amp;&amp;. &amp; \ &amp;&amp;&amp;&amp; \ sigma_r \ end {pmatrix} $ is $ \ Sigma $ ， 得 ： $ A_ {m \ times n} V_ {n \ times r} = U_ {m \ times r} \ Sigma_ {r \ times r} \ rightarrow A_ {m \ times n} = U_ {m \ times r} \ Sigma_ {r \ times r} {V ^ {-1}} _ {r \ times n} \ = U_ {m \ times r} \ Sigma_ {r \ times r} {V ^ {T}} _ {r \ times n} $</p>
<p>Vector form: $ A = \ sum_ {i = 1} ^ r \ sigma_i u_i {v_i} ^ T $</p>
<p>! [get_svd_from_AAT] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvNS5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/5.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h2 id="SVD-format"><a href="#SVD-format" class="headerlink" title="SVD format"></a>SVD format</h2><p>! [formula_svd] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvNi5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/6.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><p>! [example_svd] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvNy5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/7.png<i class="fa fa-external-link-alt"></i></span>)</p>
<p>There are two ways to find $ u_3 $:</p>
<p>Method 1: $ AA ^ Tu_3 = \ begin {pmatrix} 1 &amp; 0 \ 0 &amp; 1 \ 1 &amp; -1 \ end {pmatrix} \ begin {pmatrix} 1 &amp; 0 &amp; 1 \ 0 &amp; 1 &amp; -1 \ end {pmatrix} u_3 = \ begin {pmatrix} 1 &amp; 0 &amp; 1 \ 0 &amp; 1 &amp; -1 \ 1 &amp; -1 &amp; 2 \ end {pmatrix} u_3 = 0u_3 \ rightarrow u_3 = {1 \ over \ sqrt {3}} \ begin {pmatrix} 1 \ -1 \ -1 \ end { pmatrix} $</p>
<p>Method 2: $ u_j: = \ begin {pmatrix} x \ y \ z \ end {pmatrix}, \ sum_ {i = 1} ^ {r = 3} u_iu_j = 0 (i \ ne j), || u_j || ^ 2 = 1 \ rightarrow u_ {j = 3} = {1 \ over \ sqrt {3}} \ begin {pmatrix} 1 \ -1 \ -1 \ end {pmatrix} $</p>
<h2 id="svd-geometric-meaning"><a href="#svd-geometric-meaning" class="headerlink" title="svd geometric meaning"></a>svd geometric meaning</h2><p>! [example_geometry_svd] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvOC5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/8.png<i class="fa fa-external-link-alt"></i></span>)<br>! [geometry_svd] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvOS5wbmc=">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/9.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h2 id="svd-application"><a href="#svd-application" class="headerlink" title="svd application"></a>svd application</h2><h3 id="Four-basic-subspaces-of-svd-and-matrix"><a href="#Four-basic-subspaces-of-svd-and-matrix" class="headerlink" title="Four basic subspaces of svd and matrix"></a>Four basic subspaces of svd and matrix</h3><p>! [4_subspaces_svd] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvMTAucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/10.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h3 id="svd-and-image-compression"><a href="#svd-and-image-compression" class="headerlink" title="svd and image compression"></a>svd and image compression</h3><p>! [img_compression_by_svd] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvMTEucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/11.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h3 id="Relationship-between-singular-value-and-eigenvalue"><a href="#Relationship-between-singular-value-and-eigenvalue" class="headerlink" title="Relationship between singular value and eigenvalue"></a>Relationship between singular value and eigenvalue</h3><p>! [singular_values_and_eigenvalues] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvMTIucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/12.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h3 id="Singular-value-and-singular-matrix"><a href="#Singular-value-and-singular-matrix" class="headerlink" title="Singular value and singular matrix"></a>Singular value and singular matrix</h3><p>! [singular_values] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTMvMTMucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-3/13.png<i class="fa fa-external-link-alt"></i></span>)</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/02/Fourier_series/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/02/Fourier_series/" class="post-title-link" itemprop="url">Tsinghua linear-algebra-2 10th-lecture Fourier series</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-02 20:16:00" itemprop="dateCreated datePublished" datetime="2017-08-02T20:16:00+05:30">2017-08-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:46" itemprop="dateModified" datetime="2020-04-09T16:34:46+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>8.4k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>8 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Notes from: Tsinghua University Open Class: Linear Algebra 2-Lecture 10: Fourier Series</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>! [preface] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTEwLzEucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-10/1.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h2 id="Fourier-series-Fourier-series-definition"><a href="#Fourier-series-Fourier-series-definition" class="headerlink" title="Fourier series Fourier series definition"></a>Fourier series Fourier series definition</h2><h3 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition 1"></a>Definition 1</h3><p>Let $ f (x) $ be a continuous function of a finite number of segments ([piecewise] (<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvUGllY2V3aXNl">https://en.wikipedia.org/wiki/Piecewise<i class="fa fa-external-link-alt"></i></span>)) with period of $ 2 \ pi $ (that is, in $ [\ pi,-\ pi] There are only a limited number of discontinuities in $, and the left and right limits of the discontinuities exist), then its Fourier series is $ F = {a_0 \ over 2} + \ sum \ limits_ {k = 1} ^ {\ infty} (\ a_kcos (kx) + b_ksin (kx) ), a_k = {1 \ over \ pi} \ int _ {-\ pi} ^ {\ pi} f (x) cos (kx) dx, b_k = {1 \ over \ pi} \ int _ {-\ pi} ^ {\ pi} f (x) sin (kx) dx, k = 0,1, \ ldots $, this series again It is called the real form of Fourier series **.</p>
<p>An example of $ f (x) $ is $ (1) $, and $ (2) $ has no limit at the discontinuity points in the cycle.<br>! [example_of_2_kinds_of_piecewise_function] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTEwLzIucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-10/2.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h3 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition 2"></a>Definition 2</h3><p>$ f (x) $ As above, its ** complex form of Fourier series ** is $ F = \ sum \ limits_ {k =-\ infty} ^ {+ \ infty} c_ke ^ {ikx}, c_k = {1 \ over 2 \ pi} \ int _ {-\ pi} ^ {\ pi} f (x) e ^ {-ikx} dx $. Derived as follows:</p>
<p>In definition 1, the Euler formula is used: $ e ^ {ix} = cosx + isinx \ Rightarrow cosx = {e ^ {ix} + e ^ {-ix} \ over 2}, \ sinx = {e ^ {ix } -e ^ {-ix} \ over 2i} $, the Fourier series in definition 1 becomes $ F = {a_0 \ over 2} + \ sum \ limits_ {k = 1} ^ {\ infty} [ {a_k \ over 2} (e ^ {ikx} + e ^ {-ikx})-{ib_k \ over 2} (e ^ {ikx} -e ^ {-ikx})] = {a_0 \ over 2} + \ sum \ limits_ {k = 1} ^ {\ infty} ({a_k-ib_k \ over 2} e ^ {ikx} + {a_k + ib_k \ over 2} e ^ {-ikx}). $ where<br>$ a_k-ib_k = {1 \ over 2 \ pi} \ int _ {-\ pi} ^ {\ pi} f (x) (e ^ {ikx} + e ^ {-ikx}) dx- {i \ over 2 \ pi} \ int _ {-\ pi} ^ {\ pi} f (x) \ frac {e ^ {ikx} -e ^ {-ikx}} {i} dx = {1 \ over \ pi} \ int_ { -\ pi} ^ {\ pi} e ^ {-ikx} dx, \ a_k + ib_k = {1 \ over \ pi} \ int _ {-\ pi} ^ {\ pi} e ^ {ikx} dx $, order $ c_k = {a_k-ib_k \ over 2} = {1 \ over 2 \ pi} \ int _ {-\ pi} ^ {\ pi} f (x) e ^ {-ikx} dx, k = 1,2, \ ldots \ quad c _ {-k} = {a_k + ib_k \ over 2} = {1 \ over 2 \ pi} \ int _ {-\ pi} ^ {\ pi} f (x) e ^ {ikx} dx, k = 1,2, \ ldots $ This gives definition 2. Note: Just like the Taylor series, there is no assertion here that $ f (x) $ is equal to its Fourier series.</p>
<h3 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a>Theorem</h3><p>Let $ f (x) $ be a periodic function with a period of $ 2 \ pi $. Both $ f (x) $ and $ f ‘(x) $ are piecewise continuous on $ [-\ pi, \ pi] $ , Then the Fourier series of $ f (x) $ converges, and $ x = a $ is equal to $ f (a) $ at any continuous point, and $ x = a $ is equal to $ {1 \ over 2 at the discontinuous point } [lim_ {x \ rightarrow a ^ {+}} f (x) + lim_ {x \ rightarrow a ^ {-}} f (x)] $. </p>
<p>! [one_law_of_Fourier_series] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTEwLzMucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-10/3.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h2 id="inner-product-space"><a href="#inner-product-space" class="headerlink" title="inner product space"></a>inner product space</h2><p>Let $ V $ be a vector space (linear space) (on $ R $ or $ C $), and a ** inner product ** on $ V $ is such a function (-,-): $ V \ times V \ rightarrow R \ or \ C $ meets:</p>
<ol>
<li>$ \ forall u \ in V, (u, u) \ ge0 $, and if $ (u, u) = 0 \ rightarrow u = 0 $ </li>
<li>$ (c_1u + c_2v, w) = c_1 (u, w) + c_2 (v, w), u, v, w \ in V, c_1, c_2 \ in R \ or \ C $</li>
<li>$ \ overline {(u, v)} = (v, u) $ conjugate symmetry</li>
</ol>
<p>Note: There is no assumption that $ v $ is finite-dimensional. Article 1: The inner product of $ u $ and itself must be a real number and a positive number, or rather a non-negative number, if the inner product of $ u $ and itself is equal to 0, then you can be sure $ u $ is the $ 0 $ vector. Article 2: The inner product of the linear combination of two vectors and another vector is equivalent to the inner product of the two vectors and the other vector and then the linear combination. Article 3: The inner product of $ u $ and $ v $ is in a conjugate relationship with the inner product of $ v $ and $ u $. If this function is defined in $ V \ times V \ rightarrow R $, then this The inner product function is symmetrical. The inner product of $ u, v $ is the same as the inner product of $ v, u $. If it is defined on a complex number, then there is a conjugate difference.</p>
<p>Let $ || u || = \ sqrt {(u, u)} $, if $ || u || = 1 $, then $ u $ is a unit vector. Any vector $ u \ ne 0 \ rightarrow {v \ over || v ||} $ is a unit vector, about [norm] ($ || · || $) ($ ||||| $), The norm here is the length.</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><ol>
<li>$ V = R ^ 2, u = \ begin {pmatrix} a_1 \ a_2 \ end {pmatrix}, v = \ begin {pmatrix} b_1 \ b_2 \ end {pmatrix}, (u, v) = u ^ T v = a_1b_1 + a_2b_2 $ is an inner product, $ || u || = \ sqrt {(a_1 ^ 2 + a_2 ^ 2)} $. If $ V = C ^ 2 $, $ u, v \ in C, (u, v) = u ^ T \ bar {v} = a_1 \ overline {b_1} + a_2 \ overline {b_2} $.</li>
<li>$ C [a, b] $ is a vector space formed by all continuous real functions defined in the interval $ [a, b] $. Define the inner product of the continuous function as $ (f, g) = \ int_ {a} ^ {b} f (x) g (x) dx $. Verify this formula: $ f (x) \ in C [a, b], (f, f) \ ge 0 $, that is, $ (f, f) = \ int_ {a} ^ {b} {f (x )} ^ 2dx = \ int_ {a} ^ {b} {| f (x) |} ^ 2dx \ ge 0 $. If $ (f, f) = 0 $, that is $ \ int_ {a} ^ {b} {| f (x) |} ^ 2dx = 0 $, let $ F (t) = \ int_ {a} ^ { t} {| f (x) |} ^ 2dx, a \ le t \ le b $, then $ F (t) = 0, F (t) $ can be guided, $ F ‘(t) = {| f ( t) |} ^ 2 = 0 $, which means $ f (t) = 0, t \ in [a, b] $. Here the square of the length of the function is defined as the inner product of the function and itself, ie $ || f (x) || ^ 2 = (f (x), f (x)) = \ int_ {a} ^ {b} f (x) f (x) dx $.</li>
<li>In Example 2, if $ C [a, b] $ is a vector space of continuous complex functions on $ [a, b] $, the inner product is defined as: $ (f, g) = \ int_ {a } ^ {b} f (x) \ overline {g (x)} dx $.</li>
</ol>
<h3 id="Standard-orthogonal-system-orthonormal-system"><a href="#Standard-orthogonal-system-orthonormal-system" class="headerlink" title="Standard orthogonal system orthonormal system"></a>Standard orthogonal system orthonormal system</h3><p>! [orthonormal system] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTEwLzQucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-10/4.png<i class="fa fa-external-link-alt"></i></span>)<br>Summary: If f (x) has a Fourier series in the interval $ [a, b] $, then the Fourier series of f (x) is f (x) in the standard orthogonal system<br>$ \ {\ frac {1} {\ sqrt {2 \ pi}}, \ frac {1} {\ sqrt {\ pi}} sinx, \ frac {1} {\ sqrt {\ pi}} cosx, \ frac Projection under {1} {\ sqrt {\ pi}} sin2x, \ frac {1} {\ sqrt {\ pi}} cos2x, \ ldots } $.</p>
<h2 id="Fourier-series-of-periodic-functions"><a href="#Fourier-series-of-periodic-functions" class="headerlink" title="Fourier series of periodic functions"></a>Fourier series of periodic functions</h2><p>Real form of Fourier series $ F = {a_0 \ over 2} + \ sum \ limits_ {k = 1} ^ {\ infty} (\ a_kcos (kx) + b_ksin (kx) ), a_k = { 1 \ over \ pi} \ int _ {-\ pi} ^ {\ pi} f (x) cos (kx) dx, b_k = {1 \ over \ pi} \ int _ {-\ pi} ^ {\ pi} f (x) sin (kx) dx, k = 0,1, \ ldots $ for variable substitution, make $ x = {\ pi \ over L} t, k = n $ get: $ dx = {\ pi \ over L} dt, \ t = \ cases {L, x = \ pi \ -L, x =-\ pi} \ Rightarrow f (t) = {a_0 \ over 2} + \ sum \ limits_ {n = 1} ^ {\ infty} [a_ncos ({n \ pi t \ over L}) + b_nsin ({n \ pi t \ over L})], \ a_n = {1 \ over L} \ int _ {-L} ^ { L} f (t) cos ({n \ pi t \ over L}) dt, \ b_n = {1 \ over L} \ int _ {-L} ^ {L} f (t) sin ({n \ pi t \ over L}) dt, n = 0,1, \ ldots $, the corresponding plural form is: </p>
<p>! [Fourier-series_of_periodic_function] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTEwLzUucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-10/5.png<i class="fa fa-external-link-alt"></i></span>)</p>
<h3 id="Projection"><a href="#Projection" class="headerlink" title="Projection"></a>Projection</h3><p>! [application_of_projection_on_Fourier-series] (<span class="exturl" data-url="aHR0cDovL3E2Z204Zm9tdy5ia3QuY2xvdWRkbi5jb20vZ2l0cGFnZS90c2luZ2h1YV9saW5lYXJfYWxnZWJyYS8yLTEwLzYucG5n">http://q6gm8fomw.bkt.clouddn.com/gitpage/tsinghua_linear_algebra/2-10/6.png<i class="fa fa-external-link-alt"></i></span>)<br>Note: $ e ^ {ikx} = cos (kx) + isin (kx) \ rightarrow (e ^ {ikx}, e ^ {ikx}) = 2L, L $ is the absolute value of the half period, according to the complex function The inner product of the vector space is defined as: $ (f, g) = \ int_ {a} ^ {b} f (x) \ overline {g (x)} dx \ rightarrow (f (x), e ^ {ikx} ) $ Is $ \ int _ {-\ pi} ^ {\ pi} f (x) e ^ {-iks} dx $ under the period $ [-\ pi, \ pi] $.</p>
<h2 id="Notes-on-Fourier-Transform"><a href="#Notes-on-Fourier-Transform" class="headerlink" title="Notes on Fourier Transform"></a>Notes on Fourier Transform</h2><p>Fourier series and Fourier transformation are the main parts of Fourier analysis. Let $ f (t) $ period $ T = 2L $, then the Fourier series expansion of $ f (t) $ is $ f (t) = \ sum \ limits_ {k =-\ infty} ^ {\ infty } c_ke ^ {\ frac {ik \ pi} {L} t}, c_k = {1 \ over 2L} \ int _ {-L} ^ {L} f (t) e ^ {\ frac {-ik \ pi} {L} t} dt $ ($ c_k $ is the projection of $ f (t) $ on $ e ^ {\ frac {ik \ pi} {L} t} $). Now consider the non-periodic function $ f (t) $ ** defined on $ (-\ infty, + \ infty) $. Does it have a Fourier series expansion form?</p>
<p>Given $ L&gt; 0 $, define $ f_L (t) = \ cases {f (t), | t | &lt;L \ 0, \ quad \ | t | \ ge L} $. Suppose that when $ L \ rightarrow \ infty $, $ f_L (t) $ (consistent) approaches $ f (t) $. The function $ f_L (t) $ can be extended by the period, that is, if $ F_L (t) = \ cases {f (t), -L &lt;t \ le L \ F_L (t + 2L), T = 2L} $ then $ F_L (t) $ has Fourier series.</p>
<p>When $ -L &lt;t &lt;L, f (t) = f_L (t) = F_L (t) = \ sum \ limits_ {k =-\ infty} ^ {\ infty} c_k (L) e ^ {\ frac { ik \ pi} {L} t}, c_k (L) = {1 \ over 2L} \ int _ {-L} ^ {L} f_L (t) e ^ {\ frac {-ik \ pi} {L} t } dt $</p>
<p>Because $ f_L (t) = 0, | t |&gt; L \ rightarrow c_k (L) = {1 \ over 2L} \ int _ {-L} ^ {L} f_L (t) e ^ {\ frac {-ik \ pi} {L} t} dt = {1 \ over 2L} \ int _ {-\ infty} ^ {\ infty} f_L (t) e ^ {\ frac {-ik \ pi} {L} t} dt $</p>
<p>Since $ k \ rightarrow \ infty $ is also $ L \ rightarrow \ infty $, the exponent term on the right side of the equation is unknown, so do variable substitution, so that $ \ tilde {f} <em>L (w) = \ int _ {-\ infty } ^ {\ infty} f_L (t) e ^ {-iwt} dt $, let $ w_k = {k \ pi \ over L} $ then $ c_k (L) = {1 \ over 2L} \ tilde {f} (\ frac {k \ pi} {L}) = {1 \ over 2L} \ tilde {f} ({w_k}) = {1 \ over 2 \ pi} \ tilde {f} ({w_k}) (w</em> {k + 1} -w_k) $</p>
<p>Then get the new form of ** Fourier expansion *<em>: $ f_L (t) = F_L (t) = {1 \ over 2 \ pi} \ sum \ limits _ {-\ infty} ^ {+ \ infty} \ tilde {f} <em>L (w_k) e ^ {iw_kt} \ Delta w_k, \ tilde {f} _L (w) = \ int _ {-\ infty} ^ {+ \ infty} f_L (t) e ^ {-iw_kt} dt , \ Delta w_k = w</em> {k + 1} -w_ {k} = {\ pi \ over L} $. When $ L \ rightarrow + \ infty, \ Delta w \ rightarrow 0 $, the left side of the equation $ f_L (t) $ (consistent) approaches $ f (t) $, and the right side approaches an integral form: $ f (t) = {1 \ over 2 \ pi} \ int _ {-\ infty} ^ {+ \ infty} \ tilde {f} _L (w) e ^ {iwt} dw $, known as $ \ tilde {f} ( w) $ is the *</em> Fourier transform ** of $ f (t) $, and $ f (t) $ is the ** inverse Fourier transform ** of $ \ tilde {f} (w $).</p>
<p>$ f (t) $ is actually superimposed between $ sin \ cos $ of the time function, then $ \ tilde {f} (ω) $ is superimposed on these frequencies, which is a function of frequency. When you talk about complex matrices, you will return to this Fourier transform. The discrete form of Fourier transform will be considered. Then $ f (x) $ or $ f (t) $ will be replaced by a vector, $ \ tilde {f } (ω) $ is also replaced by a vector. The relationship between the inverse Fourier transform or the inverse Fourier transform between them is actually converted to each other through a Fourier matrix, and the corresponding fast Fourier transform.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/01/positive_definite_and_least_square/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/01/positive_definite_and_least_square/" class="post-title-link" itemprop="url">positive definite and least squares</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-01 22:16:00" itemprop="dateCreated datePublished" datetime="2017-08-01T22:16:00+05:30">2017-08-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 14:57:36" itemprop="dateModified" datetime="2020-04-09T14:57:36+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>2.8k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>3 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="positive-definite"><a href="#positive-definite" class="headerlink" title="positive definite"></a>positive definite</h2><p>When <strong>a symmetric matrix $A$ has one of these five properties, it has them all</strong> and $A$ is positive definite:</p>
<blockquote>
<ol>
<li>all <strong>n eigenvalue</strong> are positive.</li>
<li>all <strong>n principal minors(n upper left determinants)</strong> are positive.</li>
<li>all <strong>n pivots are positive</strong>.</li>
<li>$x^{T}Ax$ is positive except when $x = 0$ (this is usually the definition of positive definiteness and the <strong>energy-based</strong> definition).</li>
<li>$A$ equals $R^{T}R$ for a matrix $R$ with <strong>independent columns</strong>.</li>
</ol>
</blockquote>
<p>Let us prove the fifth rule. If $A = R^{T}R$, then</p>
<p>$$<br>\begin{eqnarray}<br>x^{T}Ax&amp;=&amp;x^{T}R^{T}Rx \nonumber\<br>&amp;=&amp;(x^{T}R^{T})Rx \nonumber\<br>&amp;=&amp;(Rx)^{T}Rx \nonumber\<br>&amp;=&amp;|Rx| \nonumber\<br>&amp;\ge&amp;0 \nonumber<br>\end{eqnarray}<br>$$</p>
<p>And the columns of $R$ are also independent, so $|Rx|=x^{T}Ax&gt;0$, except when $x$=0 and thus $A$ is positive definite.</p>
<h2 id="A-T-A"><a href="#A-T-A" class="headerlink" title="$A^{T}A$"></a>$A^{T}A$</h2><p>$A_{m\times n}$ is almost certainly not symmetric, but $A^{T}A$ is square (n by n) and symmetric. We can easily get the following equations through left multiplying $A^{T}A$ by $x^{T}$ and right multiplying $A^{T}A$ by $x$:</p>
<p>$$<br>\begin{eqnarray}<br>x^{T}A{^TA}x&amp;=&amp;x^{T}(A{^TA})x\nonumber\<br>&amp;=&amp;(x^{T}A^{T})Ax\nonumber\<br>&amp;=&amp;(Ax)^{T}(Ax)\nonumber\<br>&amp;=&amp;|Ax|\nonumber\<br>&amp;\ge&amp;0\nonumber<br>\end{eqnarray}<br>$$</p>
<p>If $A_{m\times,n}$ has rank $n$ (independent columns), then except when $x = 0$, $Ax=|Ax|=x^{T}(A{^TA})x&gt;0$ and thus $A^{T}A$ is positive definite. And vice versus.</p>
<p>Besides, $A^{T}A$ is invertible only if $A$ has rank $n$ (independent columns). To prove this, we assume $Ax=0$, then:</p>
<p>$$<br>\begin{eqnarray}<br>Ax&amp;=&amp;0\nonumber\<br>(Ax)^{T}(Ax)&amp;=&amp;0\nonumber\<br>(x^{T}A{^T})(Ax)&amp;=&amp;0\nonumber\<br>x^{T}A{^T}(Ax)&amp;=&amp;x^{T}0\nonumber\<br>(A{^TA})x&amp;=&amp;0\nonumber<br>\end{eqnarray}<br>$$</p>
<p>From the above equations, we know solutions of $Ax=0$ are also solutions of  $(A{^TA})x=0$. Because $A_{m\times,n}$ has a full set of column rank (independent columns),  $Ax=0$ only has a zero solution as well as $(A{^T}A)x=0$. Furthermore, if $A{^T}A$ is invertible, then $A_{m\times,n}$ has rank $n$ (independent columns). We also notice that if $A$ is square and invertible, then  $A{^T}A$ is invertible. </p>
<p>Overall, <strong>if all columns of $A_{m\times,n}$ are mutual independent, then $(A{^T}A)$ is invertible and positive definite as well, and vice versus.</strong></p>
<h2 id="least-square"><a href="#least-square" class="headerlink" title="least square"></a>least square</h2><p>We have learned that <strong>least square</strong> comes from <strong>projection</strong> :<br>$$b-p=e\Rightarrow,A^{T}(b-A\hat{x})=0\Rightarrow,A^{T}A\hat{x}=A^{T}b$$<br>Consequently, only if $A^{T}A$ is invertible, then we can use linear regression to find approximate solutions $\hat{x}=(A^{T}A)^{-1}A^{T}b$ to unsolvable systems of linear equations. </p>
<p>According to the reasoning before, we know as long as all columns of $A_{m\times,n}$ are mutual independent, then $A{^T}A$ is invertible. At the same time we ought to notice that the columns of $A$ are guaranteed to be independent if they are orthoganal and even orthonormal. </p>
<p>In another prospective, if $A^{T}A$ is positive definite, then $A_{m\times,n}$ has rank $n$ (independent columns) and thus $A^{T}A$ is invertible.</p>
<p><strong>Overall, if $A^{T}A$ is positive definite or invertible, then we can find approximate solutions of least square</strong>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/19/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><span class="page-number current">20</span><a class="page-number" href="/page/21/">21</a><a class="page-number" href="/page/22/">22</a><a class="extend next" rel="next" href="/page/21/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Karan"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Karan</p>
  <div class="site-description" itemprop="description">Refuse to Fall</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">87</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnNuYWtlY29kaW5nLnB5QGdtYWlsLmNvbQ==" title="Get In Touch → mailto:snakecoding.py@gmail.com"><i class="fa fa-envelope fa-fw"></i>Get In Touch</span>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Karan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">2.4m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">35:43</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  
  <script data-pjax>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


    </div>
</body>
</html>
