<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">

<script>
    (function(){
        if(''){
                         If (prompt('Please enter the article password') !== ''){
                                 Alert('Password error!');
                history.back();
            }
        }
    })();
</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"snakecoding.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":"flat","style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":false},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Refuse to Fall">
<meta property="og:type" content="website">
<meta property="og:title" content="Machine Learning">
<meta property="og:url" content="https://snakecoding.com/page/3/index.html">
<meta property="og:site_name" content="Machine Learning">
<meta property="og:description" content="Refuse to Fall">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Karan">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://snakecoding.com/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Machine Learning</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Machine Learning" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Machine Learning</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Data Science</p>
      <a>
        <img class="custom-logo-image" src="/images/custom-logo.jpg" alt="Machine Learning">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">17</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">3</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">91</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/yourname" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/06/02/Dinosaurus+Island+--+Character+level+language+model+final+-+v3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/02/Dinosaurus+Island+--+Character+level+language+model+final+-+v3/" class="post-title-link" itemprop="url">Dinosaurus Island Character level language model final</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-06-02 00:00:00" itemprop="dateCreated datePublished" datetime="2018-06-02T00:00:00+05:30">2018-06-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 04:37:42" itemprop="dateModified" datetime="2020-04-09T04:37:42+05:30">2020-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/English/" itemprop="url" rel="index"><span itemprop="name">English</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>27k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>25 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>This is one of my personal programming assignments after studying the course <a href="https://www.coursera.org/learn/nlp-sequence-models/" target="_blank" rel="noopener">nlp sequence models</a> at the 1st week and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.</p>
<h1 id="Character-level-language-model-Dinosaurus-land"><a href="#Character-level-language-model-Dinosaurus-land" class="headerlink" title="Character level language model - Dinosaurus land"></a>Character level language model - Dinosaurus land</h1><p>Welcome to Dinosaurus Island! 65 million years ago, dinosaurs existed, and in this assignment they are back. You are in charge of a special task. Leading biology researchers are creating new breeds of dinosaurs and bringing them to life on earth, and your job is to give names to these dinosaurs. If a dinosaur does not like its name, it might go beserk, so choose wisely! </p>
<table>
<td>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/dinosaurus_island/images/dino.jpg" style="width:250;height:300px;">

</td>

</table>

<p>Luckily you have learned some deep learning and you will use it to save the day. Your assistant has collected a list of all the dinosaur names they could find, and compiled them into this <a href="dinos.txt">dataset</a>. (Feel free to take a look by clicking the previous link.) To create new dinosaur names, you will build a character level language model to generate new names. Your algorithm will learn the different name patterns, and randomly generate new names. Hopefully this algorithm will keep you and your team safe from the dinosaurs’ wrath! </p>
<p>By completing this assignment you will learn:</p>
<ul>
<li>How to store text data for processing using an RNN </li>
<li>How to synthesize data, by sampling predictions at each time step and passing it to the next RNN-cell unit</li>
<li>How to build a character-level text generation recurrent neural network</li>
<li>Why clipping the gradients is important</li>
</ul>
<p>We will begin by loading in some functions that we have provided for you in <code>rnn_utils</code>. Specifically, you have access to functions such as <code>rnn_forward</code> and <code>rnn_backward</code> which are equivalent to those you’ve implemented in the previous assignment. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> random</span><br></pre></td></tr></table></figure>

<h2 id="1-Problem-Statement"><a href="#1-Problem-Statement" class="headerlink" title="1 - Problem Statement"></a>1 - Problem Statement</h2><h3 id="1-1-Dataset-and-Preprocessing"><a href="#1-1-Dataset-and-Preprocessing" class="headerlink" title="1.1 - Dataset and Preprocessing"></a>1.1 - Dataset and Preprocessing</h3><p>Run the following cell to read the dataset of dinosaur names, create a list of unique characters (such as a-z), and compute the dataset and vocabulary size. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = open(<span class="string">'dinos.txt'</span>, <span class="string">'r'</span>).read()</span><br><span class="line">data= data.lower()</span><br><span class="line">chars = list(set(data))</span><br><span class="line">data_size, vocab_size = len(data), len(chars)</span><br><span class="line">print(<span class="string">'There are %d total characters and %d unique characters in your data.'</span> % (data_size, vocab_size))</span><br></pre></td></tr></table></figure>

<pre><code>There are 19909 total characters and 27 unique characters in your data.</code></pre><p>The characters are a-z (26 characters) plus the “\n” (or newline character), which in this assignment plays a role similar to the <code>&lt;EOS&gt;</code> (or “End of sentence”) token we had discussed in lecture, only here it indicates the end of the dinosaur name rather than the end of a sentence. In the cell below, we create a python dictionary (i.e., a hash table) to map each character to an index from 0-26. We also create a second python dictionary that maps each index back to the corresponding character character. This will help you figure out what index corresponds to what character in the probability distribution output of the softmax layer. Below, <code>char_to_ix</code> and <code>ix_to_char</code> are the python dictionaries. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">char_to_ix = &#123; ch:i <span class="keyword">for</span> i,ch <span class="keyword">in</span> enumerate(sorted(chars)) &#125;</span><br><span class="line">ix_to_char = &#123; i:ch <span class="keyword">for</span> i,ch <span class="keyword">in</span> enumerate(sorted(chars)) &#125;</span><br><span class="line">print(ix_to_char)</span><br></pre></td></tr></table></figure>

<pre><code>{0: &apos;\n&apos;, 1: &apos;a&apos;, 2: &apos;b&apos;, 3: &apos;c&apos;, 4: &apos;d&apos;, 5: &apos;e&apos;, 6: &apos;f&apos;, 7: &apos;g&apos;, 8: &apos;h&apos;, 9: &apos;i&apos;, 10: &apos;j&apos;, 11: &apos;k&apos;, 12: &apos;l&apos;, 13: &apos;m&apos;, 14: &apos;n&apos;, 15: &apos;o&apos;, 16: &apos;p&apos;, 17: &apos;q&apos;, 18: &apos;r&apos;, 19: &apos;s&apos;, 20: &apos;t&apos;, 21: &apos;u&apos;, 22: &apos;v&apos;, 23: &apos;w&apos;, 24: &apos;x&apos;, 25: &apos;y&apos;, 26: &apos;z&apos;}</code></pre><h3 id="1-2-Overview-of-the-model"><a href="#1-2-Overview-of-the-model" class="headerlink" title="1.2 - Overview of the model"></a>1.2 - Overview of the model</h3><p>Your model will have the following structure: </p>
<ul>
<li>Initialize parameters </li>
<li>Run the optimization loop<ul>
<li>Forward propagation to compute the loss function</li>
<li>Backward propagation to compute the gradients with respect to the loss function</li>
<li>Clip the gradients to avoid exploding gradients</li>
<li>Using the gradients, update your parameter with the gradient descent update rule.</li>
</ul>
</li>
<li>Return the learned parameters </li>
</ul>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/dinosaurus_island/images/rnn.png" style="width:450;height:300px;">
<caption><center> **Figure 1**: Recurrent Neural Network, similar to what you had built in the previous notebook "Building a RNN - Step by Step".  </center></caption>

<p>At each time-step, the RNN tries to predict what is the next character given the previous characters. The dataset $X = (x^{\langle 1 \rangle}, x^{\langle 2 \rangle}, …, x^{\langle T_x \rangle})$ is a list of characters in the training set, while $Y = (y^{\langle 1 \rangle}, y^{\langle 2 \rangle}, …, y^{\langle T_x \rangle})$ is such that at every time-step $t$, we have $y^{\langle t \rangle} = x^{\langle t+1 \rangle}$. </p>
<h2 id="2-Building-blocks-of-the-model"><a href="#2-Building-blocks-of-the-model" class="headerlink" title="2 - Building blocks of the model"></a>2 - Building blocks of the model</h2><p>In this part, you will build two important blocks of the overall model:</p>
<ul>
<li>Gradient clipping: to avoid exploding gradients</li>
<li>Sampling: a technique used to generate characters</li>
</ul>
<p>You will then apply these two functions to build the model.</p>
<h3 id="2-1-Clipping-the-gradients-in-the-optimization-loop"><a href="#2-1-Clipping-the-gradients-in-the-optimization-loop" class="headerlink" title="2.1 - Clipping the gradients in the optimization loop"></a>2.1 - Clipping the gradients in the optimization loop</h3><p>In this section you will implement the <code>clip</code> function that you will call inside of your optimization loop. Recall that your overall loop structure usually consists of a forward pass, a cost computation, a backward pass, and a parameter update. Before updating the parameters, you will perform gradient clipping when needed to make sure that your gradients are not “exploding,” meaning taking on overly large values. </p>
<p>In the exercise below, you will implement a function <code>clip</code> that takes in a dictionary of gradients and returns a clipped version of gradients if needed. There are different ways to clip gradients; we will use a simple element-wise clipping procedure, in which every element of the gradient vector is clipped to lie between some range [-N, N]. More generally, you will provide a <code>maxValue</code> (say 10). In this example, if any component of the gradient vector is greater than 10, it would be set to 10; and if any component of the gradient vector is less than -10, it would be set to -10. If it is between -10 and 10, it is left alone. </p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/dinosaurus_island/images/clip.png" style="width:400;height:150px;">
<caption><center> **Figure 2**: Visualization of gradient descent with and without gradient clipping, in a case where the network is running into slight "exploding gradient" problems. </center></caption>

<p><strong>Exercise</strong>: Implement the function below to return the clipped gradients of your dictionary <code>gradients</code>. Your function takes in a maximum threshold and returns the clipped versions of your gradients. You can check out this <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.clip.html" target="_blank" rel="noopener">hint</a> for examples of how to clip in numpy. You will need to use the argument <code>out = ...</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### GRADED FUNCTION: clip</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clip</span><span class="params">(gradients, maxValue)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Clips the gradients' values between minimum and maximum.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    gradients -- a dictionary containing the gradients "dWaa", "dWax", "dWya", "db", "dby"</span></span><br><span class="line"><span class="string">    maxValue -- everything above this number is set to this number, and everything less than -maxValue is set to -maxValue</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    gradients -- a dictionary with the clipped gradients.</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">    dWaa, dWax, dWya, db, dby = gradients[<span class="string">'dWaa'</span>], gradients[<span class="string">'dWax'</span>], gradients[<span class="string">'dWya'</span>], gradients[<span class="string">'db'</span>], gradients[<span class="string">'dby'</span>]</span><br><span class="line">   </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># clip to mitigate exploding gradients, loop over [dWax, dWaa, dWya, db, dby]. (≈2 lines)</span></span><br><span class="line">    <span class="keyword">for</span> gradient <span class="keyword">in</span> [dWax, dWaa, dWya, db, dby]:</span><br><span class="line">        np.clip(gradient, -maxValue, maxValue, out = gradient);</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    gradients = &#123;<span class="string">"dWaa"</span>: dWaa, <span class="string">"dWax"</span>: dWax, <span class="string">"dWya"</span>: dWya, <span class="string">"db"</span>: db, <span class="string">"dby"</span>: dby&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">3</span>)</span><br><span class="line">dWax = np.random.randn(<span class="number">5</span>,<span class="number">3</span>)*<span class="number">10</span></span><br><span class="line">dWaa = np.random.randn(<span class="number">5</span>,<span class="number">5</span>)*<span class="number">10</span></span><br><span class="line">dWya = np.random.randn(<span class="number">2</span>,<span class="number">5</span>)*<span class="number">10</span></span><br><span class="line">db = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)*<span class="number">10</span></span><br><span class="line">dby = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)*<span class="number">10</span></span><br><span class="line">gradients = &#123;<span class="string">"dWax"</span>: dWax, <span class="string">"dWaa"</span>: dWaa, <span class="string">"dWya"</span>: dWya, <span class="string">"db"</span>: db, <span class="string">"dby"</span>: dby&#125;</span><br><span class="line">gradients = clip(gradients, <span class="number">10</span>)</span><br><span class="line">print(<span class="string">"gradients[\"dWaa\"][1][2] ="</span>, gradients[<span class="string">"dWaa"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWax\"][3][1] ="</span>, gradients[<span class="string">"dWax"</span>][<span class="number">3</span>][<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWya\"][1][2] ="</span>, gradients[<span class="string">"dWya"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"db\"][4] ="</span>, gradients[<span class="string">"db"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dby\"][1] ="</span>, gradients[<span class="string">"dby"</span>][<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<pre><code>gradients[&quot;dWaa&quot;][1][2] = 10.0
gradients[&quot;dWax&quot;][3][1] = -10.0
gradients[&quot;dWya&quot;][1][2] = 0.2971381536101662
gradients[&quot;db&quot;][4] = [10.]
gradients[&quot;dby&quot;][1] = [8.45833407]</code></pre><p>** Expected output:**</p>
<table>
<tr>
    <td> 
    **gradients["dWaa"][1][2] **
    </td>
    <td> 
    10.0
    </td>
</tr>

<tr>
    <td> 
    **gradients["dWax"][3][1]**
    </td>
    <td> 
    -10.0
    </td>
    </td>
</tr>
<tr>
    <td> 
    **gradients["dWya"][1][2]**
    </td>
    <td> 
0.29713815361
    </td>
</tr>
<tr>
    <td> 
    **gradients["db"][4]**
    </td>
    <td> 
[ 10.]
    </td>
</tr>
<tr>
    <td> 
    **gradients["dby"][1]**
    </td>
    <td> 
[ 8.45833407]
    </td>
</tr>

</table>

<h3 id="2-2-Sampling"><a href="#2-2-Sampling" class="headerlink" title="2.2 - Sampling"></a>2.2 - Sampling</h3><p>Now assume that your model is trained. You would like to generate new text (characters). The process of generation is explained in the picture below:</p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/dinosaurus_island/images/dinos3.png" style="width:500;height:300px;">
<caption><center> **Figure 3**: In this picture, we assume the model is already trained. We pass in $x^{\langle 1\rangle} = \vec{0}$ at the first time step, and have the network then sample one character at a time. </center></caption>

<p><strong>Exercise</strong>: Implement the <code>sample</code> function below to sample characters. You need to carry out 4 steps:</p>
<ul>
<li><p><strong>Step 1</strong>: Pass the network the first “dummy” input $x^{\langle 1 \rangle} = \vec{0}$ (the vector of zeros). This is the default input before we’ve generated any characters. We also set $a^{\langle 0 \rangle} = \vec{0}$</p>
</li>
<li><p><strong>Step 2</strong>: Run one step of forward propagation to get $a^{\langle 1 \rangle}$ and $\hat{y}^{\langle 1 \rangle}$. Here are the equations:</p>
</li>
</ul>
<p>$$ a^{\langle t+1 \rangle} = \tanh(W_{ax}  x^{\langle t \rangle } + W_{aa} a^{\langle t \rangle } + b)\tag{1}$$</p>
<p>$$ z^{\langle t + 1 \rangle } = W_{ya}  a^{\langle t + 1 \rangle } + b_y \tag{2}$$</p>
<p>$$ \hat{y}^{\langle t+1 \rangle } = softmax(z^{\langle t + 1 \rangle })\tag{3}$$</p>
<p>Note that $\hat{y}^{\langle t+1 \rangle }$ is a (softmax) probability vector (its entries are between 0 and 1 and sum to 1). $\hat{y}^{\langle t+1 \rangle}_i$ represents the probability that the character indexed by “i” is the next character.  We have provided a <code>softmax()</code> function that you can use.</p>
<ul>
<li><strong>Step 3</strong>: Carry out sampling: Pick the next character’s index according to the probability distribution specified by $\hat{y}^{\langle t+1 \rangle }$. This means that if $\hat{y}^{\langle t+1 \rangle }_i = 0.16$, you will pick the index “i” with 16% probability. To implement it, you can use <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.choice.html" target="_blank" rel="noopener"><code>np.random.choice</code></a>.</li>
</ul>
<p>Here is an example of how to use <code>np.random.choice()</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">p = np.array([<span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.7</span>, <span class="number">0.2</span>])</span><br><span class="line">index = np.random.choice([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], p = p.ravel())</span><br></pre></td></tr></table></figure>
<p>This means that you will pick the <code>index</code> according to the distribution:<br>$P(index = 0) = 0.1, P(index = 1) = 0.0, P(index = 2) = 0.7, P(index = 3) = 0.2$.</p>
<ul>
<li><strong>Step 4</strong>: The last step to implement in <code>sample()</code> is to overwrite the variable <code>x</code>, which currently stores $x^{\langle t \rangle }$, with the value of $x^{\langle t + 1 \rangle }$. You will represent $x^{\langle t + 1 \rangle }$ by creating a one-hot vector corresponding to the character you’ve chosen as your prediction. You will then forward propagate $x^{\langle t + 1 \rangle }$ in Step 1 and keep repeating the process until you get a “\n” character, indicating you’ve reached the end of the dinosaur name. </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: sample</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(parameters, char_to_ix, seed)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Sample a sequence of characters according to a sequence of probability distributions output of the RNN</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing the parameters Waa, Wax, Wya, by, and b. </span></span><br><span class="line"><span class="string">    char_to_ix -- python dictionary mapping each character to an index.</span></span><br><span class="line"><span class="string">    seed -- used for grading purposes. Do not worry about it.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    indices -- a list of length n containing the indices of the sampled characters.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve parameters and relevant shapes from "parameters" dictionary</span></span><br><span class="line">    Waa, Wax, Wya, by, b = parameters[<span class="string">'Waa'</span>], parameters[<span class="string">'Wax'</span>], parameters[<span class="string">'Wya'</span>], parameters[<span class="string">'by'</span>], parameters[<span class="string">'b'</span>]</span><br><span class="line">    vocab_size = by.shape[<span class="number">0</span>]</span><br><span class="line">    n_a = Waa.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Step 1: Create the one-hot vector x for the first character (initializing the sequence generation). (≈1 line)</span></span><br><span class="line">    x = np.zeros((vocab_size, <span class="number">1</span>));</span><br><span class="line">    <span class="comment"># Step 1': Initialize a_prev as zeros (≈1 line)</span></span><br><span class="line">    a_prev = np.zeros((n_a, <span class="number">1</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create an empty list of indices, this is the list which will contain the list of indices of the characters to generate (≈1 line)</span></span><br><span class="line">    indices = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Idx is a flag to detect a newline character, we initialize it to -1</span></span><br><span class="line">    idx = <span class="number">-1</span> </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop over time-steps t. At each time-step, sample a character from a probability distribution and append </span></span><br><span class="line">    <span class="comment"># its index to "indices". We'll stop if we reach 50 characters (which should be very unlikely with a well </span></span><br><span class="line">    <span class="comment"># trained model), which helps debugging and prevents entering an infinite loop. </span></span><br><span class="line">    counter = <span class="number">0</span></span><br><span class="line">    newline_character = char_to_ix[<span class="string">'\n'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (idx != newline_character <span class="keyword">and</span> counter != <span class="number">50</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2: Forward propagate x using the equations (1), (2) and (3)</span></span><br><span class="line">        a = np.tanh(np.dot(Wax, x) + np.dot(Waa, a_prev) + b);</span><br><span class="line">        z = np.dot(Wya, a) + by;</span><br><span class="line">        y = softmax(z);</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># for grading purposes</span></span><br><span class="line">        np.random.seed(counter+seed) </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 3: Sample the index of a character within the vocabulary from the probability distribution y</span></span><br><span class="line">        idx = np.random.choice(range(len(y)), p = y.ravel());</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Append the index to "indices"</span></span><br><span class="line">        indices.append(idx);</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 4: Overwrite the input character as the one corresponding to the sampled index.</span></span><br><span class="line">        x = np.zeros((vocab_size, <span class="number">1</span>));</span><br><span class="line">        x[idx] = <span class="number">1</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Update "a_prev" to be "a"</span></span><br><span class="line">        a_prev = a;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># for grading purposes</span></span><br><span class="line">        seed += <span class="number">1</span></span><br><span class="line">        counter +=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (counter == <span class="number">50</span>):</span><br><span class="line">        indices.append(char_to_ix[<span class="string">'\n'</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> indices</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">2</span>)</span><br><span class="line">_, n_a = <span class="number">20</span>, <span class="number">100</span></span><br><span class="line">Wax, Waa, Wya = np.random.randn(n_a, vocab_size), np.random.randn(n_a, n_a), np.random.randn(vocab_size, n_a)</span><br><span class="line">b, by = np.random.randn(n_a, <span class="number">1</span>), np.random.randn(vocab_size, <span class="number">1</span>)</span><br><span class="line">parameters = &#123;<span class="string">"Wax"</span>: Wax, <span class="string">"Waa"</span>: Waa, <span class="string">"Wya"</span>: Wya, <span class="string">"b"</span>: b, <span class="string">"by"</span>: by&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">indices = sample(parameters, char_to_ix, <span class="number">0</span>)</span><br><span class="line">print(<span class="string">"Sampling:"</span>)</span><br><span class="line">print(<span class="string">"list of sampled indices:"</span>, indices)</span><br><span class="line">print(<span class="string">"list of sampled characters:"</span>, [ix_to_char[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices])</span><br></pre></td></tr></table></figure>

<pre><code>Sampling:
list of sampled indices: [12, 17, 24, 14, 13, 9, 10, 22, 24, 6, 13, 11, 12, 6, 21, 15, 21, 14, 3, 2, 1, 21, 18, 24, 7, 25, 6, 25, 18, 10, 16, 2, 3, 8, 15, 12, 11, 7, 1, 12, 10, 2, 7, 7, 11, 3, 6, 23, 13, 1, 0]
list of sampled characters: [&apos;l&apos;, &apos;q&apos;, &apos;x&apos;, &apos;n&apos;, &apos;m&apos;, &apos;i&apos;, &apos;j&apos;, &apos;v&apos;, &apos;x&apos;, &apos;f&apos;, &apos;m&apos;, &apos;k&apos;, &apos;l&apos;, &apos;f&apos;, &apos;u&apos;, &apos;o&apos;, &apos;u&apos;, &apos;n&apos;, &apos;c&apos;, &apos;b&apos;, &apos;a&apos;, &apos;u&apos;, &apos;r&apos;, &apos;x&apos;, &apos;g&apos;, &apos;y&apos;, &apos;f&apos;, &apos;y&apos;, &apos;r&apos;, &apos;j&apos;, &apos;p&apos;, &apos;b&apos;, &apos;c&apos;, &apos;h&apos;, &apos;o&apos;, &apos;l&apos;, &apos;k&apos;, &apos;g&apos;, &apos;a&apos;, &apos;l&apos;, &apos;j&apos;, &apos;b&apos;, &apos;g&apos;, &apos;g&apos;, &apos;k&apos;, &apos;c&apos;, &apos;f&apos;, &apos;w&apos;, &apos;m&apos;, &apos;a&apos;, &apos;\n&apos;]</code></pre><p><strong>Expected output:</strong></p>
<table>
<tr>
    <td> 
    **list of sampled indices:**
    </td>
    <td> 
    [12, 17, 24, 14, 13, 9, 10, 22, 24, 6, 13, 11, 12, 6, 21, 15, 21, 14, 3, 2, 1, 21, 18, 24, <br>
    7, 25, 6, 25, 18, 10, 16, 2, 3, 8, 15, 12, 11, 7, 1, 12, 10, 2, 7, 7, 11, 5, 6, 12, 25, 0, 0]
    </td>
    </tr><tr>
    <td> 
    **list of sampled characters:**
    </td>
    <td> 
    ['l', 'q', 'x', 'n', 'm', 'i', 'j', 'v', 'x', 'f', 'm', 'k', 'l', 'f', 'u', 'o', <br>
    'u', 'n', 'c', 'b', 'a', 'u', 'r', 'x', 'g', 'y', 'f', 'y', 'r', 'j', 'p', 'b', 'c', 'h', 'o', <br>
    'l', 'k', 'g', 'a', 'l', 'j', 'b', 'g', 'g', 'k', 'e', 'f', 'l', 'y', '\n', '\n']
    </td>
</tr>
</table>

<h2 id="3-Building-the-language-model"><a href="#3-Building-the-language-model" class="headerlink" title="3 - Building the language model"></a>3 - Building the language model</h2><p>It is time to build the character-level language model for text generation. </p>
<h3 id="3-1-Gradient-descent"><a href="#3-1-Gradient-descent" class="headerlink" title="3.1 - Gradient descent"></a>3.1 - Gradient descent</h3><p>In this section you will implement a function performing one step of stochastic gradient descent (with clipped gradients). You will go through the training examples one at a time, so the optimization algorithm will be stochastic gradient descent. As a reminder, here are the steps of a common optimization loop for an RNN:</p>
<ul>
<li>Forward propagate through the RNN to compute the loss</li>
<li>Backward propagate through time to compute the gradients of the loss with respect to the parameters</li>
<li>Clip the gradients if necessary </li>
<li>Update your parameters using gradient descent </li>
</ul>
<p><strong>Exercise</strong>: Implement this optimization process (one step of stochastic gradient descent). </p>
<p>We provide you with the following functions: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_forward</span><span class="params">(X, Y, a_prev, parameters)</span>:</span></span><br><span class="line">    <span class="string">""" Performs the forward propagation through the RNN and computes the cross-entropy loss.</span></span><br><span class="line"><span class="string">    It returns the loss' value as well as a "cache" storing values to be used in the backpropagation."""</span></span><br><span class="line">    ....</span><br><span class="line">    <span class="keyword">return</span> loss, cache</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_backward</span><span class="params">(X, Y, parameters, cache)</span>:</span></span><br><span class="line">    <span class="string">""" Performs the backward propagation through time to compute the gradients of the loss with respect</span></span><br><span class="line"><span class="string">    to the parameters. It returns also all the hidden states."""</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> gradients, a</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, gradients, learning_rate)</span>:</span></span><br><span class="line">    <span class="string">""" Updates parameters using the Gradient Descent Update Rule."""</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: optimize</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimize</span><span class="params">(X, Y, a_prev, parameters, learning_rate = <span class="number">0.01</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Execute one step of the optimization to train the model.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- list of integers, where each integer is a number that maps to a character in the vocabulary.</span></span><br><span class="line"><span class="string">    Y -- list of integers, exactly the same as X but shifted one index to the left.</span></span><br><span class="line"><span class="string">    a_prev -- previous hidden state.</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing:</span></span><br><span class="line"><span class="string">                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)</span></span><br><span class="line"><span class="string">                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)</span></span><br><span class="line"><span class="string">                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)</span></span><br><span class="line"><span class="string">                        b --  Bias, numpy array of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate for the model.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    loss -- value of the loss function (cross-entropy)</span></span><br><span class="line"><span class="string">    gradients -- python dictionary containing:</span></span><br><span class="line"><span class="string">                        dWax -- Gradients of input-to-hidden weights, of shape (n_a, n_x)</span></span><br><span class="line"><span class="string">                        dWaa -- Gradients of hidden-to-hidden weights, of shape (n_a, n_a)</span></span><br><span class="line"><span class="string">                        dWya -- Gradients of hidden-to-output weights, of shape (n_y, n_a)</span></span><br><span class="line"><span class="string">                        db -- Gradients of bias vector, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        dby -- Gradients of output bias vector, of shape (n_y, 1)</span></span><br><span class="line"><span class="string">    a[len(X)-1] -- the last hidden state, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Forward propagate through time (≈1 line)</span></span><br><span class="line">    loss, cache = rnn_forward(X, Y, a_prev, parameters);</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backpropagate through time (≈1 line)</span></span><br><span class="line">    gradients, a = rnn_backward(X, Y, parameters, cache);</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Clip your gradients between -5 (min) and 5 (max) (≈1 line)</span></span><br><span class="line">    gradients = clip(gradients, maxValue = <span class="number">5</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Update parameters (≈1 line)</span></span><br><span class="line">    parameters = update_parameters(parameters, gradients, learning_rate);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss, gradients, a[len(X)<span class="number">-1</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">vocab_size, n_a = <span class="number">27</span>, <span class="number">100</span></span><br><span class="line">a_prev = np.random.randn(n_a, <span class="number">1</span>)</span><br><span class="line">Wax, Waa, Wya = np.random.randn(n_a, vocab_size), np.random.randn(n_a, n_a), np.random.randn(vocab_size, n_a)</span><br><span class="line">b, by = np.random.randn(n_a, <span class="number">1</span>), np.random.randn(vocab_size, <span class="number">1</span>)</span><br><span class="line">parameters = &#123;<span class="string">"Wax"</span>: Wax, <span class="string">"Waa"</span>: Waa, <span class="string">"Wya"</span>: Wya, <span class="string">"b"</span>: b, <span class="string">"by"</span>: by&#125;</span><br><span class="line">X = [<span class="number">12</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">11</span>,<span class="number">22</span>,<span class="number">3</span>]</span><br><span class="line">Y = [<span class="number">4</span>,<span class="number">14</span>,<span class="number">11</span>,<span class="number">22</span>,<span class="number">25</span>, <span class="number">26</span>]</span><br><span class="line"></span><br><span class="line">loss, gradients, a_last = optimize(X, Y, a_prev, parameters, learning_rate = <span class="number">0.01</span>)</span><br><span class="line">print(<span class="string">"Loss ="</span>, loss)</span><br><span class="line">print(<span class="string">"gradients[\"dWaa\"][1][2] ="</span>, gradients[<span class="string">"dWaa"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"np.argmax(gradients[\"dWax\"]) ="</span>, np.argmax(gradients[<span class="string">"dWax"</span>]))</span><br><span class="line">print(<span class="string">"gradients[\"dWya\"][1][2] ="</span>, gradients[<span class="string">"dWya"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"db\"][4] ="</span>, gradients[<span class="string">"db"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dby\"][1] ="</span>, gradients[<span class="string">"dby"</span>][<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"a_last[4] ="</span>, a_last[<span class="number">4</span>])</span><br></pre></td></tr></table></figure>

<pre><code>Loss = 126.50397572165383
gradients[&quot;dWaa&quot;][1][2] = 0.1947093153471825
np.argmax(gradients[&quot;dWax&quot;]) = 93
gradients[&quot;dWya&quot;][1][2] = -0.007773876032003897
gradients[&quot;db&quot;][4] = [-0.06809825]
gradients[&quot;dby&quot;][1] = [0.01538192]
a_last[4] = [-1.]</code></pre><p><strong>Expected output:</strong></p>
<table>


<tr>
    <td> 
    **Loss **
    </td>
    <td> 
    126.503975722
    </td>
</tr>
<tr>
    <td> 
    **gradients["dWaa"][1][2]**
    </td>
    <td> 
    0.194709315347
    </td>
<tr>
    <td> 
    **np.argmax(gradients["dWax"])**
    </td>
    <td> 93
    </td>
</tr>
<tr>
    <td> 
    **gradients["dWya"][1][2]**
    </td>
    <td> -0.007773876032
    </td>
</tr>
<tr>
    <td> 
    **gradients["db"][4]**
    </td>
    <td> [-0.06809825]
    </td>
</tr>
<tr>
    <td> 
    **gradients["dby"][1]**
    </td>
    <td>[ 0.01538192]
    </td>
</tr>
<tr>
    <td> 
    **a_last[4]**
    </td>
    <td> [-1.]
    </td>
</tr>

</table>

<h3 id="3-2-Training-the-model"><a href="#3-2-Training-the-model" class="headerlink" title="3.2 - Training the model"></a>3.2 - Training the model</h3><p>Given the dataset of dinosaur names, we use each line of the dataset (one name) as one training example. Every 100 steps of stochastic gradient descent, you will sample 10 randomly chosen names to see how the algorithm is doing. Remember to shuffle the dataset, so that stochastic gradient descent visits the examples in random order. </p>
<p><strong>Exercise</strong>: Follow the instructions and implement <code>model()</code>. When <code>examples[index]</code> contains one dinosaur name (string), to create an example (X, Y), you can use this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">index = j % len(examples)</span><br><span class="line">X = [<span class="literal">None</span>] + [char_to_ix[ch] <span class="keyword">for</span> ch <span class="keyword">in</span> examples[index]] </span><br><span class="line">Y = X[<span class="number">1</span>:] + [char_to_ix[<span class="string">"\n"</span>]]</span><br></pre></td></tr></table></figure>
<p>Note that we use: <code>index= j % len(examples)</code>, where <code>j = 1....num_iterations</code>, to make sure that <code>examples[index]</code> is always a valid statement (<code>index</code> is smaller than <code>len(examples)</code>).<br>The first entry of <code>X</code> being <code>None</code> will be interpreted by <code>rnn_forward()</code> as setting $x^{\langle 0 \rangle} = \vec{0}$. Further, this ensures that <code>Y</code> is equal to <code>X</code> but shifted one step to the left, and with an additional “\n” appended to signify the end of the dinosaur name. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: model</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(data, ix_to_char, char_to_ix, num_iterations = <span class="number">35000</span>, n_a = <span class="number">50</span>, dino_names = <span class="number">7</span>, vocab_size = <span class="number">27</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Trains the model and generates dinosaur names. </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    data -- text corpus</span></span><br><span class="line"><span class="string">    ix_to_char -- dictionary that maps the index to a character</span></span><br><span class="line"><span class="string">    char_to_ix -- dictionary that maps a character to an index</span></span><br><span class="line"><span class="string">    num_iterations -- number of iterations to train the model for</span></span><br><span class="line"><span class="string">    n_a -- number of units of the RNN cell</span></span><br><span class="line"><span class="string">    dino_names -- number of dinosaur names you want to sample at each iteration. </span></span><br><span class="line"><span class="string">    vocab_size -- number of unique characters found in the text, size of the vocabulary</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- learned parameters</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve n_x and n_y from vocab_size</span></span><br><span class="line">    n_x, n_y = vocab_size, vocab_size</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize parameters</span></span><br><span class="line">    parameters = initialize_parameters(n_a, n_x, n_y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize loss (this is required because we want to smooth our loss, don't worry about it)</span></span><br><span class="line">    loss = get_initial_loss(vocab_size, dino_names)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build list of all dinosaur names (training examples).</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"dinos.txt"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        examples = f.readlines()</span><br><span class="line">    examples = [x.lower().strip() <span class="keyword">for</span> x <span class="keyword">in</span> examples]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Shuffle list of all dinosaur names</span></span><br><span class="line">    np.random.seed(<span class="number">0</span>)</span><br><span class="line">    np.random.shuffle(examples)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize the hidden state of your LSTM</span></span><br><span class="line">    a_prev = np.zeros((n_a, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Optimization loop</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(num_iterations):</span><br><span class="line"></span><br><span class="line">        <span class="comment">### START CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Use the hint above to define one training example (X,Y) (≈ 2 lines)</span></span><br><span class="line">        index = j % len(examples);</span><br><span class="line">        X = [<span class="literal">None</span>] + [char_to_ix[ch] <span class="keyword">for</span> ch <span class="keyword">in</span> examples[index]];</span><br><span class="line">        Y = X[<span class="number">1</span>:] + [char_to_ix[<span class="string">"\n"</span>]];</span><br><span class="line"></span><br><span class="line">        learning_rate = <span class="number">0.01</span>;</span><br><span class="line">        <span class="comment"># num_partition = num_iterations / 10; </span></span><br><span class="line">        <span class="comment"># if j / num_partition &gt; 0 :</span></span><br><span class="line">        <span class="comment">#    if j % num_partition == 0 :</span></span><br><span class="line">        <span class="comment">#        learning_rate = 0.01 * (0.95 ** (j / num_partition));   </span></span><br><span class="line">        <span class="comment">#        print("current learning rate: " + str(learning_rate));</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Perform one optimization step: Forward-prop -&gt; Backward-prop -&gt; Clip -&gt; Update parameters</span></span><br><span class="line">        <span class="comment"># Choose a learning rate of 0.01</span></span><br><span class="line">        curr_loss, gradients, a_prev = optimize(X, Y, a_prev, parameters, learning_rate);</span><br><span class="line"></span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Use a latency trick to keep the loss smooth. It happens here to accelerate the training.</span></span><br><span class="line">        loss = smooth(loss, curr_loss)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Every 2000 Iteration, generate "n" characters thanks to sample() to check if the model is learning properly</span></span><br><span class="line">        <span class="keyword">if</span> j % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">            print(<span class="string">'Iteration: %d, Loss: %f'</span> % (j, loss) + <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># The number of dinosaur names to print</span></span><br><span class="line">            seed = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> name <span class="keyword">in</span> range(dino_names):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Sample indices and print them</span></span><br><span class="line">                sampled_indices = sample(parameters, char_to_ix, seed)</span><br><span class="line">                print_sample(sampled_indices, ix_to_char)</span><br><span class="line"></span><br><span class="line">                seed += <span class="number">1</span>  <span class="comment"># To get the same result for grading purposed, increment the seed by one. </span></span><br><span class="line"></span><br><span class="line">            print(<span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>

<p>Run the following cell, you should observe your model outputting random-looking characters at the first iteration. After a few thousand iterations, your model should learn to generate reasonable-looking names. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(data, ix_to_char, char_to_ix)</span><br></pre></td></tr></table></figure>

<pre><code>Iteration: 0, Loss: 23.087336

Nkzxwtdmfqoeyhsqwasjkjvu
Kneb
Kzxwtdmfqoeyhsqwasjkjvu
Neb
Zxwtdmfqoeyhsqwasjkjvu
Eb
Xwtdmfqoeyhsqwasjkjvu


Iteration: 2000, Loss: 27.884160

Liusskeomnolxeros
Hmdaairus
Hytroligoraurus
Lecalosapaus
Xusicikoraurus
Abalpsamantisaurus
Tpraneronxeros


Iteration: 4000, Loss: 25.901815

Mivrosaurus
Inee
Ivtroplisaurus
Mbaaisaurus
Wusichisaurus
Cabaselachus
Toraperlethosdarenitochusthiamamumamaon


Iteration: 6000, Loss: 24.608779

Onwusceomosaurus
Lieeaerosaurus
Lxussaurus
Oma
Xusteonosaurus
Eeahosaurus
Toreonosaurus


Iteration: 8000, Loss: 24.070350

Onxusichepriuon
Kilabersaurus
Lutrodon
Omaaerosaurus
Xutrcheps
Edaksoje
Trodiktonus


Iteration: 10000, Loss: 23.844446

Onyusaurus
Klecalosaurus
Lustodon
Ola
Xusodonia
Eeaeosaurus
Troceosaurus


Iteration: 12000, Loss: 23.291971

Onyxosaurus
Kica
Lustrepiosaurus
Olaagrraiansaurus
Yuspangosaurus
Eealosaurus
Trognesaurus


Iteration: 14000, Loss: 23.382339

Meutromodromurus
Inda
Iutroinatorsaurus
Maca
Yusteratoptititan
Ca
Troclosaurus


Iteration: 16000, Loss: 23.259291

Meustomia
Indaadps
Justolongchudosatrus
Macabosaurus
Yuspanhosaurus
Caaerosaurus
Trodon


Iteration: 18000, Loss: 22.940799

Phusaurus
Meicamitheastosaurus
Mussteratops
Peg
Ytrong
Egaltor
Trolome


Iteration: 20000, Loss: 22.894192

Meutrodon
Lledansteh
Lwuspconyxauosaurus
Macalosaurus
Yusocichugus
Eiagosaurus
Trrangosaurus


Iteration: 22000, Loss: 22.851820

Onustolia
Midcagosaurus
Mwrrodonnonus
Ola
Yurodon
Eiaeptia
Trodoniohus


Iteration: 24000, Loss: 22.700408

Meutosaurus
Jmacagosaurus
Kurrodon
Macaistel
Yuroeleton
Eiaeror
Trodonosaurus


Iteration: 26000, Loss: 22.736918

Niutosaurus
Liga
Lustoingosaurus
Necakroia
Xrprinhtilus
Eiaestehastes
Trocilosaurus


Iteration: 28000, Loss: 22.595568

Meutosaurus
Kolaaeus
Kystodonisaurus
Macahtopadrus
Xtrrararkaumurpasaurus
Eiaeosaurus
Trodmanolus


Iteration: 30000, Loss: 22.609381

Meutosaurus
Kracakosaurus
Lustodon
Macaisthachwisaurus
Wusqandosaurus
Eiacosaurus
Trsatisaurus


Iteration: 32000, Loss: 22.251308

Mausinasaurus
Incaadropeglsaurus
Itrosaurus
Macamisaurus
Wuroenatoraerax
Ehanosaurus
Trnanclodratosaurus


Iteration: 34000, Loss: 22.477910

Mawspichaniaekorocimamroberax
Inda
Itrus
Macaesis
Wrosaurus
Elaeosaurus
Stegngosaurus</code></pre><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>You can see that your algorithm has started to generate plausible dinosaur names towards the end of the training. At first, it was generating random characters, but towards the end you could see dinosaur names with cool endings. Feel free to run the algorithm even longer and play with hyperparameters to see if you can get even better results. Our implemetation generated some really cool names like <code>maconucon</code>, <code>marloralus</code> and <code>macingsersaurus</code>. Your model hopefully also learned that dinosaur names tend to end in <code>saurus</code>, <code>don</code>, <code>aura</code>, <code>tor</code>, etc.</p>
<p>If your model generates some non-cool names, don’t blame the model entirely–not all actual dinosaur names sound cool. (For example, <code>dromaeosauroides</code> is an actual dinosaur name and is in the training set.) But this model should give you a set of candidates from which you can pick the coolest! </p>
<p>This assignment had used a relatively small dataset, so that you could train an RNN quickly on a CPU. Training a model of the english language requires a much bigger dataset, and usually needs much more computation, and could run for many hours on GPUs. We ran our dinosaur name for quite some time, and so far our favoriate name is the great, undefeatable, and fierce: Mangosaurus!</p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/dinosaurus_island/images/mangosaurus.jpeg" style="width:250;height:300px;">

<h2 id="4-Writing-like-Shakespeare"><a href="#4-Writing-like-Shakespeare" class="headerlink" title="4 - Writing like Shakespeare"></a>4 - Writing like Shakespeare</h2><p>The rest of this notebook is optional and is not graded, but we hope you’ll do it anyway since it’s quite fun and informative. </p>
<p>A similar (but more complicated) task is to generate Shakespeare poems. Instead of learning from a dataset of Dinosaur names you can use a collection of Shakespearian poems. Using LSTM cells, you can learn longer term dependencies that span many characters in the text–e.g., where a character appearing somewhere a sequence can influence what should be a different character much much later in ths sequence. These long term dependencies were less important with dinosaur names, since the names were quite short. </p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/dinosaurus_island/images/shakespeare.jpg" style="width:500;height:400px;">
<caption><center> Let's become poets! </center></caption>

<p>We have implemented a Shakespeare poem generator with Keras. Run the following cell to load the required packages and models. This may take a few minutes. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> LambdaCallback</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model, load_model, Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Activation, Dropout, Input, Masking</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> keras.utils.data_utils <span class="keyword">import</span> get_file</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">from</span> shakespeare_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> io</span><br></pre></td></tr></table></figure>

<pre><code>C:\Anaconda3\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.


Loading text data...
Creating training set...
number of training examples: 31412
Vectorizing training set...
Loading model...</code></pre><p>To save you some time, we have already trained a model for ~1000 epochs on a collection of Shakespearian poems called <a href="shakespeare.txt">*”The Sonnets”*</a>. </p>
<p>Let’s train the model for one more epoch. When it finishes training for an epoch—this will also take a few minutes—you can run <code>generate_output</code>, which will prompt asking you for an input (<code>&lt;</code>40 characters). The poem will start with your sentence, and our RNN-Shakespeare will complete the rest of the poem for you! For example, try “Forsooth this maketh no sense “ (don’t enter the quotation marks). Depending on whether you include the space at the end, your results might also differ–try it both ways, and try other inputs as well. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print_callback = LambdaCallback(on_epoch_end=on_epoch_end)</span><br><span class="line"></span><br><span class="line">model.fit(x, y, batch_size=<span class="number">128</span>, epochs=<span class="number">1</span>, callbacks=[print_callback])</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/1
31412/31412 [==============================] - 244s 8ms/step - loss: 2.7302





&lt;keras.callbacks.History at 0x1c3ef0e8978&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run this cell to try with different inputs without having to re-train the model </span></span><br><span class="line">generate_output()</span><br></pre></td></tr></table></figure>

<pre><code>Write the beginning of your poem, the Shakespeare machine will complete it. Your input is: You are a flower


Here is your poem: 

You are a flower,
and tines wo why doaoty loving friel be lifles it,


whene the ford, eoreing oned his byfor mine,
the beauty astore, with the dune still weel,
doth nof berioner others should best ay commors shall&apos;s feel how the,
ti the vere datef me wenden conse,
now this, and mateh and haris by deigh doy,
how raccersake wiming to be the worlts in thine
sho nuch their astaver beloned i ustind,
that youn thou </code></pre><p>The RNN-Shakespeare model is very similar to the one you have built for dinosaur names. The only major differences are:</p>
<ul>
<li>LSTMs instead of the basic RNN to capture longer-range dependencies</li>
<li>The model is a deeper, stacked LSTM model (2 layer)</li>
<li>Using Keras instead of python to simplify the code </li>
</ul>
<p>If you want to learn more, you can also check out the Keras Team’s text generation implementation on GitHub: <a href="https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py" target="_blank" rel="noopener">https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py</a>.</p>
<p>Congratulations on finishing this notebook! </p>
<p><strong>References</strong>:</p>
<ul>
<li>This exercise took inspiration from Andrej Karpathy’s implementation: <a href="https://gist.github.com/karpathy/d4dee566867f8291f086" target="_blank" rel="noopener">https://gist.github.com/karpathy/d4dee566867f8291f086</a>. To learn more about text generation, also check out Karpathy’s <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">blog post</a>.</li>
<li>For the Shakespearian poem generator, our implementation was based on the implementation of an LSTM text generator by the Keras team: <a href="https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py" target="_blank" rel="noopener">https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py</a> </li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/06/02/Improvise+a+Jazz+Solo+with+an+LSTM+Network+-+v3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/02/Improvise+a+Jazz+Solo+with+an+LSTM+Network+-+v3/" class="post-title-link" itemprop="url">Improvise a Jazz Solo with an LSTM Network</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-06-02 00:00:00" itemprop="dateCreated datePublished" datetime="2018-06-02T00:00:00+05:30">2018-06-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 04:37:42" itemprop="dateModified" datetime="2020-04-09T04:37:42+05:30">2020-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/English/" itemprop="url" rel="index"><span itemprop="name">English</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>159k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>2:24</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>This is one of my personal programming assignments after studying the course <a href="https://www.coursera.org/learn/nlp-sequence-models/" target="_blank" rel="noopener">nlp sequence models</a> at the 1st week and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.</p>
<h1 id="Improvise-a-Jazz-Solo-with-an-LSTM-Network"><a href="#Improvise-a-Jazz-Solo-with-an-LSTM-Network" class="headerlink" title="Improvise a Jazz Solo with an LSTM Network"></a>Improvise a Jazz Solo with an LSTM Network</h1><p>Welcome to your final programming assignment of this week! In this notebook, you will implement a model that uses an LSTM to generate music. You will even be able to listen to your own music at the end of the assignment. </p>
<p><strong>You will learn to:</strong></p>
<ul>
<li>Apply an LSTM to music generation.</li>
<li>Generate your own jazz music with deep learning.</li>
</ul>
<p>Please run the following cell to load all the packages required in this assignment. This may take a few minutes. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> IPython</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> music21 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> grammar <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> qa <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> preprocess <span class="keyword">import</span> * </span><br><span class="line"><span class="keyword">from</span> music_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> data_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model, Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector</span><br><span class="line"><span class="keyword">from</span> keras.initializers <span class="keyword">import</span> glorot_uniform</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br></pre></td></tr></table></figure>

<pre><code>Using TensorFlow backend.</code></pre><h2 id="1-Problem-statement"><a href="#1-Problem-statement" class="headerlink" title="1 - Problem statement"></a>1 - Problem statement</h2><p>You would like to create a jazz music piece specially for a friend’s birthday. However, you don’t know any instruments or music composition. Fortunately, you know deep learning and will solve this problem using an LSTM netwok.  </p>
<p>You will train a network to generate novel jazz solos in a style representative of a body of performed work.</p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/images/jazz.jpg" style="width:450;height:300px;">


<h3 id="1-1-Dataset"><a href="#1-1-Dataset" class="headerlink" title="1.1 - Dataset"></a>1.1 - Dataset</h3><p>You will train your algorithm on a corpus of Jazz music. Run the cell below to listen to a snippet of the audio from the training set:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IPython.display.Audio(<span class="string">'./data/30s_seq.mp3'</span>)</span><br></pre></td></tr></table></figure>


<pre><code>&lt;audio controls=&quot;controls&quot; &gt;
    &lt;source src=&quot;http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/data/30s_seq.mp3&quot; type=&quot;audio/mpeg&quot; /&gt;
    Your browser does not support the audio element.
&lt;/audio&gt;</code></pre><p>We have taken care of the preprocessing of the musical data to render it in terms of musical “values.” You can informally think of each “value” as a note, which comprises a pitch and a duration. For example, if you press down a specific piano key for 0.5 seconds, then you have just played a note. In music theory, a “value” is actually more complicated than this–specifically, it also captures the information needed to play multiple notes at the same time. For example, when playing a music piece, you might press down two piano keys at the same time (playng multiple notes at the same time generates what’s called a “chord”). But we don’t need to worry about the details of music theory for this assignment. For the purpose of this assignment, all you need to know is that we will obtain a dataset of values, and will learn an RNN model to generate sequences of values. </p>
<p>Our music generation system will use 78 unique values. Run the following code to load the raw music data and preprocess it into values. This might take a few minutes.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X, Y, n_values, indices_values = load_music_utils()</span><br><span class="line">print(<span class="string">'shape of X:'</span>, X.shape)</span><br><span class="line">print(<span class="string">'number of training examples:'</span>, X.shape[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">'Tx (length of sequence):'</span>, X.shape[<span class="number">1</span>])</span><br><span class="line">print(<span class="string">'total # of unique values:'</span>, n_values)</span><br><span class="line">print(<span class="string">'Shape of Y:'</span>, Y.shape)</span><br></pre></td></tr></table></figure>

<pre><code>shape of X: (60, 30, 78)
number of training examples: 60
Tx (length of sequence): 30
total # of unique values: 78
Shape of Y: (30, 60, 78)</code></pre><p>You have just loaded the following:</p>
<ul>
<li><p><code>X</code>: This is an (m, $T_x$, 78) dimensional array. We have m training examples, each of which is a snippet of $T_x =30$ musical values. At each time step, the input is one of 78 different possible values, represented as a one-hot vector. Thus for example, X[i,t,:] is a one-hot vector representating the value of the i-th example at time t. </p>
</li>
<li><p><code>Y</code>: This is essentially the same as <code>X</code>, but shifted one step to the left (to the past). Similar to the dinosaurus assignment, we’re interested in the network using the previous values to predict the next value, so our sequence model will try to predict $y^{\langle t \rangle}$ given $x^{\langle 1\rangle}, \ldots, x^{\langle t \rangle}$. However, the data in <code>Y</code> is reordered to be dimension $(T_y, m, 78)$, where $T_y = T_x$. This format makes it more convenient to feed to the LSTM later. </p>
</li>
<li><p><code>n_values</code>: The number of unique values in this dataset. This should be 78. </p>
</li>
<li><p><code>indices_values</code>: python dictionary mapping from 0-77 to musical values.</p>
</li>
</ul>
<h3 id="1-2-Overview-of-our-model"><a href="#1-2-Overview-of-our-model" class="headerlink" title="1.2 - Overview of our model"></a>1.2 - Overview of our model</h3><p>Here is the architecture of the model we will use. This is similar to the Dinosaurus model you had used in the previous notebook, except that in you will be implementing it in Keras. The architecture is as follows: </p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/images/music_generation.png" style="width:600;height:400px;">

<!--
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/images/djmodel.png" style="width:600;height:400px;">
<br>
<caption><center> **Figure 1**: LSTM model. $X = (x^{\langle 1 \rangle}, x^{\langle 2 \rangle}, ..., x^{\langle T_x \rangle})$ is a window of size $T_x$ scanned over the musical corpus. Each $x^{\langle t \rangle}$ is an index corresponding to a value (ex: "A,0.250,< m2,P-4 >") while $\hat{y}$ is the prediction for the next value  </center></caption>
!--> 

<p>We will be training the model on random snippets of 30 values taken from a much longer piece of music. Thus, we won’t bother to set the first input $x^{\langle 1 \rangle} = \vec{0}$, which we had done previously to denote the start of a dinosaur name, since now most of these snippets of audio start somewhere in the middle of a piece of music. We are setting each of the snippts to have the same length $T_x = 30$ to make vectorization easier. </p>
<h2 id="2-Building-the-model"><a href="#2-Building-the-model" class="headerlink" title="2 - Building the model"></a>2 - Building the model</h2><p>In this part you will build and train a model that will learn musical patterns. To do so, you will need to build a model that takes in X of shape $(m, T_x, 78)$ and Y of shape $(T_y, m, 78)$. We will use an LSTM with 64 dimensional hidden states. Lets set <code>n_a = 64</code>. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n_a = <span class="number">64</span></span><br></pre></td></tr></table></figure>


<p>Here’s how you can create a Keras model with multiple inputs and outputs. If you’re building an RNN where even at test time entire input sequence $x^{\langle 1 \rangle}, x^{\langle 2 \rangle}, \ldots, x^{\langle T_x \rangle}$ were <em>given in advance</em>, for example if the inputs were words and the output was a label, then Keras has simple built-in functions to build the model. However, for sequence generation, at test time we don’t know all the values of $x^{\langle t\rangle}$ in advance; instead we generate them one at a time using $x^{\langle t\rangle} = y^{\langle t-1 \rangle}$. So the code will be a bit more complicated, and you’ll need to implement your own for-loop to iterate over the different time steps. </p>
<p>The function <code>djmodel()</code> will call the LSTM layer $T_x$ times using a for-loop, and it is important that all $T_x$ copies have the same weights. I.e., it should not re-initiaiize the weights every time—the $T_x$ steps should have shared weights. The key steps for implementing layers with shareable weights in Keras are: </p>
<ol>
<li>Define the layer objects (we will use global variables for this).</li>
<li>Call these objects when propagating the input.</li>
</ol>
<p>We have defined the layers objects you need as global variables. Please run the next cell to create them. Please check the Keras documentation to make sure you understand what these layers are: <a href="https://keras.io/layers/core/#reshape" target="_blank" rel="noopener">Reshape()</a>, <a href="https://keras.io/layers/recurrent/#lstm" target="_blank" rel="noopener">LSTM()</a>, <a href="https://keras.io/layers/core/#dense" target="_blank" rel="noopener">Dense()</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reshapor = Reshape((<span class="number">1</span>, <span class="number">78</span>))                        <span class="comment"># Used in Step 2.B of djmodel(), below</span></span><br><span class="line">LSTM_cell = LSTM(n_a, return_state = <span class="literal">True</span>)         <span class="comment"># Used in Step 2.C</span></span><br><span class="line">densor = Dense(n_values, activation=<span class="string">'softmax'</span>)     <span class="comment"># Used in Step 2.D</span></span><br></pre></td></tr></table></figure>

<p>Each of <code>reshapor</code>, <code>LSTM_cell</code> and <code>densor</code> are now layer objects, and you can use them to implement <code>djmodel()</code>. In order to propagate a Keras tensor object X through one of these layers, use <code>layer_object(X)</code> (or <code>layer_object([X,Y])</code> if it requires multiple inputs.). For example, <code>reshapor(X)</code> will propagate X through the <code>Reshape((1,78))</code> layer defined above.</p>
<p><strong>Exercise</strong>: Implement <code>djmodel()</code>. You will need to carry out 2 steps:</p>
<ol>
<li><p>Create an empty list “outputs” to save the outputs of the LSTM Cell at every time step.</p>
</li>
<li><p>Loop for $t \in 1, \ldots, T_x$:</p>
<p> A. Select the “t”th time-step vector from X. The shape of this selection should be (78,). To do so, create a custom <a href="https://keras.io/layers/core/#lambda" target="_blank" rel="noopener">Lambda</a> layer in Keras by using this line of code:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">           x &#x3D; Lambda(lambda x: X[:,t,:])(X)</span><br><span class="line">&#96;&#96;&#96; </span><br><span class="line">Look over the Keras documentation to figure out what this does. It is creating a &quot;temporary&quot; or &quot;unnamed&quot; function (that&#39;s what Lambda functions are) that extracts out the appropriate one-hot vector, and making this function a Keras &#96;Layer&#96; object to apply to &#96;X&#96;. </span><br><span class="line"></span><br><span class="line">    B. Reshape x to be (1,78). You may find the &#96;reshapor()&#96; layer (defined below) helpful.</span><br><span class="line"></span><br><span class="line">    C. Run x through one step of LSTM_cell. Remember to initialize the LSTM_cell with the previous step&#39;s hidden state $a$ and cell state $c$. Use the following formatting:</span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">a, _, c &#x3D; LSTM_cell(input_x, initial_state&#x3D;[previous hidden state, previous cell state])</span><br></pre></td></tr></table></figure>

<p> D. Propagate the LSTM’s output activation value through a dense+softmax layer using <code>densor</code>. </p>
<p> E. Append the predicted value to the list of “outputs”</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: djmodel</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">djmodel</span><span class="params">(Tx, n_a, n_values)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the model</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    Tx -- length of the sequence in a corpus</span></span><br><span class="line"><span class="string">    n_a -- the number of activations used in our model</span></span><br><span class="line"><span class="string">    n_values -- number of unique values in the music data </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    model -- a keras model with the </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define the input of your model with a shape </span></span><br><span class="line">    X = Input(shape=(Tx, n_values))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define s0, initial hidden state for the decoder LSTM</span></span><br><span class="line">    a0 = Input(shape=(n_a,), name=<span class="string">'a0'</span>)</span><br><span class="line">    c0 = Input(shape=(n_a,), name=<span class="string">'c0'</span>)</span><br><span class="line">    a = a0</span><br><span class="line">    c = c0</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### </span></span><br><span class="line">    <span class="comment"># Step 1: Create empty list to append the outputs while you iterate (≈1 line)</span></span><br><span class="line">    outputs = [];</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Loop</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(Tx):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2.A: select the "t"th time step vector from X. </span></span><br><span class="line">        x = Lambda(<span class="keyword">lambda</span> x: X[:,t,:])(X);</span><br><span class="line">        <span class="comment"># Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)</span></span><br><span class="line">        x = reshapor(x);</span><br><span class="line">        <span class="comment"># Step 2.C: Perform one step of the LSTM_cell</span></span><br><span class="line">        a, _, c = LSTM_cell(x, initial_state=[a, c]);</span><br><span class="line">        <span class="comment"># Step 2.D: Apply densor to the hidden state output of LSTM_Cell</span></span><br><span class="line">        out = densor(a);</span><br><span class="line">        <span class="comment"># Step 2.E: add the output to "outputs"</span></span><br><span class="line">        p = outputs.append(out);</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Step 3: Create model instance</span></span><br><span class="line">    model = Model(input=[X, a0, c0], outputs = outputs);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<p>Run the following cell to define your model. We will use <code>Tx=30</code>, <code>n_a=64</code> (the dimension of the LSTM activations), and <code>n_values=78</code>. This cell may take a few seconds to run. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = djmodel(Tx = <span class="number">30</span> , n_a = <span class="number">64</span>, n_values = <span class="number">78</span>)</span><br></pre></td></tr></table></figure>

<pre><code>/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:44: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[&lt;tf.Tenso..., inputs=[&lt;tf.Tenso...)`</code></pre><p>You now need to compile your model to be trained. We will Adam and a categorical cross-entropy loss.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">opt = Adam(lr=<span class="number">0.01</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, decay=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=opt, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>

<p>Finally, lets initialize <code>a0</code> and <code>c0</code> for the LSTM’s initial state to be zero. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = <span class="number">60</span></span><br><span class="line">a0 = np.zeros((m, n_a))</span><br><span class="line">c0 = np.zeros((m, n_a))</span><br></pre></td></tr></table></figure>

<p>Lets now fit the model! We will turn <code>Y</code> to a list before doing so, since the cost function expects <code>Y</code> to be provided in this format (one list item per time-step). So <code>list(Y)</code> is a list with 30 items, where each of the list items is of shape (60,78). Lets train for 100 epochs. This will take a few minutes. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit([X, a0, c0], list(Y), epochs=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/100
60/60 [==============================] - 5s - loss: 125.8264 - dense_1_loss_1: 4.3545 - dense_1_loss_2: 4.3464 - dense_1_loss_3: 4.3425 - dense_1_loss_4: 4.3442 - dense_1_loss_5: 4.3421 - dense_1_loss_6: 4.3446 - dense_1_loss_7: 4.3401 - dense_1_loss_8: 4.3457 - dense_1_loss_9: 4.3314 - dense_1_loss_10: 4.3323 - dense_1_loss_11: 4.3423 - dense_1_loss_12: 4.3389 - dense_1_loss_13: 4.3364 - dense_1_loss_14: 4.3380 - dense_1_loss_15: 4.3371 - dense_1_loss_16: 4.3311 - dense_1_loss_17: 4.3417 - dense_1_loss_18: 4.3396 - dense_1_loss_19: 4.3346 - dense_1_loss_20: 4.3342 - dense_1_loss_21: 4.3366 - dense_1_loss_22: 4.3406 - dense_1_loss_23: 4.3338 - dense_1_loss_24: 4.3317 - dense_1_loss_25: 4.3376 - dense_1_loss_26: 4.3340 - dense_1_loss_27: 4.3329 - dense_1_loss_28: 4.3416 - dense_1_loss_29: 4.3399 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0000e+00 - dense_1_acc_2: 0.0500 - dense_1_acc_3: 0.0500 - dense_1_acc_4: 0.0167 - dense_1_acc_5: 0.0500 - dense_1_acc_6: 0.0333 - dense_1_acc_7: 0.0500 - dense_1_acc_8: 0.0000e+00 - dense_1_acc_9: 0.1000 - dense_1_acc_10: 0.0333 - dense_1_acc_11: 0.0167 - dense_1_acc_12: 0.0667 - dense_1_acc_13: 0.0500 - dense_1_acc_14: 0.0667 - dense_1_acc_15: 0.0667 - dense_1_acc_16: 0.0500 - dense_1_acc_17: 0.0500 - dense_1_acc_18: 0.0167 - dense_1_acc_19: 0.1000 - dense_1_acc_20: 0.0667 - dense_1_acc_21: 0.0500 - dense_1_acc_22: 0.0667 - dense_1_acc_23: 0.1167 - dense_1_acc_24: 0.1000 - dense_1_acc_25: 0.0333 - dense_1_acc_26: 0.1000 - dense_1_acc_27: 0.0500 - dense_1_acc_28: 0.0500 - dense_1_acc_29: 0.0833 - dense_1_acc_30: 0.0000e+00                                                                 
Epoch 2/100
60/60 [==============================] - 0s - loss: 122.6142 - dense_1_loss_1: 4.3317 - dense_1_loss_2: 4.2991 - dense_1_loss_3: 4.2729 - dense_1_loss_4: 4.2763 - dense_1_loss_5: 4.2523 - dense_1_loss_6: 4.2653 - dense_1_loss_7: 4.2464 - dense_1_loss_8: 4.2352 - dense_1_loss_9: 4.2288 - dense_1_loss_10: 4.2197 - dense_1_loss_11: 4.2248 - dense_1_loss_12: 4.2489 - dense_1_loss_13: 4.2078 - dense_1_loss_14: 4.2074 - dense_1_loss_15: 4.2073 - dense_1_loss_16: 4.1991 - dense_1_loss_17: 4.2009 - dense_1_loss_18: 4.2387 - dense_1_loss_19: 4.1921 - dense_1_loss_20: 4.2132 - dense_1_loss_21: 4.2112 - dense_1_loss_22: 4.1933 - dense_1_loss_23: 4.1941 - dense_1_loss_24: 4.2164 - dense_1_loss_25: 4.2240 - dense_1_loss_26: 4.1728 - dense_1_loss_27: 4.2027 - dense_1_loss_28: 4.2063 - dense_1_loss_29: 4.2258 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1333 - dense_1_acc_3: 0.1500 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.1167 - dense_1_acc_7: 0.1667 - dense_1_acc_8: 0.1167 - dense_1_acc_9: 0.1833 - dense_1_acc_10: 0.1667 - dense_1_acc_11: 0.2000 - dense_1_acc_12: 0.0667 - dense_1_acc_13: 0.1333 - dense_1_acc_14: 0.1333 - dense_1_acc_15: 0.1167 - dense_1_acc_16: 0.1833 - dense_1_acc_17: 0.2000 - dense_1_acc_18: 0.0667 - dense_1_acc_19: 0.1333 - dense_1_acc_20: 0.1667 - dense_1_acc_21: 0.1333 - dense_1_acc_22: 0.1000 - dense_1_acc_23: 0.1167 - dense_1_acc_24: 0.1333 - dense_1_acc_25: 0.1167 - dense_1_acc_26: 0.1833 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.1833 - dense_1_acc_29: 0.0833 - dense_1_acc_30: 0.0000e+00     
Epoch 3/100
60/60 [==============================] - 0s - loss: 116.8061 - dense_1_loss_1: 4.3093 - dense_1_loss_2: 4.2449 - dense_1_loss_3: 4.1836 - dense_1_loss_4: 4.1745 - dense_1_loss_5: 4.1156 - dense_1_loss_6: 4.1481 - dense_1_loss_7: 4.0958 - dense_1_loss_8: 4.0446 - dense_1_loss_9: 3.9897 - dense_1_loss_10: 3.8988 - dense_1_loss_11: 3.8989 - dense_1_loss_12: 4.1165 - dense_1_loss_13: 3.8994 - dense_1_loss_14: 3.8898 - dense_1_loss_15: 3.9828 - dense_1_loss_16: 3.9182 - dense_1_loss_17: 3.8867 - dense_1_loss_18: 4.2104 - dense_1_loss_19: 3.8670 - dense_1_loss_20: 4.0711 - dense_1_loss_21: 4.0630 - dense_1_loss_22: 3.9217 - dense_1_loss_23: 3.9589 - dense_1_loss_24: 4.0469 - dense_1_loss_25: 4.0823 - dense_1_loss_26: 3.7266 - dense_1_loss_27: 3.9689 - dense_1_loss_28: 3.9623 - dense_1_loss_29: 4.1299 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.1333 - dense_1_acc_5: 0.1833 - dense_1_acc_6: 0.1000 - dense_1_acc_7: 0.1167 - dense_1_acc_8: 0.0833 - dense_1_acc_9: 0.1167 - dense_1_acc_10: 0.1167 - dense_1_acc_11: 0.0833 - dense_1_acc_12: 0.0167 - dense_1_acc_13: 0.1000 - dense_1_acc_14: 0.1000 - dense_1_acc_15: 0.0500 - dense_1_acc_16: 0.0833 - dense_1_acc_17: 0.1000 - dense_1_acc_18: 0.0167 - dense_1_acc_19: 0.1000 - dense_1_acc_20: 0.0667 - dense_1_acc_21: 0.0667 - dense_1_acc_22: 0.0500 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.0833 - dense_1_acc_25: 0.0167 - dense_1_acc_26: 0.1167 - dense_1_acc_27: 0.0500 - dense_1_acc_28: 0.0667 - dense_1_acc_29: 0.0333 - dense_1_acc_30: 0.0000e+00             
Epoch 4/100
60/60 [==============================] - 0s - loss: 112.2963 - dense_1_loss_1: 4.2889 - dense_1_loss_2: 4.1981 - dense_1_loss_3: 4.0962 - dense_1_loss_4: 4.0810 - dense_1_loss_5: 3.9790 - dense_1_loss_6: 4.0129 - dense_1_loss_7: 3.9439 - dense_1_loss_8: 3.7697 - dense_1_loss_9: 3.8046 - dense_1_loss_10: 3.6386 - dense_1_loss_11: 3.7236 - dense_1_loss_12: 3.9783 - dense_1_loss_13: 3.7060 - dense_1_loss_14: 3.7075 - dense_1_loss_15: 3.7358 - dense_1_loss_16: 3.7286 - dense_1_loss_17: 3.8079 - dense_1_loss_18: 3.9018 - dense_1_loss_19: 3.6729 - dense_1_loss_20: 3.9865 - dense_1_loss_21: 3.9529 - dense_1_loss_22: 3.8378 - dense_1_loss_23: 3.7695 - dense_1_loss_24: 3.7576 - dense_1_loss_25: 3.9597 - dense_1_loss_26: 3.6666 - dense_1_loss_27: 3.6978 - dense_1_loss_28: 3.8733 - dense_1_loss_29: 4.0193 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2667 - dense_1_acc_6: 0.1333 - dense_1_acc_7: 0.1667 - dense_1_acc_8: 0.1833 - dense_1_acc_9: 0.1667 - dense_1_acc_10: 0.1667 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.1000 - dense_1_acc_13: 0.1500 - dense_1_acc_14: 0.2167 - dense_1_acc_15: 0.1000 - dense_1_acc_16: 0.1167 - dense_1_acc_17: 0.1000 - dense_1_acc_18: 0.1000 - dense_1_acc_19: 0.1500 - dense_1_acc_20: 0.0833 - dense_1_acc_21: 0.0667 - dense_1_acc_22: 0.1167 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.0000e+00 - dense_1_acc_25: 0.1000 - dense_1_acc_26: 0.1000 - dense_1_acc_27: 0.0833 - dense_1_acc_28: 0.1167 - dense_1_acc_29: 0.0667 - dense_1_acc_30: 0.0000e+00     
Epoch 5/100
60/60 [==============================] - 0s - loss: 110.0390 - dense_1_loss_1: 4.2729 - dense_1_loss_2: 4.1581 - dense_1_loss_3: 4.0292 - dense_1_loss_4: 4.0164 - dense_1_loss_5: 3.8981 - dense_1_loss_6: 3.9318 - dense_1_loss_7: 3.8775 - dense_1_loss_8: 3.6710 - dense_1_loss_9: 3.7225 - dense_1_loss_10: 3.5653 - dense_1_loss_11: 3.6287 - dense_1_loss_12: 3.8595 - dense_1_loss_13: 3.6459 - dense_1_loss_14: 3.6176 - dense_1_loss_15: 3.7001 - dense_1_loss_16: 3.6384 - dense_1_loss_17: 3.7419 - dense_1_loss_18: 3.7274 - dense_1_loss_19: 3.6644 - dense_1_loss_20: 3.8134 - dense_1_loss_21: 3.8085 - dense_1_loss_22: 3.7113 - dense_1_loss_23: 3.6167 - dense_1_loss_24: 3.6441 - dense_1_loss_25: 3.9445 - dense_1_loss_26: 3.7134 - dense_1_loss_27: 3.6405 - dense_1_loss_28: 3.8265 - dense_1_loss_29: 3.9533 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.1333 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.2000 - dense_1_acc_5: 0.1333 - dense_1_acc_6: 0.0333 - dense_1_acc_7: 0.1000 - dense_1_acc_8: 0.1500 - dense_1_acc_9: 0.0833 - dense_1_acc_10: 0.1000 - dense_1_acc_11: 0.1000 - dense_1_acc_12: 0.0667 - dense_1_acc_13: 0.1000 - dense_1_acc_14: 0.1500 - dense_1_acc_15: 0.0833 - dense_1_acc_16: 0.0500 - dense_1_acc_17: 0.0500 - dense_1_acc_18: 0.0833 - dense_1_acc_19: 0.0333 - dense_1_acc_20: 0.0500 - dense_1_acc_21: 0.0833 - dense_1_acc_22: 0.0833 - dense_1_acc_23: 0.1667 - dense_1_acc_24: 0.0500 - dense_1_acc_25: 0.0500 - dense_1_acc_26: 0.0500 - dense_1_acc_27: 0.0833 - dense_1_acc_28: 0.0167 - dense_1_acc_29: 0.0167 - dense_1_acc_30: 0.0000e+00     
Epoch 6/100
60/60 [==============================] - 0s - loss: 106.1460 - dense_1_loss_1: 4.2571 - dense_1_loss_2: 4.1230 - dense_1_loss_3: 3.9604 - dense_1_loss_4: 3.9405 - dense_1_loss_5: 3.8132 - dense_1_loss_6: 3.8401 - dense_1_loss_7: 3.7750 - dense_1_loss_8: 3.5455 - dense_1_loss_9: 3.5752 - dense_1_loss_10: 3.4639 - dense_1_loss_11: 3.5982 - dense_1_loss_12: 3.7733 - dense_1_loss_13: 3.5049 - dense_1_loss_14: 3.4641 - dense_1_loss_15: 3.5221 - dense_1_loss_16: 3.5189 - dense_1_loss_17: 3.5414 - dense_1_loss_18: 3.5307 - dense_1_loss_19: 3.5341 - dense_1_loss_20: 3.6316 - dense_1_loss_21: 3.6324 - dense_1_loss_22: 3.5577 - dense_1_loss_23: 3.5073 - dense_1_loss_24: 3.5296 - dense_1_loss_25: 3.8212 - dense_1_loss_26: 3.4278 - dense_1_loss_27: 3.4614 - dense_1_loss_28: 3.5999 - dense_1_loss_29: 3.6956 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1667 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.2000 - dense_1_acc_5: 0.2500 - dense_1_acc_6: 0.0833 - dense_1_acc_7: 0.0833 - dense_1_acc_8: 0.1667 - dense_1_acc_9: 0.1000 - dense_1_acc_10: 0.2000 - dense_1_acc_11: 0.1333 - dense_1_acc_12: 0.1000 - dense_1_acc_13: 0.1833 - dense_1_acc_14: 0.2167 - dense_1_acc_15: 0.1167 - dense_1_acc_16: 0.1167 - dense_1_acc_17: 0.1333 - dense_1_acc_18: 0.1667 - dense_1_acc_19: 0.1833 - dense_1_acc_20: 0.1167 - dense_1_acc_21: 0.1500 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.1833 - dense_1_acc_24: 0.1167 - dense_1_acc_25: 0.0667 - dense_1_acc_26: 0.2000 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.1500 - dense_1_acc_29: 0.0667 - dense_1_acc_30: 0.0000e+00     
Epoch 7/100
60/60 [==============================] - 0s - loss: 102.2579 - dense_1_loss_1: 4.2413 - dense_1_loss_2: 4.0875 - dense_1_loss_3: 3.8934 - dense_1_loss_4: 3.8654 - dense_1_loss_5: 3.7056 - dense_1_loss_6: 3.7368 - dense_1_loss_7: 3.6732 - dense_1_loss_8: 3.4290 - dense_1_loss_9: 3.4259 - dense_1_loss_10: 3.3381 - dense_1_loss_11: 3.4889 - dense_1_loss_12: 3.6443 - dense_1_loss_13: 3.3488 - dense_1_loss_14: 3.3007 - dense_1_loss_15: 3.3981 - dense_1_loss_16: 3.3846 - dense_1_loss_17: 3.3449 - dense_1_loss_18: 3.3858 - dense_1_loss_19: 3.4057 - dense_1_loss_20: 3.4521 - dense_1_loss_21: 3.4389 - dense_1_loss_22: 3.3936 - dense_1_loss_23: 3.4140 - dense_1_loss_24: 3.3620 - dense_1_loss_25: 3.6902 - dense_1_loss_26: 3.2316 - dense_1_loss_27: 3.3343 - dense_1_loss_28: 3.3640 - dense_1_loss_29: 3.4791 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1333 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2667 - dense_1_acc_6: 0.1667 - dense_1_acc_7: 0.1333 - dense_1_acc_8: 0.2333 - dense_1_acc_9: 0.1667 - dense_1_acc_10: 0.2000 - dense_1_acc_11: 0.1833 - dense_1_acc_12: 0.1333 - dense_1_acc_13: 0.1667 - dense_1_acc_14: 0.2667 - dense_1_acc_15: 0.1667 - dense_1_acc_16: 0.1500 - dense_1_acc_17: 0.1833 - dense_1_acc_18: 0.1167 - dense_1_acc_19: 0.1333 - dense_1_acc_20: 0.1833 - dense_1_acc_21: 0.1167 - dense_1_acc_22: 0.1333 - dense_1_acc_23: 0.1333 - dense_1_acc_24: 0.1500 - dense_1_acc_25: 0.0667 - dense_1_acc_26: 0.2167 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.1500 - dense_1_acc_29: 0.1833 - dense_1_acc_30: 0.0000e+00     
Epoch 8/100
60/60 [==============================] - 0s - loss: 98.0187 - dense_1_loss_1: 4.2277 - dense_1_loss_2: 4.0477 - dense_1_loss_3: 3.8258 - dense_1_loss_4: 3.7791 - dense_1_loss_5: 3.6089 - dense_1_loss_6: 3.6218 - dense_1_loss_7: 3.5396 - dense_1_loss_8: 3.2991 - dense_1_loss_9: 3.2584 - dense_1_loss_10: 3.1349 - dense_1_loss_11: 3.2992 - dense_1_loss_12: 3.4534 - dense_1_loss_13: 3.1133 - dense_1_loss_14: 3.0906 - dense_1_loss_15: 3.2273 - dense_1_loss_16: 3.2308 - dense_1_loss_17: 3.1062 - dense_1_loss_18: 3.2503 - dense_1_loss_19: 3.2314 - dense_1_loss_20: 3.2470 - dense_1_loss_21: 3.2910 - dense_1_loss_22: 3.2553 - dense_1_loss_23: 3.2761 - dense_1_loss_24: 3.2245 - dense_1_loss_25: 3.5042 - dense_1_loss_26: 3.0631 - dense_1_loss_27: 3.2291 - dense_1_loss_28: 3.2519 - dense_1_loss_29: 3.3307 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.1667 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.2667 - dense_1_acc_6: 0.1833 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.2667 - dense_1_acc_9: 0.1667 - dense_1_acc_10: 0.2333 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.1167 - dense_1_acc_13: 0.2833 - dense_1_acc_14: 0.2333 - dense_1_acc_15: 0.1500 - dense_1_acc_16: 0.2000 - dense_1_acc_17: 0.2167 - dense_1_acc_18: 0.1333 - dense_1_acc_19: 0.1667 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.1667 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.1500 - dense_1_acc_24: 0.1333 - dense_1_acc_25: 0.1167 - dense_1_acc_26: 0.2500 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.1500 - dense_1_acc_29: 0.1667 - dense_1_acc_30: 0.0000e+00         
Epoch 9/100
60/60 [==============================] - 0s - loss: 93.9753 - dense_1_loss_1: 4.2159 - dense_1_loss_2: 4.0105 - dense_1_loss_3: 3.7472 - dense_1_loss_4: 3.6921 - dense_1_loss_5: 3.4942 - dense_1_loss_6: 3.4897 - dense_1_loss_7: 3.4181 - dense_1_loss_8: 3.1503 - dense_1_loss_9: 3.1051 - dense_1_loss_10: 2.9563 - dense_1_loss_11: 3.1541 - dense_1_loss_12: 3.2926 - dense_1_loss_13: 2.9499 - dense_1_loss_14: 2.9662 - dense_1_loss_15: 3.0675 - dense_1_loss_16: 3.1146 - dense_1_loss_17: 2.9696 - dense_1_loss_18: 3.1479 - dense_1_loss_19: 3.0151 - dense_1_loss_20: 3.0469 - dense_1_loss_21: 3.0955 - dense_1_loss_22: 3.0573 - dense_1_loss_23: 3.1520 - dense_1_loss_24: 3.0335 - dense_1_loss_25: 3.3512 - dense_1_loss_26: 2.8350 - dense_1_loss_27: 3.1168 - dense_1_loss_28: 3.1114 - dense_1_loss_29: 3.2186 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.1500 - dense_1_acc_5: 0.2500 - dense_1_acc_6: 0.1833 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.1833 - dense_1_acc_9: 0.2667 - dense_1_acc_10: 0.2500 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.1500 - dense_1_acc_13: 0.3333 - dense_1_acc_14: 0.2333 - dense_1_acc_15: 0.2000 - dense_1_acc_16: 0.2333 - dense_1_acc_17: 0.3000 - dense_1_acc_18: 0.1333 - dense_1_acc_19: 0.2000 - dense_1_acc_20: 0.3333 - dense_1_acc_21: 0.1833 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.2000 - dense_1_acc_24: 0.2000 - dense_1_acc_25: 0.1167 - dense_1_acc_26: 0.2667 - dense_1_acc_27: 0.1667 - dense_1_acc_28: 0.1500 - dense_1_acc_29: 0.2000 - dense_1_acc_30: 0.0000e+00     
Epoch 10/100
60/60 [==============================] - 0s - loss: 89.7720 - dense_1_loss_1: 4.2048 - dense_1_loss_2: 3.9711 - dense_1_loss_3: 3.6677 - dense_1_loss_4: 3.6035 - dense_1_loss_5: 3.3800 - dense_1_loss_6: 3.3506 - dense_1_loss_7: 3.2899 - dense_1_loss_8: 3.0100 - dense_1_loss_9: 2.9501 - dense_1_loss_10: 2.7743 - dense_1_loss_11: 3.0100 - dense_1_loss_12: 3.0628 - dense_1_loss_13: 2.8252 - dense_1_loss_14: 2.8456 - dense_1_loss_15: 2.9193 - dense_1_loss_16: 2.9354 - dense_1_loss_17: 2.7749 - dense_1_loss_18: 3.0148 - dense_1_loss_19: 2.8805 - dense_1_loss_20: 2.8963 - dense_1_loss_21: 2.9775 - dense_1_loss_22: 2.8919 - dense_1_loss_23: 2.9468 - dense_1_loss_24: 2.8604 - dense_1_loss_25: 3.1973 - dense_1_loss_26: 2.6616 - dense_1_loss_27: 2.9519 - dense_1_loss_28: 2.9121 - dense_1_loss_29: 3.0059 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.0667 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.2000 - dense_1_acc_7: 0.2167 - dense_1_acc_8: 0.1833 - dense_1_acc_9: 0.3000 - dense_1_acc_10: 0.2500 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.1500 - dense_1_acc_13: 0.2833 - dense_1_acc_14: 0.2500 - dense_1_acc_15: 0.2500 - dense_1_acc_16: 0.2667 - dense_1_acc_17: 0.3000 - dense_1_acc_18: 0.1000 - dense_1_acc_19: 0.2167 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.2167 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.2333 - dense_1_acc_24: 0.1667 - dense_1_acc_25: 0.1167 - dense_1_acc_26: 0.2833 - dense_1_acc_27: 0.1667 - dense_1_acc_28: 0.2167 - dense_1_acc_29: 0.2167 - dense_1_acc_30: 0.0000e+00     
Epoch 11/100
60/60 [==============================] - 0s - loss: 85.6615 - dense_1_loss_1: 4.1942 - dense_1_loss_2: 3.9323 - dense_1_loss_3: 3.5914 - dense_1_loss_4: 3.5058 - dense_1_loss_5: 3.2599 - dense_1_loss_6: 3.2069 - dense_1_loss_7: 3.1536 - dense_1_loss_8: 2.8428 - dense_1_loss_9: 2.8446 - dense_1_loss_10: 2.6600 - dense_1_loss_11: 2.8793 - dense_1_loss_12: 2.8746 - dense_1_loss_13: 2.6513 - dense_1_loss_14: 2.6880 - dense_1_loss_15: 2.7775 - dense_1_loss_16: 2.8001 - dense_1_loss_17: 2.6575 - dense_1_loss_18: 2.8262 - dense_1_loss_19: 2.6729 - dense_1_loss_20: 2.7437 - dense_1_loss_21: 2.7738 - dense_1_loss_22: 2.7370 - dense_1_loss_23: 2.8320 - dense_1_loss_24: 2.6954 - dense_1_loss_25: 2.9728 - dense_1_loss_26: 2.5801 - dense_1_loss_27: 2.7190 - dense_1_loss_28: 2.7862 - dense_1_loss_29: 2.8024 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.0667 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.2167 - dense_1_acc_5: 0.2833 - dense_1_acc_6: 0.2167 - dense_1_acc_7: 0.2333 - dense_1_acc_8: 0.2833 - dense_1_acc_9: 0.2667 - dense_1_acc_10: 0.3167 - dense_1_acc_11: 0.1333 - dense_1_acc_12: 0.2000 - dense_1_acc_13: 0.3333 - dense_1_acc_14: 0.2333 - dense_1_acc_15: 0.2333 - dense_1_acc_16: 0.2500 - dense_1_acc_17: 0.2333 - dense_1_acc_18: 0.1500 - dense_1_acc_19: 0.2500 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.2333 - dense_1_acc_22: 0.2000 - dense_1_acc_23: 0.2333 - dense_1_acc_24: 0.2000 - dense_1_acc_25: 0.1667 - dense_1_acc_26: 0.3333 - dense_1_acc_27: 0.2000 - dense_1_acc_28: 0.2167 - dense_1_acc_29: 0.3500 - dense_1_acc_30: 0.0000e+00     
Epoch 12/100
60/60 [==============================] - 0s - loss: 81.9096 - dense_1_loss_1: 4.1837 - dense_1_loss_2: 3.8924 - dense_1_loss_3: 3.5047 - dense_1_loss_4: 3.4058 - dense_1_loss_5: 3.1285 - dense_1_loss_6: 3.0528 - dense_1_loss_7: 3.0213 - dense_1_loss_8: 2.6764 - dense_1_loss_9: 2.6832 - dense_1_loss_10: 2.5371 - dense_1_loss_11: 2.7424 - dense_1_loss_12: 2.7007 - dense_1_loss_13: 2.5169 - dense_1_loss_14: 2.5984 - dense_1_loss_15: 2.5748 - dense_1_loss_16: 2.6452 - dense_1_loss_17: 2.5546 - dense_1_loss_18: 2.6831 - dense_1_loss_19: 2.6039 - dense_1_loss_20: 2.6078 - dense_1_loss_21: 2.6546 - dense_1_loss_22: 2.5963 - dense_1_loss_23: 2.6691 - dense_1_loss_24: 2.6460 - dense_1_loss_25: 2.8278 - dense_1_loss_26: 2.3809 - dense_1_loss_27: 2.6169 - dense_1_loss_28: 2.5561 - dense_1_loss_29: 2.6480 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.2167 - dense_1_acc_5: 0.3000 - dense_1_acc_6: 0.2333 - dense_1_acc_7: 0.2833 - dense_1_acc_8: 0.3167 - dense_1_acc_9: 0.3167 - dense_1_acc_10: 0.3000 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.2500 - dense_1_acc_13: 0.4000 - dense_1_acc_14: 0.2833 - dense_1_acc_15: 0.2500 - dense_1_acc_16: 0.2500 - dense_1_acc_17: 0.2500 - dense_1_acc_18: 0.1500 - dense_1_acc_19: 0.2833 - dense_1_acc_20: 0.3167 - dense_1_acc_21: 0.2667 - dense_1_acc_22: 0.2333 - dense_1_acc_23: 0.2333 - dense_1_acc_24: 0.2500 - dense_1_acc_25: 0.1333 - dense_1_acc_26: 0.3833 - dense_1_acc_27: 0.3000 - dense_1_acc_28: 0.3167 - dense_1_acc_29: 0.3167 - dense_1_acc_30: 0.0000e+00     
Epoch 13/100
60/60 [==============================] - 0s - loss: 77.9424 - dense_1_loss_1: 4.1726 - dense_1_loss_2: 3.8520 - dense_1_loss_3: 3.4239 - dense_1_loss_4: 3.3049 - dense_1_loss_5: 3.0094 - dense_1_loss_6: 2.9040 - dense_1_loss_7: 2.8879 - dense_1_loss_8: 2.5388 - dense_1_loss_9: 2.5642 - dense_1_loss_10: 2.3932 - dense_1_loss_11: 2.5736 - dense_1_loss_12: 2.5587 - dense_1_loss_13: 2.3320 - dense_1_loss_14: 2.4560 - dense_1_loss_15: 2.4168 - dense_1_loss_16: 2.5107 - dense_1_loss_17: 2.3550 - dense_1_loss_18: 2.4863 - dense_1_loss_19: 2.4692 - dense_1_loss_20: 2.4468 - dense_1_loss_21: 2.5056 - dense_1_loss_22: 2.4056 - dense_1_loss_23: 2.4519 - dense_1_loss_24: 2.6144 - dense_1_loss_25: 2.6999 - dense_1_loss_26: 2.1690 - dense_1_loss_27: 2.4230 - dense_1_loss_28: 2.4840 - dense_1_loss_29: 2.5331 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.2500 - dense_1_acc_4: 0.2000 - dense_1_acc_5: 0.3167 - dense_1_acc_6: 0.2167 - dense_1_acc_7: 0.3000 - dense_1_acc_8: 0.3500 - dense_1_acc_9: 0.3333 - dense_1_acc_10: 0.3333 - dense_1_acc_11: 0.2833 - dense_1_acc_12: 0.2500 - dense_1_acc_13: 0.3667 - dense_1_acc_14: 0.2500 - dense_1_acc_15: 0.2667 - dense_1_acc_16: 0.2333 - dense_1_acc_17: 0.3167 - dense_1_acc_18: 0.1833 - dense_1_acc_19: 0.2667 - dense_1_acc_20: 0.3333 - dense_1_acc_21: 0.3000 - dense_1_acc_22: 0.3000 - dense_1_acc_23: 0.2833 - dense_1_acc_24: 0.2500 - dense_1_acc_25: 0.1833 - dense_1_acc_26: 0.4167 - dense_1_acc_27: 0.2500 - dense_1_acc_28: 0.2167 - dense_1_acc_29: 0.3167 - dense_1_acc_30: 0.0000e+00     
Epoch 14/100
60/60 [==============================] - 0s - loss: 74.5680 - dense_1_loss_1: 4.1639 - dense_1_loss_2: 3.8115 - dense_1_loss_3: 3.3439 - dense_1_loss_4: 3.1987 - dense_1_loss_5: 2.8879 - dense_1_loss_6: 2.7570 - dense_1_loss_7: 2.7657 - dense_1_loss_8: 2.4219 - dense_1_loss_9: 2.4471 - dense_1_loss_10: 2.2721 - dense_1_loss_11: 2.4152 - dense_1_loss_12: 2.4041 - dense_1_loss_13: 2.1848 - dense_1_loss_14: 2.3034 - dense_1_loss_15: 2.2661 - dense_1_loss_16: 2.3730 - dense_1_loss_17: 2.2420 - dense_1_loss_18: 2.3084 - dense_1_loss_19: 2.3039 - dense_1_loss_20: 2.3927 - dense_1_loss_21: 2.3191 - dense_1_loss_22: 2.2784 - dense_1_loss_23: 2.3497 - dense_1_loss_24: 2.4033 - dense_1_loss_25: 2.6364 - dense_1_loss_26: 2.1220 - dense_1_loss_27: 2.3866 - dense_1_loss_28: 2.4073 - dense_1_loss_29: 2.4020 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2500 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.3333 - dense_1_acc_6: 0.2833 - dense_1_acc_7: 0.2667 - dense_1_acc_8: 0.3167 - dense_1_acc_9: 0.3333 - dense_1_acc_10: 0.3667 - dense_1_acc_11: 0.3167 - dense_1_acc_12: 0.2333 - dense_1_acc_13: 0.4000 - dense_1_acc_14: 0.3500 - dense_1_acc_15: 0.3500 - dense_1_acc_16: 0.2833 - dense_1_acc_17: 0.3667 - dense_1_acc_18: 0.2000 - dense_1_acc_19: 0.2833 - dense_1_acc_20: 0.3000 - dense_1_acc_21: 0.2833 - dense_1_acc_22: 0.2833 - dense_1_acc_23: 0.3333 - dense_1_acc_24: 0.2333 - dense_1_acc_25: 0.1667 - dense_1_acc_26: 0.3833 - dense_1_acc_27: 0.2667 - dense_1_acc_28: 0.2333 - dense_1_acc_29: 0.2833 - dense_1_acc_30: 0.0000e+00     
Epoch 15/100
60/60 [==============================] - 0s - loss: 70.7818 - dense_1_loss_1: 4.1566 - dense_1_loss_2: 3.7716 - dense_1_loss_3: 3.2704 - dense_1_loss_4: 3.1003 - dense_1_loss_5: 2.7766 - dense_1_loss_6: 2.6157 - dense_1_loss_7: 2.6423 - dense_1_loss_8: 2.3160 - dense_1_loss_9: 2.3343 - dense_1_loss_10: 2.1863 - dense_1_loss_11: 2.3080 - dense_1_loss_12: 2.2695 - dense_1_loss_13: 2.0643 - dense_1_loss_14: 2.1616 - dense_1_loss_15: 2.2092 - dense_1_loss_16: 2.2644 - dense_1_loss_17: 2.1717 - dense_1_loss_18: 2.1806 - dense_1_loss_19: 2.1495 - dense_1_loss_20: 2.2528 - dense_1_loss_21: 2.0959 - dense_1_loss_22: 2.1184 - dense_1_loss_23: 2.2349 - dense_1_loss_24: 2.2799 - dense_1_loss_25: 2.4104 - dense_1_loss_26: 1.9154 - dense_1_loss_27: 2.1144 - dense_1_loss_28: 2.2116 - dense_1_loss_29: 2.1992 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2833 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3167 - dense_1_acc_6: 0.3167 - dense_1_acc_7: 0.3167 - dense_1_acc_8: 0.3500 - dense_1_acc_9: 0.4000 - dense_1_acc_10: 0.4000 - dense_1_acc_11: 0.2333 - dense_1_acc_12: 0.2333 - dense_1_acc_13: 0.4667 - dense_1_acc_14: 0.4167 - dense_1_acc_15: 0.2833 - dense_1_acc_16: 0.3167 - dense_1_acc_17: 0.3667 - dense_1_acc_18: 0.3167 - dense_1_acc_19: 0.3500 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.3500 - dense_1_acc_22: 0.3667 - dense_1_acc_23: 0.4000 - dense_1_acc_24: 0.3000 - dense_1_acc_25: 0.2000 - dense_1_acc_26: 0.5167 - dense_1_acc_27: 0.3833 - dense_1_acc_28: 0.4167 - dense_1_acc_29: 0.4333 - dense_1_acc_30: 0.0000e+00     
Epoch 16/100
60/60 [==============================] - 0s - loss: 67.6264 - dense_1_loss_1: 4.1490 - dense_1_loss_2: 3.7330 - dense_1_loss_3: 3.1997 - dense_1_loss_4: 2.9972 - dense_1_loss_5: 2.6689 - dense_1_loss_6: 2.4691 - dense_1_loss_7: 2.4959 - dense_1_loss_8: 2.2321 - dense_1_loss_9: 2.2149 - dense_1_loss_10: 2.0676 - dense_1_loss_11: 2.1944 - dense_1_loss_12: 2.0894 - dense_1_loss_13: 1.9174 - dense_1_loss_14: 2.0482 - dense_1_loss_15: 2.0521 - dense_1_loss_16: 2.1589 - dense_1_loss_17: 2.0443 - dense_1_loss_18: 2.0343 - dense_1_loss_19: 2.0277 - dense_1_loss_20: 2.0924 - dense_1_loss_21: 2.0356 - dense_1_loss_22: 2.0433 - dense_1_loss_23: 2.1854 - dense_1_loss_24: 2.1334 - dense_1_loss_25: 2.2683 - dense_1_loss_26: 1.8710 - dense_1_loss_27: 2.0543 - dense_1_loss_28: 2.0875 - dense_1_loss_29: 2.0611 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1833 - dense_1_acc_3: 0.3000 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3333 - dense_1_acc_6: 0.3167 - dense_1_acc_7: 0.3500 - dense_1_acc_8: 0.3833 - dense_1_acc_9: 0.3833 - dense_1_acc_10: 0.3500 - dense_1_acc_11: 0.2500 - dense_1_acc_12: 0.3667 - dense_1_acc_13: 0.4167 - dense_1_acc_14: 0.4167 - dense_1_acc_15: 0.3333 - dense_1_acc_16: 0.3833 - dense_1_acc_17: 0.4000 - dense_1_acc_18: 0.4000 - dense_1_acc_19: 0.3833 - dense_1_acc_20: 0.4167 - dense_1_acc_21: 0.3833 - dense_1_acc_22: 0.3333 - dense_1_acc_23: 0.3000 - dense_1_acc_24: 0.3333 - dense_1_acc_25: 0.2167 - dense_1_acc_26: 0.4667 - dense_1_acc_27: 0.3500 - dense_1_acc_28: 0.4333 - dense_1_acc_29: 0.4333 - dense_1_acc_30: 0.0000e+00     
Epoch 17/100
60/60 [==============================] - 0s - loss: 64.3102 - dense_1_loss_1: 4.1432 - dense_1_loss_2: 3.6922 - dense_1_loss_3: 3.1260 - dense_1_loss_4: 2.9039 - dense_1_loss_5: 2.5473 - dense_1_loss_6: 2.3139 - dense_1_loss_7: 2.3524 - dense_1_loss_8: 2.1075 - dense_1_loss_9: 2.1829 - dense_1_loss_10: 1.9446 - dense_1_loss_11: 2.1464 - dense_1_loss_12: 2.0344 - dense_1_loss_13: 1.8492 - dense_1_loss_14: 1.8603 - dense_1_loss_15: 1.9291 - dense_1_loss_16: 2.0644 - dense_1_loss_17: 1.9326 - dense_1_loss_18: 1.8428 - dense_1_loss_19: 1.9004 - dense_1_loss_20: 1.9474 - dense_1_loss_21: 1.9269 - dense_1_loss_22: 1.9244 - dense_1_loss_23: 1.9607 - dense_1_loss_24: 2.0257 - dense_1_loss_25: 2.1022 - dense_1_loss_26: 1.7460 - dense_1_loss_27: 1.8937 - dense_1_loss_28: 1.9563 - dense_1_loss_29: 1.9534 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2000 - dense_1_acc_3: 0.3500 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3333 - dense_1_acc_6: 0.3500 - dense_1_acc_7: 0.3500 - dense_1_acc_8: 0.3667 - dense_1_acc_9: 0.3667 - dense_1_acc_10: 0.4333 - dense_1_acc_11: 0.3000 - dense_1_acc_12: 0.3500 - dense_1_acc_13: 0.4333 - dense_1_acc_14: 0.4167 - dense_1_acc_15: 0.3667 - dense_1_acc_16: 0.3333 - dense_1_acc_17: 0.3833 - dense_1_acc_18: 0.4833 - dense_1_acc_19: 0.4500 - dense_1_acc_20: 0.4667 - dense_1_acc_21: 0.4167 - dense_1_acc_22: 0.3667 - dense_1_acc_23: 0.4167 - dense_1_acc_24: 0.3667 - dense_1_acc_25: 0.2833 - dense_1_acc_26: 0.5667 - dense_1_acc_27: 0.4500 - dense_1_acc_28: 0.4167 - dense_1_acc_29: 0.4667 - dense_1_acc_30: 0.0000e+00     
Epoch 18/100
60/60 [==============================] - 0s - loss: 60.9770 - dense_1_loss_1: 4.1352 - dense_1_loss_2: 3.6501 - dense_1_loss_3: 3.0557 - dense_1_loss_4: 2.8116 - dense_1_loss_5: 2.4615 - dense_1_loss_6: 2.2039 - dense_1_loss_7: 2.2144 - dense_1_loss_8: 1.9720 - dense_1_loss_9: 2.0354 - dense_1_loss_10: 1.8256 - dense_1_loss_11: 1.9682 - dense_1_loss_12: 1.8455 - dense_1_loss_13: 1.7386 - dense_1_loss_14: 1.7591 - dense_1_loss_15: 1.7897 - dense_1_loss_16: 1.9169 - dense_1_loss_17: 1.8054 - dense_1_loss_18: 1.8099 - dense_1_loss_19: 1.7484 - dense_1_loss_20: 1.7715 - dense_1_loss_21: 1.7874 - dense_1_loss_22: 1.8334 - dense_1_loss_23: 1.7951 - dense_1_loss_24: 1.9296 - dense_1_loss_25: 1.9762 - dense_1_loss_26: 1.6691 - dense_1_loss_27: 1.8107 - dense_1_loss_28: 1.8523 - dense_1_loss_29: 1.8047 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2167 - dense_1_acc_3: 0.3500 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.3667 - dense_1_acc_6: 0.3333 - dense_1_acc_7: 0.4000 - dense_1_acc_8: 0.4333 - dense_1_acc_9: 0.3667 - dense_1_acc_10: 0.4500 - dense_1_acc_11: 0.3833 - dense_1_acc_12: 0.4167 - dense_1_acc_13: 0.5333 - dense_1_acc_14: 0.4667 - dense_1_acc_15: 0.4667 - dense_1_acc_16: 0.3333 - dense_1_acc_17: 0.4000 - dense_1_acc_18: 0.3667 - dense_1_acc_19: 0.4000 - dense_1_acc_20: 0.4833 - dense_1_acc_21: 0.3833 - dense_1_acc_22: 0.4500 - dense_1_acc_23: 0.4833 - dense_1_acc_24: 0.3500 - dense_1_acc_25: 0.3500 - dense_1_acc_26: 0.5333 - dense_1_acc_27: 0.4333 - dense_1_acc_28: 0.4333 - dense_1_acc_29: 0.5500 - dense_1_acc_30: 0.0000e+00     
Epoch 19/100
60/60 [==============================] - 0s - loss: 58.1739 - dense_1_loss_1: 4.1267 - dense_1_loss_2: 3.6067 - dense_1_loss_3: 2.9783 - dense_1_loss_4: 2.7143 - dense_1_loss_5: 2.3603 - dense_1_loss_6: 2.1084 - dense_1_loss_7: 2.1157 - dense_1_loss_8: 1.8884 - dense_1_loss_9: 1.9336 - dense_1_loss_10: 1.7485 - dense_1_loss_11: 1.9035 - dense_1_loss_12: 1.7516 - dense_1_loss_13: 1.5965 - dense_1_loss_14: 1.6437 - dense_1_loss_15: 1.6844 - dense_1_loss_16: 1.8346 - dense_1_loss_17: 1.7095 - dense_1_loss_18: 1.7362 - dense_1_loss_19: 1.6973 - dense_1_loss_20: 1.6533 - dense_1_loss_21: 1.6370 - dense_1_loss_22: 1.7230 - dense_1_loss_23: 1.7123 - dense_1_loss_24: 1.7885 - dense_1_loss_25: 1.8111 - dense_1_loss_26: 1.6029 - dense_1_loss_27: 1.7325 - dense_1_loss_28: 1.7083 - dense_1_loss_29: 1.6667 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2167 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.3500 - dense_1_acc_6: 0.3833 - dense_1_acc_7: 0.4000 - dense_1_acc_8: 0.4167 - dense_1_acc_9: 0.4333 - dense_1_acc_10: 0.4500 - dense_1_acc_11: 0.3167 - dense_1_acc_12: 0.5000 - dense_1_acc_13: 0.6000 - dense_1_acc_14: 0.5000 - dense_1_acc_15: 0.5333 - dense_1_acc_16: 0.3833 - dense_1_acc_17: 0.4833 - dense_1_acc_18: 0.3833 - dense_1_acc_19: 0.4333 - dense_1_acc_20: 0.5000 - dense_1_acc_21: 0.5000 - dense_1_acc_22: 0.4833 - dense_1_acc_23: 0.4833 - dense_1_acc_24: 0.4167 - dense_1_acc_25: 0.4333 - dense_1_acc_26: 0.6333 - dense_1_acc_27: 0.5000 - dense_1_acc_28: 0.5167 - dense_1_acc_29: 0.5667 - dense_1_acc_30: 0.0000e+00     
Epoch 20/100
60/60 [==============================] - 0s - loss: 55.4761 - dense_1_loss_1: 4.1189 - dense_1_loss_2: 3.5637 - dense_1_loss_3: 2.9002 - dense_1_loss_4: 2.6177 - dense_1_loss_5: 2.2596 - dense_1_loss_6: 1.9893 - dense_1_loss_7: 2.0135 - dense_1_loss_8: 1.7673 - dense_1_loss_9: 1.8833 - dense_1_loss_10: 1.6986 - dense_1_loss_11: 1.7912 - dense_1_loss_12: 1.6945 - dense_1_loss_13: 1.5218 - dense_1_loss_14: 1.5522 - dense_1_loss_15: 1.6312 - dense_1_loss_16: 1.7254 - dense_1_loss_17: 1.6705 - dense_1_loss_18: 1.5892 - dense_1_loss_19: 1.6236 - dense_1_loss_20: 1.5906 - dense_1_loss_21: 1.5903 - dense_1_loss_22: 1.6394 - dense_1_loss_23: 1.5444 - dense_1_loss_24: 1.6563 - dense_1_loss_25: 1.7084 - dense_1_loss_26: 1.4733 - dense_1_loss_27: 1.5569 - dense_1_loss_28: 1.5812 - dense_1_loss_29: 1.5237 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.3833 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.3500 - dense_1_acc_6: 0.4000 - dense_1_acc_7: 0.4000 - dense_1_acc_8: 0.4167 - dense_1_acc_9: 0.4167 - dense_1_acc_10: 0.4667 - dense_1_acc_11: 0.4167 - dense_1_acc_12: 0.4000 - dense_1_acc_13: 0.6000 - dense_1_acc_14: 0.5500 - dense_1_acc_15: 0.4833 - dense_1_acc_16: 0.4667 - dense_1_acc_17: 0.4667 - dense_1_acc_18: 0.4833 - dense_1_acc_19: 0.5000 - dense_1_acc_20: 0.5833 - dense_1_acc_21: 0.5833 - dense_1_acc_22: 0.5167 - dense_1_acc_23: 0.6167 - dense_1_acc_24: 0.5333 - dense_1_acc_25: 0.4167 - dense_1_acc_26: 0.6500 - dense_1_acc_27: 0.6000 - dense_1_acc_28: 0.5167 - dense_1_acc_29: 0.6167 - dense_1_acc_30: 0.0000e+00     
Epoch 21/100
60/60 [==============================] - 0s - loss: 52.5952 - dense_1_loss_1: 4.1115 - dense_1_loss_2: 3.5210 - dense_1_loss_3: 2.8198 - dense_1_loss_4: 2.5191 - dense_1_loss_5: 2.1622 - dense_1_loss_6: 1.8718 - dense_1_loss_7: 1.8840 - dense_1_loss_8: 1.6437 - dense_1_loss_9: 1.7017 - dense_1_loss_10: 1.5723 - dense_1_loss_11: 1.6463 - dense_1_loss_12: 1.5608 - dense_1_loss_13: 1.3714 - dense_1_loss_14: 1.4084 - dense_1_loss_15: 1.4898 - dense_1_loss_16: 1.5919 - dense_1_loss_17: 1.5521 - dense_1_loss_18: 1.4812 - dense_1_loss_19: 1.4532 - dense_1_loss_20: 1.5159 - dense_1_loss_21: 1.4975 - dense_1_loss_22: 1.5416 - dense_1_loss_23: 1.4791 - dense_1_loss_24: 1.5756 - dense_1_loss_25: 1.6586 - dense_1_loss_26: 1.4051 - dense_1_loss_27: 1.5384 - dense_1_loss_28: 1.5311 - dense_1_loss_29: 1.4903 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.4000 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3500 - dense_1_acc_6: 0.4500 - dense_1_acc_7: 0.4500 - dense_1_acc_8: 0.5000 - dense_1_acc_9: 0.5167 - dense_1_acc_10: 0.5000 - dense_1_acc_11: 0.4333 - dense_1_acc_12: 0.4667 - dense_1_acc_13: 0.7167 - dense_1_acc_14: 0.6833 - dense_1_acc_15: 0.5167 - dense_1_acc_16: 0.5500 - dense_1_acc_17: 0.4833 - dense_1_acc_18: 0.5333 - dense_1_acc_19: 0.5333 - dense_1_acc_20: 0.4833 - dense_1_acc_21: 0.6167 - dense_1_acc_22: 0.5667 - dense_1_acc_23: 0.5667 - dense_1_acc_24: 0.4833 - dense_1_acc_25: 0.4500 - dense_1_acc_26: 0.6333 - dense_1_acc_27: 0.5500 - dense_1_acc_28: 0.5833 - dense_1_acc_29: 0.6500 - dense_1_acc_30: 0.0000e+00     
Epoch 22/100
60/60 [==============================] - 0s - loss: 50.2160 - dense_1_loss_1: 4.1047 - dense_1_loss_2: 3.4770 - dense_1_loss_3: 2.7407 - dense_1_loss_4: 2.4178 - dense_1_loss_5: 2.0648 - dense_1_loss_6: 1.7635 - dense_1_loss_7: 1.7659 - dense_1_loss_8: 1.5881 - dense_1_loss_9: 1.5796 - dense_1_loss_10: 1.4720 - dense_1_loss_11: 1.5638 - dense_1_loss_12: 1.4441 - dense_1_loss_13: 1.3000 - dense_1_loss_14: 1.3932 - dense_1_loss_15: 1.3870 - dense_1_loss_16: 1.5121 - dense_1_loss_17: 1.4827 - dense_1_loss_18: 1.3958 - dense_1_loss_19: 1.4016 - dense_1_loss_20: 1.4361 - dense_1_loss_21: 1.4005 - dense_1_loss_22: 1.5129 - dense_1_loss_23: 1.3737 - dense_1_loss_24: 1.4531 - dense_1_loss_25: 1.5305 - dense_1_loss_26: 1.3757 - dense_1_loss_27: 1.4563 - dense_1_loss_28: 1.4114 - dense_1_loss_29: 1.4113 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.4167 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.3667 - dense_1_acc_6: 0.5000 - dense_1_acc_7: 0.4667 - dense_1_acc_8: 0.5167 - dense_1_acc_9: 0.6000 - dense_1_acc_10: 0.5500 - dense_1_acc_11: 0.4333 - dense_1_acc_12: 0.5167 - dense_1_acc_13: 0.7000 - dense_1_acc_14: 0.6333 - dense_1_acc_15: 0.6000 - dense_1_acc_16: 0.5333 - dense_1_acc_17: 0.5500 - dense_1_acc_18: 0.5833 - dense_1_acc_19: 0.6333 - dense_1_acc_20: 0.6833 - dense_1_acc_21: 0.6500 - dense_1_acc_22: 0.6167 - dense_1_acc_23: 0.6833 - dense_1_acc_24: 0.5667 - dense_1_acc_25: 0.5333 - dense_1_acc_26: 0.6500 - dense_1_acc_27: 0.5167 - dense_1_acc_28: 0.7000 - dense_1_acc_29: 0.6667 - dense_1_acc_30: 0.0000e+00     
Epoch 23/100
60/60 [==============================] - 0s - loss: 47.6829 - dense_1_loss_1: 4.0972 - dense_1_loss_2: 3.4353 - dense_1_loss_3: 2.6637 - dense_1_loss_4: 2.3184 - dense_1_loss_5: 1.9563 - dense_1_loss_6: 1.6456 - dense_1_loss_7: 1.6569 - dense_1_loss_8: 1.4727 - dense_1_loss_9: 1.5131 - dense_1_loss_10: 1.3883 - dense_1_loss_11: 1.4958 - dense_1_loss_12: 1.3610 - dense_1_loss_13: 1.2473 - dense_1_loss_14: 1.3105 - dense_1_loss_15: 1.3116 - dense_1_loss_16: 1.3763 - dense_1_loss_17: 1.3985 - dense_1_loss_18: 1.3418 - dense_1_loss_19: 1.3085 - dense_1_loss_20: 1.3157 - dense_1_loss_21: 1.3183 - dense_1_loss_22: 1.4045 - dense_1_loss_23: 1.3021 - dense_1_loss_24: 1.3491 - dense_1_loss_25: 1.4308 - dense_1_loss_26: 1.2834 - dense_1_loss_27: 1.3413 - dense_1_loss_28: 1.3298 - dense_1_loss_29: 1.3091 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.4333 - dense_1_acc_4: 0.3333 - dense_1_acc_5: 0.4000 - dense_1_acc_6: 0.5000 - dense_1_acc_7: 0.5000 - dense_1_acc_8: 0.5667 - dense_1_acc_9: 0.6167 - dense_1_acc_10: 0.6167 - dense_1_acc_11: 0.5667 - dense_1_acc_12: 0.6167 - dense_1_acc_13: 0.7333 - dense_1_acc_14: 0.6167 - dense_1_acc_15: 0.5833 - dense_1_acc_16: 0.6000 - dense_1_acc_17: 0.6333 - dense_1_acc_18: 0.6500 - dense_1_acc_19: 0.6833 - dense_1_acc_20: 0.7667 - dense_1_acc_21: 0.6500 - dense_1_acc_22: 0.6500 - dense_1_acc_23: 0.7333 - dense_1_acc_24: 0.6667 - dense_1_acc_25: 0.5333 - dense_1_acc_26: 0.7333 - dense_1_acc_27: 0.6667 - dense_1_acc_28: 0.7167 - dense_1_acc_29: 0.7000 - dense_1_acc_30: 0.0000e+00     
Epoch 24/100
60/60 [==============================] - 0s - loss: 45.3187 - dense_1_loss_1: 4.0901 - dense_1_loss_2: 3.3922 - dense_1_loss_3: 2.5825 - dense_1_loss_4: 2.2373 - dense_1_loss_5: 1.8703 - dense_1_loss_6: 1.5549 - dense_1_loss_7: 1.5355 - dense_1_loss_8: 1.4056 - dense_1_loss_9: 1.3904 - dense_1_loss_10: 1.3019 - dense_1_loss_11: 1.3719 - dense_1_loss_12: 1.2736 - dense_1_loss_13: 1.1612 - dense_1_loss_14: 1.2376 - dense_1_loss_15: 1.2141 - dense_1_loss_16: 1.2789 - dense_1_loss_17: 1.3098 - dense_1_loss_18: 1.2803 - dense_1_loss_19: 1.2623 - dense_1_loss_20: 1.2124 - dense_1_loss_21: 1.2315 - dense_1_loss_22: 1.3501 - dense_1_loss_23: 1.2118 - dense_1_loss_24: 1.2614 - dense_1_loss_25: 1.3370 - dense_1_loss_26: 1.2148 - dense_1_loss_27: 1.2702 - dense_1_loss_28: 1.2633 - dense_1_loss_29: 1.2155 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.4500 - dense_1_acc_4: 0.3500 - dense_1_acc_5: 0.4000 - dense_1_acc_6: 0.6000 - dense_1_acc_7: 0.5500 - dense_1_acc_8: 0.6333 - dense_1_acc_9: 0.6333 - dense_1_acc_10: 0.6500 - dense_1_acc_11: 0.5333 - dense_1_acc_12: 0.6833 - dense_1_acc_13: 0.8000 - dense_1_acc_14: 0.6000 - dense_1_acc_15: 0.6000 - dense_1_acc_16: 0.6667 - dense_1_acc_17: 0.6833 - dense_1_acc_18: 0.7167 - dense_1_acc_19: 0.7333 - dense_1_acc_20: 0.7500 - dense_1_acc_21: 0.7500 - dense_1_acc_22: 0.7000 - dense_1_acc_23: 0.7667 - dense_1_acc_24: 0.7500 - dense_1_acc_25: 0.5000 - dense_1_acc_26: 0.7167 - dense_1_acc_27: 0.6667 - dense_1_acc_28: 0.7667 - dense_1_acc_29: 0.7667 - dense_1_acc_30: 0.0000e+00     
Epoch 25/100
60/60 [==============================] - 0s - loss: 43.0943 - dense_1_loss_1: 4.0826 - dense_1_loss_2: 3.3473 - dense_1_loss_3: 2.5037 - dense_1_loss_4: 2.1542 - dense_1_loss_5: 1.7748 - dense_1_loss_6: 1.4676 - dense_1_loss_7: 1.4258 - dense_1_loss_8: 1.3439 - dense_1_loss_9: 1.2775 - dense_1_loss_10: 1.2072 - dense_1_loss_11: 1.2504 - dense_1_loss_12: 1.1964 - dense_1_loss_13: 1.0910 - dense_1_loss_14: 1.1317 - dense_1_loss_15: 1.1530 - dense_1_loss_16: 1.1781 - dense_1_loss_17: 1.2662 - dense_1_loss_18: 1.2050 - dense_1_loss_19: 1.1581 - dense_1_loss_20: 1.1413 - dense_1_loss_21: 1.1878 - dense_1_loss_22: 1.2693 - dense_1_loss_23: 1.1599 - dense_1_loss_24: 1.1910 - dense_1_loss_25: 1.2612 - dense_1_loss_26: 1.1298 - dense_1_loss_27: 1.2135 - dense_1_loss_28: 1.1730 - dense_1_loss_29: 1.1530 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3000 - dense_1_acc_3: 0.4667 - dense_1_acc_4: 0.3500 - dense_1_acc_5: 0.4500 - dense_1_acc_6: 0.6000 - dense_1_acc_7: 0.5833 - dense_1_acc_8: 0.6500 - dense_1_acc_9: 0.6833 - dense_1_acc_10: 0.6833 - dense_1_acc_11: 0.6167 - dense_1_acc_12: 0.7167 - dense_1_acc_13: 0.8333 - dense_1_acc_14: 0.7167 - dense_1_acc_15: 0.7000 - dense_1_acc_16: 0.7167 - dense_1_acc_17: 0.6333 - dense_1_acc_18: 0.7000 - dense_1_acc_19: 0.8000 - dense_1_acc_20: 0.7833 - dense_1_acc_21: 0.7667 - dense_1_acc_22: 0.7000 - dense_1_acc_23: 0.7833 - dense_1_acc_24: 0.6833 - dense_1_acc_25: 0.5833 - dense_1_acc_26: 0.7500 - dense_1_acc_27: 0.6500 - dense_1_acc_28: 0.7833 - dense_1_acc_29: 0.7667 - dense_1_acc_30: 0.0000e+00     
Epoch 26/100
60/60 [==============================] - 0s - loss: 40.8022 - dense_1_loss_1: 4.0748 - dense_1_loss_2: 3.3002 - dense_1_loss_3: 2.4259 - dense_1_loss_4: 2.0715 - dense_1_loss_5: 1.6825 - dense_1_loss_6: 1.3776 - dense_1_loss_7: 1.3323 - dense_1_loss_8: 1.2728 - dense_1_loss_9: 1.2005 - dense_1_loss_10: 1.1305 - dense_1_loss_11: 1.1444 - dense_1_loss_12: 1.1230 - dense_1_loss_13: 1.0321 - dense_1_loss_14: 1.0275 - dense_1_loss_15: 1.0911 - dense_1_loss_16: 1.0935 - dense_1_loss_17: 1.1465 - dense_1_loss_18: 1.1157 - dense_1_loss_19: 1.0581 - dense_1_loss_20: 1.0947 - dense_1_loss_21: 1.1024 - dense_1_loss_22: 1.1725 - dense_1_loss_23: 1.0688 - dense_1_loss_24: 1.0804 - dense_1_loss_25: 1.1933 - dense_1_loss_26: 1.0530 - dense_1_loss_27: 1.1423 - dense_1_loss_28: 1.0956 - dense_1_loss_29: 1.0991 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5000 - dense_1_acc_4: 0.3833 - dense_1_acc_5: 0.5000 - dense_1_acc_6: 0.6833 - dense_1_acc_7: 0.7000 - dense_1_acc_8: 0.6167 - dense_1_acc_9: 0.7000 - dense_1_acc_10: 0.7833 - dense_1_acc_11: 0.7167 - dense_1_acc_12: 0.8000 - dense_1_acc_13: 0.8833 - dense_1_acc_14: 0.8667 - dense_1_acc_15: 0.7833 - dense_1_acc_16: 0.8167 - dense_1_acc_17: 0.8000 - dense_1_acc_18: 0.7333 - dense_1_acc_19: 0.8333 - dense_1_acc_20: 0.8167 - dense_1_acc_21: 0.8667 - dense_1_acc_22: 0.7667 - dense_1_acc_23: 0.8500 - dense_1_acc_24: 0.8000 - dense_1_acc_25: 0.7000 - dense_1_acc_26: 0.8667 - dense_1_acc_27: 0.7667 - dense_1_acc_28: 0.8333 - dense_1_acc_29: 0.8333 - dense_1_acc_30: 0.0000e+00     
Epoch 27/100
60/60 [==============================] - 0s - loss: 38.8025 - dense_1_loss_1: 4.0663 - dense_1_loss_2: 3.2536 - dense_1_loss_3: 2.3506 - dense_1_loss_4: 1.9905 - dense_1_loss_5: 1.5981 - dense_1_loss_6: 1.3005 - dense_1_loss_7: 1.2525 - dense_1_loss_8: 1.2083 - dense_1_loss_9: 1.1123 - dense_1_loss_10: 1.0546 - dense_1_loss_11: 1.0712 - dense_1_loss_12: 1.0661 - dense_1_loss_13: 0.9613 - dense_1_loss_14: 0.9802 - dense_1_loss_15: 1.0168 - dense_1_loss_16: 1.0461 - dense_1_loss_17: 1.0501 - dense_1_loss_18: 1.0304 - dense_1_loss_19: 1.0029 - dense_1_loss_20: 1.0419 - dense_1_loss_21: 1.0439 - dense_1_loss_22: 1.0489 - dense_1_loss_23: 1.0150 - dense_1_loss_24: 0.9941 - dense_1_loss_25: 1.1266 - dense_1_loss_26: 1.0159 - dense_1_loss_27: 1.0529 - dense_1_loss_28: 1.0263 - dense_1_loss_29: 1.0247 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5000 - dense_1_acc_4: 0.4000 - dense_1_acc_5: 0.5167 - dense_1_acc_6: 0.6667 - dense_1_acc_7: 0.7500 - dense_1_acc_8: 0.6500 - dense_1_acc_9: 0.7500 - dense_1_acc_10: 0.8333 - dense_1_acc_11: 0.7667 - dense_1_acc_12: 0.8167 - dense_1_acc_13: 0.8833 - dense_1_acc_14: 0.8667 - dense_1_acc_15: 0.8333 - dense_1_acc_16: 0.9000 - dense_1_acc_17: 0.8500 - dense_1_acc_18: 0.7500 - dense_1_acc_19: 0.8833 - dense_1_acc_20: 0.8500 - dense_1_acc_21: 0.8500 - dense_1_acc_22: 0.8833 - dense_1_acc_23: 0.8333 - dense_1_acc_24: 0.8667 - dense_1_acc_25: 0.7000 - dense_1_acc_26: 0.8500 - dense_1_acc_27: 0.8000 - dense_1_acc_28: 0.8333 - dense_1_acc_29: 0.8333 - dense_1_acc_30: 0.0000e+00     
Epoch 28/100
60/60 [==============================] - 0s - loss: 36.8764 - dense_1_loss_1: 4.0580 - dense_1_loss_2: 3.2063 - dense_1_loss_3: 2.2747 - dense_1_loss_4: 1.9115 - dense_1_loss_5: 1.5232 - dense_1_loss_6: 1.2318 - dense_1_loss_7: 1.1687 - dense_1_loss_8: 1.1294 - dense_1_loss_9: 1.0486 - dense_1_loss_10: 0.9668 - dense_1_loss_11: 1.0165 - dense_1_loss_12: 1.0011 - dense_1_loss_13: 0.8906 - dense_1_loss_14: 0.8915 - dense_1_loss_15: 0.9522 - dense_1_loss_16: 0.9425 - dense_1_loss_17: 0.9959 - dense_1_loss_18: 0.9568 - dense_1_loss_19: 0.9452 - dense_1_loss_20: 0.9827 - dense_1_loss_21: 0.9702 - dense_1_loss_22: 0.9839 - dense_1_loss_23: 0.9601 - dense_1_loss_24: 0.9256 - dense_1_loss_25: 1.0594 - dense_1_loss_26: 0.9498 - dense_1_loss_27: 1.0003 - dense_1_loss_28: 0.9784 - dense_1_loss_29: 0.9549 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5333 - dense_1_acc_4: 0.4500 - dense_1_acc_5: 0.5500 - dense_1_acc_6: 0.7167 - dense_1_acc_7: 0.8500 - dense_1_acc_8: 0.7167 - dense_1_acc_9: 0.8167 - dense_1_acc_10: 0.8833 - dense_1_acc_11: 0.7667 - dense_1_acc_12: 0.8500 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.8833 - dense_1_acc_15: 0.8500 - dense_1_acc_16: 0.9500 - dense_1_acc_17: 0.8333 - dense_1_acc_18: 0.7667 - dense_1_acc_19: 0.8667 - dense_1_acc_20: 0.8333 - dense_1_acc_21: 0.8500 - dense_1_acc_22: 0.9000 - dense_1_acc_23: 0.8833 - dense_1_acc_24: 0.8833 - dense_1_acc_25: 0.7667 - dense_1_acc_26: 0.8833 - dense_1_acc_27: 0.8167 - dense_1_acc_28: 0.8333 - dense_1_acc_29: 0.8833 - dense_1_acc_30: 0.0000e+00     
Epoch 29/100
60/60 [==============================] - 0s - loss: 34.8516 - dense_1_loss_1: 4.0505 - dense_1_loss_2: 3.1603 - dense_1_loss_3: 2.2028 - dense_1_loss_4: 1.8335 - dense_1_loss_5: 1.4395 - dense_1_loss_6: 1.1476 - dense_1_loss_7: 1.0989 - dense_1_loss_8: 1.0629 - dense_1_loss_9: 0.9678 - dense_1_loss_10: 0.9031 - dense_1_loss_11: 0.9193 - dense_1_loss_12: 0.9352 - dense_1_loss_13: 0.8223 - dense_1_loss_14: 0.8405 - dense_1_loss_15: 0.8826 - dense_1_loss_16: 0.8818 - dense_1_loss_17: 0.9120 - dense_1_loss_18: 0.8814 - dense_1_loss_19: 0.8926 - dense_1_loss_20: 0.9129 - dense_1_loss_21: 0.8975 - dense_1_loss_22: 0.9191 - dense_1_loss_23: 0.8582 - dense_1_loss_24: 0.8664 - dense_1_loss_25: 0.9873 - dense_1_loss_26: 0.8851 - dense_1_loss_27: 0.9208 - dense_1_loss_28: 0.8919 - dense_1_loss_29: 0.8781 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5333 - dense_1_acc_4: 0.4833 - dense_1_acc_5: 0.5833 - dense_1_acc_6: 0.7667 - dense_1_acc_7: 0.9000 - dense_1_acc_8: 0.7500 - dense_1_acc_9: 0.8000 - dense_1_acc_10: 0.8833 - dense_1_acc_11: 0.8500 - dense_1_acc_12: 0.9167 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.9500 - dense_1_acc_15: 0.8833 - dense_1_acc_16: 0.9667 - dense_1_acc_17: 0.9000 - dense_1_acc_18: 0.8833 - dense_1_acc_19: 0.8667 - dense_1_acc_20: 0.9000 - dense_1_acc_21: 0.9333 - dense_1_acc_22: 0.9167 - dense_1_acc_23: 0.9167 - dense_1_acc_24: 0.9167 - dense_1_acc_25: 0.8000 - dense_1_acc_26: 0.9167 - dense_1_acc_27: 0.9000 - dense_1_acc_28: 0.8667 - dense_1_acc_29: 0.8833 - dense_1_acc_30: 0.0000e+00     
Epoch 30/100
60/60 [==============================] - 0s - loss: 33.0396 - dense_1_loss_1: 4.0425 - dense_1_loss_2: 3.1119 - dense_1_loss_3: 2.1338 - dense_1_loss_4: 1.7691 - dense_1_loss_5: 1.3593 - dense_1_loss_6: 1.0798 - dense_1_loss_7: 1.0260 - dense_1_loss_8: 0.9722 - dense_1_loss_9: 0.8939 - dense_1_loss_10: 0.8502 - dense_1_loss_11: 0.8510 - dense_1_loss_12: 0.8728 - dense_1_loss_13: 0.7624 - dense_1_loss_14: 0.8034 - dense_1_loss_15: 0.8181 - dense_1_loss_16: 0.8146 - dense_1_loss_17: 0.8315 - dense_1_loss_18: 0.8346 - dense_1_loss_19: 0.8512 - dense_1_loss_20: 0.8402 - dense_1_loss_21: 0.8208 - dense_1_loss_22: 0.8591 - dense_1_loss_23: 0.7893 - dense_1_loss_24: 0.8128 - dense_1_loss_25: 0.9424 - dense_1_loss_26: 0.7967 - dense_1_loss_27: 0.8467 - dense_1_loss_28: 0.8232 - dense_1_loss_29: 0.8301 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5500 - dense_1_acc_4: 0.4833 - dense_1_acc_5: 0.6333 - dense_1_acc_6: 0.7833 - dense_1_acc_7: 0.9500 - dense_1_acc_8: 0.8000 - dense_1_acc_9: 0.8333 - dense_1_acc_10: 0.9000 - dense_1_acc_11: 0.9000 - dense_1_acc_12: 0.9333 - dense_1_acc_13: 0.9667 - dense_1_acc_14: 0.9500 - dense_1_acc_15: 0.8833 - dense_1_acc_16: 0.9667 - dense_1_acc_17: 0.9333 - dense_1_acc_18: 0.9000 - dense_1_acc_19: 0.9000 - dense_1_acc_20: 0.9167 - dense_1_acc_21: 0.9500 - dense_1_acc_22: 0.9333 - dense_1_acc_23: 0.9333 - dense_1_acc_24: 0.9667 - dense_1_acc_25: 0.8333 - dense_1_acc_26: 0.9500 - dense_1_acc_27: 0.9167 - dense_1_acc_28: 0.9000 - dense_1_acc_29: 0.8833 - dense_1_acc_30: 0.0000e+00     
Epoch 31/100
60/60 [==============================] - 0s - loss: 31.2115 - dense_1_loss_1: 4.0347 - dense_1_loss_2: 3.0670 - dense_1_loss_3: 2.0677 - dense_1_loss_4: 1.6894 - dense_1_loss_5: 1.2791 - dense_1_loss_6: 1.0036 - dense_1_loss_7: 0.9697 - dense_1_loss_8: 0.9078 - dense_1_loss_9: 0.8270 - dense_1_loss_10: 0.7842 - dense_1_loss_11: 0.7984 - dense_1_loss_12: 0.7919 - dense_1_loss_13: 0.6998 - dense_1_loss_14: 0.7360 - dense_1_loss_15: 0.7607 - dense_1_loss_16: 0.7495 - dense_1_loss_17: 0.7710 - dense_1_loss_18: 0.7747 - dense_1_loss_19: 0.7774 - dense_1_loss_20: 0.7782 - dense_1_loss_21: 0.7584 - dense_1_loss_22: 0.7907 - dense_1_loss_23: 0.7403 - dense_1_loss_24: 0.7389 - dense_1_loss_25: 0.8684 - dense_1_loss_26: 0.7347 - dense_1_loss_27: 0.7808 - dense_1_loss_28: 0.7643 - dense_1_loss_29: 0.7672 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5667 - dense_1_acc_4: 0.4833 - dense_1_acc_5: 0.7000 - dense_1_acc_6: 0.8167 - dense_1_acc_7: 0.9333 - dense_1_acc_8: 0.8667 - dense_1_acc_9: 0.8500 - dense_1_acc_10: 0.9500 - dense_1_acc_11: 0.9000 - dense_1_acc_12: 0.9500 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9500 - dense_1_acc_15: 0.9167 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9333 - dense_1_acc_18: 0.9500 - dense_1_acc_19: 0.9500 - dense_1_acc_20: 0.9500 - dense_1_acc_21: 0.9333 - dense_1_acc_22: 0.9500 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9667 - dense_1_acc_25: 0.8500 - dense_1_acc_26: 0.9500 - dense_1_acc_27: 0.9500 - dense_1_acc_28: 0.9167 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0000e+00     
Epoch 32/100
60/60 [==============================] - 0s - loss: 29.5748 - dense_1_loss_1: 4.0282 - dense_1_loss_2: 3.0201 - dense_1_loss_3: 2.0028 - dense_1_loss_4: 1.6073 - dense_1_loss_5: 1.1976 - dense_1_loss_6: 0.9391 - dense_1_loss_7: 0.8996 - dense_1_loss_8: 0.8674 - dense_1_loss_9: 0.7689 - dense_1_loss_10: 0.7085 - dense_1_loss_11: 0.7296 - dense_1_loss_12: 0.7143 - dense_1_loss_13: 0.6478 - dense_1_loss_14: 0.6798 - dense_1_loss_15: 0.7037 - dense_1_loss_16: 0.6957 - dense_1_loss_17: 0.7155 - dense_1_loss_18: 0.7009 - dense_1_loss_19: 0.7276 - dense_1_loss_20: 0.7203 - dense_1_loss_21: 0.7206 - dense_1_loss_22: 0.7310 - dense_1_loss_23: 0.6957 - dense_1_loss_24: 0.6805 - dense_1_loss_25: 0.8066 - dense_1_loss_26: 0.6915 - dense_1_loss_27: 0.7420 - dense_1_loss_28: 0.7182 - dense_1_loss_29: 0.7141 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5500 - dense_1_acc_4: 0.5500 - dense_1_acc_5: 0.7333 - dense_1_acc_6: 0.8000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.8167 - dense_1_acc_9: 0.8833 - dense_1_acc_10: 0.9167 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 0.9667 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9500 - dense_1_acc_15: 0.9500 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9500 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9667 - dense_1_acc_20: 0.9667 - dense_1_acc_21: 0.9667 - dense_1_acc_22: 0.9833 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.8667 - dense_1_acc_26: 0.9667 - dense_1_acc_27: 0.9500 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0000e+00     
Epoch 33/100
60/60 [==============================] - 0s - loss: 27.9737 - dense_1_loss_1: 4.0216 - dense_1_loss_2: 2.9721 - dense_1_loss_3: 1.9386 - dense_1_loss_4: 1.5331 - dense_1_loss_5: 1.1200 - dense_1_loss_6: 0.8744 - dense_1_loss_7: 0.8335 - dense_1_loss_8: 0.7904 - dense_1_loss_9: 0.7247 - dense_1_loss_10: 0.6550 - dense_1_loss_11: 0.6820 - dense_1_loss_12: 0.6602 - dense_1_loss_13: 0.6051 - dense_1_loss_14: 0.6329 - dense_1_loss_15: 0.6448 - dense_1_loss_16: 0.6574 - dense_1_loss_17: 0.6564 - dense_1_loss_18: 0.6470 - dense_1_loss_19: 0.6808 - dense_1_loss_20: 0.6682 - dense_1_loss_21: 0.6471 - dense_1_loss_22: 0.6879 - dense_1_loss_23: 0.6490 - dense_1_loss_24: 0.6138 - dense_1_loss_25: 0.7459 - dense_1_loss_26: 0.6281 - dense_1_loss_27: 0.6810 - dense_1_loss_28: 0.6606 - dense_1_loss_29: 0.6623 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3000 - dense_1_acc_3: 0.5500 - dense_1_acc_4: 0.5667 - dense_1_acc_5: 0.7500 - dense_1_acc_6: 0.8333 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9167 - dense_1_acc_9: 0.9000 - dense_1_acc_10: 0.9833 - dense_1_acc_11: 0.9167 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9667 - dense_1_acc_15: 0.9667 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9667 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9667 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 0.9833 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0000e+00     
Epoch 34/100
60/60 [==============================] - 0s - loss: 26.4537 - dense_1_loss_1: 4.0143 - dense_1_loss_2: 2.9284 - dense_1_loss_3: 1.8764 - dense_1_loss_4: 1.4577 - dense_1_loss_5: 1.0544 - dense_1_loss_6: 0.8088 - dense_1_loss_7: 0.7924 - dense_1_loss_8: 0.7171 - dense_1_loss_9: 0.6815 - dense_1_loss_10: 0.6032 - dense_1_loss_11: 0.6289 - dense_1_loss_12: 0.6122 - dense_1_loss_13: 0.5585 - dense_1_loss_14: 0.5847 - dense_1_loss_15: 0.6003 - dense_1_loss_16: 0.5864 - dense_1_loss_17: 0.6140 - dense_1_loss_18: 0.6007 - dense_1_loss_19: 0.6066 - dense_1_loss_20: 0.6227 - dense_1_loss_21: 0.6074 - dense_1_loss_22: 0.6242 - dense_1_loss_23: 0.5913 - dense_1_loss_24: 0.5784 - dense_1_loss_25: 0.6959 - dense_1_loss_26: 0.5685 - dense_1_loss_27: 0.6152 - dense_1_loss_28: 0.6178 - dense_1_loss_29: 0.6057 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3000 - dense_1_acc_3: 0.5667 - dense_1_acc_4: 0.6167 - dense_1_acc_5: 0.7833 - dense_1_acc_6: 0.8333 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9167 - dense_1_acc_9: 0.9167 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 0.9667 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9667 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9333 - dense_1_acc_30: 0.0000e+00     
Epoch 35/100
60/60 [==============================] - 0s - loss: 25.3020 - dense_1_loss_1: 4.0076 - dense_1_loss_2: 2.8809 - dense_1_loss_3: 1.8127 - dense_1_loss_4: 1.3818 - dense_1_loss_5: 0.9883 - dense_1_loss_6: 0.7545 - dense_1_loss_7: 0.7398 - dense_1_loss_8: 0.6632 - dense_1_loss_9: 0.6211 - dense_1_loss_10: 0.5547 - dense_1_loss_11: 0.5828 - dense_1_loss_12: 0.5680 - dense_1_loss_13: 0.5074 - dense_1_loss_14: 0.5488 - dense_1_loss_15: 0.5518 - dense_1_loss_16: 0.5706 - dense_1_loss_17: 0.5637 - dense_1_loss_18: 0.5603 - dense_1_loss_19: 0.5770 - dense_1_loss_20: 0.5882 - dense_1_loss_21: 0.5975 - dense_1_loss_22: 0.5684 - dense_1_loss_23: 0.5613 - dense_1_loss_24: 0.5658 - dense_1_loss_25: 0.6647 - dense_1_loss_26: 0.5433 - dense_1_loss_27: 0.6020 - dense_1_loss_28: 0.5876 - dense_1_loss_29: 0.5882 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.6000 - dense_1_acc_4: 0.6500 - dense_1_acc_5: 0.7833 - dense_1_acc_6: 0.8667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9500 - dense_1_acc_9: 0.9000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9667 - dense_1_acc_15: 0.9833 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9667 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 0.9833 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.8833 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 0.9833 - dense_1_acc_28: 0.9667 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0000e+00     
Epoch 36/100
60/60 [==============================] - 0s - loss: 24.0212 - dense_1_loss_1: 4.0018 - dense_1_loss_2: 2.8350 - dense_1_loss_3: 1.7567 - dense_1_loss_4: 1.3129 - dense_1_loss_5: 0.9261 - dense_1_loss_6: 0.7048 - dense_1_loss_7: 0.7056 - dense_1_loss_8: 0.5899 - dense_1_loss_9: 0.5723 - dense_1_loss_10: 0.5290 - dense_1_loss_11: 0.5672 - dense_1_loss_12: 0.5433 - dense_1_loss_13: 0.4691 - dense_1_loss_14: 0.5052 - dense_1_loss_15: 0.5154 - dense_1_loss_16: 0.5191 - dense_1_loss_17: 0.5147 - dense_1_loss_18: 0.5275 - dense_1_loss_19: 0.5322 - dense_1_loss_20: 0.5460 - dense_1_loss_21: 0.5364 - dense_1_loss_22: 0.5149 - dense_1_loss_23: 0.5171 - dense_1_loss_24: 0.5470 - dense_1_loss_25: 0.6014 - dense_1_loss_26: 0.5223 - dense_1_loss_27: 0.5298 - dense_1_loss_28: 0.5323 - dense_1_loss_29: 0.5465 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.6500 - dense_1_acc_5: 0.8000 - dense_1_acc_6: 0.8833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9500 - dense_1_acc_9: 0.9333 - dense_1_acc_10: 0.9833 - dense_1_acc_11: 0.9333 - dense_1_acc_12: 0.9667 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 0.9833 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9333 - dense_1_acc_26: 0.9667 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9333 - dense_1_acc_30: 0.0000e+00     
Epoch 37/100
60/60 [==============================] - 0s - loss: 22.7911 - dense_1_loss_1: 3.9958 - dense_1_loss_2: 2.7889 - dense_1_loss_3: 1.6957 - dense_1_loss_4: 1.2449 - dense_1_loss_5: 0.8664 - dense_1_loss_6: 0.6546 - dense_1_loss_7: 0.6433 - dense_1_loss_8: 0.5611 - dense_1_loss_9: 0.5342 - dense_1_loss_10: 0.4752 - dense_1_loss_11: 0.4942 - dense_1_loss_12: 0.4948 - dense_1_loss_13: 0.4327 - dense_1_loss_14: 0.4618 - dense_1_loss_15: 0.4805 - dense_1_loss_16: 0.4725 - dense_1_loss_17: 0.4893 - dense_1_loss_18: 0.4711 - dense_1_loss_19: 0.5226 - dense_1_loss_20: 0.4978 - dense_1_loss_21: 0.4973 - dense_1_loss_22: 0.5085 - dense_1_loss_23: 0.4918 - dense_1_loss_24: 0.4780 - dense_1_loss_25: 0.5687 - dense_1_loss_26: 0.5094 - dense_1_loss_27: 0.4872 - dense_1_loss_28: 0.4759 - dense_1_loss_29: 0.4969 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.6833 - dense_1_acc_5: 0.8333 - dense_1_acc_6: 0.9167 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 0.9667 - dense_1_acc_21: 0.9500 - dense_1_acc_22: 0.9833 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9333 - dense_1_acc_26: 0.9500 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     
Epoch 38/100
60/60 [==============================] - 0s - loss: 21.5434 - dense_1_loss_1: 3.9901 - dense_1_loss_2: 2.7436 - dense_1_loss_3: 1.6372 - dense_1_loss_4: 1.1774 - dense_1_loss_5: 0.8135 - dense_1_loss_6: 0.6036 - dense_1_loss_7: 0.5891 - dense_1_loss_8: 0.5241 - dense_1_loss_9: 0.4945 - dense_1_loss_10: 0.4275 - dense_1_loss_11: 0.4470 - dense_1_loss_12: 0.4405 - dense_1_loss_13: 0.3920 - dense_1_loss_14: 0.4135 - dense_1_loss_15: 0.4474 - dense_1_loss_16: 0.4103 - dense_1_loss_17: 0.4569 - dense_1_loss_18: 0.4348 - dense_1_loss_19: 0.4566 - dense_1_loss_20: 0.4556 - dense_1_loss_21: 0.4633 - dense_1_loss_22: 0.4516 - dense_1_loss_23: 0.4803 - dense_1_loss_24: 0.4165 - dense_1_loss_25: 0.5328 - dense_1_loss_26: 0.4615 - dense_1_loss_27: 0.4715 - dense_1_loss_28: 0.4605 - dense_1_loss_29: 0.4501 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.7500 - dense_1_acc_5: 0.9000 - dense_1_acc_6: 0.9333 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9667 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 39/100
60/60 [==============================] - 0s - loss: 20.4096 - dense_1_loss_1: 3.9847 - dense_1_loss_2: 2.6981 - dense_1_loss_3: 1.5830 - dense_1_loss_4: 1.1062 - dense_1_loss_5: 0.7642 - dense_1_loss_6: 0.5615 - dense_1_loss_7: 0.5547 - dense_1_loss_8: 0.4929 - dense_1_loss_9: 0.4626 - dense_1_loss_10: 0.3892 - dense_1_loss_11: 0.4192 - dense_1_loss_12: 0.4008 - dense_1_loss_13: 0.3720 - dense_1_loss_14: 0.3958 - dense_1_loss_15: 0.4000 - dense_1_loss_16: 0.3839 - dense_1_loss_17: 0.4178 - dense_1_loss_18: 0.4045 - dense_1_loss_19: 0.4057 - dense_1_loss_20: 0.4201 - dense_1_loss_21: 0.4235 - dense_1_loss_22: 0.3947 - dense_1_loss_23: 0.4373 - dense_1_loss_24: 0.3695 - dense_1_loss_25: 0.4961 - dense_1_loss_26: 0.4024 - dense_1_loss_27: 0.4213 - dense_1_loss_28: 0.4212 - dense_1_loss_29: 0.4268 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.7667 - dense_1_acc_5: 0.9000 - dense_1_acc_6: 0.9500 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9833 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 40/100
60/60 [==============================] - 0s - loss: 19.3388 - dense_1_loss_1: 3.9784 - dense_1_loss_2: 2.6535 - dense_1_loss_3: 1.5344 - dense_1_loss_4: 1.0452 - dense_1_loss_5: 0.7121 - dense_1_loss_6: 0.5257 - dense_1_loss_7: 0.5184 - dense_1_loss_8: 0.4365 - dense_1_loss_9: 0.4269 - dense_1_loss_10: 0.3572 - dense_1_loss_11: 0.3919 - dense_1_loss_12: 0.3681 - dense_1_loss_13: 0.3411 - dense_1_loss_14: 0.3671 - dense_1_loss_15: 0.3574 - dense_1_loss_16: 0.3562 - dense_1_loss_17: 0.3790 - dense_1_loss_18: 0.3677 - dense_1_loss_19: 0.3747 - dense_1_loss_20: 0.3929 - dense_1_loss_21: 0.3757 - dense_1_loss_22: 0.3625 - dense_1_loss_23: 0.3857 - dense_1_loss_24: 0.3530 - dense_1_loss_25: 0.4471 - dense_1_loss_26: 0.3708 - dense_1_loss_27: 0.3588 - dense_1_loss_28: 0.3926 - dense_1_loss_29: 0.4082 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.7833 - dense_1_acc_5: 0.9000 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 41/100
60/60 [==============================] - 0s - loss: 18.4427 - dense_1_loss_1: 3.9727 - dense_1_loss_2: 2.6086 - dense_1_loss_3: 1.4855 - dense_1_loss_4: 0.9911 - dense_1_loss_5: 0.6693 - dense_1_loss_6: 0.4911 - dense_1_loss_7: 0.4898 - dense_1_loss_8: 0.3894 - dense_1_loss_9: 0.3934 - dense_1_loss_10: 0.3294 - dense_1_loss_11: 0.3655 - dense_1_loss_12: 0.3469 - dense_1_loss_13: 0.3107 - dense_1_loss_14: 0.3240 - dense_1_loss_15: 0.3409 - dense_1_loss_16: 0.3289 - dense_1_loss_17: 0.3514 - dense_1_loss_18: 0.3306 - dense_1_loss_19: 0.3551 - dense_1_loss_20: 0.3632 - dense_1_loss_21: 0.3502 - dense_1_loss_22: 0.3416 - dense_1_loss_23: 0.3415 - dense_1_loss_24: 0.3464 - dense_1_loss_25: 0.4083 - dense_1_loss_26: 0.3446 - dense_1_loss_27: 0.3314 - dense_1_loss_28: 0.3591 - dense_1_loss_29: 0.3821 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6333 - dense_1_acc_4: 0.7833 - dense_1_acc_5: 0.9167 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 0.9833 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 42/100
60/60 [==============================] - 0s - loss: 17.5646 - dense_1_loss_1: 3.9672 - dense_1_loss_2: 2.5679 - dense_1_loss_3: 1.4368 - dense_1_loss_4: 0.9286 - dense_1_loss_5: 0.6270 - dense_1_loss_6: 0.4565 - dense_1_loss_7: 0.4589 - dense_1_loss_8: 0.3703 - dense_1_loss_9: 0.3668 - dense_1_loss_10: 0.3025 - dense_1_loss_11: 0.3322 - dense_1_loss_12: 0.3195 - dense_1_loss_13: 0.2819 - dense_1_loss_14: 0.2898 - dense_1_loss_15: 0.3175 - dense_1_loss_16: 0.3034 - dense_1_loss_17: 0.3205 - dense_1_loss_18: 0.3035 - dense_1_loss_19: 0.3269 - dense_1_loss_20: 0.3342 - dense_1_loss_21: 0.3339 - dense_1_loss_22: 0.3222 - dense_1_loss_23: 0.3123 - dense_1_loss_24: 0.3104 - dense_1_loss_25: 0.3722 - dense_1_loss_26: 0.3139 - dense_1_loss_27: 0.3122 - dense_1_loss_28: 0.3210 - dense_1_loss_29: 0.3546 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6333 - dense_1_acc_4: 0.8167 - dense_1_acc_5: 0.9333 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 43/100
60/60 [==============================] - 0s - loss: 16.7271 - dense_1_loss_1: 3.9624 - dense_1_loss_2: 2.5229 - dense_1_loss_3: 1.3891 - dense_1_loss_4: 0.8766 - dense_1_loss_5: 0.5865 - dense_1_loss_6: 0.4224 - dense_1_loss_7: 0.4348 - dense_1_loss_8: 0.3382 - dense_1_loss_9: 0.3413 - dense_1_loss_10: 0.2778 - dense_1_loss_11: 0.3062 - dense_1_loss_12: 0.2913 - dense_1_loss_13: 0.2632 - dense_1_loss_14: 0.2670 - dense_1_loss_15: 0.2825 - dense_1_loss_16: 0.2767 - dense_1_loss_17: 0.2871 - dense_1_loss_18: 0.2843 - dense_1_loss_19: 0.2982 - dense_1_loss_20: 0.2984 - dense_1_loss_21: 0.3035 - dense_1_loss_22: 0.2955 - dense_1_loss_23: 0.2923 - dense_1_loss_24: 0.2757 - dense_1_loss_25: 0.3403 - dense_1_loss_26: 0.2941 - dense_1_loss_27: 0.2997 - dense_1_loss_28: 0.2961 - dense_1_loss_29: 0.3230 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.8500 - dense_1_acc_5: 0.9333 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 44/100
60/60 [==============================] - 0s - loss: 16.0275 - dense_1_loss_1: 3.9571 - dense_1_loss_2: 2.4818 - dense_1_loss_3: 1.3443 - dense_1_loss_4: 0.8290 - dense_1_loss_5: 0.5499 - dense_1_loss_6: 0.3926 - dense_1_loss_7: 0.4075 - dense_1_loss_8: 0.3038 - dense_1_loss_9: 0.3181 - dense_1_loss_10: 0.2565 - dense_1_loss_11: 0.2853 - dense_1_loss_12: 0.2629 - dense_1_loss_13: 0.2446 - dense_1_loss_14: 0.2522 - dense_1_loss_15: 0.2562 - dense_1_loss_16: 0.2535 - dense_1_loss_17: 0.2654 - dense_1_loss_18: 0.2687 - dense_1_loss_19: 0.2804 - dense_1_loss_20: 0.2723 - dense_1_loss_21: 0.2774 - dense_1_loss_22: 0.2747 - dense_1_loss_23: 0.2851 - dense_1_loss_24: 0.2579 - dense_1_loss_25: 0.3207 - dense_1_loss_26: 0.2677 - dense_1_loss_27: 0.2866 - dense_1_loss_28: 0.2823 - dense_1_loss_29: 0.2931 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9333 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 45/100
60/60 [==============================] - 0s - loss: 15.2892 - dense_1_loss_1: 3.9528 - dense_1_loss_2: 2.4409 - dense_1_loss_3: 1.2989 - dense_1_loss_4: 0.7792 - dense_1_loss_5: 0.5144 - dense_1_loss_6: 0.3656 - dense_1_loss_7: 0.3803 - dense_1_loss_8: 0.2880 - dense_1_loss_9: 0.2896 - dense_1_loss_10: 0.2389 - dense_1_loss_11: 0.2588 - dense_1_loss_12: 0.2401 - dense_1_loss_13: 0.2234 - dense_1_loss_14: 0.2316 - dense_1_loss_15: 0.2370 - dense_1_loss_16: 0.2391 - dense_1_loss_17: 0.2397 - dense_1_loss_18: 0.2462 - dense_1_loss_19: 0.2602 - dense_1_loss_20: 0.2470 - dense_1_loss_21: 0.2554 - dense_1_loss_22: 0.2459 - dense_1_loss_23: 0.2618 - dense_1_loss_24: 0.2310 - dense_1_loss_25: 0.2938 - dense_1_loss_26: 0.2389 - dense_1_loss_27: 0.2560 - dense_1_loss_28: 0.2606 - dense_1_loss_29: 0.2741 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9500 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 46/100
60/60 [==============================] - 0s - loss: 14.6790 - dense_1_loss_1: 3.9472 - dense_1_loss_2: 2.3999 - dense_1_loss_3: 1.2582 - dense_1_loss_4: 0.7286 - dense_1_loss_5: 0.4830 - dense_1_loss_6: 0.3464 - dense_1_loss_7: 0.3574 - dense_1_loss_8: 0.2724 - dense_1_loss_9: 0.2679 - dense_1_loss_10: 0.2224 - dense_1_loss_11: 0.2386 - dense_1_loss_12: 0.2260 - dense_1_loss_13: 0.2022 - dense_1_loss_14: 0.2122 - dense_1_loss_15: 0.2253 - dense_1_loss_16: 0.2226 - dense_1_loss_17: 0.2267 - dense_1_loss_18: 0.2232 - dense_1_loss_19: 0.2375 - dense_1_loss_20: 0.2378 - dense_1_loss_21: 0.2357 - dense_1_loss_22: 0.2314 - dense_1_loss_23: 0.2384 - dense_1_loss_24: 0.2123 - dense_1_loss_25: 0.2717 - dense_1_loss_26: 0.2229 - dense_1_loss_27: 0.2288 - dense_1_loss_28: 0.2388 - dense_1_loss_29: 0.2635 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4333 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 47/100
60/60 [==============================] - 0s - loss: 14.0970 - dense_1_loss_1: 3.9425 - dense_1_loss_2: 2.3600 - dense_1_loss_3: 1.2195 - dense_1_loss_4: 0.6886 - dense_1_loss_5: 0.4519 - dense_1_loss_6: 0.3266 - dense_1_loss_7: 0.3332 - dense_1_loss_8: 0.2453 - dense_1_loss_9: 0.2445 - dense_1_loss_10: 0.2051 - dense_1_loss_11: 0.2236 - dense_1_loss_12: 0.2130 - dense_1_loss_13: 0.1839 - dense_1_loss_14: 0.1961 - dense_1_loss_15: 0.2109 - dense_1_loss_16: 0.2001 - dense_1_loss_17: 0.2142 - dense_1_loss_18: 0.2039 - dense_1_loss_19: 0.2189 - dense_1_loss_20: 0.2237 - dense_1_loss_21: 0.2180 - dense_1_loss_22: 0.2095 - dense_1_loss_23: 0.2203 - dense_1_loss_24: 0.2009 - dense_1_loss_25: 0.2488 - dense_1_loss_26: 0.2097 - dense_1_loss_27: 0.2100 - dense_1_loss_28: 0.2275 - dense_1_loss_29: 0.2467 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.6667 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 48/100
60/60 [==============================] - 0s - loss: 13.5650 - dense_1_loss_1: 3.9380 - dense_1_loss_2: 2.3213 - dense_1_loss_3: 1.1828 - dense_1_loss_4: 0.6479 - dense_1_loss_5: 0.4232 - dense_1_loss_6: 0.3065 - dense_1_loss_7: 0.3102 - dense_1_loss_8: 0.2231 - dense_1_loss_9: 0.2256 - dense_1_loss_10: 0.1906 - dense_1_loss_11: 0.2100 - dense_1_loss_12: 0.1964 - dense_1_loss_13: 0.1716 - dense_1_loss_14: 0.1827 - dense_1_loss_15: 0.1923 - dense_1_loss_16: 0.1898 - dense_1_loss_17: 0.1986 - dense_1_loss_18: 0.1855 - dense_1_loss_19: 0.2080 - dense_1_loss_20: 0.2070 - dense_1_loss_21: 0.1993 - dense_1_loss_22: 0.1943 - dense_1_loss_23: 0.2010 - dense_1_loss_24: 0.1894 - dense_1_loss_25: 0.2308 - dense_1_loss_26: 0.1998 - dense_1_loss_27: 0.2002 - dense_1_loss_28: 0.2135 - dense_1_loss_29: 0.2255 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 49/100
60/60 [==============================] - 0s - loss: 13.0597 - dense_1_loss_1: 3.9339 - dense_1_loss_2: 2.2832 - dense_1_loss_3: 1.1444 - dense_1_loss_4: 0.6110 - dense_1_loss_5: 0.3977 - dense_1_loss_6: 0.2916 - dense_1_loss_7: 0.2918 - dense_1_loss_8: 0.2103 - dense_1_loss_9: 0.2145 - dense_1_loss_10: 0.1770 - dense_1_loss_11: 0.1955 - dense_1_loss_12: 0.1818 - dense_1_loss_13: 0.1640 - dense_1_loss_14: 0.1702 - dense_1_loss_15: 0.1761 - dense_1_loss_16: 0.1776 - dense_1_loss_17: 0.1823 - dense_1_loss_18: 0.1722 - dense_1_loss_19: 0.1921 - dense_1_loss_20: 0.1922 - dense_1_loss_21: 0.1825 - dense_1_loss_22: 0.1838 - dense_1_loss_23: 0.1810 - dense_1_loss_24: 0.1717 - dense_1_loss_25: 0.2133 - dense_1_loss_26: 0.1796 - dense_1_loss_27: 0.1877 - dense_1_loss_28: 0.1932 - dense_1_loss_29: 0.2074 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7167 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 50/100
60/60 [==============================] - 0s - loss: 12.6026 - dense_1_loss_1: 3.9298 - dense_1_loss_2: 2.2459 - dense_1_loss_3: 1.1076 - dense_1_loss_4: 0.5701 - dense_1_loss_5: 0.3745 - dense_1_loss_6: 0.2743 - dense_1_loss_7: 0.2741 - dense_1_loss_8: 0.1958 - dense_1_loss_9: 0.2036 - dense_1_loss_10: 0.1632 - dense_1_loss_11: 0.1818 - dense_1_loss_12: 0.1658 - dense_1_loss_13: 0.1562 - dense_1_loss_14: 0.1593 - dense_1_loss_15: 0.1637 - dense_1_loss_16: 0.1626 - dense_1_loss_17: 0.1675 - dense_1_loss_18: 0.1637 - dense_1_loss_19: 0.1737 - dense_1_loss_20: 0.1801 - dense_1_loss_21: 0.1730 - dense_1_loss_22: 0.1703 - dense_1_loss_23: 0.1721 - dense_1_loss_24: 0.1558 - dense_1_loss_25: 0.1999 - dense_1_loss_26: 0.1673 - dense_1_loss_27: 0.1757 - dense_1_loss_28: 0.1815 - dense_1_loss_29: 0.1938 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7167 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 51/100
60/60 [==============================] - 0s - loss: 12.1969 - dense_1_loss_1: 3.9255 - dense_1_loss_2: 2.2080 - dense_1_loss_3: 1.0726 - dense_1_loss_4: 0.5390 - dense_1_loss_5: 0.3548 - dense_1_loss_6: 0.2577 - dense_1_loss_7: 0.2564 - dense_1_loss_8: 0.1868 - dense_1_loss_9: 0.1882 - dense_1_loss_10: 0.1529 - dense_1_loss_11: 0.1652 - dense_1_loss_12: 0.1568 - dense_1_loss_13: 0.1446 - dense_1_loss_14: 0.1448 - dense_1_loss_15: 0.1528 - dense_1_loss_16: 0.1549 - dense_1_loss_17: 0.1573 - dense_1_loss_18: 0.1558 - dense_1_loss_19: 0.1594 - dense_1_loss_20: 0.1655 - dense_1_loss_21: 0.1656 - dense_1_loss_22: 0.1577 - dense_1_loss_23: 0.1639 - dense_1_loss_24: 0.1475 - dense_1_loss_25: 0.1874 - dense_1_loss_26: 0.1574 - dense_1_loss_27: 0.1644 - dense_1_loss_28: 0.1717 - dense_1_loss_29: 0.1822 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 52/100
60/60 [==============================] - 0s - loss: 11.7999 - dense_1_loss_1: 3.9217 - dense_1_loss_2: 2.1720 - dense_1_loss_3: 1.0392 - dense_1_loss_4: 0.5107 - dense_1_loss_5: 0.3348 - dense_1_loss_6: 0.2429 - dense_1_loss_7: 0.2425 - dense_1_loss_8: 0.1760 - dense_1_loss_9: 0.1731 - dense_1_loss_10: 0.1442 - dense_1_loss_11: 0.1543 - dense_1_loss_12: 0.1459 - dense_1_loss_13: 0.1337 - dense_1_loss_14: 0.1360 - dense_1_loss_15: 0.1401 - dense_1_loss_16: 0.1463 - dense_1_loss_17: 0.1466 - dense_1_loss_18: 0.1444 - dense_1_loss_19: 0.1508 - dense_1_loss_20: 0.1517 - dense_1_loss_21: 0.1525 - dense_1_loss_22: 0.1483 - dense_1_loss_23: 0.1505 - dense_1_loss_24: 0.1387 - dense_1_loss_25: 0.1725 - dense_1_loss_26: 0.1485 - dense_1_loss_27: 0.1516 - dense_1_loss_28: 0.1598 - dense_1_loss_29: 0.1704 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 53/100
60/60 [==============================] - 0s - loss: 11.4567 - dense_1_loss_1: 3.9172 - dense_1_loss_2: 2.1361 - dense_1_loss_3: 1.0079 - dense_1_loss_4: 0.4832 - dense_1_loss_5: 0.3156 - dense_1_loss_6: 0.2311 - dense_1_loss_7: 0.2329 - dense_1_loss_8: 0.1637 - dense_1_loss_9: 0.1621 - dense_1_loss_10: 0.1354 - dense_1_loss_11: 0.1477 - dense_1_loss_12: 0.1379 - dense_1_loss_13: 0.1248 - dense_1_loss_14: 0.1295 - dense_1_loss_15: 0.1316 - dense_1_loss_16: 0.1364 - dense_1_loss_17: 0.1378 - dense_1_loss_18: 0.1345 - dense_1_loss_19: 0.1434 - dense_1_loss_20: 0.1433 - dense_1_loss_21: 0.1424 - dense_1_loss_22: 0.1385 - dense_1_loss_23: 0.1395 - dense_1_loss_24: 0.1307 - dense_1_loss_25: 0.1613 - dense_1_loss_26: 0.1397 - dense_1_loss_27: 0.1392 - dense_1_loss_28: 0.1497 - dense_1_loss_29: 0.1637 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.7833 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 54/100
60/60 [==============================] - 0s - loss: 11.1297 - dense_1_loss_1: 3.9131 - dense_1_loss_2: 2.1021 - dense_1_loss_3: 0.9777 - dense_1_loss_4: 0.4565 - dense_1_loss_5: 0.2980 - dense_1_loss_6: 0.2192 - dense_1_loss_7: 0.2220 - dense_1_loss_8: 0.1525 - dense_1_loss_9: 0.1522 - dense_1_loss_10: 0.1263 - dense_1_loss_11: 0.1413 - dense_1_loss_12: 0.1293 - dense_1_loss_13: 0.1164 - dense_1_loss_14: 0.1224 - dense_1_loss_15: 0.1257 - dense_1_loss_16: 0.1262 - dense_1_loss_17: 0.1297 - dense_1_loss_18: 0.1259 - dense_1_loss_19: 0.1343 - dense_1_loss_20: 0.1374 - dense_1_loss_21: 0.1325 - dense_1_loss_22: 0.1280 - dense_1_loss_23: 0.1302 - dense_1_loss_24: 0.1229 - dense_1_loss_25: 0.1515 - dense_1_loss_26: 0.1306 - dense_1_loss_27: 0.1295 - dense_1_loss_28: 0.1410 - dense_1_loss_29: 0.1554 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.7833 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 55/100
60/60 [==============================] - 0s - loss: 10.8305 - dense_1_loss_1: 3.9091 - dense_1_loss_2: 2.0676 - dense_1_loss_3: 0.9481 - dense_1_loss_4: 0.4333 - dense_1_loss_5: 0.2845 - dense_1_loss_6: 0.2080 - dense_1_loss_7: 0.2110 - dense_1_loss_8: 0.1461 - dense_1_loss_9: 0.1429 - dense_1_loss_10: 0.1194 - dense_1_loss_11: 0.1314 - dense_1_loss_12: 0.1221 - dense_1_loss_13: 0.1087 - dense_1_loss_14: 0.1134 - dense_1_loss_15: 0.1198 - dense_1_loss_16: 0.1214 - dense_1_loss_17: 0.1213 - dense_1_loss_18: 0.1185 - dense_1_loss_19: 0.1254 - dense_1_loss_20: 0.1298 - dense_1_loss_21: 0.1259 - dense_1_loss_22: 0.1191 - dense_1_loss_23: 0.1219 - dense_1_loss_24: 0.1151 - dense_1_loss_25: 0.1430 - dense_1_loss_26: 0.1220 - dense_1_loss_27: 0.1234 - dense_1_loss_28: 0.1338 - dense_1_loss_29: 0.1443 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8000 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 56/100
60/60 [==============================] - 0s - loss: 10.5476 - dense_1_loss_1: 3.9054 - dense_1_loss_2: 2.0361 - dense_1_loss_3: 0.9192 - dense_1_loss_4: 0.4097 - dense_1_loss_5: 0.2699 - dense_1_loss_6: 0.1966 - dense_1_loss_7: 0.1976 - dense_1_loss_8: 0.1380 - dense_1_loss_9: 0.1355 - dense_1_loss_10: 0.1130 - dense_1_loss_11: 0.1203 - dense_1_loss_12: 0.1168 - dense_1_loss_13: 0.1029 - dense_1_loss_14: 0.1052 - dense_1_loss_15: 0.1129 - dense_1_loss_16: 0.1181 - dense_1_loss_17: 0.1149 - dense_1_loss_18: 0.1110 - dense_1_loss_19: 0.1188 - dense_1_loss_20: 0.1210 - dense_1_loss_21: 0.1195 - dense_1_loss_22: 0.1123 - dense_1_loss_23: 0.1150 - dense_1_loss_24: 0.1095 - dense_1_loss_25: 0.1334 - dense_1_loss_26: 0.1156 - dense_1_loss_27: 0.1183 - dense_1_loss_28: 0.1270 - dense_1_loss_29: 0.1341 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 57/100
60/60 [==============================] - 0s - loss: 10.2853 - dense_1_loss_1: 3.9014 - dense_1_loss_2: 2.0034 - dense_1_loss_3: 0.8925 - dense_1_loss_4: 0.3899 - dense_1_loss_5: 0.2565 - dense_1_loss_6: 0.1892 - dense_1_loss_7: 0.1875 - dense_1_loss_8: 0.1288 - dense_1_loss_9: 0.1290 - dense_1_loss_10: 0.1055 - dense_1_loss_11: 0.1154 - dense_1_loss_12: 0.1096 - dense_1_loss_13: 0.0982 - dense_1_loss_14: 0.1008 - dense_1_loss_15: 0.1044 - dense_1_loss_16: 0.1075 - dense_1_loss_17: 0.1089 - dense_1_loss_18: 0.1047 - dense_1_loss_19: 0.1123 - dense_1_loss_20: 0.1138 - dense_1_loss_21: 0.1113 - dense_1_loss_22: 0.1068 - dense_1_loss_23: 0.1086 - dense_1_loss_24: 0.1038 - dense_1_loss_25: 0.1242 - dense_1_loss_26: 0.1097 - dense_1_loss_27: 0.1119 - dense_1_loss_28: 0.1217 - dense_1_loss_29: 0.1279 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 58/100
60/60 [==============================] - 0s - loss: 10.0500 - dense_1_loss_1: 3.8974 - dense_1_loss_2: 1.9716 - dense_1_loss_3: 0.8691 - dense_1_loss_4: 0.3699 - dense_1_loss_5: 0.2441 - dense_1_loss_6: 0.1818 - dense_1_loss_7: 0.1776 - dense_1_loss_8: 0.1225 - dense_1_loss_9: 0.1224 - dense_1_loss_10: 0.0987 - dense_1_loss_11: 0.1126 - dense_1_loss_12: 0.1019 - dense_1_loss_13: 0.0948 - dense_1_loss_14: 0.0996 - dense_1_loss_15: 0.0984 - dense_1_loss_16: 0.0987 - dense_1_loss_17: 0.1031 - dense_1_loss_18: 0.0995 - dense_1_loss_19: 0.1077 - dense_1_loss_20: 0.1079 - dense_1_loss_21: 0.1046 - dense_1_loss_22: 0.1028 - dense_1_loss_23: 0.1023 - dense_1_loss_24: 0.0975 - dense_1_loss_25: 0.1167 - dense_1_loss_26: 0.1035 - dense_1_loss_27: 0.1052 - dense_1_loss_28: 0.1159 - dense_1_loss_29: 0.1220 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 59/100
60/60 [==============================] - 0s - loss: 9.8203 - dense_1_loss_1: 3.8939 - dense_1_loss_2: 1.9422 - dense_1_loss_3: 0.8429 - dense_1_loss_4: 0.3533 - dense_1_loss_5: 0.2323 - dense_1_loss_6: 0.1734 - dense_1_loss_7: 0.1676 - dense_1_loss_8: 0.1176 - dense_1_loss_9: 0.1153 - dense_1_loss_10: 0.0942 - dense_1_loss_11: 0.1060 - dense_1_loss_12: 0.0960 - dense_1_loss_13: 0.0904 - dense_1_loss_14: 0.0930 - dense_1_loss_15: 0.0923 - dense_1_loss_16: 0.0952 - dense_1_loss_17: 0.0974 - dense_1_loss_18: 0.0942 - dense_1_loss_19: 0.1022 - dense_1_loss_20: 0.1018 - dense_1_loss_21: 0.0990 - dense_1_loss_22: 0.0968 - dense_1_loss_23: 0.0966 - dense_1_loss_24: 0.0918 - dense_1_loss_25: 0.1124 - dense_1_loss_26: 0.0959 - dense_1_loss_27: 0.1002 - dense_1_loss_28: 0.1087 - dense_1_loss_29: 0.1179 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 60/100
60/60 [==============================] - 0s - loss: 9.6102 - dense_1_loss_1: 3.8901 - dense_1_loss_2: 1.9130 - dense_1_loss_3: 0.8196 - dense_1_loss_4: 0.3378 - dense_1_loss_5: 0.2224 - dense_1_loss_6: 0.1642 - dense_1_loss_7: 0.1581 - dense_1_loss_8: 0.1135 - dense_1_loss_9: 0.1082 - dense_1_loss_10: 0.0912 - dense_1_loss_11: 0.0977 - dense_1_loss_12: 0.0921 - dense_1_loss_13: 0.0849 - dense_1_loss_14: 0.0853 - dense_1_loss_15: 0.0877 - dense_1_loss_16: 0.0951 - dense_1_loss_17: 0.0930 - dense_1_loss_18: 0.0896 - dense_1_loss_19: 0.0958 - dense_1_loss_20: 0.0967 - dense_1_loss_21: 0.0938 - dense_1_loss_22: 0.0912 - dense_1_loss_23: 0.0920 - dense_1_loss_24: 0.0874 - dense_1_loss_25: 0.1076 - dense_1_loss_26: 0.0912 - dense_1_loss_27: 0.0961 - dense_1_loss_28: 0.1043 - dense_1_loss_29: 0.1108 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 61/100
60/60 [==============================] - 0s - loss: 9.4133 - dense_1_loss_1: 3.8863 - dense_1_loss_2: 1.8849 - dense_1_loss_3: 0.7978 - dense_1_loss_4: 0.3220 - dense_1_loss_5: 0.2128 - dense_1_loss_6: 0.1572 - dense_1_loss_7: 0.1521 - dense_1_loss_8: 0.1070 - dense_1_loss_9: 0.1030 - dense_1_loss_10: 0.0857 - dense_1_loss_11: 0.0937 - dense_1_loss_12: 0.0873 - dense_1_loss_13: 0.0807 - dense_1_loss_14: 0.0805 - dense_1_loss_15: 0.0843 - dense_1_loss_16: 0.0901 - dense_1_loss_17: 0.0880 - dense_1_loss_18: 0.0856 - dense_1_loss_19: 0.0903 - dense_1_loss_20: 0.0918 - dense_1_loss_21: 0.0891 - dense_1_loss_22: 0.0861 - dense_1_loss_23: 0.0880 - dense_1_loss_24: 0.0832 - dense_1_loss_25: 0.1017 - dense_1_loss_26: 0.0877 - dense_1_loss_27: 0.0909 - dense_1_loss_28: 0.1005 - dense_1_loss_29: 0.1050 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 62/100
60/60 [==============================] - 0s - loss: 9.2328 - dense_1_loss_1: 3.8825 - dense_1_loss_2: 1.8573 - dense_1_loss_3: 0.7768 - dense_1_loss_4: 0.3090 - dense_1_loss_5: 0.2032 - dense_1_loss_6: 0.1514 - dense_1_loss_7: 0.1455 - dense_1_loss_8: 0.1013 - dense_1_loss_9: 0.0986 - dense_1_loss_10: 0.0806 - dense_1_loss_11: 0.0914 - dense_1_loss_12: 0.0821 - dense_1_loss_13: 0.0775 - dense_1_loss_14: 0.0791 - dense_1_loss_15: 0.0815 - dense_1_loss_16: 0.0832 - dense_1_loss_17: 0.0835 - dense_1_loss_18: 0.0818 - dense_1_loss_19: 0.0859 - dense_1_loss_20: 0.0878 - dense_1_loss_21: 0.0853 - dense_1_loss_22: 0.0816 - dense_1_loss_23: 0.0841 - dense_1_loss_24: 0.0788 - dense_1_loss_25: 0.0971 - dense_1_loss_26: 0.0838 - dense_1_loss_27: 0.0861 - dense_1_loss_28: 0.0956 - dense_1_loss_29: 0.1004 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 63/100
60/60 [==============================] - 0s - loss: 9.0548 - dense_1_loss_1: 3.8792 - dense_1_loss_2: 1.8308 - dense_1_loss_3: 0.7560 - dense_1_loss_4: 0.2950 - dense_1_loss_5: 0.1932 - dense_1_loss_6: 0.1463 - dense_1_loss_7: 0.1384 - dense_1_loss_8: 0.0973 - dense_1_loss_9: 0.0945 - dense_1_loss_10: 0.0765 - dense_1_loss_11: 0.0868 - dense_1_loss_12: 0.0783 - dense_1_loss_13: 0.0737 - dense_1_loss_14: 0.0760 - dense_1_loss_15: 0.0766 - dense_1_loss_16: 0.0795 - dense_1_loss_17: 0.0796 - dense_1_loss_18: 0.0771 - dense_1_loss_19: 0.0826 - dense_1_loss_20: 0.0834 - dense_1_loss_21: 0.0810 - dense_1_loss_22: 0.0785 - dense_1_loss_23: 0.0788 - dense_1_loss_24: 0.0750 - dense_1_loss_25: 0.0926 - dense_1_loss_26: 0.0799 - dense_1_loss_27: 0.0815 - dense_1_loss_28: 0.0906 - dense_1_loss_29: 0.0961 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 64/100
60/60 [==============================] - 0s - loss: 8.8914 - dense_1_loss_1: 3.8755 - dense_1_loss_2: 1.8055 - dense_1_loss_3: 0.7353 - dense_1_loss_4: 0.2827 - dense_1_loss_5: 0.1841 - dense_1_loss_6: 0.1409 - dense_1_loss_7: 0.1301 - dense_1_loss_8: 0.0936 - dense_1_loss_9: 0.0905 - dense_1_loss_10: 0.0738 - dense_1_loss_11: 0.0813 - dense_1_loss_12: 0.0759 - dense_1_loss_13: 0.0702 - dense_1_loss_14: 0.0716 - dense_1_loss_15: 0.0723 - dense_1_loss_16: 0.0781 - dense_1_loss_17: 0.0761 - dense_1_loss_18: 0.0736 - dense_1_loss_19: 0.0786 - dense_1_loss_20: 0.0793 - dense_1_loss_21: 0.0781 - dense_1_loss_22: 0.0746 - dense_1_loss_23: 0.0752 - dense_1_loss_24: 0.0720 - dense_1_loss_25: 0.0887 - dense_1_loss_26: 0.0761 - dense_1_loss_27: 0.0778 - dense_1_loss_28: 0.0867 - dense_1_loss_29: 0.0931 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5500 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 65/100
60/60 [==============================] - 0s - loss: 8.7391 - dense_1_loss_1: 3.8723 - dense_1_loss_2: 1.7804 - dense_1_loss_3: 0.7166 - dense_1_loss_4: 0.2720 - dense_1_loss_5: 0.1767 - dense_1_loss_6: 0.1358 - dense_1_loss_7: 0.1244 - dense_1_loss_8: 0.0892 - dense_1_loss_9: 0.0861 - dense_1_loss_10: 0.0708 - dense_1_loss_11: 0.0780 - dense_1_loss_12: 0.0725 - dense_1_loss_13: 0.0674 - dense_1_loss_14: 0.0686 - dense_1_loss_15: 0.0695 - dense_1_loss_16: 0.0742 - dense_1_loss_17: 0.0727 - dense_1_loss_18: 0.0706 - dense_1_loss_19: 0.0747 - dense_1_loss_20: 0.0758 - dense_1_loss_21: 0.0747 - dense_1_loss_22: 0.0707 - dense_1_loss_23: 0.0721 - dense_1_loss_24: 0.0693 - dense_1_loss_25: 0.0842 - dense_1_loss_26: 0.0727 - dense_1_loss_27: 0.0748 - dense_1_loss_28: 0.0830 - dense_1_loss_29: 0.0892 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5500 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 66/100
60/60 [==============================] - 0s - loss: 8.5942 - dense_1_loss_1: 3.8689 - dense_1_loss_2: 1.7559 - dense_1_loss_3: 0.6982 - dense_1_loss_4: 0.2609 - dense_1_loss_5: 0.1701 - dense_1_loss_6: 0.1306 - dense_1_loss_7: 0.1191 - dense_1_loss_8: 0.0851 - dense_1_loss_9: 0.0818 - dense_1_loss_10: 0.0680 - dense_1_loss_11: 0.0746 - dense_1_loss_12: 0.0693 - dense_1_loss_13: 0.0646 - dense_1_loss_14: 0.0660 - dense_1_loss_15: 0.0671 - dense_1_loss_16: 0.0708 - dense_1_loss_17: 0.0694 - dense_1_loss_18: 0.0676 - dense_1_loss_19: 0.0714 - dense_1_loss_20: 0.0726 - dense_1_loss_21: 0.0712 - dense_1_loss_22: 0.0675 - dense_1_loss_23: 0.0694 - dense_1_loss_24: 0.0669 - dense_1_loss_25: 0.0796 - dense_1_loss_26: 0.0696 - dense_1_loss_27: 0.0718 - dense_1_loss_28: 0.0809 - dense_1_loss_29: 0.0853 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5667 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 67/100
60/60 [==============================] - 0s - loss: 8.4597 - dense_1_loss_1: 3.8653 - dense_1_loss_2: 1.7322 - dense_1_loss_3: 0.6813 - dense_1_loss_4: 0.2504 - dense_1_loss_5: 0.1646 - dense_1_loss_6: 0.1260 - dense_1_loss_7: 0.1150 - dense_1_loss_8: 0.0816 - dense_1_loss_9: 0.0788 - dense_1_loss_10: 0.0654 - dense_1_loss_11: 0.0715 - dense_1_loss_12: 0.0665 - dense_1_loss_13: 0.0620 - dense_1_loss_14: 0.0631 - dense_1_loss_15: 0.0643 - dense_1_loss_16: 0.0678 - dense_1_loss_17: 0.0667 - dense_1_loss_18: 0.0647 - dense_1_loss_19: 0.0686 - dense_1_loss_20: 0.0697 - dense_1_loss_21: 0.0677 - dense_1_loss_22: 0.0649 - dense_1_loss_23: 0.0665 - dense_1_loss_24: 0.0640 - dense_1_loss_25: 0.0765 - dense_1_loss_26: 0.0670 - dense_1_loss_27: 0.0691 - dense_1_loss_28: 0.0773 - dense_1_loss_29: 0.0814 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5833 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 68/100
60/60 [==============================] - 0s - loss: 8.3313 - dense_1_loss_1: 3.8621 - dense_1_loss_2: 1.7093 - dense_1_loss_3: 0.6644 - dense_1_loss_4: 0.2410 - dense_1_loss_5: 0.1584 - dense_1_loss_6: 0.1217 - dense_1_loss_7: 0.1098 - dense_1_loss_8: 0.0788 - dense_1_loss_9: 0.0759 - dense_1_loss_10: 0.0629 - dense_1_loss_11: 0.0685 - dense_1_loss_12: 0.0640 - dense_1_loss_13: 0.0594 - dense_1_loss_14: 0.0603 - dense_1_loss_15: 0.0613 - dense_1_loss_16: 0.0656 - dense_1_loss_17: 0.0639 - dense_1_loss_18: 0.0619 - dense_1_loss_19: 0.0660 - dense_1_loss_20: 0.0670 - dense_1_loss_21: 0.0648 - dense_1_loss_22: 0.0628 - dense_1_loss_23: 0.0633 - dense_1_loss_24: 0.0610 - dense_1_loss_25: 0.0739 - dense_1_loss_26: 0.0641 - dense_1_loss_27: 0.0664 - dense_1_loss_28: 0.0742 - dense_1_loss_29: 0.0783 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 69/100
60/60 [==============================] - 0s - loss: 8.2080 - dense_1_loss_1: 3.8588 - dense_1_loss_2: 1.6867 - dense_1_loss_3: 0.6497 - dense_1_loss_4: 0.2312 - dense_1_loss_5: 0.1523 - dense_1_loss_6: 0.1170 - dense_1_loss_7: 0.1045 - dense_1_loss_8: 0.0760 - dense_1_loss_9: 0.0730 - dense_1_loss_10: 0.0605 - dense_1_loss_11: 0.0660 - dense_1_loss_12: 0.0614 - dense_1_loss_13: 0.0570 - dense_1_loss_14: 0.0581 - dense_1_loss_15: 0.0590 - dense_1_loss_16: 0.0633 - dense_1_loss_17: 0.0611 - dense_1_loss_18: 0.0595 - dense_1_loss_19: 0.0633 - dense_1_loss_20: 0.0644 - dense_1_loss_21: 0.0625 - dense_1_loss_22: 0.0602 - dense_1_loss_23: 0.0608 - dense_1_loss_24: 0.0586 - dense_1_loss_25: 0.0714 - dense_1_loss_26: 0.0612 - dense_1_loss_27: 0.0638 - dense_1_loss_28: 0.0713 - dense_1_loss_29: 0.0755 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 70/100
60/60 [==============================] - 0s - loss: 8.0932 - dense_1_loss_1: 3.8554 - dense_1_loss_2: 1.6644 - dense_1_loss_3: 0.6344 - dense_1_loss_4: 0.2231 - dense_1_loss_5: 0.1467 - dense_1_loss_6: 0.1132 - dense_1_loss_7: 0.1002 - dense_1_loss_8: 0.0731 - dense_1_loss_9: 0.0704 - dense_1_loss_10: 0.0579 - dense_1_loss_11: 0.0641 - dense_1_loss_12: 0.0590 - dense_1_loss_13: 0.0547 - dense_1_loss_14: 0.0564 - dense_1_loss_15: 0.0570 - dense_1_loss_16: 0.0605 - dense_1_loss_17: 0.0586 - dense_1_loss_18: 0.0574 - dense_1_loss_19: 0.0612 - dense_1_loss_20: 0.0617 - dense_1_loss_21: 0.0602 - dense_1_loss_22: 0.0581 - dense_1_loss_23: 0.0583 - dense_1_loss_24: 0.0565 - dense_1_loss_25: 0.0686 - dense_1_loss_26: 0.0590 - dense_1_loss_27: 0.0614 - dense_1_loss_28: 0.0689 - dense_1_loss_29: 0.0725 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 71/100
60/60 [==============================] - 0s - loss: 7.9833 - dense_1_loss_1: 3.8521 - dense_1_loss_2: 1.6440 - dense_1_loss_3: 0.6199 - dense_1_loss_4: 0.2144 - dense_1_loss_5: 0.1410 - dense_1_loss_6: 0.1097 - dense_1_loss_7: 0.0962 - dense_1_loss_8: 0.0707 - dense_1_loss_9: 0.0678 - dense_1_loss_10: 0.0558 - dense_1_loss_11: 0.0620 - dense_1_loss_12: 0.0569 - dense_1_loss_13: 0.0526 - dense_1_loss_14: 0.0543 - dense_1_loss_15: 0.0549 - dense_1_loss_16: 0.0583 - dense_1_loss_17: 0.0564 - dense_1_loss_18: 0.0554 - dense_1_loss_19: 0.0587 - dense_1_loss_20: 0.0594 - dense_1_loss_21: 0.0580 - dense_1_loss_22: 0.0557 - dense_1_loss_23: 0.0561 - dense_1_loss_24: 0.0546 - dense_1_loss_25: 0.0658 - dense_1_loss_26: 0.0568 - dense_1_loss_27: 0.0590 - dense_1_loss_28: 0.0666 - dense_1_loss_29: 0.0701 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 72/100
60/60 [==============================] - 0s - loss: 7.8793 - dense_1_loss_1: 3.8491 - dense_1_loss_2: 1.6233 - dense_1_loss_3: 0.6055 - dense_1_loss_4: 0.2075 - dense_1_loss_5: 0.1360 - dense_1_loss_6: 0.1063 - dense_1_loss_7: 0.0922 - dense_1_loss_8: 0.0684 - dense_1_loss_9: 0.0655 - dense_1_loss_10: 0.0538 - dense_1_loss_11: 0.0597 - dense_1_loss_12: 0.0548 - dense_1_loss_13: 0.0509 - dense_1_loss_14: 0.0519 - dense_1_loss_15: 0.0528 - dense_1_loss_16: 0.0567 - dense_1_loss_17: 0.0545 - dense_1_loss_18: 0.0533 - dense_1_loss_19: 0.0564 - dense_1_loss_20: 0.0573 - dense_1_loss_21: 0.0558 - dense_1_loss_22: 0.0536 - dense_1_loss_23: 0.0542 - dense_1_loss_24: 0.0528 - dense_1_loss_25: 0.0632 - dense_1_loss_26: 0.0548 - dense_1_loss_27: 0.0568 - dense_1_loss_28: 0.0645 - dense_1_loss_29: 0.0678 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 73/100
60/60 [==============================] - 0s - loss: 7.7824 - dense_1_loss_1: 3.8456 - dense_1_loss_2: 1.6041 - dense_1_loss_3: 0.5923 - dense_1_loss_4: 0.2004 - dense_1_loss_5: 0.1317 - dense_1_loss_6: 0.1029 - dense_1_loss_7: 0.0889 - dense_1_loss_8: 0.0664 - dense_1_loss_9: 0.0632 - dense_1_loss_10: 0.0521 - dense_1_loss_11: 0.0574 - dense_1_loss_12: 0.0529 - dense_1_loss_13: 0.0493 - dense_1_loss_14: 0.0501 - dense_1_loss_15: 0.0510 - dense_1_loss_16: 0.0550 - dense_1_loss_17: 0.0527 - dense_1_loss_18: 0.0514 - dense_1_loss_19: 0.0545 - dense_1_loss_20: 0.0553 - dense_1_loss_21: 0.0539 - dense_1_loss_22: 0.0516 - dense_1_loss_23: 0.0523 - dense_1_loss_24: 0.0509 - dense_1_loss_25: 0.0612 - dense_1_loss_26: 0.0528 - dense_1_loss_27: 0.0548 - dense_1_loss_28: 0.0620 - dense_1_loss_29: 0.0656 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 74/100
60/60 [==============================] - 0s - loss: 7.6862 - dense_1_loss_1: 3.8425 - dense_1_loss_2: 1.5849 - dense_1_loss_3: 0.5793 - dense_1_loss_4: 0.1927 - dense_1_loss_5: 0.1273 - dense_1_loss_6: 0.0993 - dense_1_loss_7: 0.0849 - dense_1_loss_8: 0.0644 - dense_1_loss_9: 0.0610 - dense_1_loss_10: 0.0502 - dense_1_loss_11: 0.0555 - dense_1_loss_12: 0.0509 - dense_1_loss_13: 0.0478 - dense_1_loss_14: 0.0484 - dense_1_loss_15: 0.0494 - dense_1_loss_16: 0.0531 - dense_1_loss_17: 0.0509 - dense_1_loss_18: 0.0496 - dense_1_loss_19: 0.0527 - dense_1_loss_20: 0.0534 - dense_1_loss_21: 0.0521 - dense_1_loss_22: 0.0499 - dense_1_loss_23: 0.0506 - dense_1_loss_24: 0.0491 - dense_1_loss_25: 0.0593 - dense_1_loss_26: 0.0512 - dense_1_loss_27: 0.0528 - dense_1_loss_28: 0.0598 - dense_1_loss_29: 0.0633 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 75/100
60/60 [==============================] - 0s - loss: 7.5985 - dense_1_loss_1: 3.8396 - dense_1_loss_2: 1.5661 - dense_1_loss_3: 0.5669 - dense_1_loss_4: 0.1867 - dense_1_loss_5: 0.1231 - dense_1_loss_6: 0.0963 - dense_1_loss_7: 0.0820 - dense_1_loss_8: 0.0623 - dense_1_loss_9: 0.0592 - dense_1_loss_10: 0.0486 - dense_1_loss_11: 0.0536 - dense_1_loss_12: 0.0492 - dense_1_loss_13: 0.0461 - dense_1_loss_14: 0.0469 - dense_1_loss_15: 0.0479 - dense_1_loss_16: 0.0513 - dense_1_loss_17: 0.0492 - dense_1_loss_18: 0.0480 - dense_1_loss_19: 0.0510 - dense_1_loss_20: 0.0517 - dense_1_loss_21: 0.0506 - dense_1_loss_22: 0.0483 - dense_1_loss_23: 0.0489 - dense_1_loss_24: 0.0476 - dense_1_loss_25: 0.0574 - dense_1_loss_26: 0.0496 - dense_1_loss_27: 0.0511 - dense_1_loss_28: 0.0580 - dense_1_loss_29: 0.0615 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 76/100
60/60 [==============================] - 0s - loss: 7.5125 - dense_1_loss_1: 3.8364 - dense_1_loss_2: 1.5483 - dense_1_loss_3: 0.5546 - dense_1_loss_4: 0.1802 - dense_1_loss_5: 0.1192 - dense_1_loss_6: 0.0934 - dense_1_loss_7: 0.0791 - dense_1_loss_8: 0.0603 - dense_1_loss_9: 0.0576 - dense_1_loss_10: 0.0469 - dense_1_loss_11: 0.0519 - dense_1_loss_12: 0.0477 - dense_1_loss_13: 0.0446 - dense_1_loss_14: 0.0454 - dense_1_loss_15: 0.0463 - dense_1_loss_16: 0.0498 - dense_1_loss_17: 0.0475 - dense_1_loss_18: 0.0464 - dense_1_loss_19: 0.0493 - dense_1_loss_20: 0.0500 - dense_1_loss_21: 0.0490 - dense_1_loss_22: 0.0467 - dense_1_loss_23: 0.0472 - dense_1_loss_24: 0.0460 - dense_1_loss_25: 0.0555 - dense_1_loss_26: 0.0479 - dense_1_loss_27: 0.0494 - dense_1_loss_28: 0.0563 - dense_1_loss_29: 0.0593 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 77/100
60/60 [==============================] - 0s - loss: 7.4341 - dense_1_loss_1: 3.8334 - dense_1_loss_2: 1.5311 - dense_1_loss_3: 0.5435 - dense_1_loss_4: 0.1750 - dense_1_loss_5: 0.1158 - dense_1_loss_6: 0.0910 - dense_1_loss_7: 0.0767 - dense_1_loss_8: 0.0585 - dense_1_loss_9: 0.0560 - dense_1_loss_10: 0.0454 - dense_1_loss_11: 0.0504 - dense_1_loss_12: 0.0463 - dense_1_loss_13: 0.0432 - dense_1_loss_14: 0.0440 - dense_1_loss_15: 0.0450 - dense_1_loss_16: 0.0483 - dense_1_loss_17: 0.0461 - dense_1_loss_18: 0.0450 - dense_1_loss_19: 0.0478 - dense_1_loss_20: 0.0483 - dense_1_loss_21: 0.0475 - dense_1_loss_22: 0.0451 - dense_1_loss_23: 0.0458 - dense_1_loss_24: 0.0446 - dense_1_loss_25: 0.0535 - dense_1_loss_26: 0.0465 - dense_1_loss_27: 0.0480 - dense_1_loss_28: 0.0547 - dense_1_loss_29: 0.0576 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 78/100
60/60 [==============================] - 0s - loss: 7.3557 - dense_1_loss_1: 3.8301 - dense_1_loss_2: 1.5137 - dense_1_loss_3: 0.5326 - dense_1_loss_4: 0.1695 - dense_1_loss_5: 0.1125 - dense_1_loss_6: 0.0882 - dense_1_loss_7: 0.0739 - dense_1_loss_8: 0.0568 - dense_1_loss_9: 0.0543 - dense_1_loss_10: 0.0441 - dense_1_loss_11: 0.0487 - dense_1_loss_12: 0.0448 - dense_1_loss_13: 0.0419 - dense_1_loss_14: 0.0426 - dense_1_loss_15: 0.0435 - dense_1_loss_16: 0.0469 - dense_1_loss_17: 0.0447 - dense_1_loss_18: 0.0435 - dense_1_loss_19: 0.0463 - dense_1_loss_20: 0.0468 - dense_1_loss_21: 0.0460 - dense_1_loss_22: 0.0437 - dense_1_loss_23: 0.0444 - dense_1_loss_24: 0.0434 - dense_1_loss_25: 0.0519 - dense_1_loss_26: 0.0451 - dense_1_loss_27: 0.0468 - dense_1_loss_28: 0.0532 - dense_1_loss_29: 0.0558 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 79/100
60/60 [==============================] - 0s - loss: 7.2792 - dense_1_loss_1: 3.8274 - dense_1_loss_2: 1.4976 - dense_1_loss_3: 0.5203 - dense_1_loss_4: 0.1640 - dense_1_loss_5: 0.1092 - dense_1_loss_6: 0.0854 - dense_1_loss_7: 0.0712 - dense_1_loss_8: 0.0553 - dense_1_loss_9: 0.0525 - dense_1_loss_10: 0.0428 - dense_1_loss_11: 0.0473 - dense_1_loss_12: 0.0433 - dense_1_loss_13: 0.0407 - dense_1_loss_14: 0.0412 - dense_1_loss_15: 0.0423 - dense_1_loss_16: 0.0455 - dense_1_loss_17: 0.0433 - dense_1_loss_18: 0.0422 - dense_1_loss_19: 0.0449 - dense_1_loss_20: 0.0454 - dense_1_loss_21: 0.0445 - dense_1_loss_22: 0.0423 - dense_1_loss_23: 0.0432 - dense_1_loss_24: 0.0420 - dense_1_loss_25: 0.0507 - dense_1_loss_26: 0.0437 - dense_1_loss_27: 0.0455 - dense_1_loss_28: 0.0514 - dense_1_loss_29: 0.0542 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 80/100
60/60 [==============================] - 0s - loss: 7.2088 - dense_1_loss_1: 3.8242 - dense_1_loss_2: 1.4811 - dense_1_loss_3: 0.5108 - dense_1_loss_4: 0.1594 - dense_1_loss_5: 0.1063 - dense_1_loss_6: 0.0832 - dense_1_loss_7: 0.0692 - dense_1_loss_8: 0.0537 - dense_1_loss_9: 0.0511 - dense_1_loss_10: 0.0415 - dense_1_loss_11: 0.0459 - dense_1_loss_12: 0.0420 - dense_1_loss_13: 0.0396 - dense_1_loss_14: 0.0399 - dense_1_loss_15: 0.0412 - dense_1_loss_16: 0.0442 - dense_1_loss_17: 0.0419 - dense_1_loss_18: 0.0410 - dense_1_loss_19: 0.0436 - dense_1_loss_20: 0.0441 - dense_1_loss_21: 0.0431 - dense_1_loss_22: 0.0411 - dense_1_loss_23: 0.0420 - dense_1_loss_24: 0.0408 - dense_1_loss_25: 0.0494 - dense_1_loss_26: 0.0423 - dense_1_loss_27: 0.0441 - dense_1_loss_28: 0.0497 - dense_1_loss_29: 0.0524 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 81/100
60/60 [==============================] - 0s - loss: 7.1396 - dense_1_loss_1: 3.8213 - dense_1_loss_2: 1.4653 - dense_1_loss_3: 0.5001 - dense_1_loss_4: 0.1549 - dense_1_loss_5: 0.1030 - dense_1_loss_6: 0.0809 - dense_1_loss_7: 0.0669 - dense_1_loss_8: 0.0520 - dense_1_loss_9: 0.0497 - dense_1_loss_10: 0.0404 - dense_1_loss_11: 0.0447 - dense_1_loss_12: 0.0409 - dense_1_loss_13: 0.0384 - dense_1_loss_14: 0.0388 - dense_1_loss_15: 0.0400 - dense_1_loss_16: 0.0428 - dense_1_loss_17: 0.0407 - dense_1_loss_18: 0.0398 - dense_1_loss_19: 0.0422 - dense_1_loss_20: 0.0428 - dense_1_loss_21: 0.0420 - dense_1_loss_22: 0.0400 - dense_1_loss_23: 0.0406 - dense_1_loss_24: 0.0398 - dense_1_loss_25: 0.0478 - dense_1_loss_26: 0.0411 - dense_1_loss_27: 0.0429 - dense_1_loss_28: 0.0486 - dense_1_loss_29: 0.0511 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 82/100
60/60 [==============================] - 0s - loss: 7.0758 - dense_1_loss_1: 3.8183 - dense_1_loss_2: 1.4507 - dense_1_loss_3: 0.4906 - dense_1_loss_4: 0.1508 - dense_1_loss_5: 0.1003 - dense_1_loss_6: 0.0791 - dense_1_loss_7: 0.0651 - dense_1_loss_8: 0.0507 - dense_1_loss_9: 0.0485 - dense_1_loss_10: 0.0393 - dense_1_loss_11: 0.0435 - dense_1_loss_12: 0.0398 - dense_1_loss_13: 0.0374 - dense_1_loss_14: 0.0377 - dense_1_loss_15: 0.0388 - dense_1_loss_16: 0.0418 - dense_1_loss_17: 0.0396 - dense_1_loss_18: 0.0386 - dense_1_loss_19: 0.0410 - dense_1_loss_20: 0.0417 - dense_1_loss_21: 0.0407 - dense_1_loss_22: 0.0388 - dense_1_loss_23: 0.0395 - dense_1_loss_24: 0.0387 - dense_1_loss_25: 0.0460 - dense_1_loss_26: 0.0400 - dense_1_loss_27: 0.0417 - dense_1_loss_28: 0.0475 - dense_1_loss_29: 0.0497 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 83/100
60/60 [==============================] - 0s - loss: 7.0105 - dense_1_loss_1: 3.8154 - dense_1_loss_2: 1.4350 - dense_1_loss_3: 0.4811 - dense_1_loss_4: 0.1461 - dense_1_loss_5: 0.0975 - dense_1_loss_6: 0.0767 - dense_1_loss_7: 0.0629 - dense_1_loss_8: 0.0494 - dense_1_loss_9: 0.0473 - dense_1_loss_10: 0.0382 - dense_1_loss_11: 0.0422 - dense_1_loss_12: 0.0388 - dense_1_loss_13: 0.0363 - dense_1_loss_14: 0.0366 - dense_1_loss_15: 0.0375 - dense_1_loss_16: 0.0410 - dense_1_loss_17: 0.0385 - dense_1_loss_18: 0.0375 - dense_1_loss_19: 0.0398 - dense_1_loss_20: 0.0405 - dense_1_loss_21: 0.0396 - dense_1_loss_22: 0.0378 - dense_1_loss_23: 0.0382 - dense_1_loss_24: 0.0377 - dense_1_loss_25: 0.0446 - dense_1_loss_26: 0.0389 - dense_1_loss_27: 0.0406 - dense_1_loss_28: 0.0463 - dense_1_loss_29: 0.0484 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 84/100
60/60 [==============================] - 0s - loss: 6.9501 - dense_1_loss_1: 3.8125 - dense_1_loss_2: 1.4203 - dense_1_loss_3: 0.4719 - dense_1_loss_4: 0.1424 - dense_1_loss_5: 0.0951 - dense_1_loss_6: 0.0747 - dense_1_loss_7: 0.0612 - dense_1_loss_8: 0.0482 - dense_1_loss_9: 0.0460 - dense_1_loss_10: 0.0372 - dense_1_loss_11: 0.0412 - dense_1_loss_12: 0.0377 - dense_1_loss_13: 0.0353 - dense_1_loss_14: 0.0357 - dense_1_loss_15: 0.0366 - dense_1_loss_16: 0.0398 - dense_1_loss_17: 0.0374 - dense_1_loss_18: 0.0365 - dense_1_loss_19: 0.0388 - dense_1_loss_20: 0.0393 - dense_1_loss_21: 0.0385 - dense_1_loss_22: 0.0368 - dense_1_loss_23: 0.0372 - dense_1_loss_24: 0.0367 - dense_1_loss_25: 0.0435 - dense_1_loss_26: 0.0379 - dense_1_loss_27: 0.0395 - dense_1_loss_28: 0.0449 - dense_1_loss_29: 0.0473 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 85/100
60/60 [==============================] - 0s - loss: 6.8908 - dense_1_loss_1: 3.8096 - dense_1_loss_2: 1.4065 - dense_1_loss_3: 0.4622 - dense_1_loss_4: 0.1385 - dense_1_loss_5: 0.0926 - dense_1_loss_6: 0.0726 - dense_1_loss_7: 0.0596 - dense_1_loss_8: 0.0470 - dense_1_loss_9: 0.0448 - dense_1_loss_10: 0.0362 - dense_1_loss_11: 0.0401 - dense_1_loss_12: 0.0367 - dense_1_loss_13: 0.0344 - dense_1_loss_14: 0.0348 - dense_1_loss_15: 0.0358 - dense_1_loss_16: 0.0387 - dense_1_loss_17: 0.0364 - dense_1_loss_18: 0.0355 - dense_1_loss_19: 0.0379 - dense_1_loss_20: 0.0381 - dense_1_loss_21: 0.0375 - dense_1_loss_22: 0.0358 - dense_1_loss_23: 0.0363 - dense_1_loss_24: 0.0357 - dense_1_loss_25: 0.0427 - dense_1_loss_26: 0.0369 - dense_1_loss_27: 0.0384 - dense_1_loss_28: 0.0436 - dense_1_loss_29: 0.0460 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 86/100
60/60 [==============================] - 0s - loss: 6.8355 - dense_1_loss_1: 3.8069 - dense_1_loss_2: 1.3923 - dense_1_loss_3: 0.4541 - dense_1_loss_4: 0.1352 - dense_1_loss_5: 0.0904 - dense_1_loss_6: 0.0708 - dense_1_loss_7: 0.0582 - dense_1_loss_8: 0.0458 - dense_1_loss_9: 0.0436 - dense_1_loss_10: 0.0352 - dense_1_loss_11: 0.0392 - dense_1_loss_12: 0.0357 - dense_1_loss_13: 0.0335 - dense_1_loss_14: 0.0339 - dense_1_loss_15: 0.0349 - dense_1_loss_16: 0.0376 - dense_1_loss_17: 0.0355 - dense_1_loss_18: 0.0347 - dense_1_loss_19: 0.0370 - dense_1_loss_20: 0.0371 - dense_1_loss_21: 0.0366 - dense_1_loss_22: 0.0349 - dense_1_loss_23: 0.0354 - dense_1_loss_24: 0.0348 - dense_1_loss_25: 0.0417 - dense_1_loss_26: 0.0360 - dense_1_loss_27: 0.0373 - dense_1_loss_28: 0.0424 - dense_1_loss_29: 0.0448 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 87/100
60/60 [==============================] - 0s - loss: 6.7820 - dense_1_loss_1: 3.8038 - dense_1_loss_2: 1.3795 - dense_1_loss_3: 0.4460 - dense_1_loss_4: 0.1318 - dense_1_loss_5: 0.0884 - dense_1_loss_6: 0.0693 - dense_1_loss_7: 0.0568 - dense_1_loss_8: 0.0447 - dense_1_loss_9: 0.0426 - dense_1_loss_10: 0.0343 - dense_1_loss_11: 0.0381 - dense_1_loss_12: 0.0348 - dense_1_loss_13: 0.0326 - dense_1_loss_14: 0.0330 - dense_1_loss_15: 0.0340 - dense_1_loss_16: 0.0367 - dense_1_loss_17: 0.0346 - dense_1_loss_18: 0.0337 - dense_1_loss_19: 0.0359 - dense_1_loss_20: 0.0362 - dense_1_loss_21: 0.0356 - dense_1_loss_22: 0.0339 - dense_1_loss_23: 0.0346 - dense_1_loss_24: 0.0339 - dense_1_loss_25: 0.0404 - dense_1_loss_26: 0.0351 - dense_1_loss_27: 0.0364 - dense_1_loss_28: 0.0414 - dense_1_loss_29: 0.0438 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 88/100
60/60 [==============================] - 0s - loss: 6.7287 - dense_1_loss_1: 3.8010 - dense_1_loss_2: 1.3661 - dense_1_loss_3: 0.4374 - dense_1_loss_4: 0.1286 - dense_1_loss_5: 0.0861 - dense_1_loss_6: 0.0677 - dense_1_loss_7: 0.0553 - dense_1_loss_8: 0.0436 - dense_1_loss_9: 0.0417 - dense_1_loss_10: 0.0335 - dense_1_loss_11: 0.0371 - dense_1_loss_12: 0.0341 - dense_1_loss_13: 0.0317 - dense_1_loss_14: 0.0321 - dense_1_loss_15: 0.0331 - dense_1_loss_16: 0.0360 - dense_1_loss_17: 0.0338 - dense_1_loss_18: 0.0329 - dense_1_loss_19: 0.0350 - dense_1_loss_20: 0.0353 - dense_1_loss_21: 0.0347 - dense_1_loss_22: 0.0330 - dense_1_loss_23: 0.0336 - dense_1_loss_24: 0.0331 - dense_1_loss_25: 0.0393 - dense_1_loss_26: 0.0341 - dense_1_loss_27: 0.0356 - dense_1_loss_28: 0.0406 - dense_1_loss_29: 0.0427 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 89/100
60/60 [==============================] - 0s - loss: 6.6773 - dense_1_loss_1: 3.7981 - dense_1_loss_2: 1.3530 - dense_1_loss_3: 0.4293 - dense_1_loss_4: 0.1254 - dense_1_loss_5: 0.0840 - dense_1_loss_6: 0.0658 - dense_1_loss_7: 0.0538 - dense_1_loss_8: 0.0427 - dense_1_loss_9: 0.0406 - dense_1_loss_10: 0.0327 - dense_1_loss_11: 0.0361 - dense_1_loss_12: 0.0332 - dense_1_loss_13: 0.0309 - dense_1_loss_14: 0.0313 - dense_1_loss_15: 0.0324 - dense_1_loss_16: 0.0353 - dense_1_loss_17: 0.0330 - dense_1_loss_18: 0.0321 - dense_1_loss_19: 0.0341 - dense_1_loss_20: 0.0345 - dense_1_loss_21: 0.0339 - dense_1_loss_22: 0.0322 - dense_1_loss_23: 0.0328 - dense_1_loss_24: 0.0324 - dense_1_loss_25: 0.0384 - dense_1_loss_26: 0.0333 - dense_1_loss_27: 0.0348 - dense_1_loss_28: 0.0397 - dense_1_loss_29: 0.0417 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 90/100
60/60 [==============================] - 0s - loss: 6.6297 - dense_1_loss_1: 3.7953 - dense_1_loss_2: 1.3410 - dense_1_loss_3: 0.4219 - dense_1_loss_4: 0.1224 - dense_1_loss_5: 0.0822 - dense_1_loss_6: 0.0643 - dense_1_loss_7: 0.0526 - dense_1_loss_8: 0.0418 - dense_1_loss_9: 0.0397 - dense_1_loss_10: 0.0319 - dense_1_loss_11: 0.0354 - dense_1_loss_12: 0.0324 - dense_1_loss_13: 0.0302 - dense_1_loss_14: 0.0305 - dense_1_loss_15: 0.0317 - dense_1_loss_16: 0.0344 - dense_1_loss_17: 0.0321 - dense_1_loss_18: 0.0313 - dense_1_loss_19: 0.0334 - dense_1_loss_20: 0.0336 - dense_1_loss_21: 0.0331 - dense_1_loss_22: 0.0315 - dense_1_loss_23: 0.0320 - dense_1_loss_24: 0.0315 - dense_1_loss_25: 0.0376 - dense_1_loss_26: 0.0325 - dense_1_loss_27: 0.0340 - dense_1_loss_28: 0.0387 - dense_1_loss_29: 0.0407 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 91/100
60/60 [==============================] - 0s - loss: 6.5828 - dense_1_loss_1: 3.7927 - dense_1_loss_2: 1.3288 - dense_1_loss_3: 0.4146 - dense_1_loss_4: 0.1198 - dense_1_loss_5: 0.0803 - dense_1_loss_6: 0.0626 - dense_1_loss_7: 0.0514 - dense_1_loss_8: 0.0409 - dense_1_loss_9: 0.0387 - dense_1_loss_10: 0.0311 - dense_1_loss_11: 0.0347 - dense_1_loss_12: 0.0316 - dense_1_loss_13: 0.0295 - dense_1_loss_14: 0.0299 - dense_1_loss_15: 0.0311 - dense_1_loss_16: 0.0334 - dense_1_loss_17: 0.0313 - dense_1_loss_18: 0.0306 - dense_1_loss_19: 0.0326 - dense_1_loss_20: 0.0328 - dense_1_loss_21: 0.0323 - dense_1_loss_22: 0.0307 - dense_1_loss_23: 0.0313 - dense_1_loss_24: 0.0308 - dense_1_loss_25: 0.0368 - dense_1_loss_26: 0.0317 - dense_1_loss_27: 0.0332 - dense_1_loss_28: 0.0377 - dense_1_loss_29: 0.0397 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 92/100
60/60 [==============================] - 0s - loss: 6.5360 - dense_1_loss_1: 3.7898 - dense_1_loss_2: 1.3168 - dense_1_loss_3: 0.4072 - dense_1_loss_4: 0.1168 - dense_1_loss_5: 0.0785 - dense_1_loss_6: 0.0611 - dense_1_loss_7: 0.0502 - dense_1_loss_8: 0.0400 - dense_1_loss_9: 0.0379 - dense_1_loss_10: 0.0304 - dense_1_loss_11: 0.0339 - dense_1_loss_12: 0.0309 - dense_1_loss_13: 0.0289 - dense_1_loss_14: 0.0292 - dense_1_loss_15: 0.0304 - dense_1_loss_16: 0.0326 - dense_1_loss_17: 0.0306 - dense_1_loss_18: 0.0298 - dense_1_loss_19: 0.0319 - dense_1_loss_20: 0.0320 - dense_1_loss_21: 0.0315 - dense_1_loss_22: 0.0301 - dense_1_loss_23: 0.0306 - dense_1_loss_24: 0.0301 - dense_1_loss_25: 0.0358 - dense_1_loss_26: 0.0310 - dense_1_loss_27: 0.0324 - dense_1_loss_28: 0.0369 - dense_1_loss_29: 0.0387 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 93/100
60/60 [==============================] - 0s - loss: 6.4926 - dense_1_loss_1: 3.7870 - dense_1_loss_2: 1.3053 - dense_1_loss_3: 0.4006 - dense_1_loss_4: 0.1143 - dense_1_loss_5: 0.0767 - dense_1_loss_6: 0.0598 - dense_1_loss_7: 0.0491 - dense_1_loss_8: 0.0391 - dense_1_loss_9: 0.0371 - dense_1_loss_10: 0.0297 - dense_1_loss_11: 0.0331 - dense_1_loss_12: 0.0302 - dense_1_loss_13: 0.0282 - dense_1_loss_14: 0.0286 - dense_1_loss_15: 0.0296 - dense_1_loss_16: 0.0320 - dense_1_loss_17: 0.0299 - dense_1_loss_18: 0.0292 - dense_1_loss_19: 0.0311 - dense_1_loss_20: 0.0313 - dense_1_loss_21: 0.0307 - dense_1_loss_22: 0.0295 - dense_1_loss_23: 0.0299 - dense_1_loss_24: 0.0295 - dense_1_loss_25: 0.0349 - dense_1_loss_26: 0.0304 - dense_1_loss_27: 0.0317 - dense_1_loss_28: 0.0362 - dense_1_loss_29: 0.0379 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 94/100
60/60 [==============================] - 0s - loss: 6.4500 - dense_1_loss_1: 3.7845 - dense_1_loss_2: 1.2939 - dense_1_loss_3: 0.3931 - dense_1_loss_4: 0.1121 - dense_1_loss_5: 0.0750 - dense_1_loss_6: 0.0586 - dense_1_loss_7: 0.0481 - dense_1_loss_8: 0.0383 - dense_1_loss_9: 0.0363 - dense_1_loss_10: 0.0291 - dense_1_loss_11: 0.0323 - dense_1_loss_12: 0.0296 - dense_1_loss_13: 0.0275 - dense_1_loss_14: 0.0280 - dense_1_loss_15: 0.0289 - dense_1_loss_16: 0.0315 - dense_1_loss_17: 0.0293 - dense_1_loss_18: 0.0285 - dense_1_loss_19: 0.0305 - dense_1_loss_20: 0.0306 - dense_1_loss_21: 0.0300 - dense_1_loss_22: 0.0288 - dense_1_loss_23: 0.0292 - dense_1_loss_24: 0.0289 - dense_1_loss_25: 0.0341 - dense_1_loss_26: 0.0297 - dense_1_loss_27: 0.0311 - dense_1_loss_28: 0.0354 - dense_1_loss_29: 0.0371 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 95/100
60/60 [==============================] - 0s - loss: 6.4081 - dense_1_loss_1: 3.7817 - dense_1_loss_2: 1.2828 - dense_1_loss_3: 0.3861 - dense_1_loss_4: 0.1097 - dense_1_loss_5: 0.0733 - dense_1_loss_6: 0.0572 - dense_1_loss_7: 0.0471 - dense_1_loss_8: 0.0375 - dense_1_loss_9: 0.0355 - dense_1_loss_10: 0.0285 - dense_1_loss_11: 0.0317 - dense_1_loss_12: 0.0289 - dense_1_loss_13: 0.0269 - dense_1_loss_14: 0.0273 - dense_1_loss_15: 0.0283 - dense_1_loss_16: 0.0308 - dense_1_loss_17: 0.0286 - dense_1_loss_18: 0.0279 - dense_1_loss_19: 0.0297 - dense_1_loss_20: 0.0300 - dense_1_loss_21: 0.0294 - dense_1_loss_22: 0.0282 - dense_1_loss_23: 0.0286 - dense_1_loss_24: 0.0283 - dense_1_loss_25: 0.0334 - dense_1_loss_26: 0.0291 - dense_1_loss_27: 0.0304 - dense_1_loss_28: 0.0348 - dense_1_loss_29: 0.0364 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 96/100
60/60 [==============================] - 0s - loss: 6.3681 - dense_1_loss_1: 3.7790 - dense_1_loss_2: 1.2717 - dense_1_loss_3: 0.3798 - dense_1_loss_4: 0.1075 - dense_1_loss_5: 0.0719 - dense_1_loss_6: 0.0562 - dense_1_loss_7: 0.0461 - dense_1_loss_8: 0.0367 - dense_1_loss_9: 0.0348 - dense_1_loss_10: 0.0279 - dense_1_loss_11: 0.0311 - dense_1_loss_12: 0.0283 - dense_1_loss_13: 0.0264 - dense_1_loss_14: 0.0268 - dense_1_loss_15: 0.0278 - dense_1_loss_16: 0.0301 - dense_1_loss_17: 0.0280 - dense_1_loss_18: 0.0273 - dense_1_loss_19: 0.0291 - dense_1_loss_20: 0.0293 - dense_1_loss_21: 0.0287 - dense_1_loss_22: 0.0275 - dense_1_loss_23: 0.0279 - dense_1_loss_24: 0.0277 - dense_1_loss_25: 0.0327 - dense_1_loss_26: 0.0284 - dense_1_loss_27: 0.0298 - dense_1_loss_28: 0.0339 - dense_1_loss_29: 0.0356 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 97/100
60/60 [==============================] - 0s - loss: 6.3282 - dense_1_loss_1: 3.7764 - dense_1_loss_2: 1.2606 - dense_1_loss_3: 0.3734 - dense_1_loss_4: 0.1054 - dense_1_loss_5: 0.0702 - dense_1_loss_6: 0.0549 - dense_1_loss_7: 0.0451 - dense_1_loss_8: 0.0359 - dense_1_loss_9: 0.0341 - dense_1_loss_10: 0.0273 - dense_1_loss_11: 0.0305 - dense_1_loss_12: 0.0276 - dense_1_loss_13: 0.0258 - dense_1_loss_14: 0.0263 - dense_1_loss_15: 0.0273 - dense_1_loss_16: 0.0293 - dense_1_loss_17: 0.0274 - dense_1_loss_18: 0.0268 - dense_1_loss_19: 0.0285 - dense_1_loss_20: 0.0287 - dense_1_loss_21: 0.0282 - dense_1_loss_22: 0.0270 - dense_1_loss_23: 0.0274 - dense_1_loss_24: 0.0271 - dense_1_loss_25: 0.0320 - dense_1_loss_26: 0.0278 - dense_1_loss_27: 0.0292 - dense_1_loss_28: 0.0332 - dense_1_loss_29: 0.0348 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 98/100
60/60 [==============================] - 0s - loss: 6.2921 - dense_1_loss_1: 3.7737 - dense_1_loss_2: 1.2509 - dense_1_loss_3: 0.3680 - dense_1_loss_4: 0.1033 - dense_1_loss_5: 0.0688 - dense_1_loss_6: 0.0540 - dense_1_loss_7: 0.0442 - dense_1_loss_8: 0.0352 - dense_1_loss_9: 0.0335 - dense_1_loss_10: 0.0267 - dense_1_loss_11: 0.0299 - dense_1_loss_12: 0.0271 - dense_1_loss_13: 0.0253 - dense_1_loss_14: 0.0257 - dense_1_loss_15: 0.0267 - dense_1_loss_16: 0.0288 - dense_1_loss_17: 0.0268 - dense_1_loss_18: 0.0263 - dense_1_loss_19: 0.0279 - dense_1_loss_20: 0.0281 - dense_1_loss_21: 0.0276 - dense_1_loss_22: 0.0264 - dense_1_loss_23: 0.0268 - dense_1_loss_24: 0.0265 - dense_1_loss_25: 0.0313 - dense_1_loss_26: 0.0272 - dense_1_loss_27: 0.0286 - dense_1_loss_28: 0.0326 - dense_1_loss_29: 0.0341 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 99/100
60/60 [==============================] - 0s - loss: 6.2552 - dense_1_loss_1: 3.7710 - dense_1_loss_2: 1.2403 - dense_1_loss_3: 0.3620 - dense_1_loss_4: 0.1015 - dense_1_loss_5: 0.0674 - dense_1_loss_6: 0.0530 - dense_1_loss_7: 0.0433 - dense_1_loss_8: 0.0346 - dense_1_loss_9: 0.0329 - dense_1_loss_10: 0.0262 - dense_1_loss_11: 0.0292 - dense_1_loss_12: 0.0266 - dense_1_loss_13: 0.0247 - dense_1_loss_14: 0.0251 - dense_1_loss_15: 0.0261 - dense_1_loss_16: 0.0285 - dense_1_loss_17: 0.0263 - dense_1_loss_18: 0.0257 - dense_1_loss_19: 0.0273 - dense_1_loss_20: 0.0275 - dense_1_loss_21: 0.0270 - dense_1_loss_22: 0.0258 - dense_1_loss_23: 0.0263 - dense_1_loss_24: 0.0260 - dense_1_loss_25: 0.0307 - dense_1_loss_26: 0.0267 - dense_1_loss_27: 0.0280 - dense_1_loss_28: 0.0320 - dense_1_loss_29: 0.0334 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 100/100
60/60 [==============================] - 0s - loss: 6.2195 - dense_1_loss_1: 3.7686 - dense_1_loss_2: 1.2304 - dense_1_loss_3: 0.3562 - dense_1_loss_4: 0.0996 - dense_1_loss_5: 0.0661 - dense_1_loss_6: 0.0518 - dense_1_loss_7: 0.0425 - dense_1_loss_8: 0.0339 - dense_1_loss_9: 0.0322 - dense_1_loss_10: 0.0257 - dense_1_loss_11: 0.0285 - dense_1_loss_12: 0.0261 - dense_1_loss_13: 0.0242 - dense_1_loss_14: 0.0246 - dense_1_loss_15: 0.0256 - dense_1_loss_16: 0.0281 - dense_1_loss_17: 0.0257 - dense_1_loss_18: 0.0252 - dense_1_loss_19: 0.0267 - dense_1_loss_20: 0.0269 - dense_1_loss_21: 0.0265 - dense_1_loss_22: 0.0253 - dense_1_loss_23: 0.0257 - dense_1_loss_24: 0.0255 - dense_1_loss_25: 0.0301 - dense_1_loss_26: 0.0261 - dense_1_loss_27: 0.0275 - dense_1_loss_28: 0.0314 - dense_1_loss_29: 0.0328 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6500 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     





&lt;keras.callbacks.History at 0x7fcff481d908&gt;</code></pre><p>You should see the model loss going down. Now that you have trained a model, lets go on the the final section to implement an inference algorithm, and generate some music! </p>
<h2 id="3-Generating-music"><a href="#3-Generating-music" class="headerlink" title="3 - Generating music"></a>3 - Generating music</h2><p>You now have a trained model which has learned the patterns of the jazz soloist. Lets now use this model to synthesize new music. </p>
<h4 id="3-1-Predicting-amp-Sampling"><a href="#3-1-Predicting-amp-Sampling" class="headerlink" title="3.1 - Predicting &amp; Sampling"></a>3.1 - Predicting &amp; Sampling</h4><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/images/music_gen.png" style="width:600;height:400px;">

<p>At each step of sampling, you will take as input the activation <code>a</code> and cell state <code>c</code> from the previous state of the LSTM, forward propagate by one step, and get a new output activation as well as cell state. The new activation <code>a</code> can then be used to generate the output, using <code>densor</code> as before. </p>
<p>To start off the model, we will initialize <code>x0</code> as well as the LSTM activation and and cell value <code>a0</code> and <code>c0</code> to be zeros. </p>
<!-- 
You are about to build a function that will do this inference for you. Your function takes in your previous model and the number of time steps `Ty` that you want to sample. It will return a keras model that would be able to generate sequences for you. Furthermore, the function takes in a dense layer of `78` units and the number of activations. 
!--> 


<p><strong>Exercise:</strong> Implement the function below to sample a sequence of musical values. Here are some of the key steps you’ll need to implement inside the for-loop that generates the $T_y$ output characters: </p>
<p>Step 2.A: Use <code>LSTM_Cell</code>, which inputs the previous step’s <code>c</code> and <code>a</code> to generate the current step’s <code>c</code> and <code>a</code>. </p>
<p>Step 2.B: Use <code>densor</code> (defined previously) to compute a softmax on <code>a</code> to get the output for the current step. </p>
<p>Step 2.C: Save the output you have just generated by appending it to <code>outputs</code>.</p>
<p>Step 2.D: Sample x to the be “out”‘s one-hot version (the prediction) so that you can pass it to the next LSTM’s step.  We have already provided this line of code, which uses a <a href="https://keras.io/layers/core/#lambda" target="_blank" rel="noopener">Lambda</a> function. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = Lambda(one_hot)(out)</span><br></pre></td></tr></table></figure>
<p>[Minor technical note: Rather than sampling a value at random according to the probabilities in <code>out</code>, this line of code actually chooses the single most likely note at each step using an argmax.]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: music_inference_model</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">music_inference_model</span><span class="params">(LSTM_cell, densor, n_values = <span class="number">78</span>, n_a = <span class="number">64</span>, Ty = <span class="number">100</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Uses the trained "LSTM_cell" and "densor" from model() to generate a sequence of values.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    LSTM_cell -- the trained "LSTM_cell" from model(), Keras layer object</span></span><br><span class="line"><span class="string">    densor -- the trained "densor" from model(), Keras layer object</span></span><br><span class="line"><span class="string">    n_values -- integer, umber of unique values</span></span><br><span class="line"><span class="string">    n_a -- number of units in the LSTM_cell</span></span><br><span class="line"><span class="string">    Ty -- integer, number of time steps to generate</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    inference_model -- Keras model instance</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define the input of your model with a shape </span></span><br><span class="line">    x0 = Input(shape=(<span class="number">1</span>, n_values))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define s0, initial hidden state for the decoder LSTM</span></span><br><span class="line">    a0 = Input(shape=(n_a,), name=<span class="string">'a0'</span>)</span><br><span class="line">    c0 = Input(shape=(n_a,), name=<span class="string">'c0'</span>)</span><br><span class="line">    a = a0</span><br><span class="line">    c = c0</span><br><span class="line">    x = x0</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Step 1: Create an empty list of "outputs" to later store your predicted values (≈1 line)</span></span><br><span class="line">    outputs = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 2: Loop over Ty and generate a value at every time step</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(Ty):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2.A: Perform one step of LSTM_cell (≈1 line)</span></span><br><span class="line">        a, _, c = LSTM_cell(x, initial_state=[a, c]);</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)</span></span><br><span class="line">        out = densor(a);</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2.C: Append the prediction "out" to "outputs". out.shape = (None, 78) (≈1 line)</span></span><br><span class="line">        outputs.append(out);</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2.D: Select the next value according to "out", and set "x" to be the one-hot representation of the</span></span><br><span class="line">        <span class="comment">#           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided </span></span><br><span class="line">        <span class="comment">#           the line of code you need to do this. </span></span><br><span class="line">        x = Lambda(one_hot)(out);</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 3: Create model instance with the correct "inputs" and "outputs" (≈1 line)</span></span><br><span class="line">    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs);</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> inference_model</span><br></pre></td></tr></table></figure>

<p>Run the cell below to define your inference model. This model is hard coded to generate 50 values.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inference_model = music_inference_model(LSTM_cell, densor, n_values = <span class="number">78</span>, n_a = <span class="number">64</span>, Ty = <span class="number">50</span>)</span><br></pre></td></tr></table></figure>

<p>Finally, this creates the zero-valued vectors you will use to initialize <code>x</code> and the LSTM state variables <code>a</code> and <code>c</code>. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_initializer = np.zeros((<span class="number">1</span>, <span class="number">1</span>, <span class="number">78</span>))</span><br><span class="line">a_initializer = np.zeros((<span class="number">1</span>, n_a))</span><br><span class="line">c_initializer = np.zeros((<span class="number">1</span>, n_a))</span><br></pre></td></tr></table></figure>

<p><strong>Exercise</strong>: Implement <code>predict_and_sample()</code>. This function takes many arguments including the inputs [x_initializer, a_initializer, c_initializer]. In order to predict the output corresponding to this input, you will need to carry-out 3 steps:</p>
<ol>
<li>Use your inference model to predict an output given your set of inputs. The output <code>pred</code> should be a list of length $T_y$ where each element is a numpy-array of shape (1, n_values).</li>
<li>Convert <code>pred</code> into a numpy array of $T_y$ indices. Each index corresponds is computed by taking the <code>argmax</code> of an element of the <code>pred</code> list. <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html" target="_blank" rel="noopener">Hint</a>.</li>
<li>Convert the indices into their one-hot vector representations. <a href="https://keras.io/utils/#to_categorical" target="_blank" rel="noopener">Hint</a>.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: predict_and_sample</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_and_sample</span><span class="params">(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, </span></span></span><br><span class="line"><span class="function"><span class="params">                       c_initializer = c_initializer)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Predicts the next value of values using the inference model.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    inference_model -- Keras model instance for inference time</span></span><br><span class="line"><span class="string">    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation</span></span><br><span class="line"><span class="string">    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell</span></span><br><span class="line"><span class="string">    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated</span></span><br><span class="line"><span class="string">    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.</span></span><br><span class="line">    pred = inference_model.predict([x_initializer, a_initializer, c_initializer]);</span><br><span class="line">    <span class="comment"># Step 2: Convert "pred" into an np.array() of indices with the maximum probabilities</span></span><br><span class="line">    indices = np.argmax(np.array(pred), axis = <span class="number">-1</span>);</span><br><span class="line">    <span class="comment"># Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )</span></span><br><span class="line">    results = to_categorical(indices, num_classes = x_initializer.shape[<span class="number">-1</span>]);</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> results, indices</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)</span><br><span class="line">print(<span class="string">"np.argmax(results[12]) ="</span>, np.argmax(results[<span class="number">12</span>]))</span><br><span class="line">print(<span class="string">"np.argmax(results[17]) ="</span>, np.argmax(results[<span class="number">17</span>]))</span><br><span class="line">print(<span class="string">"list(indices[12:18]) ="</span>, list(indices[<span class="number">12</span>:<span class="number">18</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>np.argmax(results[12]) = 21
np.argmax(results[17]) = 7
list(indices[12:18]) = [array([21]), array([10]), array([57]), array([43]), array([12]), array([7])]</code></pre><p><strong>Expected Output</strong>: Your results may differ because Keras’ results are not completely predictable. However, if you have trained your LSTM_cell with model.fit() for exactly 100 epochs as described above, you should very likely observe a sequence of indices that are not all identical. Moreover, you should observe that: np.argmax(results[12]) is the first element of list(indices[12:18]) and np.argmax(results[17]) is the last element of list(indices[12:18]). </p>
<table>
    <tr>
        <td>
            **np.argmax(results[12])** =
        </td>
        <td>
        1
        </td>
    </tr>
    <tr>
        <td>
            **np.argmax(results[12])** =
        </td>
        <td>
        42
        </td>
    </tr>
    <tr>
        <td>
            **list(indices[12:18])** =
        </td>
        <td>
            [array([1]), array([42]), array([54]), array([17]), array([1]), array([42])]
        </td>
    </tr>
</table>

<h4 id="3-3-Generate-music"><a href="#3-3-Generate-music" class="headerlink" title="3.3 - Generate music"></a>3.3 - Generate music</h4><p>Finally, you are ready to generate music. Your RNN generates a sequence of values. The following code generates music by first calling your <code>predict_and_sample()</code> function. These values are then post-processed into musical chords (meaning that multiple values or notes can be played at the same time). </p>
<p>Most computational music algorithms use some post-processing because it is difficult to generate music that sounds good without such post-processing. The post-processing does things such as clean up the generated audio by making sure the same sound is not repeated too many times, that two successive notes are not too far from each other in pitch, and so on. One could argue that a lot of these post-processing steps are hacks; also, a lot the music generation literature has also focused on hand-crafting post-processors, and a lot of the output quality depends on the quality of the post-processing and not just the quality of the RNN. But this post-processing does make a huge difference, so lets use it in our implementation as well. </p>
<p>Lets make some music! </p>
<p>Run the following cell to generate music and record it into your <code>out_stream</code>. This can take a couple of minutes.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out_stream = generate_music(inference_model)</span><br></pre></td></tr></table></figure>

<pre><code>Predicting new values for different set of chords.
Generated 51 sounds using the predicted values for the set of chords (&quot;1&quot;) and after pruning
Generated 50 sounds using the predicted values for the set of chords (&quot;2&quot;) and after pruning
Generated 50 sounds using the predicted values for the set of chords (&quot;3&quot;) and after pruning
Generated 51 sounds using the predicted values for the set of chords (&quot;4&quot;) and after pruning
Generated 51 sounds using the predicted values for the set of chords (&quot;5&quot;) and after pruning
Your generated music is saved in output/my_music.midi</code></pre><p>To listen to your music, click File-&gt;Open… Then go to “output/“ and download “my_music.midi”. Either play it on your computer with an application that can read midi files if you have one, or use one of the free online “MIDI to mp3” conversion tools to convert this to mp3.  </p>
<p>As reference, here also is a 30sec audio clip we generated using this algorithm. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IPython.display.Audio(<span class="string">'./data/30s_trained_model.mp3'</span>)</span><br></pre></td></tr></table></figure>





<pre><code>&lt;audio controls=&quot;controls&quot; &gt;</code></pre><p>y                    <source src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/data/30s_trained_model.mp3" type="audio/mpeg" /><br>                    Your browser does not support the audio element.<br>                </audio></p>
<h3 id="Congratulations"><a href="#Congratulations" class="headerlink" title="Congratulations!"></a>Congratulations!</h3><p>You have come to the end of the notebook. </p>
<font color="blue">
Here's what you should remember:
- A sequence model can be used to generate musical values, which are then post-processed into midi music. 
- Fairly similar models can be used to generate dinosaur names or to generate music, with the major difference being the input fed to the model.  
- In Keras, sequence generation involves defining layers with shared weights, which are then repeated for the different time steps $1, \ldots, T_x$. 

<p>Congratulations on completing this assignment and generating a jazz solo! </p>
<p><strong>References</strong></p>
<p>The ideas presented in this notebook came primarily from three computational music papers cited below. The implementation here also took significant inspiration and used many components from Ji-Sung Kim’s github repository.</p>
<ul>
<li>Ji-Sung Kim, 2016, <a href="https://github.com/jisungk/deepjazz" target="_blank" rel="noopener">deepjazz</a></li>
<li>Jon Gillick, Kevin Tang and Robert Keller, 2009. <a href="http://ai.stanford.edu/~kdtang/papers/smc09-jazzgrammar.pdf" target="_blank" rel="noopener">Learning Jazz Grammars</a></li>
<li>Robert Keller and David Morrison, 2007, <a href="http://smc07.uoa.gr/SMC07%20Proceedings/SMC07%20Paper%2055.pdf" target="_blank" rel="noopener">A Grammatical Approach to Automatic Improvisation</a></li>
<li>François Pachet, 1999, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.7473&rep=rep1&type=pdf" target="_blank" rel="noopener">Surprising Harmonies</a></li>
</ul>
<p>We’re also grateful to François Germain for valuable feedback.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/06/01/01_recurrent-neural-networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/01/01_recurrent-neural-networks/" class="post-title-link" itemprop="url">recurrent neural networks</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-06-01 00:00:00" itemprop="dateCreated datePublished" datetime="2018-06-01T00:00:00+05:30">2018-06-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 05:59:51" itemprop="dateModified" datetime="2020-04-09T05:59:51+05:30">2020-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/English/" itemprop="url" rel="index"><span itemprop="name">English</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>76k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>1:09</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>This is my personal lecture note after studying the course <a href="https://www.coursera.org/learn/nlp-sequence-models/" target="_blank" rel="noopener">nlp sequence models</a> at the 1st week and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.</p>
<h3 id="01-why-sequence-models"><a href="#01-why-sequence-models" class="headerlink" title="01_why-sequence-models"></a>01_why-sequence-models</h3><p>Welcome to this fifth course on deep learning. In this course, you learn about sequence models, one of the most exciting areas in deep learning. Models like recurrent neural networks or RNNs have transformed speech recognition, natural language processing and other areas. And in this course, you learn how to build these models for yourself. Let’s start by looking at a few examples of where sequence models can be useful. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week1/images/1.png" alt=""><br>In speech recognition you are given an input audio clip X and asked to map it to a text transcript Y. Both the input and the output here are sequence data, because X is an audio clip and so that plays out over time and Y, the output, is a sequence of words. So sequence models such as a recurrent neural networks and other variations, you’ll learn about in a little bit have been very useful for speech recognition. Music generation is another example of a problem with sequence data. In this case, only the output Y is a sequence, the input can be the empty set, or it can be a single integer, maybe referring to the genre of music you want to generate or maybe the first few notes of the piece of music you want. But here X can be nothing or maybe just an integer and output Y is a sequence. In sentiment classification the input X is a sequence, so given the input phrase like, “There is nothing to like in this movie” how many stars do you think this review will be? Sequence models are also very useful for DNA sequence analysis. So your DNA is represented via the four alphabets A, C, G, and T. And so given a DNA sequence can you label which part of this DNA sequence say corresponds to a protein. In machine translation you are given an input sentence, voulez-vou chante avec moi? And you’re asked to output the translation in a different language. In video activity recognition you might be given a sequence of video frames and asked to recognize the activity. And in name entity recognition you might be given a sentence and asked to identify the people in that sentence. <strong>So all of these problems can be addressed as supervised learning with label data X, Y as the training set. But, as you can tell from this list of examples, there are a lot of different types of sequence problems. In some, both the input X and the output Y are sequences, and in that case (speech recognition), sometimes X and Y can have different lengths, or in this example (at DNA case) and this example(at Name entity recognition), X and Y have the same length. And in some of these examples only either X or only the opposite Y is a sequence. So in this course you learn about sequence models are applicable, so all of these different settings</strong>. </p>
<p>So I hope this gives you a sense of the exciting set of problems that sequence models might be able to help you to address. With that let us go on to the next video where we start to define the notation we use to define these sequence-models.</p>
<h3 id="02-notation"><a href="#02-notation" class="headerlink" title="02_notation"></a>02_notation</h3><p>In the last video, you saw some of the wide range of applications through which you can apply sequence models. Let’s start by defining a notation that we’ll use to build up these sequence models. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week1/images/2.png" alt=""><br>As a motivating example, let’s say you want to build a sequence model to input a sentence like this, Harry Potter and Hermione Granger invented a new spell. And these are characters by the way, from the Harry Potter sequence of novels by J. K. Rowling. And let say you want a sequence model to automatically tell you where are the peoples names in this sentence. So, this is a problem called Named-entity recognition and this is used by search engines for example, to index all of say the last 24 hours news of all the people mentioned in the news articles so that they can index them appropriately. And name into the recognition systems can be used to find people’s names, companies names, times, locations, countries names, currency names, and so on in different types of text. Now, given this input x let’s say that you want a model to operate y that has one outputs per input word and the target output the design y tells you for each of the input words is that part of a person’s name. And technically this maybe isn’t the best output representation, there are some more sophisticated output representations that tells you not just is a word part of a person’s name, but tells you where are the start and ends of people’s names their sentence, you want to know Harry Potter starts here, and ends here, starts here, and ends here. But for this motivating example, I’m just going to stick with this simpler output representation. Now, the input is the sequence of nine words. So, eventually we’re going to have nine sets of features to represent these nine words, and index into the positions and sequence, I’m going to use X and then superscript angle brackets 1, 2, 3 and so on up to X angle brackets nine to index into the different positions. <strong>I’m going to use $X^{<t>}$ with the index t to index into positions, in the middle of the sequence</strong>. And t implies that these are temporal sequences although whether the sequences are temporal one or not, I’m going to use the index t to index into the positions in the sequence. And similarly for the outputs, we’re going to refer to these outputs as y and go back at 1, 2, 3 and so on up to y nine. Let’s also used T sub of x to denote the length of the input sequence, so in this case there are nine words. So $T_x$ is equal to 9 and we used $T_y$ to denote the length of the output sequence. In this example $T_x$ is equal to $T_y$ but you saw on the last video $T_x$ and $T_y$ can be different. So, you will remember that in the notation we’ve been using, we’ve been writing X round brackets i to denote the i training example. So, to refer to the TIF element or the TIF element in the sequence of training example i will use this notation and if $T_x$ is the length of a sequence then different examples in your training set can have different lengths. And so $T_x^i$ would be the input sequence length for training example i, and similarly $y^{(i)<t>}$ means the TIF element in the output sequence of the i for an example and $T_y^i$ will be the length of the output sequence in the i training example. So into this example, $T_x^i$ is equal to 9 would be the highly different training example with a sentence of 15 words and $T_x^i$ will be close to 15 for that different training example. Now, that we’re starting to work in NLP or Natural Language Processing. Now, this is our first serious foray into NLP or Natural Language Processing. And one of the things we need to decide is, how to represent individual words in the sequence. So, how do you represent a word like Harry, and why should $x^{&lt;1&gt;}$ really be? Let’s next talk about how we would represent individual words in a sentence. </p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2018/06/01/01_recurrent-neural-networks/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/05/04/04_special-applications-face-recognition-neural-style-transfer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/05/04/04_special-applications-face-recognition-neural-style-transfer/" class="post-title-link" itemprop="url">04_special-applications-face-recognition-neural-style-transfer</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-05-04 00:00:00" itemprop="dateCreated datePublished" datetime="2018-05-04T00:00:00+05:30">2018-05-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 04:37:42" itemprop="dateModified" datetime="2020-04-09T04:37:42+05:30">2020-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/English/" itemprop="url" rel="index"><span itemprop="name">English</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>52k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>47 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>This is my personal note after studying the course of the 4th week <a href="https://www.coursera.org/learn/convolutional-neural-networks" target="_blank" rel="noopener">convolutional neural networks</a> and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.</p>
<h2 id="01-face-recognition"><a href="#01-face-recognition" class="headerlink" title="01_face-recognition"></a>01_face-recognition</h2><h3 id="01-what-is-face-recognition"><a href="#01-what-is-face-recognition" class="headerlink" title="01_what-is-face-recognition"></a>01_what-is-face-recognition</h3><p>Hi, and welcome to this fourth and final week of this course on convolutional neural networks. By now, you’ve learned a lot about confidence. What I want to do this week is show you a couple important special applications of confidence. We’ll start the face recognition, and then go on later this week to neurosal transfer, which you get to implement in the problem exercise as well to create your own artwork. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/1.png" alt=""><br>But first, let’s start the face recognition and just for fun, I want to show you a demo. When I was leading by those AI group, one of the teams I worked with led by Yuanqing Lin had built a face recognition system that I thought is really cool. Let’s take a look. So, I’m going to play this video here, but I can also get whoever is editing this raw video configure out to this better to splice in the raw video or take the one I’m playing here. I want to show you a face recognition demo. I’m in Baidu’s headquarters in China. Most companies require that to get inside, you swipe an ID card like this one but here we don’t need that. Using face recognition, check what I can do. When I walk up, it recognizes my face, it says, “Welcome Andrew,” and I just walk right through without ever having to use my ID card. Let me show you something else. I’m actually here with Lin Yuanqing, the director of IDL which developed all of this face recognition technology. I’m gonna hand him my ID card, which has my face printed on it, and he’s going to use it to try to sneak in using my picture instead of a live human. I’m gonna use Andrew’s card and try to sneak in and see what happens. So the system is not recognizing it, it refuses to recognize. Okay. Now, I’m going to use my own face. So face recognition technology like this is taking off very rapidly in China and I hope that this type of technology soon makes it way to other countries.. So, pretty cool, right? The video you just saw demoed both face recognition as well as liveness detection. The latter meaning making sure that you are a live human. It turns out liveness detection can be implemented using supervised learning as well to predict live human versus not live human but I want to spend less time on that. Instead, I want to focus our time on talking about how to build the face recognition portion of the system. First, let’s start by going over some of the terminology used in face recognition. In the face recognition literature, people often talk about face verification and face recognition. This is the face verification problem which is if you’re given an input image as well as a name or ID of a person and the job of the system is to verify whether or not the input image is that of the claimed person. So, sometimes this is also called a one to one problem where you just want to know if the person is the person they claim to be. So, the recognition problem is much harder than the verification problem. To see why, let’s say, you have a verification system that’s 99 percent accurate. So, 99 percent might not be too bad but now suppose that K is equal to 100 in a recognition system. If you apply this system to a recognition task with a 100 people in your database, you now have a hundred times of chance of making a mistake and if the chance of making mistakes on each person is just one percent. So, if you have a database of a 100 persons and if you want an acceptable recognition error, you might actually need a verification system with maybe 99.9 or even higher accuracy before you can run it on a database of 100 persons that have a high chance and still have a high chance of getting incorrect. In fact, if you have a database of 100 persons currently just be even quite a bit higher than 99 percent for that to work well. <strong>But what we do in the next few videos is focus on building a face verification system as a building block and then if the accuracy is high enough, then you probably use that in a recognition system as well</strong>. </p>
<p>So in the next video, we’ll start describing how you can build a face verification system. It turns out one of the reasons that is a difficult problem is you need to solve a one shot learning problem. Let’s see in the next video what that means.</p>
<h3 id="02-one-shot-learning"><a href="#02-one-shot-learning" class="headerlink" title="02_one-shot-learning"></a>02_one-shot-learning</h3><p>One of the challenges of face recognition is that you need to solve the one-shot learning problem. What that means is that for most face recognition applications you need to be able to recognize a person given just one single image, or given just one example of that person’s face. And, historically, deep learning algorithms don’t work well if you have only one training example. Let’s see an example of what this means and talk about how to address this problem. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/2.png" alt=""><br>Let’s say you have a database of four pictures of employees in you’re organization. These are actually some of my colleagues at Deeplearning.AI, Khan, Danielle, Younes and Thian. Now let’s say someone shows up at the office and they want to be let through the turnstile. What the system has to do is, despite ever having seen only one image of Danielle, to recognize that this is actually the same person. And, in contrast, if it sees someone that’s not in this database, then it should recognize that this is not any of the four persons in the database. So in the one shot learning problem, you have to learn from just one example to recognize the person again. And you need this for most face recognition systems because you might have only one picture of each of your employees or of your team members in your employee database. So one approach you could try is to input the image of the person, feed it too a ConvNet. And have it output a label, y, using a softmax unit with four outputs or maybe five outputs corresponding to each of these four persons or none of the above. So that would be 5 outputs in the softmax. But this really doesn’t work well. Because if you have such a small training set it is really not enough to train a robust neural network for this task. And also what if a new person joins your team? So now you have 5 persons you need to recognize, so there should now be six outputs. Do you have to retrain the ConvNet every time? That just doesn’t seem like a good approach. So to carry out face recognition, to carry out one-shot learning. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/3.png" alt=""><br>So instead, to make this work, what you’re going to do instead is learn a similarity function. In particular, you want a neural network to learn a function which going to denote d, which inputs two images and outputs the degree of difference between the two images. So if the two images are of the same person, you want this to output a small number. And if the two images are of two very different people you want it to output a large number. So during recognition time, if the degree of difference between them is less than some threshold called tau, which is a hyperparameter. Then you would predict that these two pictures are the same person. And if it is greater than tau, you would predict that these are different persons. And so this is how you address the face verification problem. To use this for a recognition task, what you do is, given this new picture, you will use this function d to compare these two images. And maybe I’ll output a very large number, let’s say 10, for this example. And then you compare this with the second image in your database. And because these two are the same person, hopefully you output a very small number. You do this for the other images in your database and so on. And based on this, you would figure out that this is actually that person, which is Danielle. And in contrast, if someone not in your database shows up, as you use the function d to make all of these pairwise comparisons, hopefully d will output have a very large number for all four pairwise comparisons. And then you say that this is not any one of the four persons in the database. Notice how this allows you to solve the one-shot learning problem. So long as you can learn this function d, which inputs a pair of images and tells you, basically, if they’re the same person or different persons. Then if you have someone new join your team, you can add a fifth person to your database, and it just works fine. </p>
<p>So you’ve seen how learning this function d, which inputs two images, allows you to address the one-shot learning problem. In the next video, let’s take a look at how you can actually train the neural network to learn dysfunction d.</p>
<h3 id="03-siamese-network"><a href="#03-siamese-network" class="headerlink" title="03_siamese-network"></a>03_siamese-network</h3><p>The job of the function d, which you learned about in the last video, is to input two faces and tell you how similar or how different they are. A good way to do this is to use a Siamese network. Let’s take a look. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/4.png" alt=""><br>You’re used to seeing pictures of confidence like these where you input an image, let’s say x1. And through a sequence of convolutional and pulling and fully connected layers, end up with a feature vector like that. And sometimes this is fed to a softmax unit to make a classification. We’re not going to use that in this video. Instead, we’re going to focus on this vector of let’s say 128 numbers computed by some fully connected layer that is deeper in the network. And I’m going to give this list of 128 numbers a name. I’m going to <strong>call this f of x1, and you should think of f of x1 as an encoding of the input image x1</strong>. So it’s taken the input image, here this picture of Kian, and is re-representing it as a vector of 128 numbers. The way you can build a face recognition system is then that if you want to compare two pictures, let’s say this first picture with this second picture here. What you can do is feed this second picture to the same neural network with the same parameters and get a different vector of 128 numbers, which encodes this second picture. So I’m going to call this second picture. So I’m going to call this encoding of this second picture f of x2, and here I’m using x1 and x2 just to denote two input images. They don’t necessarily have to be the first and second examples in your training sets. It can be any two pictures. <strong>Finally, if you believe that these encodings are a good representation of these two images, what you can do is then define the image d of distance between x1 and x2 as the norm of the difference between the encodings of these two images. So this idea of running two identical, convolutional neural networks on two different inputs and then comparing them, sometimes that’s called a Siamese neural network architecture</strong>. And a lot of the ideas I’m presenting here came from this paper due to Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, and Lior Wolf in the research system that they developed called DeepFace. And many of the ideas I’m presenting here came from a paper due to Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, and Lior Wolf in a system that they developed called DeepFace. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/5.png" alt=""><br>So how do you train this Siamese neural network? Remember that these two neural networks have the same parameters. So what you want to do is really train the neural network so that the encoding that it computes results in a function d that tells you when two pictures are of the same person. So more formally, the parameters of the neural network define an encoding f of xi. So given any input image xi, the neural network outputs this 128 dimensional encoding f of xi. So more formally, what you want to do is learn parameters so that if two pictures, xi and xj, are of the same person, then you want that distance between their encodings to be small. And in the previous slide, l was using x1 and x2, but it’s really any pair xi and xj from your training set. And in contrast, if xi and xj are of different persons, then you want that distance between their encodings to be large. So as you vary the parameters in all of these layers of the neural network, you end up with different encodings. And what you can do is use back propagation and vary all those parameters in order to make sure these conditions are satisfied. </p>
<p>So you’ve learned about the Siamese network architecture and have a sense of what you want the neural network to output for you in terms of what would make a good encoding. But how do you actually define an objective function to make a neural network learn to do what we just discussed here? Let’s see how you can do that in the next video using the triplet loss function.</p>
<h3 id="04-triplet-loss"><a href="#04-triplet-loss" class="headerlink" title="04_triplet-loss"></a>04_triplet-loss</h3><p>One way to learn the parameters of the neural network so that it gives you a good encoding for your pictures of faces is to define an applied gradient descent on the triplet loss function. Let’s see what that means. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/6.png" alt=""><br>To apply the triplet loss, you need to compare pairs of images. For example, given this picture, to learn the parameters of the neural network, you have to look at several pictures at the same time. For example, given this pair of images, you want their encodings to be similar because these are the same person. Whereas, given this pair of images, you want their encodings to be quite different because these are different persons. In the terminology of the triplet loss, what you’re going do is always look at one anchor image and then you want to distance between the anchor and the positive image, really a positive example, meaning as the same person to be similar. Whereas, you want the anchor when pairs are compared to the negative example for their distances to be much further apart. <strong>So, this is what gives rise to the term triplet loss, which is that you’ll always be looking at three images at a time. You’ll be looking at an anchor image, a positive image, as well as a negative image. And I’m going to abbreviate anchor positive and negative as A, P, and N</strong>. So to formalize this, what you want is for the parameters of your neural network of your encodings to have the following property, which is that you want the encoding between the anchor minus the encoding of the positive example, you want this to be small and in particular, you want this to be less than or equal to the distance of the squared norm between the encoding of the anchor and the encoding of the negative, where of course, this is d of A, P and this is d of A, N. And you can think of d as a distance function, which is why we named it with the alphabet d. Now, if we move to term from the right side of this equation to the left side, what you end up with is f of A minus f of P squared minus, let’s take the right-hand side now, minus F of N squared, you want this to be less than or equal to zero. <strong>But now, we’re going to make a slight change to this expression, which is one trivial way to make sure this is satisfied, is to just learn everything equals zero. If f always equals zero, then this is zero minus zero, which is zero, this is zero minus zero which is zero. And so, well, by saying f of any image equals a vector of all zeroes, you can almost trivially satisfy this equation. So, to make sure that the neural network doesn’t just output zero for all the encoding, so to make sure that it doesn’t set all the encodings equal to each other. Another way for the neural network to give a trivial output is if the encoding for every image was identical to the encoding to every other image, in which case, you again get zero minus zero. So to prevent a neural network from doing that, what we’re going to do is modify this objective</strong> to say that, this doesn’t need to be just less than or equal to zero, it needs to be quite a bit smaller than zero. So, in particular, if we say this needs to be less than negative alpha, where alpha is another hyperparameter, then this prevents a neural network from outputting the trivial solutions. And by convention, usually, we write plus alpha instead of negative alpha there. And this is also called, <strong>a margin</strong>, which is terminology that you’d be familiar with if you’ve also seen the literature on support vector machines, but don’t worry about it if you haven’t. And we can also modify this equation on top by adding this margin parameter. So to give an example, let’s say the margin is set to 0.2. If in this example, d of the anchor and the positive is equal to 0.5, then you won’t be satisfied if d between the anchor and the negative was just a little bit bigger, say 0.51. Even though 0.51 is bigger than 0.5, you’re saying, that’s not good enough, we want a dfA, N to be much bigger than dfA, P and in particular, you want this to be at least 0.7 or higher. Alternatively, to achieve this margin or this gap of at least 0.2, you could either push this up or push this down so that there is at least this gap of this alpha, hyperparameter alpha 0.2 between the distance between the anchor and the positive versus the anchor and the negative. So that’s what having a margin parameter here does, which is it pushes the anchor positive pair and the anchor negative pair further away from each other. So, let’s take this equation we have here at the bottom, and on the next slide, formalize it, and define the triplet loss function. So, <strong>the triplet loss function is defined on triples of images</strong>. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/7.png" alt=""><br>So, given three images, A, P, and N, the anchor positive and negative examples. So the positive examples is of the same person as the anchor, but the negative is of a different person than the anchor. We’re going to define the loss as follows. The loss on this example, which is really defined on a triplet of images is, let me first copy over what we had on the previous slide. So, that was fA minus fP squared minus fA minus fN squared, and then plus alpha, the margin parameter. And what you want is for this to be less than or equal to zero. So, to define the loss function, let’s take the max between this and zero. So, the effect of taking the max here is that, so long as this is less than zero, then the loss is zero, because the max is something less than equal to zero, when zero is going to be zero. So, so long as you achieve the goal of making this thing I’ve underlined in green, so long as you’ve achieved the objective of making that less than or equal to zero, then the loss on this example is equals to zero. But if on the other hand, if this is greater than zero, then if you take the max, the max we end up selecting, this thing I’ve underlined in green, and so you would have a positive loss. So by trying to minimize this, this has the effect of trying to send this thing to be zero, less than or equal to zero. And then, so long as there’s zero or less than or equal to zero, the neural network doesn’t care how much further negative it is. So, this is how you define the loss on a single triplet and the overall cost function for your neural network can be sum over a training set of these individual losses on different triplets. So, if you have a training set of say 10,000 pictures with 1,000 different persons, what you’d have to do is take your 10,000 pictures and use it to generate, to select triplets like this and then train your learning algorithm using gradient descent on this type of cost function, which is really defined on triplets of images drawn from your training set. <strong>Notice that in order to define this dataset of triplets, you do need some pairs of A and P. Pairs of pictures of the same person. So the purpose of training your system, you do need a dataset where you have multiple pictures of the same person. That’s why in this example, I said if you have 10,000 pictures of 1,000 different person, so maybe have 10 pictures on average of each of your 1,000 persons to make up your entire dataset. If you had just one picture of each person, then you can’t actually train this system</strong>. But of course after training, if you’re applying this, but of course after having trained the system, you can then apply it to your one shot learning problem where for your face recognition system, maybe you have only a single picture of someone you might be trying to recognize. But for your training set, you do need to make sure you have multiple images of the same person at least for some people in your training set so that you can have pairs of anchor and positive images. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/8.png" alt=""><br>Now, how do you actually choose these triplets to form your training set? One of the problems if you choose A, P, and N randomly from your training set subject to A and P being from the same person, and A and N being different persons, one of the problems is that if you choose them so that they’re at random, then this constraint is very easy to satisfy. Because given two randomly chosen pictures of people, chances are A and N are much different than A and P. I hope you still recognize this notation, this d(A, P) was what we had written on the last few slides as this encoding. So this is just equal to this squared known distance between the encodings that we have on the previous slide. <strong>But if A and N are two randomly chosen different persons, then there is a very high chance that this will be much bigger more than the margin alpha that that term on the left. And so, the neural network won’t learn much from it. So to construct a training set, what you want to do is to choose triplets A, P, and N that are hard to train on. So in particular, what you want is for all triplets that this constraint be satisfied. So, a triplet that is hard will be if you choose values for A, P, and N so that maybe d(A, P) is actually quite close to d(A,N). So in that case, the learning algorithm has to try extra hard to take this thing on the right and try to push it up or take this thing on the left and try to push it down so that there is at least a margin of alpha between the left side and the right side. And the effect of choosing these triplets is that it increases the computational efficiency of your learning algorithm. If you choose your triplets randomly, then too many triplets would be really easy, and so, gradient descent won’t do anything because your neural network will just get them right, pretty much all the time. And it’s only by using hard triplets that the gradient descent procedure has to do some work to try to push these quantities further away from those quantities</strong>. And if you’re interested, the details are presented in this paper by Florian Schroff, Dmitry Kalinichenko, and James Philbin, where they have a system called <strong>FaceNet</strong>, which is where a lot of the ideas I’m presenting in this video come from. </p>
<p>By the way, this is also a fun fact about how algorithms are often named in the deep learning world, which is if you work in a certain domain, then we call that blank. You often have a system called blank net or deep blank. So, we’ve been talking about face recognition. So this paper is called FaceNet, and in the last video, you just saw deep face. <strong>But this idea of a blank net or deep blank is a very popular way of naming algorithms in the deep learning world. And you should feel free to take a look at that paper if you want to learn some of these other details for speeding up your algorithm by choosing the most useful triplets to train on, it is a nice paper</strong>. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/9.png" alt=""><br>So, just to wrap up, to train on triplet loss, you need to take your training set and map it to a lot of triples. So, here is our triple with an anchor and a positive, both for the same person and the negative of a different person. Here’s another one where the anchor and positive are of the same person but the anchor and negative are of different persons and so on. And what you do having defined this training sets of anchor positive and negative triples is use gradient descent to try to minimize the cost function J we defined on an earlier slide, and that will have the effect of that propagating to all of the parameters of the neural network in order to learn an encoding so that d of two images will be small when these two images are of the same person, and they’ll be large when these are two images of different persons. </p>
<p>. <strong>Now, it turns out that today’s face recognition systems especially the large scale commercial face recognition systems are trained on very large datasets</strong>. Datasets north of a million images is not uncommon, some companies are using north of 10 million images and some companies have north of 100 million images with which to try to train these systems. So these are very large datasets even by modern standards, these dataset assets are not easy to acquire. <strong>Fortunately, some of these companies have trained these large networks and posted parameters online. So, rather than trying to train one of these networks from scratch, this is one domain where because of the share data volume sizes, this is one domain where often it might be useful for you to download someone else’s pre-train model, rather than do everything from scratch yourself. But even if you do download someone else’s pre-train model, I think it’s still useful to know how these algorithms were trained or in case you need to apply these ideas from scratch yourself for some application</strong>. So that’s it for the triplet loss. In the next video, I want to show you also some other variations on siamese networks and how to train these systems. Let’s go onto the next video.</p>
<h3 id="05-face-verification-and-binary-classification"><a href="#05-face-verification-and-binary-classification" class="headerlink" title="05_face-verification-and-binary-classification"></a>05_face-verification-and-binary-classification</h3><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/10.png" alt=""><br>The Triplet Loss is one good way to learn the parameters of a continent for face recognition. There’s another way to learn these parameters. Let me show you how face recognition can also be posed as a straight binary classification problem. Another way to train a neural network, is to take this pair of neural networks to take this Siamese Network and have them both compute these embeddings, maybe 128 dimensional embeddings, maybe even higher dimensional, and then have these be input to a logistic regression unit to then just make a prediction. Where the target output will be one if both of these are the same persons, and zero if both of these are of different persons. So, this is a way to treat face recognition just as a binary classification problem. And this is an alternative to the triplet loss for training a system like this. Now, what does this final logistic regression unit actually do? The output y hat will be a sigmoid function, applied to some set of features but rather than just feeding in, these encodings, what you can do is take the differences between the encodings. So, let me show you what I mean. Let’s say, I write a sum over K equals 1 to 128 of the absolute value, taken element wise between the two different encodings. Let me just finish writing this out and then we’ll see what this means. In this notation, f of x i is the encoding of the image $x_i$ and the substitute k means to just select out the kth components of this vector. <strong>This is taking the element Y’s difference in absolute values between these two encodings. And what you might do is think of these 128 numbers as features that you then feed into logistic regression. And, you’ll find that logistic regression can add additional parameters $w_i$, and $b$ similar to a normal logistic regression unit. And you would train appropriate weighting on these 128 features in order to predict whether or not these two images are of the same person or of different persons. So, this will be one pretty useful way to learn to predict zero or one whether these are the same person or different persons.</strong> </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/11.png" alt=""><br>And there are a few other variations on how you can compute this formula that I had underlined in green. For example, another formula could be this k minus f of $x_j$, k squared divided by f of x i on plus f of x j k. This is sometimes called the chi square form. This is the Greek alphabet chi. But this is sometimes called a <strong>$\chi$ square similarity</strong>. And this and other variations are explored in this deep face paper, which I referenced earlier as well. So in this learning formulation, the input is a pair of images, so this is really your training input x and the output y is either zero or one depending on whether you’re inputting a pair of similar or dissimilar images. And same as before, you’re training is Siamese Network so that means that, this neural network up here has parameters that are what they’re really tied to the parameters in this lower neural network. And this system can work pretty well as well. <strong>Lastly, just to mention, one computational trick that can help neural deployment significantly, which is that, if this is the new image, so this is an employee walking in hoping that the turnstile the doorway will open for them and that this is from your database image. Then instead of having to compute, this embedding every single time, where you can do is actually pre-compute that, so, when the new employee walks in, what you can do is use this upper components to compute that encoding and use it, then compare it to your pre-computed encoding and then use that to make a prediction y hat. Because you don’t need to store the raw images and also because if you have a very large database of employees, you don’t need to compute these encodings every single time for every employee database. This idea of free computing, some of these encodings can save a significant computation</strong>. And this type of pre-computation works both for this type of Siamese Central architecture where you treat face recognition as a binary classification problem, as well as, when you were learning encodings maybe using the Triplet Loss function as described in the last couple of videos. </p>
<p>And so just to wrap up, to treat face verification supervised learning, you create a training set of just pairs of images now is of triplets of pairs of images where the target label is one. When these are a pair of pictures of the same person and where the tag label is zero, when these are pictures of different persons and you use different pairs to train the neural network to train the scientists that were using back propagation. </p>
<p>So, this version that you just saw of treating face verification and by extension face recognition as a binary classification problem, this works quite well as well. As sort of that, I hope that you now know, whether it would take to train your own face verification or your own face recognition system one that can do one.</p>
<h2 id="02-neural-style-transfer"><a href="#02-neural-style-transfer" class="headerlink" title="02_neural-style-transfer"></a>02_neural-style-transfer</h2><h3 id="01-what-is-neural-style-transfer"><a href="#01-what-is-neural-style-transfer" class="headerlink" title="01_what-is-neural-style-transfer"></a>01_what-is-neural-style-transfer</h3><p>One of the most fun and exciting applications of ConvNet recently has been Neural Style Transfer. You get to implement this yourself and generate your own artwork in the problem exercise. But what is Neural Style Transfer? Let me show you a few examples. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/12.png" alt=""><br>Let’s say you take this image, this is actually taken from the Stanford University not far from my Stanford office and you want this picture recreated in the style of this image on the right. This is actually Van Gogh’s, Starry Night painting. What Neural Style Transfer allows you to do is generated new image like the one below which is a picture of the Stanford University Campus that painted but drawn in the style of the image on the right. In order to describe how you can implement this yourself, I’m going to use C to denote the content image, S to denote the style image, and G to denote the image you will generate. Here’s another example, let’s say you have this content image so let’s see this is of the Golden Gate Bridge in San Francisco and you have this style image, this is actually Pablo Picasso image. You can then combine these to generate this image G which is the Golden Gate painted in the style of that Picasso shown on the right. The examples shown on this slide were generated by Justin Johnson. </p>
<p>What you’ll learn in the next few videos is how you can generate these images yourself. In order to implement Neural Style Transfer, you need to look at the features extracted by ConvNet at various layers, the shallow and the deeper layers of a ConvNet. Before diving into how you can implement a Neural Style Transfer, what I want to do in the next video is try to give you better intuition about whether all these layers of a ConvNet really computing. Let’s take a look at that in the next video.</p>
<h3 id="02-what-are-deep-convnets-learning"><a href="#02-what-are-deep-convnets-learning" class="headerlink" title="02_what-are-deep-convnets-learning"></a>02_what-are-deep-convnets-learning</h3><p>What are deep ConvNets really learning? In this video, I want to share with you some visualizations that will help you hone your intuition about what the deeper layers of a ConvNet really are doing. And this will help us think through how you can implement neural style transfer as well. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/13.png" alt=""><br>Let’s start with an example. Lets say you’ve trained a ConvNet, this is an alex net like network, and you want to visualize what the hidden units in different layers are computing. Here’s what you can do. Let’s start with a hidden unit in layer 1. And suppose you scan through your training sets and find out what are the images or what are the image patches that maximize that unit’s activation. <strong>So in other words pause your training set through your neural network, and figure out what is the image that maximizes that particular unit’s activation. Now, notice that a hidden unit in layer 1, will see only a relatively small portion of the neural network</strong>. And so if you visualize, if you plot what activated unit’s activation, it makes makes sense to plot just a small image patches, because all of the image that that particular unit sees. <strong>So if you pick one hidden unit and find the nine input images that maximizes that unit’s activation, you might find nine image patches like this</strong>.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/15.png" alt=""><br>So looks like that in the lower region of an image that this particular hidden unit sees, <strong>it’s looking for an egde or a line that looks like that</strong>. So those are the nine image patches that maximally activate one hidden unit’s activation. Now, you can then pick a different hidden unit in layer 1 and do the same thing.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/16.png" alt=""><br>So that’s a different hidden unit, and looks like this second one, represented by these 9 image patches here. Looks like <strong>this hidden unit is looking for a line sort of in that portion of its input region</strong>, we’ll also call this <strong>receptive field</strong>. And if you do this for other hidden units, you’ll find other hidden units, tend to activate in image patches that look like that.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/17.png" alt=""><br>This one seems to have <strong>a preference for a vertical light edge</strong>, but with a preference that the left side of it be green.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/18.png" alt=""><br>This one really <strong>prefers orange colors</strong>, and this is an interesting image patch. This red and green together will make a brownish or a brownish-orangish color, but the neuron is still happy to activate with that, and so on.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/19.png" alt=""><br>So this is nine different representative neurons and for each of them the nine image patches that they maximally activate on. <strong>So this gives you a sense that, units, train hidden units in layer 1, they’re often looking for relatively simple features such as edge or a particular shade of color. And all of the examples I’m using in this video come from this paper by Mathew Zeiler and Rob Fergus, titled visualizing and understanding convolutional networks. And I’m just going to use one of the simpler ways to visualize what a hidden unit in a neural network is computing. If you read their paper, they have some other more sophisticated ways of visualizing when the ConvNet is running as well</strong>. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/20.png" alt=""><br>But now you have repeated this procedure several times for nine hidden units in layer 1. What if you do this for some of the hidden units in the deeper layers of the neuron network. And what does the neural network then learning at a deeper layers. So in the deeper layers, a hidden unit will see a larger region of the image. Where at the extreme end each pixel could hypothetically affect the output of these later layers of the neural network. So later units are actually seen larger image patches, I’m still going to plot the image patches as the same size on these slides. But if we repeat this procedure, this is what you had previously for layer 1, and this is a visualization of what maximally activates nine different hidden units in layer 2. So I want to be clear about what this visualization is. These are the nine patches that cause one hidden unit to be highly activated. And then each grouping, this is a different set of nine image patches that cause one hidden unit to be activated. So this visualization shows nine hidden units in layer 2, and for each of them shows nine image patches that causes that hidden unit to have a very large output, a very large activation. And you can repeat these for deeper layers as well. </p>
<p>Now, on this slide, I know it’s kind of hard to see these tiny little image patches, so let me zoom in for some of them. For layer 1, this is what you saw. <img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/21.png" alt=""> So for example, this is that first unit we saw which was highly activated, <strong>if in the region of the input image, you can see there’s an edge maybe at that angle</strong>. </p>
<p>Now let’s zoom in for layer 2 as well, to that visualization.<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/22.png" alt=""> So this is interesting, layer 2 looks it’s detecting <strong>more complex shapes and patterns</strong>. So for example, this hidden unit looks like it’s looking for a vertical texture with lots of vertical lines. This hidden unit looks like its highly activated when there’s a rounder shape to the left part of the image. Here’s one that is looking for very thin vertical lines and so on. And so the features the second layer is detecting are getting more complicated. </p>
<p>How about layer 3? Let’s zoom into that, in fact let me zoom in even bigger, so you can see this better, these are the things that maximally activate layer 3.<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/23.png" alt=""> But let’s zoom in even bigger, and so this is pretty interesting again. It looks like there is a hidden unit that seems to respond highly to a rounder shape in the lower left hand portion of the image, maybe. So that ends up detecting a lot of cars, dogs and wonders is even starting to detect people. And this one look like it is detecting certain textures like honeycomb shapes, or square shapes, this irregular texture. And some of these it’s difficult to look at and manually figure out what is it detecting, but it is clearly starting to detect more complex patterns. </p>
<p>How about the next layer? Well, here is layer 4, and you’ll see that the features or the patterns is detecting or even more complex. <img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/24.png" alt=""> It looks like this has learned almost a dog detector, but all these dogs likewise similar, right? Is this, I don’t know what dog species or dog breed this is. But now all those are dogs, but they look relatively similar as dogs go. Looks like this hidden unit and therefore it is detecting water. This looks like it is actually detecting the legs of a bird and so on. </p>
<p>And then layer 5 is detecting even more sophisticated things. <img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/25.png" alt=""> So you’ll notice there’s also a neuron that seems to be a dog detector, but set of dogs detecting here seems to be more varied. And then this seems to be detecting keyboards and things with a keyboard like texture, although maybe lots of dots against background. I think this neuron here may be detecting text, it’s always hard to be sure. And then this one here is detecting flowers. So we’ve gone a long way from detecting relatively simple things such as edges in layer 1 to textures in layer 2, up to detecting very complex objects in the deeper layers. </p>
<p>So I hope this gives you some better intuition about what the shallow and deeper layers of a neural network are computing. Next, let’s use this intuition to start building a neural-style transfer algorithm.</p>
<h3 id="03-cost-function"><a href="#03-cost-function" class="headerlink" title="03_cost-function"></a>03_cost-function</h3><p>To build a Neural Style Transfer system, let’s define a cost function for the generated image. What you see later is that by minimizing this cost function, you can generate the image that you want. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/26.png" alt=""><br>Remember what the problem formulation is. You’re given a content image C, given a style image S and you goal is to generate a new image G. In order to implement neural style transfer, what you’re going to do is define a cost function J of G that measures how good is a particular generated image and we’ll use gradient to descent to minimize J of G in order to generate this image. How good is a particular image? Well, we’re going to define two parts to this cost function. The first part is called the <strong>content cost</strong>. This is a function of the content image and of the generated image and what it does is it measures how similar is the contents of the generated image to the content of the content image C. And then going to add that to a <strong>style cost function</strong> which is now a function of S,G and what this does is it measures how similar is the style of the image G to the style of the image S. Finally, we’ll weight these with two hyper parameters alpha and beta to specify the relative weighting between the content costs and the style cost. <strong>It seems redundant to use two different hyper parameters to specify the relative cost of the weighting. One hyper parameter seems like it would be enough but the original authors of the Neural Style Transfer Algorithm, use two different hyper parameters. I’m just going to follow their convention here</strong>. </p>
<p>The Neural Style Transfer Algorithm I’m going to present in the next few videos is due to Leon Gatys, Alexander Ecker and Matthias. Their papers is not too hard to read so after watching these few videos if you wish, I certainly encourage you to take a look at their paper as well if you want. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/27.png" alt=""><br>The way the algorithm would run is as follows, having to find the cost function J of G in order to actually generate a new image what you do is the following. <strong>You would initialize the generated image G randomly so it might be 100 by 100 by 3 or 500 by 500 by 3 or whatever dimension you want it to be. Then we’ll define the cost function J of G on the previous slide. What you can do is use gradient descent to minimize this so you can update G as G minus the derivative respect to the cost function of J of G. In this process, you’re actually updating the pixel values of this image G which is a 100 by 100 by 3 maybe rgb channel image</strong>. Here’s an example, let’s say you start with this content image and this style image. This is a another probably Picasso image. Then when you initialize G randomly, you’re initial randomly generated image is just this white noise image with each pixel value chosen at random. As you run gradient descent, you minimize the cost function J of G slowly through the pixel value so then you get slowly an image that looks more and more like your content image rendered in the style of your style image. </p>
<p>In this video, you saw the overall outline of the Neural Style Transfer Algorithm where you define a cost function for the generated image G and minimize it. Next, we need to see how to define the content cost function as well as the style cost function. Let’s take a look at that starting in the next video.</p>
<h3 id="04-content-cost-function"><a href="#04-content-cost-function" class="headerlink" title="04_content-cost-function"></a>04_content-cost-function</h3><p>The cost function of the neural style transfer algorithm had a content cost component and a style cost component. Let’s start by defining the content cost component. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/28.png" alt=""><br>Remember that this is the overall cost function of the neural style transfer algorithm. So, let’s figure out what should the content cost function be. <strong>Let’s say that you use hidden layer l to compute the content cost. If l is a very small number, if you use hidden layer one, then it will really force your generated image to pixel values very similar to your content image. Whereas, if you use a very deep layer, then it’s just asking, “Well, if there is a dog in your content image, then make sure there is a dog somewhere in your generated image. “ So in practice, layer l chosen somewhere in between. It’s neither too shallow nor too deep in the neural network.</strong> And because you program this yourself, in the problem exercise that you did at the end of this week, I’ll leave you to gain some intuitions with the concrete examples in the problem exercise as well. But usually, I was chosen to be somewhere in the middle of the layers of the neural network, neither too shallow nor too deep. What you can do is then use a pre-trained ConvNet, maybe a VGG network, or could be some other neural network as well. And now, you want to measure, given a content image and given a generated image, how similar are they in content. So let’s let this a_superscript_<a href="c">l</a> and this be the activations of layer l on these two images, on the images C and G. So, if these two activations are similar, then that would seem to imply that both images have similar content. So, what we’ll do is define J_content(C,G) as just how soon or how different are these two activations. So, we’ll take the element-wise difference between these hidden unit activations in layer l, between when you pass in the content image compared to when you pass in the generated image, and take that squared. And you could have a normalization constant in front or not, so it’s just one of the two or something else. It doesn’t really matter since this can be adjusted as well by this hyperparameter alpha. So, just be clear on using this notation as if both of these have been unrolled into vectors, so then, this becomes the square root of the l_2 norm between this and this, after you’ve unrolled them both into vectors. There’s really just the element-wise sum of squared differences between these two activation. But <strong>it’s really just the element-wise sum of squares of differences between the activations in layer l, between the images in C and G</strong>. And so, <strong>when later you perform gradient descent on J_of_G to try to find a value of G, so that the overall cost is low, this will incentivize the algorithm to find an image G, so that these hidden layer activations are similar to what you got for the content image</strong>. </p>
<p>So, that’s how you define the content cost function for the neural style transfer. Next, let’s move on to the style cost function.</p>
<h3 id="05-style-cost-function"><a href="#05-style-cost-function" class="headerlink" title="05_style-cost-function"></a>05_style-cost-function</h3><p>In the last video, you saw how to define the content cost function for the neural style transfer. Next, let’s take a look at the style cost function. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/29.png" alt=""><br>So, what is the style of an image mean? Let’s say you have an input image like this, they used to seeing a convnet like that, compute features that there’s different layers. And let’s say you’ve chosen some layer L, maybe that layer to define the measure of the style of an image. What we need to do is define the style as the correlation between activations across different channels in this layer L activation. So here’s what I mean by that. Let’s say you take that layer L activation. So this is going to be nh by nw by nc block of activations, and we’re going to ask how correlated are the activations across different channels. So to explain what I mean by this may be slightly cryptic phrase, let’s take this block of activations and let me shade the different channels by a different colors. So in this below example, we have say five channels and which is why I have five shades of color here. In practice, of course, in neural network we usually have a lot more channels than five, but using just five makes it drawing easier. But to capture the style of an image, what you’re going to do is the following. <strong>Let’s look at the first two channels. Let’s see for the red channel and the yellow channel and say how correlated are activations in these first two channels. So, for example, in the lower right hand corner, you have some activation in the first channel and some activation in the second channel. So that gives you a pair of numbers. And what you do is look at different positions across this block of activations and just look at those two pairs of numbers, one in the first channel, the red channel, one in the yellow channel, the second channel. And you just look at these two pairs of numbers and see when you look across all of these positions, all of these nh by nw positions, how correlated are these two numbers. So, why does this capture style</strong>? </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/30.png" alt=""><br>Let’s look another example. Here’s one of the visualizations from the earlier video. This comes from again the paper by Matthew Zeiler and Rob Fergus that I have reference earlier. <strong>And let’s say for the sake of arguments, that the red neuron corresponds to, and let’s say for the sake of arguments, that the red channel corresponds to this neurons (at the second grid cell which is circled in red color), so we’re trying to figure out if there’s this little vertical texture in a particular position in the nh and let’s say that this second channel, this yellow second channel corresponds to this neuron (at the 4th grid cell which is circled in yellow color), which is vaguely looking for orange colored patches. What does it mean for these two channels to be highly correlated? Well, if they’re highly correlated what that means is whatever part of the image has this type of subtle vertical texture, that part of the image will probably have these orange-ish tint. And what does it mean for them to be uncorrelated? Well, it means that whenever there is this vertical texture, it’s probably won’t have that orange-ish tint. And so the correlation tells you which of these high level texture components tend to occur or not occur together in part of an image and that’s the degree of correlation that gives you one way of measuring how often these different high level features, such as vertical texture or this orange tint or other things as well, how often they occur and how often they occur together and don’t occur together in different parts of an image. And so, if we use the degree of correlation between channels as a measure of the style, then what you can do is measure the degree to which in your generated image, this first channel is correlated or uncorrelated with the second channel and that will tell you in the generated image how often this type of vertical texture occurs or doesn’t occur with this orange-ish tint and this gives you a measure of how similar is the style of the generated image to the style of the input style image</strong>. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/31.png" alt=""><br>So let’s now formalize this intuition. So what you can to do is given an image computes something called <strong>a style matrix</strong>, which will measure all those correlations we talks about on the last slide. So, more formally, let’s let a superscript l, subscript i, j,k denote the activation at position i,j,k in hidden layer l. So i indexes into the height, j indexes into the width, and k indexes across the different channels. So, in the previous slide, we had five channels that k will index across those five channels. So what the style matrix will do is you’re going to compute a matrix clauses G superscript square bracketed l. This is going to be an nc by nc dimensional matrix, so it’d be a square matrix. Remember you have nc channels and so you have an nc by nc dimensional matrix in order to measure how correlated each pair of them is. <strong>So particular G, l, k, k prime will measure how correlated are the activations in channel k compared to the activations in channel k prime. Well here, k and k prime will range from 1 through nc, the number of channels they’re all up in that layer.</strong> So more formally, the way you compute G, l and I’m just going to write down the formula for computing one elements. So the k, k prime elements of this. This is going to be sum of a i, sum of a j, of deactivation and that layer i, j, k times the activation at i, j, k prime. So, here, remember i and j index across to a different positions in the block, indexes over the height and width. So i is the sum from one to nh and j is a sum from one to nw and k here and k prime index over the channel so k and k prime range from one to the total number of channels in that layer of the neural network. <strong>So all this is doing is summing over the different positions that the image over the height and width and just multiplying the activations together of the channels k and k prime and that’s the definition of G,k,k prime. And you do this for every value of k and k prime to compute this matrix G, also called the style matrix.</strong> And so notice that if both of these activations tend to be large together, then G, k, k prime will be large, whereas if they are uncorrelated then g,k, k prime might be small. And technically, I’ve been using the term correlation to convey intuition but this is actually the <strong>unnormalized cross-variance</strong> of the areas because we’re not subtracting out the mean and this is just multiplied by these elements directly. So this is how you compute the style of an image. And you’d actually do this for both the style image s,n for the generated image G. So just to distinguish that this is the style image, maybe let me add a round bracket S there, just to denote that this is the style image for the image S and those are the activations on the image S. And what you do is then compute the same thing for the generated image. So it’s really the same thing summarized sum of a j, a, i, j, k, l, a, i, j,k,l and the summation indices are the same. Let’s follow this and you want to just denote this is for the generated image, I’ll just put the round brackets G there. So, now, you have two matrices they capture what is the style with the image s and what is the style of the image G. And, by the way, we’ve been using the alphabet capital G to denote these matrices. In linear algebra, these are also called the <a href="https://en.wikipedia.org/wiki/Gramian_matrix" target="_blank" rel="noopener">Gram matrix</a> of these in called grand matrices but <strong>in this video, I’m just going to use the term style matrix because this term Gram matrix that most of these using capital G to denote these matrices</strong>. Finally, the cost function, the style cost function. If you’re doing this on layer l between s and G, you can now define that to be just the difference between these two matrices, G l, G square and these are matrices. So just take it from the previous one. This is just the sum of squares of the element wise differences between these two matrices and just divides this out this is going to be sum over k, sum over k prime of these differences of s, k, k prime minus G l, G, k, k prime and then the sum of square of the elements. The authors actually used this for the normalization constants two times of nh, nw, in that layer, nc in that layer and I’ll square this and you can put this up here as well. But a normalization constant doesn’t matter that much because this causes multiplied by some hyperparameter b anyway. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/32.png" alt=""><br>So just to finish up, this is the style cost function defined using layer l and as you saw on the previous slide, this is basically the Frobenius norm between the two star matrices computed on the image s and on the image G Frobenius on squared and never by the just low normalization constants, which isn’t that important. <strong>And, finally, it turns out that you get more visually pleasing results if you use the style cost function from multiple different layers. So, the overall style cost function, you can define as sum over all the different layers of the style cost function for that layer. We should define them all weighted by some set of parameters, by some set of additional hyperparameters, which we’ll denote as lambda l here. So what it does is allows you to use different layers in a neural network. Well of the early ones, which measure relatively simpler low level features like edges as well as some later layers, which measure high level features and cause a neural network to take both low level and high level correlations into account when computing style.</strong> And, in the following exercise, you gain more intuition about what might be reasonable choices for this type of parameter lambda as well. And so just to wrap this up, you can now define the overall cost function as alpha times the content cost between c and G plus beta times the style cost between s and G and then just create in the sense or a more sophisticated optimization algorithm if you want in order to try to find an image G that normalize, that tries to minimize this cost function j of G. And if you do that, you can generate pretty good looking neural artistic and if you do that you’ll be able to generate some pretty nice novel artwork. </p>
<p>So that’s it for neural style transfer and I hope you have fun implementing it in this week’s printing exercise. <strong>Before wrapping up this week, there’s just one last thing I want to share of you, which is how to do convolutions over 1D or 3D data rather than over only 2D images</strong>. Let’s go into the last video.</p>
<h3 id="06-1d-and-3d-generalizations"><a href="#06-1d-and-3d-generalizations" class="headerlink" title="06_1d-and-3d-generalizations"></a>06_1d-and-3d-generalizations</h3><p>You have learned a lot about ConvNets, everything ranging from the architecture of the ConvNet to how to use it for image recognition, to object detection, to face recognition and neural-style transfer. And even though most of the discussion has focused on images, on sort of 2D data, because images are so pervasive. It turns out that many of the ideas you’ve learned about also apply, not just to 2D images but also to 1D data as well as to 3D data. Let’s take a look. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/convolutional-neural-networks/lectures/week4/images/33.png" alt=""><br>In the first week of this course, you learned about the 2D convolution, where you might input a 14 x 14 image and convolve that with a 5 x 5 filter. And you saw how 14 x 14 convolved with 5 x 5, this gives you a 10 x 10 output. And if you have multiple channels, maybe those 14 x 14 x 3, then it would be 5 x 5 that matches the same 3. And then if you have multiple filters, say 16 filters, you end up with 10 x 10 x 16. It turns out that a similar idea can be applied to 1D data as well. For example, on the left is <strong>an EKG signa</strong>l, also called <strong>an electrocardioagram</strong>. Basically if you place an electrode over your chest, this measures the little voltages that vary across your chest as your heart beats. Because the little electric waves generated by your heart’s beating can be measured with a pair of electrodes. And so this is an EKG of someone’s heart beating. And so <strong>each of these peaks corresponds to one heartbeat. So if you want to use EKG signals to make medical diagnoses, for example, then you would have 1D data because what EKG data is, is it’s a time series showing the voltage at each instant in time</strong>. So rather than a 14 x 14 dimensional input, <strong>maybe you just have a 14 dimensional input. And in that case, you might want to convolve this with a 1 dimensional filter</strong>. So rather than the 5 by 5, <strong>you just have 5 dimensional filter</strong>. So with 2D data what a convolution will allow you to do was to take the same 5 x 5 feature detector and apply it across at different positions throughout the image. And that’s how you wound up with your 10 x 10 output. What a 1D filter allows you to do is take your 5 dimensional filter and similarly apply that in lots of different positions throughout this 1D signal. And so <strong>if you apply this convolution, what you find is that a 14 dimensional thing convolved with this 5 dimensional thing, this would give you a 10 dimensional output. And again, if you have multiple channels, you might have in this case you can use just 1 channel, if you have 1 lead or 1 electrode for EKG, so times 5 x 1. And if you have 16 filters, maybe end up with 10 x 16 over there, and this could be one layer of your ConvNet. And then for the next layer of your ConvNet, if you input a 10 x 16 dimensional input and you might convolve that with a 5 dimensional filter again. Then these have 16 channels, so that has a match. And we have 32 filters, then the output of another layer would be 6 x 32</strong>, if you have 32 filters, right? And the analogy to the the 2D data, this is similar to all of the 10 x 10 x 16 data and convolve it with a 5 x 5 x 16, and that has to match. That will give you a 6 by 6 dimensional output, and you have 32 filters, that’s where the 32 comes from. So all of these ideas apply also to 1D data, where you can have the same feature detector, such as this, apply to a variety of positions. For example, to detect the different heartbeats in an EKG signal. But to use the same set of features to detect the heartbeats even at different positions along these time series, and so ConvNet can be used even on 1D data. For along with 1D data applications, you actually use a recurrent neural network, which you learn about in the next course. But some people can also try using ConvNets in these problems. And in the next course on sequence models, which we will talk about recurring neural networks and LCM and other models like that. We’ll talk about the pros and cons of using 1D ConvNets versus some of those other models that are explicitly designed to sequenced data. So that’s the generalization from 2D to 1D. </p>
<p><img src="I://imgs/deeplearning.ai/convolutional-neural-networks/04_special-applications-face-recognition-neural-style-transfer/2.gif" alt=""><br>How about 3D data? Well, what is three dimensional data? It is that, instead of having a 1D list of numbers or a 2D matrix of numbers, you now have a 3D block, a three dimensional input volume of numbers. So here’s the example of that which is if you take a <strong>CT scan</strong>, this is a type of <strong>X-ray scan</strong> that gives a three dimensional model of your body. But what a CT scan does is it takes different slices through your body. So as you scan through a CT scan which I’m doing here, you can look at different slices of the human torso to see how they look and so this data is fundamentally three dimensional. And one way to think of this data is if your data now has some height, some width, and then also some depth. Where this is the different slices through this volume, are the different slices through the torso. </p>
<p>So if you want to apply a ConvNet to detect features in this three dimensional CAT scan or CT scan, then you can generalize the ideas from the first slide to three dimensional convolutions as well. So if you have a 3D volume, and for the sake of simplicity let’s say is 14 x 14 x 14 and so this is the height, width, and depth of the input CT scan. And again, just like images they’ll all have to be square, a 3D volume doesn’t have to be a perfect cube as well. So the height and width of a image can be different, and in the same way the height and width and the depth of a CT scan can be different. But I’m just using 14 x 14 x 14 here to simplify the discussion. And if you convolve this with a now a 5 x 5 x 5 filter, so you’re filters now are also three dimensional then this would give you a 10 x 10 x 10 volume. And technically, you could also have by 1, if this is the number of channels. So this is just a 3D volume, but your data can also have different numbers of channels, then this would be times 1 as well. Because the number of channels here and the number of channels here has to match. And then if you have 16 filters did a 5 x 5 x 5 x 1 then the next output will be a 10 x 10 x 10 x 16. So this could be one layer of your ConvNet over 3D data, and if the next layer of the ConvNet convolves this again with a 5 x 5 x 5 x 16 dimensional filter. So this number of channels has to match data as usual, and if you have 32 filters then similar to what you saw was ConvNet of the images. Now you’ll end up with a 6 x 6 x 6 volume across 32 channels. So 3D data can also be learned on, sort of directly using a three dimensional ConvNet. And what these filters do is really detect features across your 3D data, CAT scans, medical scans as one example of 3D volumes. But another example of data, you could treat as a 3D volume would be movie data, where the different slices could be different slices in time through a movie. And you could use this to detect motion or people taking actions in movies. </p>
<p>So that’s it on generalization of ConvNets from 2D data to also 1D as well as 3D data. Image data is so pervasive that the vast majority of ConvNets are on 2D data, on image data, but I hope that these other models will be helpful to you as well. So this is it, this is the last video of this week and the last video of this course on ConvNets. You’ve learned a lot about ConvNets and I hope you find many of these ideas useful for your future work. So congratulations on finishing these videos. I hope you enjoyed this week’s exercise and I look forward also to seeing you in the next course on sequence models.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Karan"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Karan</p>
  <div class="site-description" itemprop="description">Refuse to Fall</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">91</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yourname" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yourname@gmail.com" title="E-Mail → mailto:yourname@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://youtube.com/yourname" title="YouTube → https:&#x2F;&#x2F;youtube.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/yourname" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i></a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Karan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">2.2m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">33:59</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


    </div>
</body>
</html>
