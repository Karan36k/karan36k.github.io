<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">

<script>
    (function(){
        if(''){
                         If (prompt('Please enter the article password') !== ''){
                                 Alert('Password error!');
                history.back();
            }
        }
    })();
</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"snakecoding.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":true,"sidebar":{"position":"left","display":"post","padding":20,"offset":15,"onmobile":false},"copycode":{"enable":true,"show_result":"flat","style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":false},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Refuse to Fall">
<meta property="og:type" content="website">
<meta property="og:title" content="Machine Learning">
<meta property="og:url" content="https://snakecoding.com/page/16/index.html">
<meta property="og:site_name" content="Machine Learning">
<meta property="og:description" content="Refuse to Fall">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Karan">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://snakecoding.com/page/16/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Machine Learning</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Machine Learning" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Machine Learning</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Data Science</p>
      <a>
        <img class="custom-logo-image" src="/images/custom-logo.jpg" alt="Machine Learning">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">15</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">6</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">87</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="#" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/27/mean_and_variance_of_a_piecewise_constant_PDF%2015-47-55-618/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/27/mean_and_variance_of_a_piecewise_constant_PDF%2015-47-55-618/" class="post-title-link" itemprop="url">Classic Excerpts-Mean and Variance of Piecewise Constant Probability Density Functions</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-27 20:16:00" itemprop="dateCreated datePublished" datetime="2017-08-27T20:16:00+05:30">2017-08-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:42" itemprop="dateModified" datetime="2020-04-09T16:34:42+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>1.8k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>2 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>This article is excerpted from [Introduction to probability, 2nd Edition] (<a href="http://www.athenasc.com/probbook.html" target="_blank" rel="noopener">http://www.athenasc.com/probbook.html</a>) Example 3.17 Mean and Variance of a Piecewise Constant PDF</p>
<p>Suppose a random variable $ X $ has a piecewise constant probability density function</p>
<p>$$ f_x (x) = \ cases {\ frac {1} {3}, &amp; if $ 0 \ le x \ le 1 $, \ \ frac {2} {3}, &amp; if $ 1 &lt;x \ le 2 $, \ 0, &amp; if otherwise} $$</p>
<p>! [Figure3.14_Piecewise_constant_PDF_for_Example3.17.png] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/mean_and_variance_of_a_piecewise-constant_PDF/2.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/mean_and_variance_of_a_piecewise-constant_PDF/2.png</a>)</p>
<p>Consider the event:</p>
<p>$$ A_1 = \ {\ text {X is in the first interval [0,1]} } $$</p>
<p>$$ A_2 = \ {\ text {X is in the second interval (1,2)} } $$</p>
<p>We get from the known probability density function:</p>
<p>$$ P (A_1) = \ int_ {0} ^ {1} f_X (x) dx = \ frac {1} {3}, \ quad P (A_2) = \ int_ {1} ^ {2} f_X (x ) dx = \ frac {2} {3} $$</p>
<p>Therefore, the conditional mean and the conditional second moment of $ X $ are easy to calculate because the related probability density functions $ PDF_S $: $ f_ {X | A_1} $ and $ f_ {X | A_2} $ are uniform, recall example 3.4 It is obtained that the mean value of the random variable uniformly distributed in the interval $ [a, b] $ is: $ \ frac {(a + b)} {2} $, and its second moment is $ \ frac {(a ^ 2 + ab + b ^ 2)} {3} $, so:</p>
<p>$$<br>\ begin {eqnarray}<br>E [X | A_1] &amp; = &amp; \ frac {1} {2}, \ quad E [X | A_2] &amp; = &amp; \ frac {3} {2} \<br>E [X ^ 2 | A_1] &amp; = &amp; \ frac {1} {3}, \ quad E [X ^ 2 | A_2] &amp; = &amp; \ frac {7} {3}<br>\ end {eqnarray}<br>$$</p>
<p>Use the total expectation theorem to get:<br>$$<br>\ begin {eqnarray}<br>E [X] &amp; = &amp; P (A_1) E [X | A_1] + P (A_2) E [X | A_2] &amp; = &amp; \ frac {1} {3} \ cdot \ frac {1} {2} + \ frac {2} {3} \ cdot \ frac {3} {2} &amp; = &amp; \ frac {7} {6} \<br>E [X ^ 2] &amp; = &amp; P (A_1) E [X ^ 2 | A_1] + P (A_2) E [X ^ 2 | A_2] &amp; = &amp; \ frac {1} {3} \ cdot \ frac { 1} {3} + \ frac {2} {3} \ cdot \ frac {7} {3} &amp; = &amp; \ frac {15} {9}<br>\ end {eqnarray}<br>$$<br>Then you can get the variance:</p>
<p>$$ var (x) = E [X ^ 2]-(E [X]) ^ 2 = \ frac {15} {9}-\ frac {49} {36} = \ frac {11} {36} $ $</p>
<p>** Note: ** The method for calculating the mean and variance is easy to generalize to a multi-segment constant probability density function.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/27/normal_random_variables/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/27/normal_random_variables/" class="post-title-link" itemprop="url">Classic Excerpt-Normal Random Variables</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-27 20:16:00" itemprop="dateCreated datePublished" datetime="2017-08-27T20:16:00+05:30">2017-08-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:39" itemprop="dateModified" datetime="2020-04-09T16:34:39+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>11k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>10 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>** Description **: The full text is taken from [Introduction to probability, 2nd Edition] (<a href="http://www.athenasc.com/probbook.html" target="_blank" rel="noopener">http://www.athenasc.com/probbook.html</a>) 3.3 normal random variables</p>
<h2 id="Normal-random-variables"><a href="#Normal-random-variables" class="headerlink" title="Normal random variables"></a>Normal random variables</h2><p>If the probability density of a continuous random variable $ X $ has the following form, then the random variable is called normal or Gaussian.<br>$$<br>f_X (x) = \ frac {1} {\ sqrt {2 \ pi} \ sigma} e ^ {\ frac {-(x- \ mu) ^ 2} {2 \ sigma ^ 2}}<br>$$<br>Among them, $ u $ and $ \ sigma $ are two parameters of the density function, and $ \ sigma $ must also be a positive number. It can be proved that $ f_X (x) $ satisfies the normalization condition of the following probability density function (see the exercises on theorems in this chapter):<br>$$<br>\ frac {1} {\ sqrt {2 \ pi} \ sigma} \ int _ {-\ infty} ^ {+ \ infty} e ^ {\ frac {-(x- \ mu) ^ 2} {2 \ sigma ^ 2}} dx = 1<br>$$<br>The figure below is the density function and distribution function of the normal distribution $ (\ mu = 1 \ text {and} \ sigma ^ 2 = 1) $.</p>
<p>! [A_normal_PDF_and_CDF_with_u = 1_and_sigmal ^ 2 = 1] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/normal-random-variable/1.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/normal-random-variable/1.png</a>)</p>
<p>It can be seen from the figure that the probability density function of a normal random variable is a symmetrical bell curve with respect to the mean $ \ mu $. When $ x $ leaves $ \ mu $, the term $ e ^ {\ frac {-(x- \ mu) ^ 2} {2 \ sigma ^ 2}} $ in the expression of the probability density function quickly decline. In the figure, the probability density function is very close to $ 0 $ outside the interval $ [-1,3] $.</p>
<p>The mean and variance of a normal random variable can be given by the following formula:<br>$$<br>E [X] = \ mu, \ quad var (X) = \ sigma ^ 2<br>$$<br>Since the probability density function of $ X $ is symmetric with respect to $ \ mu $, its mean can only be $ \ mu $. As for the formula of variance, one sentence is defined as:<br>$$<br>var (X) = \ frac {1} {\ sqrt {2 \ pi} \ sigma} \ int _ {-\ infty} ^ {+ \ infty} (x- \ mu) ^ 2e ^ {-\ frac {(x -\ mu) ^ 2} {2 \ sigma ^ 2}} dx<br>$$<br>Replacing the integral in the formula as an integral variable $ y = \ frac {(x- \ mu)} {\ sigma} $ and the distributed integral yields:<br>$$<br>\ begin {eqnarray}<br>var (X) &amp; = &amp; \ frac {\ sigma ^ 2} {\ sqrt {2 \ pi}} \ int _ {-\ infty} ^ {+ \ infty} y ^ 2e ^ {-\ frac {y ^ 2} {2}} dy \<br>&amp; = &amp; \ frac {\ sigma ^ 2} {\ sqrt {2 \ pi}} (-ye ^ {-\ frac {y ^ 2} {2}}) | ^ {+ \ infty} _ {-\ infty } + \ frac {\ sigma ^ 2} {\ sqrt {2 \ pi}} \ int _ {-\ infty} ^ {+ \ infty} e ^ {\ frac {y ^ 2} {2}} dy \<br>&amp; = &amp; \ frac {\ sigma ^ 2} {\ sqrt {2 \ pi}} \ int _ {-\ infty} ^ {+ \ infty} e ^ {-\ frac {y ^ 2} {2}} dy \ <br>&amp; = &amp; \ sigma ^ 2<br>\ end {eqnarray}<br>$$<br>The last equation above is due to<br>$$<br>\ frac {1} {\ sqrt {2 \ pi}} \ int _ {-\ infty} ^ {+ \ infty} e ^ {-\ frac {y ^ 2} {2}} dy = 1<br>$$<br>This formula happens to be the normalization condition of the probability density function of the normal random variable when $ \ mu = 0 $ and $ \ sigma ^ 2 = 1 $. The problem is proved in the problem 14 of this chapter. The screenshot is as follows:</p>
<p>! [the_normal_PDF_satisfies_the_normalization_property] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/normal-random-variable/2.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/normal-random-variable/2.png</a>)</p>
<p>Normal random variables have several important properties. The following properties are particularly important and will be discussed in Chapter 4<br>This is demonstrated in the first section of on Random Variables.</p>
<h3 id="The-normality-of-random-variables-remains-unchanged-under-linear-transformation"><a href="#The-normality-of-random-variables-remains-unchanged-under-linear-transformation" class="headerlink" title="The normality of random variables remains unchanged under linear transformation"></a>The normality of random variables remains unchanged under linear transformation</h3><p>Let $ X $ be a normal random variable, the mean of which is $ \ mu $ and the variance is $ \ sigma ^ 2 $. If $ a \ ne 0 $ and $ b $ are two constants, then the random variable<br>$$<br>Y = aX + b<br>$$<br>It is still a normal random variable, and its mean and variance are given by the following formula:<br>$$<br>E [Y] = a \ mu + b, \ quad var (Y) = a ^ 2 \ sigma ^ 2<br>$$</p>
<h2 id="Standard-normal-random-variables"><a href="#Standard-normal-random-variables" class="headerlink" title="Standard normal random variables"></a>Standard normal random variables</h2><p>Suppose the expectation of the normal random variable $ Y $ is $ 0 $ and the variance is $ 1 $, then $ Y $ is called the standard normal random variable. Let $ \ Phi $ be its CDF:<br>$$<br>\ Phi (y) = P (Y \ le y) = P (Y &lt;y) = \ frac {1} {\ sqrt {2 \ pi}} \ int _ {-\ infty} ^ {y} e ^ {\ frac {-t ^ 2} {2}} dt<br>$$<br>It is usually listed as a table-the standard normal cumulative distribution table (see the table below), which is an important tool for calculating the probability of normal random variables. Each item of the standard normal table provides the value of $ \ Phi (y) = P (Y \ le y) $, where $ Y $ is a normal random variable, and in this table $ y \ in [0,4.09 ] $. How to use this table? For example, to find the value of $ \ Phi (1.71) $, look at the row where $ 1.7 $ is located and the column where $ 0.01 $ is located, and you get $ \ Phi (1.71) = 0.95637 $.</p>
<p>Note that the following table only lists the value of \ Phi (y) $ when $ y&gt; 0, the symmetry of the probability density function of the standard normal random variable can be used, and $ \ Phi (y ) The value of $ is derived. E.g:<br>$$<br>\ begin {eqnarray}<br>\ Phi (-0.5) &amp; = &amp; P (Y \ le -0.5) = P (Y \ ge 0.5) = 1-P (Y &lt;0.5) \<br>&amp; = &amp; 1- \ Phi (0.5) = 1-0.69146 = 0.30854<br>\ end {eqnarray}<br>$$<br>Expandable<br>$$<br>\ forall \ y&gt; 0, \ Phi (-y) = 1- \ Phi (y)<br>$$</p>
<table>
<thead>
<tr>
<th align="center">y</th>
<th>+0.00</th>
<th>+0.01</th>
<th>+0.02</th>
<th>+0.03</th>
<th>+0.04</th>
<th>+0.05</th>
<th>+0.06</th>
<th>+0.07</th>
<th>+0.08</th>
<th>+0.09</th>
</tr>
</thead>
<tbody><tr>
<td align="center">0.0</td>
<td>0.50000</td>
<td>0.50399</td>
<td>0.50798</td>
<td>0.51197</td>
<td>0.51595</td>
<td>0.51994</td>
<td>0.52392</td>
<td>0.52790</td>
<td>0.53188</td>
<td>0.53586</td>
</tr>
<tr>
<td align="center">0.1</td>
<td>0.53983</td>
<td>0.54380</td>
<td>0.54776</td>
<td>0.55172</td>
<td>0.55567</td>
<td>0.55966</td>
<td>0.56360</td>
<td>0.56749</td>
<td>0.57142</td>
<td></td>
</tr>
<tr>
<td align="center">0.2</td>
<td>0.57926</td>
<td>0.58317</td>
<td>0.58706</td>
<td>0.59095</td>
<td>0.59483</td>
<td>0.59871</td>
<td>0.60257</td>
<td>0.60642</td>
<td>0.61026</td>
<td></td>
</tr>
<tr>
<td align="center">0.3</td>
<td>0.61791</td>
<td>0.62172</td>
<td>0.62552</td>
<td>0.62930</td>
<td>0.63307</td>
<td>0.63683</td>
<td>0.64058</td>
<td>0.64431</td>
<td>0.64803</td>
<td>0.65173</td>
</tr>
<tr>
<td align="center">0.4</td>
<td>0.65542</td>
<td>0.65910</td>
<td>0.66276</td>
<td>0.66640</td>
<td>0.67003</td>
<td>0.67364</td>
<td>0.67724</td>
<td>0.68082</td>
<td>0.68439</td>
<td></td>
</tr>
<tr>
<td align="center">0.5</td>
<td>0.69146</td>
<td>0.69497</td>
<td>0.69847</td>
<td>0.70194</td>
<td>0.70540</td>
<td>0.70884</td>
<td>0.71226</td>
<td>0.71566</td>
<td>0.71904</td>
<td>0.72240</td>
</tr>
<tr>
<td align="center">0.6</td>
<td>0.72575</td>
<td>0.72907</td>
<td>0.73237</td>
<td>0.73565</td>
<td>0.73891</td>
<td>0.74215</td>
<td>0.74537</td>
<td>0.74857</td>
<td>0.75175</td>
<td></td>
</tr>
<tr>
<td align="center">0.7</td>
<td>0.75804</td>
<td>0.76115</td>
<td>0.76424</td>
<td>0.76730</td>
<td>0.77035</td>
<td>0.77337</td>
<td>0.77637</td>
<td>0.77935</td>
<td>0.78230</td>
<td>0.78524</td>
</tr>
<tr>
<td align="center">0.8</td>
<td>0.78814</td>
<td>0.79103</td>
<td>0.79389</td>
<td>0.79673</td>
<td>0.79955</td>
<td>0.80234</td>
<td>0.80511</td>
<td>0.80785</td>
<td>0.81057</td>
<td>0.81327</td>
</tr>
<tr>
<td align="center">0.9</td>
<td>0.81594</td>
<td>0.81859</td>
<td>0.82121</td>
<td>0.82381</td>
<td>0.82639</td>
<td>0.82894</td>
<td>0.83147</td>
<td>0.83398</td>
<td>0.83646</td>
<td>0.83891</td>
</tr>
<tr>
<td align="center">1.0</td>
<td>0.84134</td>
<td>0.84375</td>
<td>0.84614</td>
<td>0.84849</td>
<td>0.85083</td>
<td>0.85314</td>
<td>0.85543</td>
<td>0.85769</td>
<td>0.85993</td>
<td></td>
</tr>
<tr>
<td align="center">1.1</td>
<td>0.86433</td>
<td>0.86650</td>
<td>0.86864</td>
<td>0.87076</td>
<td>0.87286</td>
<td>0.87493</td>
<td>​​0.87698</td>
<td>0.87900</td>
<td>0.88100</td>
<td></td>
</tr>
<tr>
<td align="center">1.2</td>
<td>0.88493</td>
<td>​​0.88686</td>
<td>0.88877</td>
<td>0.89065</td>
<td>0.89251</td>
<td>0.89435</td>
<td>0.89617</td>
<td>0.89796</td>
<td>0.89973</td>
<td></td>
</tr>
<tr>
<td align="center">1.3</td>
<td>0.90320</td>
<td>0.90490</td>
<td>0.90658</td>
<td>0.90824</td>
<td>0.90988</td>
<td>0.91149</td>
<td>0.91308</td>
<td>0.91466</td>
<td>0.91621</td>
<td>0.91774</td>
</tr>
<tr>
<td align="center">1.4</td>
<td>0.91924</td>
<td>0.92073</td>
<td>0.92220</td>
<td>0.92364</td>
<td>0.92507</td>
<td>0.92647</td>
<td>0.92785</td>
<td>0.92922</td>
<td>0.93056</td>
<td>0.93189</td>
</tr>
<tr>
<td align="center">1.5</td>
<td>0.93319</td>
<td>0.93448</td>
<td>0.93574</td>
<td>0.93699</td>
<td>0.93822</td>
<td>0.93943</td>
<td>0.94062</td>
<td>0.94179</td>
<td>0.94295</td>
<td>0.94408</td>
</tr>
<tr>
<td align="center">1.6</td>
<td>0.94520</td>
<td>0.94630</td>
<td>0.94738</td>
<td>0.94845</td>
<td>0.94950</td>
<td>0.95053</td>
<td>0.95154</td>
<td>0.95254</td>
<td>0.95352</td>
<td>0.95449</td>
</tr>
<tr>
<td align="center">1.7</td>
<td>0.95543</td>
<td>0.95637</td>
<td>0.95728</td>
<td>0.95818</td>
<td>0.95907</td>
<td>0.95994</td>
<td>0.96080</td>
<td>0.96164</td>
<td>0.96246</td>
<td>0.96327</td>
</tr>
<tr>
<td align="center">1.8</td>
<td>0.96407</td>
<td>0.96485</td>
<td>0.96562</td>
<td>0.96638</td>
<td>0.96712</td>
<td>0.96784</td>
<td>0.96856</td>
<td>0.96926</td>
<td>0.96995</td>
<td>0.97062</td>
</tr>
<tr>
<td align="center">0.99128</td>
<td>0.97193</td>
<td>0.97257</td>
<td>0.97320</td>
<td>0.97381</td>
<td>0.97441</td>
<td>0.97500</td>
<td>0.97558</td>
<td>0.97615</td>
<td>0.97670</td>
<td></td>
</tr>
<tr>
<td align="center">2.0</td>
<td>0.97725</td>
<td>0.97778</td>
<td>0.97831</td>
<td>0.97882</td>
<td>0.97932</td>
<td>0.97982</td>
<td>0.98030</td>
<td>0.98077</td>
<td>0.98124</td>
<td>0.98169</td>
</tr>
<tr>
<td align="center">2.1</td>
<td>0.98214</td>
<td>0.98257</td>
<td>0.98300</td>
<td>0.98341</td>
<td>0.98382</td>
<td>0.98422</td>
<td>0.98461</td>
<td>0.98500</td>
<td>0.98537</td>
<td></td>
</tr>
<tr>
<td align="center">2.2</td>
<td>0.98610</td>
<td>0.98645</td>
<td>0.98679</td>
<td>0.98713</td>
<td>0.98745</td>
<td>0.98778</td>
<td>0.98809</td>
<td>0.98840</td>
<td>0.98870</td>
<td></td>
</tr>
<tr>
<td align="center">2.3</td>
<td>0.98928</td>
<td>0.98956</td>
<td>0.98983</td>
<td>0.99010</td>
<td>0.99036</td>
<td>0.99061</td>
<td>0.99086</td>
<td>0.99111</td>
<td>0.99134</td>
<td>0.99158</td>
</tr>
<tr>
<td align="center">2.4</td>
<td>0.99180</td>
<td>0.99202</td>
<td>0.99224</td>
<td>0.99245</td>
<td>0.99266</td>
<td>0.99286</td>
<td>0.99305</td>
<td>0.99324</td>
<td>0.99343</td>
<td>0.99361</td>
</tr>
<tr>
<td align="center">2.5</td>
<td>0.99379</td>
<td>0.99396</td>
<td>0.99413</td>
<td>0.99430</td>
<td>0.99446</td>
<td>0.99461</td>
<td>0.99477</td>
<td>0.99492</td>
<td>0.99506</td>
<td>0.99520</td>
</tr>
<tr>
<td align="center">2.6</td>
<td>0.99534</td>
<td>0.99547</td>
<td>0.99560</td>
<td>0.99573</td>
<td>0.99585</td>
<td>0.99598</td>
<td>0.99609</td>
<td>0.99621</td>
<td>0.99632</td>
<td>0.99643</td>
</tr>
<tr>
<td align="center">2.7</td>
<td>0.99653</td>
<td>0.99664</td>
<td>0.99674</td>
<td>0.99683</td>
<td>0.99693</td>
<td>0.99702</td>
<td>0.99711</td>
<td>0.99720</td>
<td>0.99728</td>
<td>0.99736</td>
</tr>
<tr>
<td align="center">2.8</td>
<td>0.99744</td>
<td>0.99752</td>
<td>0.99760</td>
<td>0.99767</td>
<td>0.99774</td>
<td>0.99781</td>
<td>0.99788</td>
<td>0.99795</td>
<td>0.99801</td>
<td>0.99807</td>
</tr>
<tr>
<td align="center">2.9</td>
<td>0.99813</td>
<td>0.99819</td>
<td>0.99825</td>
<td>0.99831</td>
<td>0.99836</td>
<td>0.99841</td>
<td>0.99846</td>
<td>0.99851</td>
<td>0.99856</td>
<td>0.99861</td>
</tr>
<tr>
<td align="center">3.0</td>
<td>0.99865</td>
<td>0.99869</td>
<td>0.99874</td>
<td>0.99878</td>
<td>0.99882</td>
<td>0.99886</td>
<td>0.99889</td>
<td>0.99893</td>
<td>0.99896</td>
<td>0.99900</td>
</tr>
<tr>
<td align="center">3.1</td>
<td>0.99903</td>
<td>0.99906</td>
<td>0.99910</td>
<td>0.99913</td>
<td>0.99916</td>
<td>0.99918</td>
<td>0.99921</td>
<td>0.99924</td>
<td>0.99926</td>
<td>0.99929</td>
</tr>
<tr>
<td align="center">3.2</td>
<td>0.99931</td>
<td>0.99934</td>
<td>0.99936</td>
<td>0.99938</td>
<td>0.99940</td>
<td>0.99942</td>
<td>0.99944</td>
<td>0.99946</td>
<td>0.99948</td>
<td>0.99950</td>
</tr>
<tr>
<td align="center">3.3</td>
<td>0.99952</td>
<td>0.99953</td>
<td>0.99955</td>
<td>0.99957</td>
<td>0.99958</td>
<td>0.99960</td>
<td>0.99961</td>
<td>0.99962</td>
<td>0.99964</td>
<td>0.99965</td>
</tr>
<tr>
<td align="center">3.4</td>
<td>0.99966</td>
<td>0.99968</td>
<td>0.99969</td>
<td>0.99970</td>
<td>0.99971</td>
<td>0.99972</td>
<td>0.99973</td>
<td>0.99974</td>
<td>0.99975</td>
<td>0.99976</td>
</tr>
<tr>
<td align="center">3.5</td>
<td>0.99977</td>
<td>0.99978</td>
<td>0.99978</td>
<td>0.99979</td>
<td>0.99980</td>
<td>0.99981</td>
<td>0.99981</td>
<td>0.99982</td>
<td>0.99983</td>
<td>0.99983</td>
</tr>
<tr>
<td align="center">3.6</td>
<td>0.99984</td>
<td>0.99985</td>
<td>0.99985</td>
<td>0.99986</td>
<td>0.99986</td>
<td>0.99987</td>
<td>0.99987</td>
<td>0.99988</td>
<td>0.99988</td>
<td>0.99989</td>
</tr>
<tr>
<td align="center">3.7</td>
<td>0.99989</td>
<td>0.99990</td>
<td>0.99990</td>
<td>0.99990</td>
<td>0.99991</td>
<td>0.99991</td>
<td>0.99992</td>
<td>0.99992</td>
<td>0.99992</td>
<td>0.99992</td>
</tr>
<tr>
<td align="center">3.8</td>
<td>0.99993</td>
<td>0.99993</td>
<td>0.99993</td>
<td>0.99994</td>
<td>0.99994</td>
<td>0.99994</td>
<td>0.99994</td>
<td>0.99995</td>
<td>0.99995</td>
<td>0.99995</td>
</tr>
<tr>
<td align="center">3.9</td>
<td>0.99995</td>
<td>0.99995</td>
<td>0.99996</td>
<td>0.99996</td>
<td>0.99996</td>
<td>0.99996</td>
<td>0.99996</td>
<td>0.99996</td>
<td>0.99997</td>
<td>0.99997</td>
</tr>
<tr>
<td align="center">4.0</td>
<td>0.99997</td>
<td>0.99997</td>
<td>0.99997</td>
<td>0.99997</td>
<td>0.99997</td>
<td>0.99997</td>
<td>0.99998</td>
<td>0.99998</td>
<td>0.99998</td>
<td>0.99998</td>
</tr>
</tbody></table>
<p>Now use $ X $ to represent a normal random variable with a mean of $ \ mu $ and a variance of $ \ sigma ^ 2 $. Standardize $ X $ (“standardize”) by defining a new random variable $ Y $:<br>$$<br>Y = \ frac {X- \ mu} {\ sigma}<br>$$<br>Because $ Y $ is a linear function of $ X $, $ Y $ is also a normal random variable. and<br>$$<br>E [Y] = \ frac {E [X] -u} {\ sigma} = 0, \ quad var (Y) = \ frac {var (X)} {\ sigma ^ 2} = 1<br>$$<br>Therefore, $ Y $ is a standard normal random variable. This fact allows us to redefine the event represented by $ X $ with $ Y $, and then use the standard normal table to calculate.</p>
<h4 id="Example-of-using-normal-distribution-table"><a href="#Example-of-using-normal-distribution-table" class="headerlink" title="Example of using normal distribution table"></a>Example of using normal distribution table</h4><p>The annual snowfall in a certain area is a normal random variable, the expectation is $ \ mu = 60 $ inches, and the standard deviation is $ \ sigma = 20 $. What is the probability that the snowfall will be at least $ 80 $ inches this year?</p>
<p>Let $ X $ be the annual snowfall, so that<br>$$<br>Y = \ frac {X- \ mu} {\ sigma} = \ frac {X-60} {20}<br>$$<br>Obviously $ Y $ is a standard normal random variable.<br>$$<br>P (X \ ge 80) = P (\ frac {X-60} {20} \ ge \ frac {80-60} {20}) = P (Y \ ge \ frac {80-60} {20}) = P (Y \ ge 1) = 1- \ Phi (1)<br>$$<br>Where $ \ Phi $ is the standard normal cumulative distribution function. Obtained by querying the above table: $ \ Phi (1) = 0.84134 $, so<br>$$<br>P (X \ ge 80) = 1- \ Phi (1) = 0.15866<br>$$<br>Promoting the method in this example, we get the following:</p>
<h3 id="Calculation-of-the-cumulative-distribution-function-of-normal-random-variables"><a href="#Calculation-of-the-cumulative-distribution-function-of-normal-random-variables" class="headerlink" title="Calculation of the cumulative distribution function of normal random variables"></a>Calculation of the cumulative distribution function of normal random variables</h3><p>For a normal random variable $ X $ with a mean of $ \ mu $ and a variance of $ \ sigma ^ 2 $, use the following steps:</p>
<ol>
<li><p>Normalized $ X $: First subtract $ \ mu $ and then divide by $ \ sigma $ to obtain the standard random variable $ Y $.</p>
</li>
<li><p>Read the cumulative distribution function value from the standard normal table:<br> $$<br> P (X \ le x) = P (\ frac {X- \ mu} {\ sigma} \ le \ frac {x- \ mu} {\ sigma}) = P (Y \ le \ frac {x- \ mu } {\ sigma}) = \ Phi (\ frac {x- \ mu} {\ sigma})<br> $$<br> Normal random variables are often used in signal processing and communication engineering to model noise and signal distortion.</p>
</li>
</ol>
<h4 id="Example-3-8-Signal-detection"><a href="#Example-3-8-Signal-detection" class="headerlink" title="Example 3.8 Signal detection"></a>Example 3.8 Signal detection</h4><p>Binary information is transmitted with the signal $ s $. This information is either $ -1 $ and $ + 1 $. The signal will be accompanied by some noise during the channel transmission. The noise satisfies the normal distribution with a mean value of $ \ mu = 0 $ and a variance of $ \ sigma ^ 2 $. The receiver will receive a signal mixed with noise, if the received value is less than $ 0 $, then the signal is considered to be $ -1 $, if the received value is greater than $ 0 $, then the received signal is considered to be $ + 1 $. How big is the error of this judgment method?</p>
<p>The error only appears in the following two cases:</p>
<ol>
<li>The actual transmitted signal is $ -1 $, but the value of the noise variable $ N $ is at least $ 1 $, so $ s + N = -1 + N \ ge 0 $. </li>
<li>The actual transmitted signal is $ + 1 $, but the value of the noise variable $ N $ is less than $ -1 $. Therefore $ s + N = 1 + N &lt;0 $.</li>
</ol>
<p>! [Figure_3.11_The_signal_detection] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/normal-random-variable/3.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/normal-random-variable/3.png</a>)</p>
<p>Therefore, the probability of error in this judgment method in case 1 is:<br>$$<br>\ begin {eqnarray}<br>P (N \ ge 1) &amp; = &amp; 1-P (N &lt;1) = 1-P (N &lt;1) = 1-P (\ frac {N- \ mu} {\ sigma} &lt;\ frac {1- \ mu} {\ sigma}) \<br>&amp; = &amp; 1- \ Phi (\ frac {1- \ mu} {\ sigma}) \<br>&amp; = &amp; 1- \ Phi (\ frac {1} {\ sigma})<br>\ end {eqnarray}<br>$$<br>The probability of an error in the second case is obtained according to the symmetry of the normal distribution as in the previous case. $ \ Phi (\ frac {1} {\ sigma}) $ can be obtained from the normal distribution table. For example, for $ \ sigma = 1 $, $ \ Phi (\ frac {1} {\ sigma}) = \ Phi (1) = 0.84134 $, so the probability of error is $ 0.15864 $.</p>
<p>Normal random variables play an important role in a wide range of probabilistic models. The reason is that normal random variables can well simulate the superposition effect of many independent factors in physics, engineering and statistics. Mathematically, the key fact is that the distribution of the sum of a large number of independent and identically distributed random variables (not necessarily normal) obey the normal distribution, and this fact has nothing to do with the specific distribution of each sum. This fact is the famous central limit theorem, which will be explained in detail in Chapter 5 of this book.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/26/cumulative_distribution_function/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/26/cumulative_distribution_function/" class="post-title-link" itemprop="url">Classic Excerpt- [Cumulative] Distribution Function CDF</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-26 20:16:00" itemprop="dateCreated datePublished" datetime="2017-08-26T20:16:00+05:30">2017-08-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:49" itemprop="dateModified" datetime="2020-04-09T16:34:49+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>11k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>10 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Note: The full text is taken from [Introduction to probability, 2nd Edition] (<a href="http://www.athenasc.com/probbook.html" target="_blank" rel="noopener">http://www.athenasc.com/probbook.html</a>)</p>
<h2 id="Distribution-function"><a href="#Distribution-function" class="headerlink" title="Distribution function"></a>Distribution function</h2><p>We use the probability mass function PMF (Probability Mass Function) and the probability density function PDF (Probability Density Function) to characterize the value of the random variable $ X $. Now ** hope to use a unified mathematical tool to describe the law of random variables **.  </p>
<p>** Distribution function ** (denoted by CDF for short) can accomplish this task. The CDF of $ X $ is a function of $ x $. For each $ x $, $ F_X (x) $ is defined as $ P (X \ le x) $. In particular, when $ X $ is discrete or continuous:<br>$$<br>F_X (x) = P (X \ le x) = \ cases {\ sum \ limits_ {k \ le x} p_X (k), \ text {if $ X $ is discrete} \\ int _ {-\ infty } ^ {x} f_X (x) dt, \ text {if $ X $ is continuous}}<br>$$<br>** Distribution function is also called cumulative distribution function (cumulative distribution function) **, accumulation means that the probability of $ F_X (x) $ taking the value of $ X $ from $-\ infty \ rightarrow x $. </p>
<p>In a probabilistic model, random variables can be of different types, either discrete or continuous, or even neither discrete nor continuous. But no matter what type of random variable, they have a common feature, that is, they all have a distribution function, because $ \ {X \ le x } $ is a random event, and the probability of these events forms a probability distribution. From now on, all the probability of describing the event $ \ {X \ le x } $ through PMF \ PDF \ CDF will be called ** the probability law of the random variable $ X $ **. Therefore, the distribution sequence in the discrete case, the probability density function in the continuous case and the distribution function in the general case are the probability laws of the corresponding random variables.</p>
<p>The following figure gives some descriptions of the CDF of different discrete random variables and continuous random variables. From these images and the definition of CDF, some properties of CDF can be obtained.</p>
<p>! [Figure_3.6_CDFs_of_some_discrete_variables.png] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/cumulative-distribution-function/1.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/cumulative-distribution-function/1.png</a>)</p>
<p>The CDF of these discrete random variables in the above figure, the corresponding distribution function can be obtained by the probability mass function (PMF) of the random variable:<br>$$<br>F_X (x) = P (X \ le x) = \ sum \ limits_ {k \ le x} p_ {X} (k)<br>$$<br>This function is a step function with jumps at those points with positive probability. At the jump point, $ F_X (x) $ takes the larger value, that is, $ F_X (x) $ remains right continuous.</p>
<p>! [Figure_3.7_CDFs_of_some_continuous_random_variables.png] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/cumulative-distribution-function/2.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/cumulative-distribution-function/2.png</a>)</p>
<p>The $ CDF $ of these continuous random variables in the above figure. Through the probability density function (PDF) of random variables, the corresponding distribution function can be obtained:<br>$$<br>F_X (x) = P (X \ le x) = \ int _ {-\ infty} ^ {+ \ infty} f_X (t) dt<br>$$<br>The probability density function $ f_X (x) $ can be obtained by differentiating the CDF:<br>$$<br>f_X (x) = \ frac {dF_X (x)} {dx} (x)<br>$$<br>For continuous random variables, CDF is continuous</p>
<h2 id="The-nature-of-CDF"><a href="#The-nature-of-CDF" class="headerlink" title="The nature of CDF"></a>The nature of CDF</h2><p>Suppose the CDF of $ X $ $ F_X (x) $ is defined by:<br>$$<br>F_X (x) = P (X \ le x), \ forall x<br>$$<br>And $ F_X (x) $ has the following properties:</p>
<ol>
<li><p>$ F_X (x) $ is a monotonic non-subtractive function of $ x $: if $ x \ le y $, then $ F_X (x) \ le F_X (y) $.</p>
</li>
<li><p>When $ x \ rightarrow-\ infty $, then $ F_X (x) \ rightarrow 0 $, when $ x \ rightarrow + \ infty $, then $ F_X (x) \ rightarrow 1 $.</p>
</li>
<li><p>When $ X $ is a discrete random variable, $ F_X (x) $ is a step function.</p>
</li>
<li><p>When $ X $ is a continuous random variable, $ F_X (x) $ is a continuous function of $ x $.</p>
</li>
<li><p>When $ X $ is a discrete random variable and takes an integer value, the distribution function and probability mass function (PMF) can be summed or differenced to each other:<br> $$<br> F_X (k) = \ sum \ limits_ {i =-\ infty} ^ {k} p_X (i) \<br> p_X (k) = P (X \ le k) -P (X \ le k-1) = F_X (k) -F_X (k-1)<br> $$<br> Where $ k $ can be any integer. </p>
</li>
<li><p>When $ X $ is a continuous random variable, the distribution function and the probability density function can use the integral and differential to find each other:<br> $$<br> F_X (x) = \ int _ {-\ infty} ^ {x} f_X (t) dt, \ quad f_X (x) = \ frac {dF_X} {dx} (x)<br> $$<br> (The second equation holds only at those points where the distribution function is differentiable)</p>
</li>
</ol>
<p>** Sometimes in order to calculate the probability mass function or probability density function of a random variable, it is more convenient to first calculate the distribution function of the random variable **. In the case of continuous random variables, we will systematically introduce the distribution of the function of the random variable by this method in Section 4.1. The following is a calculation example of discrete random variables.</p>
<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><h3 id="The-maximum-value-of-several-random-variables"><a href="#The-maximum-value-of-several-random-variables" class="headerlink" title="The maximum value of several random variables"></a>The maximum value of several random variables</h3><p>You take a certain test, and the highest score of the three tests is set as your final score, set $ X = max \ {X_1, X_2, X_3 } $, where $ X_1, X_2, X_3 $ are the results of three tests, $ X $ Is your final score. Suppose your test score is between 1 and 10 points each time, and $ P (X = i) = \ frac {1} {10}, i = 1, …, 10 $. Now find the probability quality function of the final score $ X $.</p>
<p>Use an indirect method to find the distribution function. First calculate the CDF of $ X $ and then pass<br>$$<br>p_X (k) = F_X (k) -F_X (k-1), i = 1, \ ldots, 10<br>$$<br>Get the probability mass function of $ X $. For $ F_X (k) $, we get:<br>$$<br>\ begin {eqnarray}<br>F_X (k) &amp; = &amp; P (X \ le k) \<br>&amp; = &amp; P (X_1 \ le k, X_2 \ le k, X_3 \ le k) \<br>&amp; = &amp; P (X_1 \ le k) P (X_2 \ le k) P (X_3 \ le k) \<br>&amp; = &amp; (\ frac {k} {10}) ^ 3<br>\ end {eqnarray}<br>$$<br>The third equation here is caused by the events $ \ {X_1 \ le k }, \ {X_2 \ le k }, \ {X_3 \ le k } $ being independent of each other. Thus the probability mass function of $ X $ is:<br>$$<br>p_X (k) = (\ frac {k} {10}) ^ 3-(\ frac {k-1} {10}) ^ 3, k = 1, \ ldots, 10<br>$$<br>The method in this example can be extended to the case of $ n $ random variables $ X_1, \ ldots, X_n $. If the events $ \ {X_1 \ le x }, \ ldots, \ {X_n \ le x } $ are independent of each other, then $ X = max \ {X_1, \ ldots, X_n } $ The CDF is:<br>$$<br>F (x) = F_ {X_1} (x) \ cdots F_ {X_n} (x)<br>$$<br>Using this formula, $ P_X (x) $ can be obtained by difference in discrete cases, and $ f_X (x) $ can be obtained by differentiation in continuous cases.</p>
<h3 id="Distance-distribution-function-and-probability-density-function"><a href="#Distance-distribution-function-and-probability-density-function" class="headerlink" title="Distance distribution function and probability density function"></a>Distance distribution function and probability density function</h3><p>Exercise 3.5: According to the law of uniform distribution, randomly select a point in a triangle, set the height of the known triangle, and find the distribution function and probability density function of the distance $ X $ from this point to the bottom.</p>
<p>Let $ b $ denote the length of the base, $ h $ denote the height of the triangle, and $ A = \ frac {bh} {2} $ denote the area of ​​the triangle. Randomly select a point within the triangle, and then draw an auxiliary line parallel to the base of the triangle, using $ A_x $ to represent the area of ​​the small triangle formed by this auxiliary line, then the height of the small triangle is $ hx $, which The bottom edge of is calculated proportionally: $ b \ frac {hx} {h} $, so $ A_x = \ frac {b (hx) ^ 2} {2h} $. For $ x \ in [0, h] $, you get:<br>$$<br>F_X (x) = P (0 &lt;x \ le x) = 1-P (X&gt; x) = 1- \ frac {A_x} {A} = 1- \ frac {\ frac {b (hx) ^ 2} {2h}} {\ frac {bh} {2}} = 1-(\ frac {hx} {h}) ^ 2<br>$$<br>When $ x &lt;0, $ then $ F_X (x) = 0 $; when $ x&gt; h, $ then $ F_X (x) = 1 $.</p>
<p>The probability density function can be obtained by differentiating the cumulative distribution function CDF:<br>$$<br>f_X (x) = \ frac {dF_X} {dx} (x) = \ cases {\ frac {2 (hx)} {h ^ 2}, &amp; when $ 0 \ le x \ le h $ \ 0, &amp; others Happening}<br>$$</p>
<h3 id="waiting-time"><a href="#waiting-time" class="headerlink" title="waiting time"></a>waiting time</h3><p>Exercise 3.6: Jane goes to the bank to withdraw money, there are 1 or 0 customers in front of her, these two situations are equally possible. It is known that the service time of a customer is an exponential random variable, and the parameter is $ \ lambda $. So what is the time distribution function that Jane is waiting for?</p>
<p>Use $ X $ to indicate the waiting time, and $ Y $ to indicate the number of customers before Jane. So we get: $ \ forall x &lt;0, F_X (x) = 0 $, in other cases, according to the meaning of the question:<br>$$<br>F_X (x) = P (X \ le x) = \ frac {1} {2} P (X \ le x | Y = 0) + \ frac {1} {2} P (X \ le x | Y = 1)<br>$$<br>also because<br>$$<br>P (X \ le x | Y = 0) = 1, \ quad P (X \ le x | Y = 1) = 1-e ^ {-\ lambda x}<br>$$<br>get<br>$$<br>F_X (x) = \ cases {\ frac {1} {2} (2-e ^ {-\ lambda x}), &amp; if $ x \ ge 0 $ \ 0, &amp; other cases}<br>$$<br>Note: This cumulative distribution function CDF is continuous at $ x = 0 $, and the random variable $ X $ is neither discrete nor continuous.</p>
<h3 id="Throwing-standard-game"><a href="#Throwing-standard-game" class="headerlink" title="Throwing standard game"></a>Throwing standard game</h3><p>Alvin is playing darts. The target of the dart is a circular plate with radius r. Let $ X $ be the distance between the dart’s landing point and the bull’s eye. It is assumed that the falling points are evenly distributed on the target board.</p>
<p>(a) Find the probability density function, mean and variance of $ X $.</p>
<p>The cumulative distribution function of $ X $ is relatively easy to find:<br>$$<br>F_X (x) = \ cases {<br>P (X \ le x) = \ frac {\ pi x ^ 2} {\ pi r ^ 2} = (\ frac {x} {r}) ^ 2, &amp; if $ \ forall x \ in [0, r ] $ \<br>0, &amp; if $ x &lt;0 $ \<br>1, &amp; if $ x&gt; r $<br>}<br>$$<br>Through differentiation, the probability density function is obtained:<br>$$<br>f_X (x) = \ cases {<br>\ frac {2x} {r ^ 2}, &amp; if $ 0 \ le x \ le r $ \<br>0, &amp; otherwise<br>}<br>$$<br>Then through the points to get:<br>$$<br>E [X] = \ int_ {0} ^ {r} \ frac {2x ^ 2} {r ^ 2} dx = \ frac {2r} {3} \<br>E [X ^ 2] = \ int_ {0} {r} \ frac {2x ^ 3} {r ^ 2} dx = \ frac {r ^ 2} {2} \<br>var (X) = E [X ^ 2]-(E [X]) ^ 2 = \ frac {r ^ 2} {2}-\ frac {4r ^ 2} {9} = \ frac {r ^ 2} {18}<br>$$<br>(b) A concentric circle with a radius of $ t $ is drawn on the target. If $ X \ le t $, Alvin ’s score is $ S = \ frac {1} {X} $, otherwise $ S = 0 $. Find the distribution function of $ S $. Is $ S $ a continuous random variable?</p>
<p>From the question: If and only if $ X \ le t $, Alvin gets a score s between $ [\ frac {1} {t}, + \ infty) $, otherwise, his score is 0 . therefore:<br>$$<br>F_S (s) = \ cases {<br>0, \ quad \ text {if $ s &lt;0 $} \<br>P (S \ le s) = 1-P (X \ le t), \ quad \ text {if $ 0 \ le s \ le \ frac {1} {t} $ (that is, Alvin hits outside the inner circle) } \<br>P (S \ le s) = P (X \ le t) P (S \ le s | X \ le t) + P (X&gt; t) P (S \ le s | X&gt; t) \ quad \ text { if $ s&gt; \ frac {1} {t} $}<br>}<br>$$<br>According to the title, get:<br>$$<br>P (X \ le t) = \ frac {t ^ 2} {r ^ 2}, \ quad P (X&gt; t) = 1- \ frac {t ^ 2} {r ^ 2}<br>$$<br>And because when $ X&gt; t, S = 0 $, so $ P (S \ le s | X&gt; t) = 1 $.</p>
<p>In turn:<br>$$<br>P (S \ le s | X \ le t) = P (\ frac {1} {X} \ le s | X \ le t) = P (\ frac {1} {s} \ le X | X \ le t) = \ frac {P (\ frac {1} {s} \ le X \ le t)} {P (X \ le t)} = \ frac {\ frac {\ pi t ^ 2-\ pi (\ frac {1} {s}) ^ 2} {\ pi r ^ 2}} {\ frac {\ pi t ^ 2} {\ pi r ^ 2}} = 1- \ frac {1} {s ^ 2t ^ 2}<br>$$<br>Finally get:<br>$$<br>F_S (s) = \ cases {<br>    0, &amp; \ text {if} s &lt;0 \<br>    1- \ frac {t ^ 2} {r ^ 2}, &amp; \ text {if} 0 \ le s \ le \ frac {1} {t} \<br>    1- \ frac {1} {s ^ 2r ^ 2} &amp; \ text {if} \ frac {1} {t} &lt;s<br>}<br>$$<br>Because $ F_S (s) $ is not continuous at $ s = 0 $, the random variable $ S $ is not continuous.</p>
<h2 id="Distribution-functions-of-geometric-and-exponential-random-variables"><a href="#Distribution-functions-of-geometric-and-exponential-random-variables" class="headerlink" title="Distribution functions of geometric and exponential random variables"></a>Distribution functions of geometric and exponential random variables</h2><p>** Since the distribution function is applicable to all random variables, you can use it to explore the relationship between discrete and continuous random variables **. In particular, the relationship between geometric random variables and exponential random variables is discussed here.</p>
<p>Let $ X $ be a geometric random variable whose parameter is $ p $, that is, $ X $ is the number of trials required until the first success in the Bernoulli independent test sequence, and the parameter of the Bernoulli test is $ p $. So for $ k = 1,2 \ cdots, $ we get $ P (X = k) = p (1-p) ^ {k-1} $, and the CDF of $ X $ is:<br>$$<br>F_ {geo} (n) = \ sum \ limits_ {k = 1} ^ {n} p (1-p) ^ {k-1} = p \ frac {1- (1-p) ^ n} {1 -(1-p)} = 1- (1-p) ^ n, \ quad n = 1,2, \ cdots<br>$$<br>Now let $ X $ be an exponential random variable, and its parameter $ \ lambda&gt; 0 $. Its CDF is<br>$$<br>F_ {exp} (x) = P (X \ le x) = 0, \ quad x \ le 0 \<br>F_ {exp} (x) = \ int_ {0} ^ {x} \ lambda e ^ {-\ lambda t} dt = -e ^ {-\ lambda t} | ^ {x} _ {0} = 1- e ^ {-\ lambda x}, \ quad x&gt; 0<br>$$<br>Now compare the two distribution functions, let $ \ delta = \ frac {-ln (1-p)} {\ lambda} \ rightarrow \ delta \ lambda = -ln (1-p) $, so we get:<br>$$<br>e ^ {-\ lambda \ delta} = 1-p \ quad (\ <em>)<br>$$<br>Then, substitute $ (</em>) $ into $ F_ {geo} (n) $ to get: $ 1- (e ^ {-\ lambda \ delta}) ^ n = 1-e ^ {-n \ lambda \ delta} $, And the distribution function $ F_ {exp} $ at $ x = n \ delta $ is: $ 1-e ^ {-\ lambda n \ delta} = 1-e ^ {-n \ lambda \ delta} $ Is equal to $ F_ {geo} $ at $ n $, $ n = 1,2, \ cdots $, that is:<br>$$<br>F_ {exp} (n \ delta) = F_ {geo} (n) =, n = 1,2, \ cdots<br>$$<br>Now suppose that an uneven coin is tossed at a very fast rate (tossed every $ \ delta $ seconds, $ \ delta \ ll 1 $), and the probability of heading upwards for each toss is $ p = 1-e ^ { -\ lambda \ delta} $. In this way, the number of times tossed upwards for the first time is $ X $, and the first time to get positives is $ X \ delta $, which is very close to the exponential random variable with the parameter $ \ lambda $. All it takes is to look at their distribution functions (see the figure below). This relationship is particularly important when the sixth chapter of the book discusses the Bernoulli and Poisson distribution process.<br>! [Figure_3.8_Relation_of_the_geometric_and_the_exponential_CDFs.png] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/cumulative-distribution-function/3.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/cumulative-distribution-function/3.png</a>)</p>
<p>The relationship between the distribution functions of geometric random variables and exponential random variables. The discrete distribution function in the figure is the distribution function of $ X \ delta $. $ X $ is a geometric random variable with the parameter $ p = 1-e ^ {-\ lambda x} $ When $ \ delta \ rightarrow 0 $, the distribution function of $ X \ delta $ tends to the exponential distribution function $ 1-e ^ {-\ lambda x} $.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/26/mean_and_variance_of_uniform_random_variable/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/26/mean_and_variance_of_uniform_random_variable/" class="post-title-link" itemprop="url">Classic Excerpts-Mean and Variance of Uniform Random Variables</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-26 20:16:00" itemprop="dateCreated datePublished" datetime="2017-08-26T20:16:00+05:30">2017-08-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:39" itemprop="dateModified" datetime="2020-04-09T16:34:39+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>2.5k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>2 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Note: The full text is taken from [Introduction to robability, 2nd Edition] (<a href="http://www.athenasc.com/probbook.html" target="_blank" rel="noopener">http://www.athenasc.com/probbook.html</a>)</p>
<h2 id="Uniformly-distributed-discrete-random-variables"><a href="#Uniformly-distributed-discrete-random-variables" class="headerlink" title="Uniformly distributed discrete random variables"></a>Uniformly distributed discrete random variables</h2><p>By definition, the range of discrete uniform random variables is a finite set of adjacent integers, and the probability of taking each integer is equal. So its distribution column:</p>
<p>$$ p_X (k) = \ cases {\ frac {1} {b-a + 1}, &amp; if k = a, a + 1, …, b \ 0, &amp; otherwise} $$</p>
<p>! [mean_and_variance_of_the_discrete_uniform_random_variable.png] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/mean_and_variance_of_uniform_random_variable/1.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/mean_and_variance_of_uniform_random_variable/1.png</a>)</p>
<p>Where $ a, b $ are two integers, as the two endpoints of the range of random variables, $ a &lt;b $. Since its probability function is symmetric with respect to (a + b) / 2, its mean is:</p>
<p>$$ E [X] = \ frac {a + b} {2} $$</p>
<p>To calculate the variance of $ X $, first consider the simple case of a = 1 and b = n. Using induction can prove:</p>
<p>$$ E [X ^ 2] = \ frac {1} {n} \ sum \ limits_ {k = 1} ^ {n} k ^ 2 = \ frac {1} {6} (n + 1) (2n + 1) $$</p>
<p>(The specific proof process is reserved for exercises). Using the first and second moments in this way, the variance of $ X $ can be obtained<br>$$<br>\ begin {eqnarray \ <em>}<br>var (X) &amp; = &amp; E [X ^ 2]-(E [X]) ^ 2 \<br>&amp; = &amp; \ frac {1} {6} (n + 1) (2n + 1)-\ frac {1} {4} (n + 1) ^ 2 \<br>&amp; = &amp; \ frac {n ^ 2-1} {12}<br>\ end {eqnarray \ *}<br>$$<br>*</em> For the general case of $ a $ and $ b $, the difference between the uniform distribution in the interval $ [a, b] $ and the distribution in the interval $ [1, b-a + 1] $ , Only one distribution is the offset of another distribution, so the two have the same variance (here the interval $ [a, b] $ refers to the set of integers between $ a $ and $ b $) **. So under normal circumstances, the variance of $ X $ only needs to replace $ n $ in the formula in the simple case with $ b-a + 1 $, that is:</p>
<p>$$ var (X) = \ frac {(b-a + 1) ^ 2-1} {12} = \ frac {(b-a) (b-a + 2)} {12} $$</p>
<h2 id="Evenly-distributed-continuous-random-variables"><a href="#Evenly-distributed-continuous-random-variables" class="headerlink" title="Evenly distributed continuous random variables"></a>Evenly distributed continuous random variables</h2><p>Excerpt from Example 3.4. Mean and Variance of the Uniform Random Variable</p>
<p>If the distribution of the random variable $ X $ is a uniform distribution on $ [a, b] $, we get:<br>$$<br>\ begin {eqnarray \ *}<br>E [X] &amp; = &amp; \ int _ {-\ infty} ^ {+ \ infty} xf_X (x) dx \<br>&amp; = &amp; \ int_ {a} ^ {b} x \ frac {1} {b-a} dx \<br>&amp; = &amp; \ frac {1} {b-a} \ cdot \ frac {1} {2} x ^ 2 | ^ {b} _ {a} \<br>&amp; = &amp; \ frac {1} {b-a} \ cdot \ frac {b ^ 2-a ^ 2} {2} \<br>&amp; = &amp; \ frac {b + a} {2}<br>\ end {eqnarray \ *}<br>$$<br>This expected value is exactly equal to the center of symmetry of $ PDF $ $ \ frac {b + a} {2} $.</p>
<p>To find the variance, first calculate the second moment of $ X $:<br>$$<br>\ begin {eqnarray \ *}<br>E [X ^ 2] &amp; = &amp; \ int_ {a} ^ {b} \ frac {x ^ 2} {b-a} dx \<br>&amp; = &amp; \ frac {1} {b-a} \ cdot \ int_ {a} {b} x ^ 2dx \<br>&amp; = &amp; \ frac {1} {b-a} \ cdot \ frac {1} {3} x ^ 3 | _ {a} ^ {b} \<br>&amp; = &amp; \ frac {b ^ 3-a ^ 3} {3 (b-a)} \<br>&amp; = &amp; \ frac {a ^ 2 + ab + b ^ 2} {3} \<br>\ end {eqnarray \ *}<br>$$<br>So the variance of the random variable $ X $ is:<br>$$<br>var (X) = E [X ^ 2]-(E [X]) ^ 2 = \ frac {a ^ 2 + ab + b ^ 2} {3}-\ frac {(a + b) ^ 2} { 4} = \ frac {(ba) ^ 2} {12}<br>$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/15/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><span class="page-number current">16</span><a class="page-number" href="/page/17/">17</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><a class="extend next" rel="next" href="/page/17/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Karan"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Karan</p>
  <div class="site-description" itemprop="description">Refuse to Fall</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">87</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnNuYWtlY29kaW5nLnB5QGdtYWlsLmNvbQ==" title="Get In Touch → mailto:snakecoding.py@gmail.com"><i class="fa fa-envelope fa-fw"></i>Get In Touch</span>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Karan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">2.4m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">35:43</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  
  <script data-pjax>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


    </div>
</body>
</html>
