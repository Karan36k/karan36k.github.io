<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">

<script>
    (function(){
        if(''){
                         If (prompt('Please enter the article password') !== ''){
                                 Alert('Password error!');
                history.back();
            }
        }
    })();
</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"snakecoding.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":"flat","style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":false},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Refuse to Fall">
<meta property="og:type" content="website">
<meta property="og:title" content="Machine Learning">
<meta property="og:url" content="https://snakecoding.com/page/17/index.html">
<meta property="og:site_name" content="Machine Learning">
<meta property="og:description" content="Refuse to Fall">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Karan">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://snakecoding.com/page/17/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Machine Learning</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Machine Learning" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Machine Learning</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Data Science</p>
      <a>
        <img class="custom-logo-image" src="/images/custom-logo.jpg" alt="Machine Learning">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">15</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">6</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">87</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="#" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/25/exponential_random_variables/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/25/exponential_random_variables/" class="post-title-link" itemprop="url">Classic Excerpts-Mean and Variance of Exponential Random Variables</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-25 20:16:00" itemprop="dateCreated datePublished" datetime="2017-08-25T20:16:00+05:30">2017-08-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:46" itemprop="dateModified" datetime="2020-04-09T16:34:46+05:30">2020-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning-Maths/" itemprop="url" rel="index"><span itemprop="name">Machine Learning Maths</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>5.6k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>5 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>** Description **: The full text is taken from [Introduction to probability, 2nd Edition] (<a href="http://www.athenasc.com/probbook.html" target="_blank" rel="noopener">http://www.athenasc.com/probbook.html</a>) </p>
<p>An exponential random variable has the following form of ** probability density function *<em>:<br>$$<br>f_X (x) = \ cases {<br>    \ lambda e ^ {-\ lambda x}, &amp; if $ x \ ge 0 $ \<br>    0, &amp; other situations<br>}<br>$$<br>In this formula, *</em> $ \ lambda $ is a positive number *<em>, which is a definition that conforms to probability normality because:<br>$$<br>\ int _ {-\ infty} ^ {+ \ infty} f_X (x) dx = \ int _ {-\ infty} ^ {+ \ infty} \ lambda e ^ {-\ lambda} dx = -e ^ {\ lambda x } | <em>0 ^ {+ \ infty} = 1<br>$$<br>Note that the exponential probability density function has such characteristics: $ X $ The probability of exceeding a certain value decreases exponentially as the value increases<br>$$<br>\ forall a \ ge 0, P (X \ ge a) = \ int</em> {a} ^ {\ infty} \ lambda e ^ {-\ lambda x} dx = -e ^ {-\ lambda x} | _a ^ { + \ infty} = e ^ {-\ lambda a}<br>$$<br>The *</em> cumulative distribution function ** is obtained from the probability density function:<br>$$<br>\ forall x \ ge 0, P (X \ le x) = \ int_ {0} ^ {x} \ lambda e ^ {-\ lambda x} dx = 1-e ^ {-\ lambda x}<br>$$<br>! [The_PDF_of_an_exponential_random_variable] (<a href="http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/exponential-random-variable/1.png" target="_blank" rel="noopener">http://q6gm8fomw.bkt.clouddn.com/gitpage/introduction-to-probability/exponential-random-variable/1.png</a>)</p>
<p>** Exponential random variables can model the time until the event occurs, for example: the time when the message reaches the computer, the service life of the device, the life of the light bulb, the time of the accident, etc. , be a good model for the amount of time until an incident of interest takes place). As we will see in later chapters, exponential random variables are closely related to geometric random variables, and geometric random variables are also related to the (discrete) time at which related events occur. ** Exponential random variables will play an important role in the study of random processes in Chapter VI **. But so far, it has only been regarded as a special kind of analyzable random variable.</p>
<p>** Mean and variance of exponential random variables **:<br>$$<br>\ begin {eqnarray}<br>E [X] &amp; = &amp; \ int_ {0} ^ {\ infty} x \ lambda e ^ {-\ lambda x} dx \<br>&amp; = &amp; (-xe ^ {-\ lambda x}) | <em>0 ^ {\ infty} + \ int</em> {0} ^ {\ infty} e ^ {-\ lambda x} dx \ quad \ text {This step uses points Department integral method} \<br>&amp; = &amp; 0- \ frac {e ^ {-\ lambda x}} {\ lambda} | <em>0 ^ {\ infty} \<br>&amp; = &amp; \ frac {1} {\ lambda}<br>\ end {eqnarray}<br>$$<br>Using the distributed integration method, the second moment of $ X $ can be obtained:<br>$$<br>\ begin {eqnarray}<br>E [X ^ 2] &amp; = &amp; \ int</em> {0} ^ {\ infty} x ^ 2 \ lambda e ^ {-\ lambda x} dx \<br>&amp; = &amp; (-x ^ 2e ^ {-\ lambda x}) | <em>0 ^ {\ infty} + \ int</em> {0} ^ {\ infty} 2xe ^ {-\ lambda x} dx<br>&amp; = &amp; 0+ \ frac {2} {\ lambda} E [X] \<br>&amp; = &amp; \ frac {2} {\ lambda ^ 2}<br>\ end {eqnarray}<br>$$<br>Finally, using the formula $ var (x) = E [X ^ 2]-(E [X]) ^ 2 $, we get:<br>$$<br>var (X) = \ frac {2} {\ lambda ^ 2}-\ frac {1} {\ lambda} = \ frac {1} {\ lambda ^ 2}<br>$$</p>
<h3 id="Example-3-5"><a href="#Example-3-5" class="headerlink" title="Example 3.5"></a>Example 3.5</h3><p>The time when the small meteorites fell into the Sahara Desert in Africa followed the exponential distribution. Specifically, when an observer starts to observe, it is found that a meteorite falls into the desert. This time is simulated as an exponential random variable with an average value of $ 10 $ days. It is now assumed that the current time is at $ 12 $ in the evening. Q. What is the probability that the meteorite will fall for the first time between $ 6: 00 $ in the morning and $ 6: 00 $ in the evening?</p>
<p>Suppose $ X $ is the waiting time required to observe the falling of the meteorite. Since $ X $ satisfies the exponential distribution, the mean value is $ \ frac {1} {\ lambda} = 10 $, which results in: $ \ lambda = \ frac {1} {10} $. The required probability is:<br>$$<br>P (\ frac {1} {4} \ le X \ le \ frac {3} {4}) = P (X \ ge \ frac {1} {4})-P (X \ ge \ frac {3} {4}) = e ^ {-\ frac {1} {40}}-e ^ {-\ frac {3} {40}} = 0.0476<br>$$<br>In this process, the continuous random variable $ P (X \ ge a) = P (X&gt; a) = e ^ {-\ lambda a} $ was used.</p>
<h3 id="Memorylessness-of-exponential-random-variables"><a href="#Memorylessness-of-exponential-random-variables" class="headerlink" title="Memorylessness of exponential random variables"></a>Memorylessness of exponential random variables</h3><p>The lifetime of a light bulb $ T $ is an exponential random variable whose parameter is $ \ lambda $. Ariadne left the room after turning on the light, and after staying outside for a period of time (the length of time was $ t $), when he returned to the room, the light was still on. This is equivalent to the occurrence of the event $ A = \ {T&gt; t } $. Let $ X $ be the remaining life of the bulb. What is the distribution function of $ X $?</p>
<p>answer:</p>
<p>Actually $ X $ is the lifetime under the condition where $ A $ occurs, and we get:<br>$$<br>\ begin {eqnarray}<br>P (X&gt; x | A) &amp; = &amp; P (T&gt; t + x | T&gt; t) \<br>&amp; = &amp; \ frac {P (T&gt; t + x, T&gt; t)} {P (T&gt; t)} \<br>&amp; = &amp; \ frac {P (T&gt; t + x)} {P (T&gt; t)} \<br>&amp; = &amp; \ frac {e ^ {-\ lambda (t + x)}} {e ^ {-\ lambda t}} \<br>&amp; = &amp; e ^ {-\ lambda x}<br>\ end {eqnarray}<br>$$<br>The distribution function of the remaining life of the lamp $ X $ is an exponential distribution, and its parameter is also $ \ lambda $, which has nothing to do with how many hours the lamp has been on. This property of exponential distribution is ** memory-free distribution *<em>. *</em> In general, if the distribution of the time required to complete a certain task is located in an exponential distribution. So as long as this task is not completed, the distribution of the remaining time required to complete this task is still exponential, and its parameters are also unchanged **.</p>
<h4 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h4><p>A careless professor mistakenly arranged the question answering time of the two students in the same time period. It is known that the length of time for the two students to answer questions is two independent and identically distributed random variables. The distribution is an exponential distribution. The expected value is $ 30 $ minutes. The first student arrives on time. After 5 minutes, the second student also arrives. . What is the expected time from the arrival of the first student until the second student leaves?</p>
<p>answer:</p>
<p>Use $ T_ {total} $ to indicate the total time for the professor to answer the question, and use $ T_ {s_1}, T_ {s_2} $ to indicate the time that the professor will answer the questions of student $ 1 $ and student $ 2 $, then<br>$$<br>E [T_ {total}] = P (T_ {s_1} &lt;5) \ cdot E [5 + E [T_ {s_2}]] + P (T_ {s_1} \ ge 5) (E [T_ {s_1} | T_ {s_1} \ ge5] + E [T_ {s_2}])<br>$$<br>According to the title: $ E [T_ {s_1}] = E [T_ {s_2}] = 30 $, using the memorylessness of exponential random variables: $ E [T_ {s_1} | T_ {s_1} \ ge5] = 5 + E [T_ {s_1}] = 35 $.<br>$$<br>P (T_ {s_1} \ ge 5) = e ^ {-\ frac {1} {30} \ cdot5} \<br>P (T_ {s_1} &lt;5) = 1-P (T_ {s_1} \ ge 5) = 1-e ^ {-\ frac {1} {30} \ cdot5} \<br>$$<br>therefore:<br>$$<br>E [T_ {total}] = (1-e ^ {-\ frac {1} {30} \ cdot5}) \ cdot (5 + 30) + (e ^ {-\ frac {1} {30} \ cdot5 }) \ cdot (35 + 30) = 35 + 30 \ cdot e ^ {-\ frac {5} {30}} = 60.394<br>$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/25/mean_and_variance_of_sample_and_estimating_probability_by_simulation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/25/mean_and_variance_of_sample_and_estimating_probability_by_simulation/" class="post-title-link" itemprop="url">Classic Excerpts-Expected Variance of Sample Means and Simulation Methods to Estimate Probability</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-25 20:16:00" itemprop="dateCreated datePublished" datetime="2017-08-25T20:16:00+05:30">2017-08-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:41" itemprop="dateModified" datetime="2020-04-09T16:34:41+05:30">2020-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning-Maths/" itemprop="url" rel="index"><span itemprop="name">Machine Learning Maths</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>3.2k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>3 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Expected-variance-of-sample-mean"><a href="#Expected-variance-of-sample-mean" class="headerlink" title="Expected variance of sample mean"></a>Expected variance of sample mean</h2><p>Excerpt from: [Introduction to probability, 2nd Edition] (<a href="http://www.athenasc.com/probbook.html" target="_blank" rel="noopener">http://www.athenasc.com/probbook.html</a>) Example 2.21. Mean and Variance of the Sample Mean</p>
<p>We hope to estimate the president’s approval rating. To this end, we randomly select n voters and ask their views. Let $ x_i $ denote the attitude of $ i $ voters asked:</p>
<p>$$ X_i = \ cases {1, \ text {if the first voted voter supports the president} \ 0, \ text {if the first voted voter does not support the president}} $$</p>
<p>** Assume that $ X_1, \ ldots, X_n $ are independent and identically distributed Bernoulli random variables **, whose mean is $ p $ and variance is $ p (1-p) $. Here we consider the probability that $ p $ believes voters support the president, and will average the responses to the survey, calculate the sample mean $ S_n $, and define $ S_n $ as</p>
<p>$$ S_n = \ frac {X_1 + \ ldots + X_n} {n} $$</p>
<p>Therefore, the random variable $ S_n $ is the support rate for sampling n voters.</p>
<p>Since ** $ S_n $ is a linear function of $ X_1, \ ldots, X_n $ *<em>, we *</em> use the linear relationship of means ** to get,</p>
<p>$ E [S_n] = \ sum \ limits_ {i = 1} ^ {n} E [\ frac {X_i} {n}] = \ sum \ limits_ {i = 1} ^ {n} \ frac {1} { n} E [X_i] = \ sum \ limits_ {i = 1} ^ {n} \ frac {1} {n} p = p = E [X] $</p>
<p>Then ** using the independence of $ X_1, \ ldots, X_n $ **, you can get:</p>
<p>$$ var (S_n) = \ sum \ limits_ {i = 1} ^ {n} var (\ frac {X_i} {n}) = \ sum \ limits_ {i = 1} ^ {n} \ frac {1} {n ^ 2} var (X_i) = \ frac {p (1-p)} {n} $$</p>
<p>** The sample mean of $ S_n $ is considered a good estimate of the support rate, because its expected value is exactly $ p $. Then the variance reflecting the accuracy becomes smaller and smaller as the sample size $ n $ increases. **</p>
<p>Note that even though $ X_i $ is not a Bernoulli random variable in the above example, the conclusion</p>
<p>$$ var (S_n) = \ frac {var (X)} {n} $$</p>
<p>It still holds true, as long as $ X_i $ is independent of each other, after all, expectations and variances have nothing to do with $ i $. Therefore, as the sample size increases, the sample mean is still a good estimate of the mean of the random variable. We will discuss these attributes of the sample mean in more detail in Chapter 5 and combine them with the law of large numbers.</p>
<h2 id="Simulation-method-to-estimate-probability"><a href="#Simulation-method-to-estimate-probability" class="headerlink" title="Simulation method to estimate probability"></a>Simulation method to estimate probability</h2><p>Excerpt from: [Introduction to probability, 2nd Edition] (<a href="http://www.athenasc.com/probbook.html" target="_blank" rel="noopener">http://www.athenasc.com/probbook.html</a>) Example 2.22. Estimating Probabilities by Simulation</p>
<p>In many practical problems, sometimes it is very difficult to calculate the probability of an event, and then we can repeat the experiment using physical methods or computer methods. These test results can show whether the event has occurred. Using this simulation method, the probability of an event can be calculated with high accuracy. You can independently simulate the test $ n $ times, and record the number of occurrences of $ A $ in the $ n $ test $ m $. Use $ \ frac {m} {n} $ to approximate the probability $ P (A) $. For example, in the coin toss test, calculate the probability $ p = P $ (frontal appearance), independently toss $ n $ times, and use the ratio (the number of heads in the record divided by the total number of trials n) to approximate the probability $ p $.</p>
<p>To calculate the accuracy of this method, consider $ n $ independent and identically distributed Bernoulli random variables $ X_1, \ ldots, X_n $, and the probability mass function of each $ X_i $:</p>
<p>$$ p_ {X_i} (k) = \ cases {P (A), if \ k = 1 \ 1-P (A), if \ k = 0} $$</p>
<p>In the simulated environment, $ X_i $ is related to the result of the $ i $ th test. If the $ i $ test result belongs to $ A $, then the value of $ X_i $ is 1, and the value of the random variable $ X = \ frac {X_1 + X_2 + \ ldots + X_n} {n} $$) is the estimated value of the probability $ P (A) $. From the results of Example 2.21, the expectation of $ X $ is $ P (A) $, and the variance is $ \ frac {P (A) (1-P (A))} {n} $. So when $ n $ is large, $ X $ provides an accurate estimate of $ P (A) $.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/24/the_two-envelopes_paradox/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/24/the_two-envelopes_paradox/" class="post-title-link" itemprop="url">Classic Excerpt-Paradox of Two Envelope</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-24 20:16:00" itemprop="dateCreated datePublished" datetime="2017-08-24T20:16:00+05:30">2017-08-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:35" itemprop="dateModified" datetime="2020-04-09T16:34:35+05:30">2020-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning-Maths/" itemprop="url" rel="index"><span itemprop="name">Machine Learning Maths</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>5.2k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>5 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>This article is extracted from: [Introduction to probability, 2nd Edition] (<a href="http://www.athenasc.com/probbook.html" target="_blank" rel="noopener">http://www.athenasc.com/probbook.html</a>) Example 2.18. The Two-Envelopes Paradox.  </p>
<p>This is a widely-interested intelligence test question, which involves mathematical points about conditional expectations.</p>
<p>The host gives you two envelopes and tells you that there is cash in the two envelopes. The money in one envelope is $ m $ times the other envelope ($ m&gt; 1 $ and an integer). When you open an envelope and see the amount of money in the envelope, you have two options. One is to accept the money in this envelope as your bonus, and the other is to give up the money in this envelope and choose another envelope. Your money as your bonus. So what good strategy can make you get more bonuses?</p>
<p>There is a reasoning below, which proves that we should turn to choose the second envelope. Let A denote the envelope you opened, B be the envelope you might change, and $ x $ and $ y $ denote the money in envelopes A and B, respectively. The argument is as follows: since either $ y = {x \ over m} $ or $ y = mx $, and the probability of both occurrences is $ {1 \ over 2} $, the The expected value is:</p>
<p>$$ \ frac {1} {2} \ cdot \ frac {x} {m} + \ frac {1} {2} \ cdot mx = \ frac {1} {2} (\ frac {1} {m} + m) x = \ frac {1 + m ^ 2} {2m} x&gt; x $$</p>
<p>In this way, you should always turn to envelope B. When you randomly choose B, for the same reason, you get back to A. This is in a contradiction, because according to this reasoning, no matter which envelope is selected, another envelope must be selected as a bonus.</p>
<p>In fact, in this paradox, two assumptions are flawed:</p>
<ol>
<li>For the money in the two envelopes, you cannot know in advance. When the value of $ x $ is given, what you think you know is $ y = \ frac {x} {m} $ or $ y = mx $ . And there is no reason which situation is more likely.</li>
<li>Use the random variables $ X $ and $ Y $ to represent the money in the two envelopes. If $ E [Y | X = x]&gt; x, x \ in \ forall $ is established, then always switch to another envelope. Get more expected bonuses.</li>
</ol>
<p>Let us examine these two assumptions carefully:</p>
<p>Hypothesis 1 is flawed because it relies on an incomplete certain probability model. In fact, the events of various models, including the possible values ​​of $ X $ and $ Y $, must have a certain probability. With such probability information of $ X $ $ Y $, the value of $ X $ may reveal a lot of information about the value of $ Y $. For example, suppose the following probabilistic model: a person chooses $ Z $ yuan to be placed in an envelope, the value range of $ Z $ is an integer of $ [\ underline {z}, \ overline {z}] $, and obey Probability distribution, and $ mZ $ is deposited in another envelope. Then, you randomly select an envelope from the two envelopes with equal probability, and look at the value of the amount of money inside $ X $. When the value of $ X $ is greater than the upper limit of $ Z $$ \ overline {z} $, you can be sure that the amount of money in the envelope you get is relatively large, so you do not have to change the envelope. If the amount of money you get is equal to the value of $ \ underline {z} $, then you can be sure that the money in another envelope is more than $ \ underline {z} $, so you must change the envelope. Generally speaking, if you know the range of X and the possibility of the value of X, you can judge whether the amount of money X in envelope A is relatively small or relatively large, and then make a choice accordingly.</p>
<p>Mathematically, using an accurate probability model, we can certainly find the joint probability function of $ X $ and $ Y $. The joint probability score of $ X $ and $ Y $ can be determined by the distribution law of the smallest of the money in the two envelopes, $ Z $, as $ P_Z $, then for all $ z $, $ p_ {X, Y} (mz, z ) = p_ {X, Y} (z, mz) = \ frac {1} {2} p_Z (z) $, for $ that does not have the form of $ (mz, z) $ or $ (z, mz) $ (x, y) $, $ p_ {X, Y} (x, y) = 0 $. When $ p_ {X, Y} (x, y) $ is given, we can use this rule for changing envelopes: the necessary and sufficient condition for changing envelopes is $ E [Y | X = x]&gt; x $, according to this rule You can determine whether to change the envelope or not.</p>
<p>The question now is: Can the envelope be converted according to certain values ​​of x according to the appeal model and conversion rules, while other values ​​cannot be changed? In general, it is possible. For example, if the value range of the $ Z $ out earlier is a bounded set, such a conversion rule can be implemented. However, the following quirky example makes you always change envelopes:</p>
<p>Toss an even coin until the front appears. Let $ N $ be the number of coin flips. At this point, you put $ m ^ N $ into one envelope, and put $ m ^ {N-1} $ into another envelope. Let $ X $ be the amount of money in the envelope (envelope A) you opened, and $ Y $ be the amount of money in an envelope (envelope B). Now suppose there is only one dollar in A, and obviously B contains $ m $. You should change the envelope. When A contains $ m ^ n $, B contains either $ m ^ {n-1} $ or $ m ^ {n + 1} $. Since $ N $ has a geometric distribution column, we have:</p>
<p>$$ \ frac {P (Y = m ^ {m + 1} | X = m ^ n)} {P (Y = m ^ {m-1} | X = m ^ n)} = \ frac {P ( Y = m ^ {m + 1}, X = m ^ n)} {P (Y = m ^ {m-1}, X = m ^ n)} = \ frac {P (N = n + 1)} {P (N = n)} = \ frac {1} {2} $$</p>
<p>This way we have:</p>
<p>$$ P (Y = m ^ {m-1} | X = m ^ n) = \ frac {2} {3}, P (Y = m ^ {m + 1} | X = m ^ n) = \ frac {1} {3} $$</p>
<p>$$ E \ {Number of money in envelope B | x = m ^ n } = \ frac {2} {3} m ^ {n-1} + \ frac {1} {3} m ^ {n + 1 } = \ frac {2 + m ^ 2} {3m} \ cdot m ^ n $$</p>
<p>The necessary and sufficient condition of $ \ frac {2 + m ^ 2} {3m}&gt; 1 $ is $ m ^ 2-3m + 2&gt; 0 $ or $ (m-1) (m-2)&gt; 0 $. If $ m&gt; 2 $, then:</p>
<p>$$ E [Number of money in envelope B | X = m ^ n]&gt; m ^ n $$</p>
<p>In this way, in order to get the maximum expected bonus, you should turn to the envelope $ B $. In this example, due to the value of $ x $ for all,</p>
<p>$$ E [Y | X = x]&gt; x $$</p>
<p>You choose B. Intuitively, using the total expectation theorem, there should be a conclusion $ E [Y]&gt; E [X] $. However, since $ X $ and $ Y $ have the same probability function (PMFs, probability mass function (PMF)), the conclusion $ E [Y]&gt; E [X] $ cannot be established. In fact, we have:</p>
<p>$$ E [Y] = E [X] = \ infty $$</p>
<p>This conclusion does not contradict $ E [Y | X = x]&gt; x, \ forall x $. When $ E [Y] = E [X] = \ infty $, using the relationship $ E [Y | X = x]&gt; x $ and converting the envelope does not improve the average bonus. Thereby solving the paradox problem.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2017/08/23/mean_and_variance_of_the_geometric/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/23/mean_and_variance_of_the_geometric/" class="post-title-link" itemprop="url">Classic Excerpt-Mean and Variance of Geometric Random Variables</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-23 22:16:00" itemprop="dateCreated datePublished" datetime="2017-08-23T22:16:00+05:30">2017-08-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 16:34:40" itemprop="dateModified" datetime="2020-04-09T16:34:40+05:30">2020-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning-Maths/" itemprop="url" rel="index"><span itemprop="name">Machine Learning Maths</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>1.7k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>2 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>This article is excerpted from [Introduction to probability, 2nd Edition] (<a href="http://www.athenasc.com/probbook.html" target="_blank" rel="noopener">http://www.athenasc.com/probbook.html</a>) Example 2.17 mean_and_variance_of_the_geometric</p>
<p>You write a piece of computer software again and again, and every time you write it there is a probability of success $ p $. Assume that each success is independent of previous historical records. Let $ X $ be the number of times you wrote until you succeeded (the last time you succeeded!) What are the expectations and variance of $ X $?</p>
<p>Since $ X $ is a geometric random variable, then we regard $ X $ as a geometric random variable, and the probability mass function is:</p>
<p>$$ p_X (k) = (1-p) ^ {k-1} p, k = 1, 2, …. $$</p>
<p>Then the variance and mean of $ X $ are:</p>
<p>$$ E [X] = \ sum \ limits_ {k = 1} ^ {\ infty} k (1-p) ^ {k-1} p, var (X) = \ sum \ limits_ {k = 1} ^ {\ infty} (kE [X]) ^ 2 (1-p) ^ {k-1} p $$</p>
<p>But measuring these infinity and a little trouble. We use the full expectation theorem to calculate. Remember $ A_1 = \ {X = 1 } = \ {\ text {first try is a success} }, A_2 = \ {X&gt; 1 } = \ {\ text {first try is a failure} } $ . If it succeeds the first time, you get $ X = 1 $, and</p>
<p>$$ E [X | X = 1] = \ sum \ limits _ {} ^ {} xp_ {X | X = 1} = 1p_ {1 | X = 1} = 1 $$</p>
<p>If the first attempt fails (X&gt; 1), we will waste one attempt, we start again, because under the condition of the first failure, then the average value of the number of attempts $ X $ must be greater than 1, the remaining attempts The expectation is $ E [X] $.</p>
<p>$$ E [X | X&gt; 1] = E [X + 1] = 1 + E [X] $$</p>
<p>Therefore, by the expectation theorem:</p>
<p>$$<br>\ begin {eqnarray}<br>E [X] &amp; = &amp; P [X = 1] E [X | X = 1] + P (X&gt; 1) E [X | X&gt; 1] \<br>&amp; = &amp; p + (1-p) (1 + E [X])<br>\ end {eqnarray}<br>$$<br>So you can get:</p>
<p>$$ E [X] = \ frac {1} {p} $$</p>
<p>Similar reasoning, we also get</p>
<p>$$ E [X ^ 2 | X = 1] = 1, \ quad E [X ^ 2 | X&gt; 1] = E [(1 + X) ^ 2] = 1 + 2E [X] + E [X ^ 2] $$</p>
<p>therefore,</p>
<p>$$ E [X ^ 2] = p + (1-p) (1 + 2E [X] + E [X ^ 2]) $$</p>
<p>Combined with $ E [X] = \ frac {1} {p} $, you get:</p>
<p>$$ E [X ^ 2] = \ frac {2} {p ^ 2}-\ frac {1} {p} $$</p>
<p>to sum up:</p>
<p>$$ var (X) = E [X ^ 2]-(E [X]) ^ 2 = \ frac {2} {p ^ 2}-\ frac {1} {p}-\ frac {1} {p ^ 2} = \ frac {1-p} {p ^ 2} $$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/16/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><span class="page-number current">17</span><a class="page-number" href="/page/18/">18</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><a class="extend next" rel="next" href="/page/18/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Karan"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Karan</p>
  <div class="site-description" itemprop="description">Refuse to Fall</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">87</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:snakecoding.py@gmail.com" title="Get In Touch → mailto:snakecoding.py@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>Get In Touch</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Karan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">2.4m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">35:43</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


    </div>
</body>
</html>
