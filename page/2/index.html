<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">

<script>
    (function(){
        if(''){
                         If (prompt('Please enter the article password') !== ''){
                                 Alert('Password error!');
                history.back();
            }
        }
    })();
</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"snakecoding.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":true,"sidebar":{"position":"left","display":"post","padding":20,"offset":15,"onmobile":false},"copycode":{"enable":true,"show_result":"flat","style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":false},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Refuse to Fall">
<meta property="og:type" content="website">
<meta property="og:title" content="Machine Learning">
<meta property="og:url" content="https://snakecoding.com/page/2/index.html">
<meta property="og:site_name" content="Machine Learning">
<meta property="og:description" content="Refuse to Fall">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Karan">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://snakecoding.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Machine Learning</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Machine Learning" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Machine Learning</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Data Science</p>
      <a>
        <img class="custom-logo-image" src="/images/custom-logo.jpg" alt="Machine Learning">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">15</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">6</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">87</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="#" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/06/03/Emojify+-+v2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/03/Emojify+-+v2/" class="post-title-link" itemprop="url">Emojify</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-06-03 00:00:00" itemprop="dateCreated datePublished" datetime="2018-06-03T00:00:00+05:30">2018-06-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 14:57:25" itemprop="dateModified" datetime="2020-04-09T14:57:25+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>32k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>29 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>This is one of my personal programming assignments after studying the course <a href="https://www.coursera.org/learn/nlp-sequence-models/" target="_blank" rel="noopener">nlp sequence models</a> at the 2nd week and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.</p>
<h1 id="Emojify"><a href="#Emojify" class="headerlink" title="Emojify!"></a>Emojify!</h1><p>Welcome to the second assignment of Week 2. You are going to use word vector representations to build an Emojifier. </p>
<p>Have you ever wanted to make your text messages more expressive? Your emojifier app will help you do that. So rather than writing “Congratulations on the promotion! Lets get coffee and talk. Love you!” the emojifier can automatically turn this into “Congratulations on the promotion! 👍 Lets get coffee and talk. ☕️ Love you! ❤️”</p>
<p>You will implement a model which inputs a sentence (such as “Let’s go see the baseball game tonight!”) and finds the most appropriate emoji to be used with this sentence (⚾️). In many emoji interfaces, you need to remember that ❤️ is the “heart” symbol rather than the “love” symbol. But using word vectors, you’ll see that even if your training set explicitly relates only a few words to a particular emoji, your algorithm will be able to generalize and associate words in the test set to the same emoji even if those words don’t even appear in the training set. This allows you to build an accurate classifier mapping from sentences to emojis, even using a small training set. </p>
<p>In this exercise, you’ll start with a baseline model (Emojifier-V1) using word embeddings, then build a more sophisticated model (Emojifier-V2) that further incorporates an LSTM. </p>
<p>Lets get started! Run the following cell to load the package you are going to use. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> emo_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> emoji</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<h2 id="1-Baseline-model-Emojifier-V1"><a href="#1-Baseline-model-Emojifier-V1" class="headerlink" title="1 - Baseline model: Emojifier-V1"></a>1 - Baseline model: Emojifier-V1</h2><h3 id="1-1-Dataset-EMOJISET"><a href="#1-1-Dataset-EMOJISET" class="headerlink" title="1.1 - Dataset EMOJISET"></a>1.1 - Dataset EMOJISET</h3><p>Let’s start by building a simple baseline classifier. </p>
<p>You have a tiny dataset (X, Y) where:</p>
<ul>
<li>X contains 127 sentences (strings)</li>
<li>Y contains a integer label between 0 and 4 corresponding to an emoji for each sentence</li>
</ul>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week2/Emojify/images/data_set.png" style="width:700px;height:300px;">
<caption><center> **Figure 1**: EMOJISET - a classification problem with 5 classes. A few examples of sentences are given here. </center></caption>

<p>Let’s load the dataset using the code below. We split the dataset between training (127 examples) and testing (56 examples).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, Y_train = read_csv(<span class="string">'data/train_emoji.csv'</span>)</span><br><span class="line">X_test, Y_test = read_csv(<span class="string">'data/tesss.csv'</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">maxLen = len(max(X_train, key=len).split())</span><br></pre></td></tr></table></figure>

<p>Run the following cell to print sentences from X_train and corresponding labels from Y_train. Change <code>index</code> to see different examples. Because of the font the iPython notebook uses, the heart emoji may be colored black rather than red.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">index = <span class="number">1</span></span><br><span class="line">print(X_train[index], label_to_emoji(Y_train[index]))</span><br></pre></td></tr></table></figure>

<pre><code>I am proud of your achievements 😄</code></pre><h3 id="1-2-Overview-of-the-Emojifier-V1"><a href="#1-2-Overview-of-the-Emojifier-V1" class="headerlink" title="1.2 - Overview of the Emojifier-V1"></a>1.2 - Overview of the Emojifier-V1</h3><p>In this part, you are going to implement a baseline model called “Emojifier-v1”.  </p>
<center>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week2/Emojify/images/image_1.png" style="width:900px;height:300px;">
<caption><center> **Figure 2**: Baseline model (Emojifier-V1).</center></caption>
</center>

<p>The input of the model is a string corresponding to a sentence (e.g. “I love you). In the code, the output will be a probability vector of shape (1,5), that you then pass in an argmax layer to extract the index of the most likely emoji output.</p>
<p>To get our labels into a format suitable for training a softmax classifier, lets convert $Y$ from its current shape  current shape $(m, 1)$ into a “one-hot representation” $(m, 5)$, where each row is a one-hot vector giving the label of one example, You can do so using this next code snipper. Here, <code>Y_oh</code> stands for “Y-one-hot” in the variable names <code>Y_oh_train</code> and <code>Y_oh_test</code>: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Y_oh_train = convert_to_one_hot(Y_train, C = <span class="number">5</span>)</span><br><span class="line">Y_oh_test = convert_to_one_hot(Y_test, C = <span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>Let’s see what <code>convert_to_one_hot()</code> did. Feel free to change <code>index</code> to print out different values. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">index = <span class="number">50</span></span><br><span class="line">print(Y_train[index], <span class="string">"is converted into one hot"</span>, Y_oh_train[index])</span><br></pre></td></tr></table></figure>

<pre><code>0 is converted into one hot [ 1.  0.  0.  0.  0.]</code></pre><p>All the data is now ready to be fed into the Emojify-V1 model. Let’s implement the model!</p>
<h3 id="1-3-Implementing-Emojifier-V1"><a href="#1-3-Implementing-Emojifier-V1" class="headerlink" title="1.3 - Implementing Emojifier-V1"></a>1.3 - Implementing Emojifier-V1</h3><p>As shown in Figure (2), the first step is to convert an input sentence into the word vector representation, which then get averaged together. Similar to the previous exercise, we will use pretrained 50-dimensional GloVe embeddings. Run the following cell to load the <code>word_to_vec_map</code>, which contains all the vector representations.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(<span class="string">'data/glove.6B.50d.txt'</span>)</span><br></pre></td></tr></table></figure>

<p>You’ve loaded:</p>
<ul>
<li><code>word_to_index</code>: dictionary mapping from words to their indices in the vocabulary (400,001 words, with the valid indices ranging from 0 to 400,000)</li>
<li><code>index_to_word</code>: dictionary mapping from indices to their corresponding words in the vocabulary</li>
<li><code>word_to_vec_map</code>: dictionary mapping words to their GloVe vector representation.</li>
</ul>
<p>Run the following cell to check if it works.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">word = <span class="string">"cucumber"</span></span><br><span class="line">index = <span class="number">289846</span></span><br><span class="line">print(<span class="string">"the index of"</span>, word, <span class="string">"in the vocabulary is"</span>, word_to_index[word])</span><br><span class="line">print(<span class="string">"the"</span>, str(index) + <span class="string">"th word in the vocabulary is"</span>, index_to_word[index])</span><br></pre></td></tr></table></figure>

<pre><code>the index of cucumber in the vocabulary is 113317
the 289846th word in the vocabulary is potatos</code></pre><p><strong>Exercise</strong>: Implement <code>sentence_to_avg()</code>. You will need to carry out two steps:</p>
<ol>
<li>Convert every sentence to lower-case, then split the sentence into a list of words. <code>X.lower()</code> and <code>X.split()</code> might be useful. </li>
<li>For each word in the sentence, access its GloVe representation. Then, average all these values.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: sentence_to_avg</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentence_to_avg</span><span class="params">(sentence, word_to_vec_map)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word</span></span><br><span class="line"><span class="string">    and averages its value into a single vector encoding the meaning of the sentence.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    sentence -- string, one training example from X</span></span><br><span class="line"><span class="string">    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Step 1: Split sentence into list of lower case words (≈ 1 line)</span></span><br><span class="line">    words = sentence.lower().split();</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize the average word vector, should have the same shape as your word vectors.</span></span><br><span class="line">    avg = np.zeros((word_to_vec_map[words[<span class="number">0</span>]].shape));</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: average the word vectors. You can loop over the words in the list "words".</span></span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> words:</span><br><span class="line">        avg += word_to_vec_map[w];</span><br><span class="line">    avg = avg / len(words);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> avg</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">avg = sentence_to_avg(<span class="string">"Morrocan couscous is my favorite dish"</span>, word_to_vec_map)</span><br><span class="line">print(<span class="string">"avg = "</span>, avg)</span><br></pre></td></tr></table></figure>

<pre><code>avg =  [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983
 -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867
  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767
  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061
  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265
  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925
 -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333
 -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433
  0.1445417   0.09808667]</code></pre><p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **avg= **
        </td>
        <td>
           [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983
 -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867
  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767
  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061
  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265
  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925
 -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333
 -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433
  0.1445417   0.09808667]
        </td>
    </tr>
</table>

<h4 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h4><p>You now have all the pieces to finish implementing the <code>model()</code> function. After using <code>sentence_to_avg()</code> you need to pass the average through forward propagation, compute the cost, and then backpropagate to update the softmax’s parameters. </p>
<p><strong>Exercise</strong>: Implement the <code>model()</code> function described in Figure (2). Assuming here that $Yoh$ (“Y one hot”) is the one-hot encoding of the output labels, the equations you need to implement in the forward pass and to compute the cross-entropy cost are:<br>$$ z^{(i)} = W . avg^{(i)} + b$$<br>$$ a^{(i)} = softmax(z^{(i)})$$<br>$$ \mathcal{L}^{(i)} = - \sum_{k = 0}^{n_y - 1} Yoh^{(i)}_k * log(a^{(i)}_k)$$</p>
<p>It is possible to come up with a more efficient vectorized implementation. But since we are using a for-loop to convert the sentences one at a time into the avg^{(i)} representation anyway, let’s not bother this time. </p>
<p>We provided you a function <code>softmax()</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: model</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X, Y, word_to_vec_map, learning_rate = <span class="number">0.01</span>, num_iterations = <span class="number">400</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Model to train word vector representations in numpy.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input data, numpy array of sentences as strings, of shape (m, 1)</span></span><br><span class="line"><span class="string">    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)</span></span><br><span class="line"><span class="string">    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation</span></span><br><span class="line"><span class="string">    learning_rate -- learning_rate for the stochastic gradient descent algorithm</span></span><br><span class="line"><span class="string">    num_iterations -- number of iterations</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    pred -- vector of predictions, numpy-array of shape (m, 1)</span></span><br><span class="line"><span class="string">    W -- weight matrix of the softmax layer, of shape (n_y, n_h)</span></span><br><span class="line"><span class="string">    b -- bias of the softmax layer, of shape (n_y,)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define number of training examples</span></span><br><span class="line">    m = Y.shape[<span class="number">0</span>]                          <span class="comment"># number of training examples</span></span><br><span class="line">    n_y = <span class="number">5</span>                                 <span class="comment"># number of classes  </span></span><br><span class="line">    n_h = <span class="number">50</span>                                <span class="comment"># dimensions of the GloVe vectors </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize parameters using Xavier initialization</span></span><br><span class="line">    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)</span><br><span class="line">    b = np.zeros((n_y,))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Convert Y to Y_onehot with n_y classes</span></span><br><span class="line">    Y_oh = convert_to_one_hot(Y, C = n_y) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Optimization loop</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(num_iterations):                       <span class="comment"># Loop over the number of iterations</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                                <span class="comment"># Loop over the training examples</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">### START CODE HERE ### (≈ 4 lines of code)</span></span><br><span class="line">            <span class="comment"># Average the word vectors of the words from the i'th training example</span></span><br><span class="line">            avg = sentence_to_avg(X[i], word_to_vec_map);</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Forward propagate the avg through the softmax layer</span></span><br><span class="line">            z = np.dot(W, avg) + b;</span><br><span class="line">            a = softmax(z);</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Compute cost using the i'th training label's one hot representation and "A" (the output of the softmax)</span></span><br><span class="line">            cost = np.sum(-Y_oh[i] * np.log(a));</span><br><span class="line">            <span class="comment">### END CODE HERE ###</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Compute gradients </span></span><br><span class="line">            dz = a - Y_oh[i]</span><br><span class="line">            dW = np.dot(dz.reshape(n_y,<span class="number">1</span>), avg.reshape(<span class="number">1</span>, n_h))</span><br><span class="line">            db = dz</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Update parameters with Stochastic Gradient Descent</span></span><br><span class="line">            W = W - learning_rate * dW</span><br><span class="line">            b = b - learning_rate * db</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Epoch: "</span> + str(t) + <span class="string">" --- cost = "</span> + str(cost))</span><br><span class="line">            pred = predict(X, Y, W, b, word_to_vec_map)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pred, W, b</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">print(X_train.shape)</span><br><span class="line">print(Y_train.shape)</span><br><span class="line">print(np.eye(<span class="number">5</span>)[Y_train.reshape(<span class="number">-1</span>)].shape)</span><br><span class="line">print(X_train[<span class="number">0</span>])</span><br><span class="line">print(type(X_train))</span><br><span class="line">Y = np.asarray([<span class="number">5</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">5</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line">print(Y.shape)</span><br><span class="line"></span><br><span class="line">X = np.asarray([<span class="string">'I am going to the bar tonight'</span>, <span class="string">'I love you'</span>, <span class="string">'miss you my dear'</span>,</span><br><span class="line"> <span class="string">'Lets go party and drinks'</span>,<span class="string">'Congrats on the new job'</span>,<span class="string">'Congratulations'</span>,</span><br><span class="line"> <span class="string">'I am so happy for you'</span>, <span class="string">'Why are you feeling bad'</span>, <span class="string">'What is wrong with you'</span>,</span><br><span class="line"> <span class="string">'You totally deserve this prize'</span>, <span class="string">'Let us go play football'</span>,</span><br><span class="line"> <span class="string">'Are you down for football this afternoon'</span>, <span class="string">'Work hard play harder'</span>,</span><br><span class="line"> <span class="string">'It is suprising how people can be dumb sometimes'</span>,</span><br><span class="line"> <span class="string">'I am very disappointed'</span>,<span class="string">'It is the best day in my life'</span>,</span><br><span class="line"> <span class="string">'I think I will end up alone'</span>,<span class="string">'My life is so boring'</span>,<span class="string">'Good job'</span>,</span><br><span class="line"> <span class="string">'Great so awesome'</span>])</span><br><span class="line"></span><br><span class="line">print(X.shape)</span><br><span class="line">print(np.eye(<span class="number">5</span>)[Y_train.reshape(<span class="number">-1</span>)].shape)</span><br><span class="line">print(type(X_train))</span><br></pre></td></tr></table></figure>

<pre><code>(132,)
(132,)
(132, 5)
never talk to me again
&lt;class &apos;numpy.ndarray&apos;&gt;
(20,)
(20,)
(132, 5)
&lt;class &apos;numpy.ndarray&apos;&gt;</code></pre><p>Run the next cell to train your model and learn the softmax parameters (W,b). </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pred, W, b = model(X_train, Y_train, word_to_vec_map)</span><br><span class="line">print(pred)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch: 0 --- cost = 1.95204988128
Accuracy: 0.348484848485
Epoch: 100 --- cost = 0.0797181872601
Accuracy: 0.931818181818
Epoch: 200 --- cost = 0.0445636924368
Accuracy: 0.954545454545
Epoch: 300 --- cost = 0.0343226737879
Accuracy: 0.969696969697
[[ 3.]
 [ 2.]
 [ 3.]
 [ 0.]
 [ 4.]
 [ 0.]
 [ 3.]
 [ 2.]
 [ 3.]
 [ 1.]
 [ 3.]
 [ 3.]
 [ 1.]
 [ 3.]
 [ 2.]
 [ 3.]
 [ 2.]
 [ 3.]
 [ 1.]
 [ 2.]
 [ 3.]
 [ 0.]
 [ 2.]
 [ 2.]
 [ 2.]
 [ 1.]
 [ 4.]
 [ 3.]
 [ 3.]
 [ 4.]
 [ 0.]
 [ 3.]
 [ 4.]
 [ 2.]
 [ 0.]
 [ 3.]
 [ 2.]
 [ 2.]
 [ 3.]
 [ 4.]
 [ 2.]
 [ 2.]
 [ 0.]
 [ 2.]
 [ 3.]
 [ 0.]
 [ 3.]
 [ 2.]
 [ 4.]
 [ 3.]
 [ 0.]
 [ 3.]
 [ 3.]
 [ 3.]
 [ 4.]
 [ 2.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 2.]
 [ 3.]
 [ 1.]
 [ 0.]
 [ 0.]
 [ 0.]
 [ 3.]
 [ 4.]
 [ 4.]
 [ 2.]
 [ 2.]
 [ 1.]
 [ 2.]
 [ 0.]
 [ 3.]
 [ 2.]
 [ 2.]
 [ 0.]
 [ 3.]
 [ 3.]
 [ 1.]
 [ 2.]
 [ 1.]
 [ 2.]
 [ 2.]
 [ 4.]
 [ 3.]
 [ 3.]
 [ 2.]
 [ 4.]
 [ 0.]
 [ 0.]
 [ 3.]
 [ 3.]
 [ 3.]
 [ 3.]
 [ 2.]
 [ 0.]
 [ 1.]
 [ 2.]
 [ 3.]
 [ 0.]
 [ 2.]
 [ 2.]
 [ 2.]
 [ 3.]
 [ 2.]
 [ 2.]
 [ 2.]
 [ 4.]
 [ 1.]
 [ 1.]
 [ 3.]
 [ 3.]
 [ 4.]
 [ 1.]
 [ 2.]
 [ 1.]
 [ 1.]
 [ 3.]
 [ 1.]
 [ 0.]
 [ 4.]
 [ 0.]
 [ 3.]
 [ 3.]
 [ 4.]
 [ 4.]
 [ 1.]
 [ 4.]
 [ 3.]
 [ 0.]
 [ 2.]]</code></pre><p><strong>Expected Output</strong> (on a subset of iterations):</p>
<table>
    <tr>
        <td>
            **Epoch: 0**
        </td>
        <td>
           cost = 1.95204988128
        </td>
        <td>
           Accuracy: 0.348484848485
        </td>
    </tr>


<tr>
        <td>
            **Epoch: 100**
        </td>
        <td>
           cost = 0.0797181872601
        </td>
        <td>
           Accuracy: 0.931818181818
        </td>
    </tr>

<tr>
        <td>
            **Epoch: 200**
        </td>
        <td>
           cost = 0.0445636924368
        </td>
        <td>
           Accuracy: 0.954545454545
        </td>
    </tr>

<pre><code>&lt;tr&gt;
    &lt;td&gt;
        **Epoch: 300**
    &lt;/td&gt;
    &lt;td&gt;
       cost = 0.0343226737879
    &lt;/td&gt;
    &lt;td&gt;
       Accuracy: 0.969696969697
    &lt;/td&gt;
&lt;/tr&gt;</code></pre></table>

<p>Great! Your model has pretty high accuracy on the training set. Lets now see how it does on the test set. </p>
<h3 id="1-4-Examining-test-set-performance"><a href="#1-4-Examining-test-set-performance" class="headerlink" title="1.4 - Examining test set performance"></a>1.4 - Examining test set performance</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Training set:"</span>)</span><br><span class="line">pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)</span><br><span class="line">print(<span class="string">'Test set:'</span>)</span><br><span class="line">pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)</span><br></pre></td></tr></table></figure>

<pre><code>Training set:
Accuracy: 0.977272727273
Test set:
Accuracy: 0.857142857143</code></pre><p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **Train set accuracy**
        </td>
        <td>
           97.7
        </td>
    </tr>
    <tr>
        <td>
            **Test set accuracy**
        </td>
        <td>
           85.7
        </td>
    </tr>
</table>

<p>Random guessing would have had 20% accuracy given that there are 5 classes. This is pretty good performance after training on only 127 examples. </p>
<p>In the training set, the algorithm saw the sentence “<em>I love you</em>“ with the label ❤️. You can check however that the word “adore” does not appear in the training set. Nonetheless, lets see what happens if you write “<em>I adore you</em>.”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_my_sentences = np.array([<span class="string">"i adore you"</span>, <span class="string">"i love you"</span>, <span class="string">"funny lol"</span>, <span class="string">"lets play with a ball"</span>, <span class="string">"food is ready"</span>, <span class="string">"not feeling happy"</span>])</span><br><span class="line">Y_my_labels = np.array([[<span class="number">0</span>], [<span class="number">0</span>], [<span class="number">2</span>], [<span class="number">1</span>], [<span class="number">4</span>],[<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)</span><br><span class="line">print_predictions(X_my_sentences, pred)</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy: 0.833333333333

i adore you ❤️
i love you ❤️
funny lol 😄
lets play with a ball ⚾
food is ready 🍴
not feeling happy 😄</code></pre><p>Amazing! Because <em>adore</em> has a similar embedding as <em>love</em>, the algorithm has generalized correctly even to a word it has never seen before. Words such as <em>heart</em>, <em>dear</em>, <em>beloved</em> or <em>adore</em> have embedding vectors similar to <em>love</em>, and so might work too—feel free to modify the inputs above and try out a variety of input sentences. How well does it work?</p>
<p>Note though that it doesn’t get “not feeling happy” correct. This algorithm ignores word ordering, so is not good at understanding phrases like “not happy.” </p>
<p>Printing the confusion matrix can also help understand which classes are more difficult for your model. A confusion matrix shows how often an example whose label is one class (“actual” class) is mislabeled by the algorithm with a different class (“predicted” class). </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(Y_test.shape)</span><br><span class="line">print(<span class="string">'           '</span>+ label_to_emoji(<span class="number">0</span>)+ <span class="string">'    '</span> + label_to_emoji(<span class="number">1</span>) + <span class="string">'    '</span> +  label_to_emoji(<span class="number">2</span>)+ <span class="string">'    '</span> + label_to_emoji(<span class="number">3</span>)+<span class="string">'   '</span> + label_to_emoji(<span class="number">4</span>))</span><br><span class="line">print(pd.crosstab(Y_test, pred_test.reshape(<span class="number">56</span>,), rownames=[<span class="string">'Actual'</span>], colnames=[<span class="string">'Predicted'</span>], margins=<span class="literal">True</span>))</span><br><span class="line">plot_confusion_matrix(Y_test, pred_test)</span><br></pre></td></tr></table></figure>

<pre><code>(56,)
           ❤️    ⚾    😄    😞   🍴
Predicted  0.0  1.0  2.0  3.0  4.0  All
Actual                                 
0            6    0    0    1    0    7
1            0    8    0    0    0    8
2            2    0   16    0    0   18
3            1    1    2   12    0   16
4            0    0    1    0    6    7
All          9    9   19   13    6   56</code></pre><p><img src="output_34_1.png" alt="png"></p>
<font color='blue'>
**What you should remember from this part**:
- Even with a 127 training examples, you can get a reasonably good model for Emojifying. This is due to the generalization power word vectors gives you. 
- Emojify-V1 will perform poorly on sentences such as *"This movie is not good and not enjoyable"* because it doesn't understand combinations of words--it just averages all the words' embedding vectors together, without paying attention to the ordering of words. You will build a better algorithm in the next part. 


<h2 id="2-Emojifier-V2-Using-LSTMs-in-Keras"><a href="#2-Emojifier-V2-Using-LSTMs-in-Keras" class="headerlink" title="2 - Emojifier-V2: Using LSTMs in Keras:"></a>2 - Emojifier-V2: Using LSTMs in Keras:</h2><p>Let’s build an LSTM model that takes as input word sequences. This model will be able to take word ordering into account. Emojifier-V2 will continue to use pre-trained word embeddings to represent words, but will feed them into an LSTM, whose job it is to predict the most appropriate emoji. </p>
<p>Run the following cell to load the Keras packages.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Input, Dropout, LSTM, Activation</span><br><span class="line"><span class="keyword">from</span> keras.layers.embeddings <span class="keyword">import</span> Embedding</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> sequence</span><br><span class="line"><span class="keyword">from</span> keras.initializers <span class="keyword">import</span> glorot_uniform</span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Using TensorFlow backend.</code></pre><h3 id="2-1-Overview-of-the-model"><a href="#2-1-Overview-of-the-model" class="headerlink" title="2.1 - Overview of the model"></a>2.1 - Overview of the model</h3><p>Here is the Emojifier-v2 you will implement:</p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week2/Emojify/images/emojifier-v2.png" style="width:700px;height:400px;"> <br></p>
<caption><center> **Figure 3**: Emojifier-V2. A 2-layer LSTM sequence classifier. </center></caption>



<h3 id="2-2-Keras-and-mini-batching"><a href="#2-2-Keras-and-mini-batching" class="headerlink" title="2.2 Keras and mini-batching"></a>2.2 Keras and mini-batching</h3><p>In this exercise, we want to train Keras using mini-batches. However, most deep learning frameworks require that all sequences in the same mini-batch have the same length. This is what allows vectorization to work: If you had a 3-word sentence and a 4-word sentence, then the computations needed for them are different (one takes 3 steps of an LSTM, one takes 4 steps) so it’s just not possible to do them both at the same time.</p>
<p>The common solution to this is to use padding. Specifically, set a maximum sequence length, and pad all sequences to the same length. For example, of the maximum sequence length is 20, we could pad every sentence with “0”s so that each input sentence is of length 20. Thus, a sentence “i love you” would be represented as $(e_{i}, e_{love}, e_{you}, \vec{0}, \vec{0}, \ldots, \vec{0})$. In this example, any sentences longer than 20 words would have to be truncated. One simple way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set. </p>
<h3 id="2-3-The-Embedding-layer"><a href="#2-3-The-Embedding-layer" class="headerlink" title="2.3 - The Embedding layer"></a>2.3 - The Embedding layer</h3><p>In Keras, the embedding matrix is represented as a “layer”, and maps positive integers (indices corresponding to words) into dense vectors of fixed size (the embedding vectors). It can be trained or initialized with a pretrained embedding. In this part, you will learn how to create an <a href="https://keras.io/layers/embeddings/" target="_blank" rel="noopener">Embedding()</a> layer in Keras, initialize it with the GloVe 50-dimensional vectors loaded earlier in the notebook. Because our training set is quite small, we will not update the word embeddings but will instead leave their values fixed. But in the code below, we’ll show you how Keras allows you to either train or leave fixed this layer.  </p>
<p>The <code>Embedding()</code> layer takes an integer matrix of size (batch size, max input length) as input. This corresponds to sentences converted into lists of indices (integers), as shown in the figure below.</p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week2/Emojify/images/embedding1.png" style="width:700px;height:250px;">
<caption><center> **Figure 4**: Embedding layer. This example shows the propagation of two examples through the embedding layer. Both have been zero-padded to a length of `max_len=5`. The final dimension of the representation is  `(2,max_len,50)` because the word embeddings we are using are 50 dimensional. </center></caption>

<p>The largest integer (i.e. word index) in the input should be no larger than the vocabulary size. The layer outputs an array of shape (batch size, max input length, dimension of word vectors).</p>
<p>The first step is to convert all your training sentences into lists of indices, and then zero-pad all these lists so that their length is the length of the longest sentence. </p>
<p><strong>Exercise</strong>: Implement the function below to convert X (array of sentences as strings) into an array of indices corresponding to words in the sentences. The output shape should be such that it can be given to <code>Embedding()</code> (described in Figure 4). </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: sentences_to_indices</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentences_to_indices</span><span class="params">(X, word_to_index, max_len)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.</span></span><br><span class="line"><span class="string">    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- array of sentences (strings), of shape (m, 1)</span></span><br><span class="line"><span class="string">    word_to_index -- a dictionary containing the each word mapped to its index</span></span><br><span class="line"><span class="string">    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    m = X.shape[<span class="number">0</span>]                                   <span class="comment"># number of training examples</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)</span></span><br><span class="line">    X_indices = np.zeros((m, max_len));</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                               <span class="comment"># loop over training examples</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Convert the ith training sentence in lower case and split is into words. You should get a list of words.</span></span><br><span class="line">        sentence_words = X[i].lower().split();</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Initialize j to 0</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Loop over the words of sentence_words</span></span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> sentence_words:</span><br><span class="line">            <span class="comment"># Set the (i,j)th entry of X_indices to the index of the correct word.</span></span><br><span class="line">            X_indices[i, j] = word_to_index[w];</span><br><span class="line">            <span class="comment"># Increment j to j + 1</span></span><br><span class="line">            j = j + <span class="number">1</span>;</span><br><span class="line">            </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X_indices</span><br></pre></td></tr></table></figure>

<p>Run the following cell to check what <code>sentences_to_indices()</code> does, and check your results.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X1 = np.array([<span class="string">"funny lol"</span>, <span class="string">"lets play baseball"</span>, <span class="string">"food is ready for you"</span>])</span><br><span class="line">X1_indices = sentences_to_indices(X1,word_to_index, max_len = <span class="number">5</span>)</span><br><span class="line">print(<span class="string">"X1 ="</span>, X1)</span><br><span class="line">print(<span class="string">"X1_indices ="</span>, X1_indices)</span><br></pre></td></tr></table></figure>

<pre><code>X1 = [&apos;funny lol&apos; &apos;lets play baseball&apos; &apos;food is ready for you&apos;]
X1_indices = [[ 155345.  225122.       0.       0.       0.]
 [ 220930.  286375.   69714.       0.       0.]
 [ 151204.  192973.  302254.  151349.  394475.]]</code></pre><p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **X1 =**
        </td>
        <td>
           ['funny lol' 'lets play football' 'food is ready for you']
        </td>
    </tr>
    <tr>
        <td>
            **X1_indices =**
        </td>
        <td>
           [[ 155345.  225122.       0.       0.       0.] <br>
            [ 220930.  286375.  151266.       0.       0.] <br>
            [ 151204.  192973.  302254.  151349.  394475.]]
        </td>
    </tr>
</table>

<p>Let’s build the <code>Embedding()</code> layer in Keras, using pre-trained word vectors. After this layer is built, you will pass the output of <code>sentences_to_indices()</code> to it as an input, and the <code>Embedding()</code> layer will return the word embeddings for a sentence. </p>
<p><strong>Exercise</strong>: Implement <code>pretrained_embedding_layer()</code>. You will need to carry out the following steps:</p>
<ol>
<li>Initialize the embedding matrix as a numpy array of zeroes with the correct shape.</li>
<li>Fill in the embedding matrix with all the word embeddings extracted from <code>word_to_vec_map</code>.</li>
<li>Define Keras embedding layer. Use <a href="https://keras.io/layers/embeddings/" target="_blank" rel="noopener">Embedding()</a>. Be sure to make this layer non-trainable, by setting <code>trainable = False</code> when calling <code>Embedding()</code>. If you were to set <code>trainable = True</code>, then it will allow the optimization algorithm to modify the values of the word embeddings. </li>
<li>Set the embedding weights to be equal to the embedding matrix </li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: pretrained_embedding_layer</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pretrained_embedding_layer</span><span class="params">(word_to_vec_map, word_to_index)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.</span></span><br><span class="line"><span class="string">    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    embedding_layer -- pretrained layer Keras instance</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    vocab_len = len(word_to_index) + <span class="number">1</span>                  <span class="comment"># adding 1 to fit Keras embedding (requirement)</span></span><br><span class="line">    emb_dim = word_to_vec_map[<span class="string">"cucumber"</span>].shape[<span class="number">0</span>]      <span class="comment"># define dimensionality of your GloVe word vectors (= 50)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)</span></span><br><span class="line">    emb_matrix = np.zeros((vocab_len, emb_dim));</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Set each row "index" of the embedding matrix to be the word vector representation of the "index"th word of the vocabulary</span></span><br><span class="line">    <span class="keyword">for</span> word, index <span class="keyword">in</span> word_to_index.items():</span><br><span class="line">        emb_matrix[index, :] = word_to_vec_map[word];</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define Keras embedding layer with the correct output/input sizes, make it trainable. Use Embedding(...). Make sure to set trainable=False. </span></span><br><span class="line">    embedding_layer = Embedding(vocab_len, emb_dim, trainable = <span class="literal">False</span>);</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the "None".</span></span><br><span class="line">    embedding_layer.build((<span class="literal">None</span>,))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.</span></span><br><span class="line">    embedding_layer.set_weights([emb_matrix])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> embedding_layer</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)</span><br><span class="line">print(<span class="string">"weights[0][1][3] ="</span>, embedding_layer.get_weights()[<span class="number">0</span>][<span class="number">1</span>][<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<pre><code>weights[0][1][3] = -0.3403</code></pre><p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **weights[0][1][3] =**
        </td>
        <td>
           -0.3403
        </td>
    </tr>
</table>

<h2 id="2-3-Building-the-Emojifier-V2"><a href="#2-3-Building-the-Emojifier-V2" class="headerlink" title="2.3 Building the Emojifier-V2"></a>2.3 Building the Emojifier-V2</h2><p>Lets now build the Emojifier-V2 model. You will do so using the embedding layer you have built, and feed its output to an LSTM network. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week2/Emojify/images/emojifier-v2.png" style="width:700px;height:400px;"> <br></p>
<caption><center> **Figure 3**: Emojifier-v2. A 2-layer LSTM sequence classifier. </center></caption>


<p><strong>Exercise:</strong> Implement <code>Emojify_V2()</code>, which builds a Keras graph of the architecture shown in Figure 3. The model takes as input an array of sentences of shape (<code>m</code>, <code>max_len</code>, ) defined by <code>input_shape</code>. It should output a softmax probability vector of shape (<code>m</code>, <code>C = 5</code>). You may need <code>Input(shape = ..., dtype = &#39;...&#39;)</code>, <a href="https://keras.io/layers/recurrent/#lstm" target="_blank" rel="noopener">LSTM()</a>, <a href="https://keras.io/layers/core/#dropout" target="_blank" rel="noopener">Dropout()</a>, <a href="https://keras.io/layers/core/#dense" target="_blank" rel="noopener">Dense()</a>, and <a href="https://keras.io/activations/" target="_blank" rel="noopener">Activation()</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: Emojify_V2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Emojify_V2</span><span class="params">(input_shape, word_to_vec_map, word_to_index)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Function creating the Emojify-v2 model's graph.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    input_shape -- shape of the input, usually (max_len,)</span></span><br><span class="line"><span class="string">    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation</span></span><br><span class="line"><span class="string">    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    model -- a model instance in Keras</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).</span></span><br><span class="line">    sentence_indices = Input(shape = input_shape, dtype = <span class="string">'int32'</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the embedding layer pretrained with GloVe Vectors (≈1 line)</span></span><br><span class="line">    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index);</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Propagate sentence_indices through your embedding layer, you get back the embeddings</span></span><br><span class="line">    embeddings = embedding_layer(sentence_indices);   </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Propagate the embeddings through an LSTM layer with 128-dimensional hidden state</span></span><br><span class="line">    <span class="comment"># Be careful, the returned output should be a batch of sequences.</span></span><br><span class="line">    X = LSTM(<span class="number">128</span>, return_sequences = <span class="literal">True</span>)(embeddings);</span><br><span class="line">    <span class="comment"># Add dropout with a probability of 0.5</span></span><br><span class="line">    X = Dropout(<span class="number">0.5</span>)(X);</span><br><span class="line">    <span class="comment"># Propagate X trough another LSTM layer with 128-dimensional hidden state</span></span><br><span class="line">    <span class="comment"># Be careful, the returned output should be a single hidden state, not a batch of sequences.</span></span><br><span class="line">    X = LSTM(<span class="number">128</span>, return_sequences = <span class="literal">False</span>)(X);</span><br><span class="line">    <span class="comment"># Add dropout with a probability of 0.5</span></span><br><span class="line">    X = Dropout(<span class="number">0.5</span>)(X);</span><br><span class="line">    <span class="comment"># Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.</span></span><br><span class="line">    X = Dense(<span class="number">5</span>, activation = <span class="string">'softmax'</span>)(X);</span><br><span class="line">    <span class="comment"># Add a softmax activation</span></span><br><span class="line">    X = Activation(<span class="string">'softmax'</span>)(X);</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create Model instance which converts sentence_indices into X.</span></span><br><span class="line">    model = Model(inputs = sentence_indices, outputs = X);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<p>Run the following cell to create your model and check its summary. Because all sentences in the dataset are less than 10 words, we chose <code>max_len = 10</code>.  You should see your architecture, it uses “20,223,927” parameters, of which 20,000,050 (the word embeddings) are non-trainable, and the remaining 223,877 are. Because our vocabulary size has 400,001 words (with valid indices from 0 to 400,000) there are 400,001*50 = 20,000,050 non-trainable parameters. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 10)                0         
_________________________________________________________________
embedding_2 (Embedding)      (None, 10, 50)            20000050  
_________________________________________________________________
lstm_1 (LSTM)                (None, 10, 128)           91648     
_________________________________________________________________
dropout_1 (Dropout)          (None, 10, 128)           0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 128)               131584    
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 5)                 645       
_________________________________________________________________
activation_1 (Activation)    (None, 5)                 0         
=================================================================
Total params: 20,223,927
Trainable params: 223,877
Non-trainable params: 20,000,050
_________________________________________________________________</code></pre><p>As usual, after creating your model in Keras, you need to compile it and define what loss, optimizer and metrics your are want to use. Compile your model using <code>categorical_crossentropy</code> loss, <code>adam</code> optimizer and <code>[&#39;accuracy&#39;]</code> metrics:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>

<p>It’s time to train your model. Your Emojifier-V2 <code>model</code> takes as input an array of shape (<code>m</code>, <code>max_len</code>) and outputs probability vectors of shape (<code>m</code>, <code>number of classes</code>). We thus have to convert X_train (array of sentences as strings) to X_train_indices (array of sentences as list of word indices), and Y_train (labels as indices) to Y_train_oh (labels as one-hot vectors).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)</span><br><span class="line">Y_train_oh = convert_to_one_hot(Y_train, C = <span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>Fit the Keras model on <code>X_train_indices</code> and <code>Y_train_oh</code>. We will use <code>epochs = 50</code> and <code>batch_size = 32</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(X_train_indices, Y_train_oh, epochs = <span class="number">50</span>, batch_size = <span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/50
132/132 [==============================] - 0s - loss: 1.6086 - acc: 0.1818     
Epoch 2/50
132/132 [==============================] - 0s - loss: 1.5867 - acc: 0.3409     
Epoch 3/50
132/132 [==============================] - 0s - loss: 1.5721 - acc: 0.2652     
Epoch 4/50
132/132 [==============================] - 0s - loss: 1.5540 - acc: 0.3485     
Epoch 5/50
132/132 [==============================] - 0s - loss: 1.5413 - acc: 0.3030     
Epoch 6/50
132/132 [==============================] - 0s - loss: 1.5195 - acc: 0.3712     
Epoch 7/50
132/132 [==============================] - 0s - loss: 1.5275 - acc: 0.3258     
Epoch 8/50
132/132 [==============================] - 0s - loss: 1.4633 - acc: 0.4545     
Epoch 9/50
132/132 [==============================] - 0s - loss: 1.4320 - acc: 0.4924     
Epoch 10/50
132/132 [==============================] - 0s - loss: 1.3712 - acc: 0.6136     
Epoch 11/50
132/132 [==============================] - 0s - loss: 1.3441 - acc: 0.6136     
Epoch 12/50
132/132 [==============================] - 0s - loss: 1.2784 - acc: 0.6894     
Epoch 13/50
132/132 [==============================] - 0s - loss: 1.2723 - acc: 0.6364     
Epoch 14/50
132/132 [==============================] - 0s - loss: 1.2651 - acc: 0.6667     
Epoch 15/50
132/132 [==============================] - 0s - loss: 1.2106 - acc: 0.6970     
Epoch 16/50
132/132 [==============================] - 0s - loss: 1.2334 - acc: 0.7197     
Epoch 17/50
132/132 [==============================] - 0s - loss: 1.2150 - acc: 0.7045     
Epoch 18/50
132/132 [==============================] - 0s - loss: 1.1613 - acc: 0.7803     
Epoch 19/50
132/132 [==============================] - 0s - loss: 1.1587 - acc: 0.7576     
Epoch 20/50
132/132 [==============================] - 0s - loss: 1.1129 - acc: 0.8182     
Epoch 21/50
132/132 [==============================] - 0s - loss: 1.1016 - acc: 0.8030     
Epoch 22/50
132/132 [==============================] - 0s - loss: 1.1939 - acc: 0.6970     
Epoch 23/50
132/132 [==============================] - 0s - loss: 1.2618 - acc: 0.6288     
Epoch 24/50
132/132 [==============================] - 0s - loss: 1.2123 - acc: 0.6818     
Epoch 25/50
132/132 [==============================] - 0s - loss: 1.1606 - acc: 0.7652     
Epoch 26/50
132/132 [==============================] - 0s - loss: 1.1066 - acc: 0.8030     
Epoch 27/50
132/132 [==============================] - 0s - loss: 1.1312 - acc: 0.7727     
Epoch 28/50
132/132 [==============================] - 0s - loss: 1.1400 - acc: 0.7652     
Epoch 29/50
132/132 [==============================] - 0s - loss: 1.1107 - acc: 0.8030     
Epoch 30/50
132/132 [==============================] - 0s - loss: 1.0676 - acc: 0.8485     
Epoch 31/50
132/132 [==============================] - 0s - loss: 1.0660 - acc: 0.8258     
Epoch 32/50
132/132 [==============================] - 0s - loss: 1.0450 - acc: 0.8712     
Epoch 33/50
132/132 [==============================] - 0s - loss: 1.0246 - acc: 0.8939     
Epoch 34/50
132/132 [==============================] - 0s - loss: 1.0163 - acc: 0.8939     
Epoch 35/50
132/132 [==============================] - 0s - loss: 1.0080 - acc: 0.9015     
Epoch 36/50
132/132 [==============================] - 0s - loss: 1.0144 - acc: 0.9015     
Epoch 37/50
132/132 [==============================] - 0s - loss: 1.0861 - acc: 0.8106     
Epoch 38/50
132/132 [==============================] - 0s - loss: 1.0484 - acc: 0.8561     
Epoch 39/50
132/132 [==============================] - 0s - loss: 1.1126 - acc: 0.7955     
Epoch 40/50
132/132 [==============================] - 0s - loss: 1.0712 - acc: 0.8561     
Epoch 41/50
132/132 [==============================] - 0s - loss: 1.0277 - acc: 0.8864     
Epoch 42/50
132/132 [==============================] - 0s - loss: 1.0459 - acc: 0.8561     
Epoch 43/50
132/132 [==============================] - 0s - loss: 1.0214 - acc: 0.8864     
Epoch 44/50
132/132 [==============================] - 0s - loss: 1.0012 - acc: 0.9091     
Epoch 45/50
132/132 [==============================] - 0s - loss: 0.9877 - acc: 0.9242     
Epoch 46/50
132/132 [==============================] - 0s - loss: 0.9827 - acc: 0.9167     
Epoch 47/50
132/132 [==============================] - 0s - loss: 0.9835 - acc: 0.9167     
Epoch 48/50
132/132 [==============================] - 0s - loss: 0.9817 - acc: 0.9242     
Epoch 49/50
132/132 [==============================] - 0s - loss: 0.9894 - acc: 0.9167     
Epoch 50/50
132/132 [==============================] - 0s - loss: 0.9780 - acc: 0.9318     





&lt;keras.callbacks.History at 0x7f49ffd55e48&gt;</code></pre><p>Your model should perform close to <strong>100% accuracy</strong> on the training set. The exact accuracy you get may be a little different. Run the following cell to evaluate your model on the test set. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)</span><br><span class="line">Y_test_oh = convert_to_one_hot(Y_test, C = <span class="number">5</span>)</span><br><span class="line">loss, acc = model.evaluate(X_test_indices, Y_test_oh)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">"Test accuracy = "</span>, acc)</span><br></pre></td></tr></table></figure>

<pre><code>32/56 [================&gt;.............] - ETA: 0s
Test accuracy =  0.839285714286</code></pre><p>You should get a test accuracy between 80% and 95%. Run the cell below to see the mislabelled examples. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This code allows you to see the mislabelled examples</span></span><br><span class="line">C = <span class="number">5</span></span><br><span class="line">y_test_oh = np.eye(C)[Y_test.reshape(<span class="number">-1</span>)]</span><br><span class="line">X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)</span><br><span class="line">pred = model.predict(X_test_indices)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(X_test)):</span><br><span class="line">    x = X_test_indices</span><br><span class="line">    num = np.argmax(pred[i])</span><br><span class="line">    <span class="keyword">if</span>(num != Y_test[i]):</span><br><span class="line">        print(<span class="string">'Expected emoji:'</span>+ label_to_emoji(Y_test[i]) + <span class="string">' prediction: '</span>+ X_test[i] + label_to_emoji(num).strip())</span><br></pre></td></tr></table></figure>

<pre><code>Expected emoji:😄 prediction: she got me a nice present    ❤️
Expected emoji:😞 prediction: work is hard    😄
Expected emoji:😞 prediction: This girl is messing with me    ❤️
Expected emoji:😞 prediction: work is horrible    😄
Expected emoji:😄 prediction: you brighten my day    ❤️
Expected emoji:😞 prediction: she is a bully    😄
Expected emoji:😞 prediction: My life is so boring    ❤️
Expected emoji:😄 prediction: will you be my valentine    😞
Expected emoji:😄 prediction: What you did was awesome    😞</code></pre><p>Now you can try it on your own example. Write your own sentence below. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.  </span></span><br><span class="line">x_test = np.array([<span class="string">'not feeling happy'</span>])</span><br><span class="line">X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)</span><br><span class="line">print(x_test[<span class="number">0</span>] +<span class="string">' '</span>+  label_to_emoji(np.argmax(model.predict(X_test_indices))))</span><br></pre></td></tr></table></figure>

<pre><code>not feeling happy 😄</code></pre><p>Previously, Emojify-V1 model did not correctly label “not feeling happy,” but our implementation of Emojiy-V2 got it right. (Keras’ outputs are slightly random each time, so you may not have obtained the same result.) The current model still isn’t very robust at understanding negation (like “not happy”) because the training set is small and so doesn’t have a lot of examples of negation. But if the training set were larger, the LSTM model would be much better than the Emojify-V1 model at understanding such complex sentences. </p>
<h3 id="Congratulations"><a href="#Congratulations" class="headerlink" title="Congratulations!"></a>Congratulations!</h3><p>You have completed this notebook! ❤️❤️❤️</p>
<font color='blue'>
**What you should remember**:
- If you have an NLP task where the training set is small, using word embeddings can help your algorithm significantly. Word embeddings allow your model to work on words in the test set that may not even have appeared in your training set. 
- Training sequence models in Keras (and in most other deep learning frameworks) requires a few important details:
    - To use mini-batches, the sequences need to be padded so that all the examples in a mini-batch have the same length. 
    - An `Embedding()` layer can be initialized with pretrained values. These values can be either fixed or trained further on your dataset. If however your labeled dataset is small, it's usually not worth trying to train a large pre-trained set of embeddings.   
    - `LSTM()` has a flag called `return_sequences` to decide if you would like to return every hidden states or only the last one. 
    - You can use `Dropout()` right after `LSTM()` to regularize your network. 


<p>Congratulations on finishing this assignment and building an Emojifier. We hope you’re happy with what you’ve accomplished in this notebook! </p>
<h1 id="😀😀😀😀😀😀"><a href="#😀😀😀😀😀😀" class="headerlink" title="😀😀😀😀😀😀"></a>😀😀😀😀😀😀</h1><h2 id="Acknowledgments"><a href="#Acknowledgments" class="headerlink" title="Acknowledgments"></a>Acknowledgments</h2><p>Thanks to Alison Darcy and the Woebot team for their advice on the creation of this assignment. Woebot is a chatbot friend that is ready to speak with you 24/7. As part of Woebot’s technology, it uses word embeddings to understand the emotions of what you say. You can play with it by going to <a href="http://woebot.io" target="_blank" rel="noopener">http://woebot.io</a></p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week2/Emojify/images/woebot.png" style="width:600px;height:300px;">




      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/06/03/03_sequence-models-attention-mechanism/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/03/03_sequence-models-attention-mechanism/" class="post-title-link" itemprop="url">sequence models attention mechanism</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-06-03 00:00:00" itemprop="dateCreated datePublished" datetime="2018-06-03T00:00:00+05:30">2018-06-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 14:57:00" itemprop="dateModified" datetime="2020-04-09T14:57:00+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>70k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>1:03</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>This is my personal lecture note after studying the course <a href="https://www.coursera.org/learn/nlp-sequence-models/" target="_blank" rel="noopener">nlp sequence models</a> at the 3rd week and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.## 01_various-sequence-to-sequence-architectures</p>
<h3 id="01-basic-models"><a href="#01-basic-models" class="headerlink" title="01_basic-models"></a>01_basic-models</h3><p>Hello, and welcome to this final week of this course, as well as to the final week of this sequence of five courses in the deep learning specialization. You’re nearly at the finish line. In this week, you hear about sequence-to-sequence models, which are useful for everything from machine translation to speech recognition. Let’s start with the basic models and then later this week you, hear about beam search, the attention model, and we’ll wrap up the discussion of models for audio data, like speech. Let’s get started. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/1.png" alt=""><br>Let’s say you want to input a French sentence like Jane visite l’Afrique en septembre, and you want to translate it to the English sentence, Jane is visiting Africa in September. As usual, let’s use x&lt;1&gt; through x, in this case &lt;5&gt;, to represent the words in the input sequence, and we’ll use y&lt;1&gt; through y&lt;6&gt; to represent the words in the output sequence. So, how can you train a new network to input the sequence x and output the sequence y? Well, here’s something you could do, and the ideas I’m about to present are mainly from these two papers due to Sutskever, Oriol Vinyals, and Quoc Le, and that one by Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwen, and Yoshua Bengio. First, let’s have a network, which we’re going to call the encoder network be built as a RNN, and this could be a GRU and LSTM, feed in the input French words one word at a time. And after ingesting the input sequence, the RNN then offers a vector that represents the input sentence. After that, you can build a decoder network which I’m going to draw here, which takes as input the encoding output by the encoder network shown in black on the left, and then can be trained to output the translation one word at a time until eventually it outputs say, the end of sequence or end the sentence token upon which the decoder stops and as usual we could take the generated tokens and feed them to the next [inaudible] in the sequence like we ‘re doing before when synthesizing text using the language model. One of the most remarkable recent results in deep learning is that this model works, given enough pairs of French and English sentences. If you train the model to input a French sentence and output the corresponding English translation, this will actually work decently well. And this model simply uses an encoder network, whose job it is to find an encoding of the input French sentence and then use a decoder network to then generate the corresponding English translation. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/2.png" alt=""><br>An architecture very similar to this also works for image captioning so given an image like the one shown here, maybe wanted to be captioned automatically as a cat sitting on a chair. So how do you train a new network to input an image and output a caption like that phrase up there? Here’s what you can do. From the earlier course on ConvNet you’ve seen how you can input an image into a convolutional network, maybe a pre-trained AlexNet, and have that learn an encoding or learn a set of features of the input image. So, this is actually the AlexNet architecture and if we get rid of this final Softmax unit, the pre-trained AlexNet can give you a 4096-dimensional feature vector of which to represent this picture of a cat. And so this pre-trained network can be the encoder network for the image and you now have a 4096-dimensional vector that represents the image. You can then take this and feed it to an RNN, whose job it is to generate the caption one word at a time. So similar to what we saw with machine translation translating from French to English, you can now input a feature vector describing the input and then have it generate an output sequence or output set of words one word at a time. And this actually works pretty well for image captioning, especially if the caption you want to generate is not too long. As far as I know, this type of model was first proposed by Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Zhiheng Huang, and Alan Yuille, although it turns out there were multiple groups coming up with very similar models independently and at about the same time. So two other groups that had done very similar work at about the same time and I think independently of Mao et al were Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan, as well as Andrej Karpathy and Fei-Fei Yi. </p>
<p><strong>So, you’ve now seen how a basic sequence-to-sequence model works, or how a basic image-to-sequence or image captioning model works, but there are some differences between how you would run a model like this, so generating a sequence compared to how you were synthesizing novel text using a language model. One of the key differences is, you don’t want a randomly chosen translation, you maybe want the most likely translation, or you don’t want a randomly chosen caption, maybe not, but you might want the best caption and most likely caption</strong>. So let’s see in the next video how you go about generating that.</p>
<h3 id="02-picking-the-most-likely-sentence"><a href="#02-picking-the-most-likely-sentence" class="headerlink" title="02_picking-the-most-likely-sentence"></a>02_picking-the-most-likely-sentence</h3><p>There are some similarities between the sequence to sequence machine translation model and the language models that you have worked within the first week of this course, but there are some significant differences as well. Let’s take a look. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/3.png" alt=""><br>So, you can think of machine translation as building a conditional language model. Here’s what I mean, in language modeling, this was the network we had built in the first week. And this model allows you to estimate the probability of a sentence. That’s what a language model does. And you can also use this to generate novel sentences, and sometimes when you are writing x1 and x2 here, where in this example, x2 would be equal to y1 or equal to y and one is just a feedback. But x1, x2, and so on were not important. So just to clean this up for this slide, I’m going to just cross these off. X1 could be the vector of all zeros and x2, x3 are just the previous output you are generating. So that was the language model. The machine translation model looks as follows, and I am going to use a couple different colors, green and purple, to denote respectively the coded network in green and the decoded network in purple. And you notice that the decoded network looks pretty much identical to the language model that we had up there. So what the machine translation model is, is very similar to the language model, except that instead of always starting along with the vector of all zeros, it instead has an encoded network that figures out some representation for the input sentence, and it takes that input sentence and starts off the decoded network with representation of the input sentence rather than with the representation of all zeros. So, that’s why I call this a <strong>conditional language model</strong>, and instead of modeling the probability of any sentence, it is now modeling the probability of, say, the output English translation, conditions on some input French sentence. So in other words, you’re trying to estimate the probability of an English translation. Like, what’s the chance that the translation is “Jane is visiting Africa in September,” but conditions on the input French censors like, “Jane visite I’Afrique en septembre.” So, this is really the probability of an English sentence conditions on an input French sentence which is why it is a conditional language model. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/4.png" alt=""><br>Now, if you want to apply this model to actually translate a sentence from French into English, given this input French sentence, the model might tell you what is the probability of difference in corresponding English translations. So, x is the French sentence, “Jane visite l’Afrique en septembre.” And, this now tells you what is the probability of different English translations of that French input. And, what you do not want is to sample outputs at random. If you sample words from this distribution, p of y given x, maybe one time you get a pretty good translation, “Jane is visiting Africa in September.” But, maybe another time you get a different translation, “Jane is going to be visiting Africa in September. “ Which sounds a little awkward but is not a terrible translation, just not the best one. And sometimes, just by chance, you get, say, others: “In September, Jane will visit Africa.” And maybe, just by chance, sometimes you sample a really bad translation: “Her African friend welcomed Jane in September.” So, when you’re using this model for machine translation, you’re not trying to sample at random from this distribution. Instead, what you would like is to find the English sentence, y, that maximizes that conditional probability. So in developing a machine translation system, one of the things you need to do is come up with an algorithm that can actually find the value of y that maximizes this term over here. The most common algorithm for doing this is called <strong>beam search</strong>, and it’s something you’ll see in the next video. But, before moving on to describe beam search, you might wonder, why not just use greedy search? So, what is greedy search? </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/5.png" alt=""><br>Well, greedy search is an algorithm from computer science which says to generate the first word just pick whatever is the most likely first word according to your conditional language model. Going to your machine translation model and then after having picked the first word, you then pick whatever is the second word that seems most likely, then pick the third word that seems most likely. This algorithm is called <strong>greedy search</strong>. <strong>And, what you would really like is to pick the entire sequence of words, $y^{&lt;1&gt;}, y^{&lt;2&gt;}$ , up to $y^{<T_y>}$, that’s there, that maximizes the joint probability of that whole thing. And it turns out that the greedy approach, where you just pick the best first word, and then, after having picked the best first word, try to pick the best second word, and then, after that, try to pick the best third word, that approach doesn’t really work.</strong> To demonstrate that, let’s consider the following two translations. <strong>The first one is a better translation</strong>, so hopefully, in our machine translation model, it will say that p of y given x is higher for the first sentence. It’s just a better, more succinct translation of the French input. The second one is not a bad translation, it’s just more verbose, it has more unnecessary words. But, if the algorithm has picked “Jane is” as the first two words, because “going” is a more common English word, probably the chance of “Jane is going,” given the French input, this might actually be higher than the chance of “Jane is visiting,” given the French sentence. So, it’s quite possible that if you just pick the third word based on whatever maximizes the probability of just the first three words, you end up choosing option number two. But, this ultimately ends up resulting in a less optimal sentence, in a less good sentence as measured by this model for p of y given x. I know this was may be a slightly hand-wavey argument, but, this is an example of a broader phenomenon, where if you want to find the sequence of words, y1, y2, all the way up to the final word that together maximize the probability, <strong>it’s not always optimal to just pick one word at a time. And, of course, the total number of combinations of words in the English sentence is exponentially larger. So, if you have just 10,000 words in a dictionary and if you’re contemplating translations that are up to ten words long, then there are 10000 to the tenth possible sentences that are ten words long. Picking words from the vocabulary size, the dictionary size of 10000 words. So, this is just a huge space of possible sentences, and it’s impossible to rate them all, which is why the most common thing to do is use an approximate search out of them.</strong> </p>
<p><strong>And, what an approximate search algorithm does, is it will try, it won’t always succeed, but it will to pick the sentence, y, that maximizes that conditional probability. And, even though it’s not guaranteed to find the value of y that maximizes this, it usually does a good enough job.</strong></p>
<p>So, to summarize, in this video, you saw how machine translation can be posed as a conditional language modeling problem. But one major difference between this and the earlier language modeling problems is rather than wanting to generate a sentence at random, you may want to try to find the most likely English sentence, most likely English translation. But the set of all English sentences of a certain length is too large to exhaustively enumerate. So, we have to resort to a search algorithm. So, with that, let’s go onto the next video where you’ll learn about beam search algorithm.</p>
<h3 id="03-beam-search"><a href="#03-beam-search" class="headerlink" title="03_beam-search"></a>03_beam-search</h3><p>In this video, you learn about the <strong>beam search</strong> algorithm. In the last video, you remember how for machine translation given an input French sentence, you don’t want to output a random English translation, you want to output the best and the most likely English translation. The same is also true for speech recognition where given an input audio clip, you don’t want to output a random text transcript of that audio, you want to output the best, maybe the most likely, text transcript. Beam search is the most widely used algorithm to do this. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/6.png" alt=""><br>And in this video, you see how to get beam search to work for yourself. Let’s just try Beam Search using our running example of the French sentence, “Jane, visite l’Afrique en Septembre”. Hopefully being translated into, “Jane, visits Africa in September”. The first thing Beam search has to do is try to pick the first words of the English translation, that’s going to operate. So here I’ve listed, say, 10,000 words into vocabulary. And to simplify the problem a bit, I’m going to ignore capitalization. So I’m just listing all the words in lower case. So, in the first step of Beam Search, I use this network fragment with the coalition in green and decoalition in purple, to try to evaluate what is the probability of that for a square. So, what’s the probability of the first output y, given the input sentence x gives the French input. So, whereas greedy search will pick only the one most likely words and move on, Beam Search instead can consider multiple alternatives. So, the Beam Search algorithm has a parameter called B, which is called the <strong>beam width</strong> and for this example I’m going to set the beam width to be with the three. And what this means is Beam search will cause that not just one possibility but consider three at the time. So in particular, let’s say evaluating this probability over different choices the first words, it finds that the choices in, Jane and September are the most likely three possibilities for the first words in the English outputs. Then Beam search will stowaway in computer memory that it wants to try all of three of these words, and if the beam width parameter were said differently, the beam width parameter was 10, then we keep track of not just three but of the ten, most likely possible choices for the first word. So, to be clear in order to perform this first step of Beam search, what you need to do is run the input French sentence through this encoder network and then this first step will then decode the network, this is a softmax output overall 10,000 possibilities. Then you would take those 10,000 possible outputs and keep in memory which were the top three. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/7.png" alt=""><br>Let’s go into the second step of Beam search. Having picked in, Jane and September as the three most likely choice of the first word, what Beam search will do now, is for each of these three choices consider what should be the second word, so after “in” maybe a second word is “a” or maybe as Aaron, I’m just listing words from the vocabulary, from the dictionary or somewhere down the list will be September, somewhere down the list there’s visit and then all the way to z and then the last word is zulu. So, to evaluate the probability of second word, it will use this new network fragments where is coder in green and for the decoder portion when trying to decide what comes after in. Remember the decoder first outputs, y hat one. So, I’m going to set to this y hat one to the word “in” as it goes back in. So there’s the word “in” because it decided for now. That’s because It trying to figure out that the first word was “in”, what is the second word, and then this will output I guess y hat two. And so by hard wiring y hat one here, really the inputs here to be the first words “in” this time were fragment can be used to evaluate whether it’s the probability of the second word given the input french sentence and that the first words of the translation has been the word “in”. Now notice that what we also need help out in this second step would be assertions to find the pair of the first and second words that is most likely it’s not just a second where is most likely that the pair of the first and second whereas the most likely and by the rules of conditional probability. This can be expressed as P of the first words times P of probability of the second words. Which you are getting from this network fragment and so if for each of the three words you’ve chosen “in”, “Jane,” and “September” you save away this probability then you can multiply them by this second probabilities to get the probability of the first and second words. </p>
<p>So now you’ve seen how if the first word was “in” how you can evaluate the probability of the second word. Now at first it was “Jane” you do the same thing. The sentence could be “Jane a”,” Jane Aaron”, and so on down to “Jane is”, “Jane visits” and so on. And you will use this in your network fragments let me draw this in as well where here you will hardwire, Y hat One to be Jane. And so with the First word y one hat’s hard wired as Jane than just the network fragments can tell you what’s the probability of the second words to me. And given that the first word is “Jane”. And then same as above you can multiply with P of Y1 to get the probability of Y1 and Y2 for each of these 10,000 different possible choices for the second word. And then finally do the same thing for September although words from a down to Zulu and use this network fragment. That just goes in as well to see if the first word was September. What was the most likely options for the second words. So for this second step of beam search because we’re continuing to use a beam width of three and because there are 10,000 words in the vocabulary you’d end up considering three times 10000 or thirty thousand possibilities because there are 10,000 here, 10,000 here, 10,000 here as the beam width times the number of words in the vocabulary and what you do is you evaluate all of these 30000 options according to the probably the first and second words and then pick the top three. So with a cut down, these 30,000 possibilities down to three again down the beam width rounded again so let’s say that 30,000 choices, the most likely were in September and say Jane is, and Jane visits sorry this bit messy but those are the most likely three out of the 30,000 choices then that’s what Beam’s search would memorize away and take on to the next step being surge. So notice one thing if beam search decides that the most likely choices are the first and second words are in September, or Jane is, or Jane visits. Then what that means is that it is now rejecting September as a candidate for the first words of the output English translation so we’re now down to two possibilities for the first words but we still have a beam width of three keeping track of three choices for pairs of Y1, Y2 before going onto the third step of beam search. <strong>Just want to notice that because of beam width is equal to three, every step you instantiate three copies of the network to evaluate these partial sentence fragments and the output. And it’s because of beam width is equal to three that you have three copies of the network with different choices for the first words, but these three copies of the network can be very efficiently used to evaluate all 30,000 options for the second word. So just don’t instantiate 30,000 copies of the network or three copies of the network to very quickly evaluate all 10,000 possible outputs at that softmax output say for Y2.</strong> </p>
<p>Let’s just quickly illustrate one more step of beam search. So said that the most likely choices for first two words were in September, Jane is, and Jane visits and for each of these pairs of words which we should have saved the way in computer memory the probability of Y1 and Y2 given the input X given the French sentence X. So similar to before, we now want to consider what is the third word. So in September a? In September Aaron? All the way down to is in September Zulu and to evaluate possible choices for the third word, you use this network fragments where you Hardwire the first word here to be in the second word to be September. And so this network fragment allows you to evaluate what’s the probability of the third word given the input French sentence X and given that the first two words are in September and English output. And then you do the same thing for the second fragment. So like so. And same thing for Jane visits and so beam search will then once again pick the top three possibilities may be that things in September. Jane is a likely outcome or Jane is visiting is likely or maybe Jane visits Africa is likely for that first three words and then it keeps going and then you go onto the fourth step of beam search hat one more word and on it goes. And the outcome of this process hopefully will be that adding one word at a time that Beam search will decide that. Jane visits Africa in September will be terminated by the end of sentence symbol using that system is quite common. They’ll find that this is a likely output English sentence and you’ll see more details of this yourself. In this week’s exercise as well where you get to play with beam search yourself. So with a beam of three being searched considers three possibilities at a time. <strong>Notice that if the beam width was said to be equal to one, say cause there’s only one, then this essentially becomes the greedy search algorithm which we had discussed in the last video but by considering multiple possibilities say three or ten or some other number at the same time beam search will usually find a much better output sentence than greedy search</strong>. </p>
<p>You’ve now seen how Beam Search works but it turns out there’s some additional tips and tricks refinements that help you to make beam search work even better. Let’s go onto the next video to take a look.</p>
<h3 id="04-refinements-to-beam-search"><a href="#04-refinements-to-beam-search" class="headerlink" title="04_refinements-to-beam-search"></a>04_refinements-to-beam-search</h3><p>In the last video, you saw the basic beam search algorithm. In this video, you’ll learn some little changes that make it work even better. Length normalization is a small change to the beam search algorithm that can help you get much better results. Here’s what it is. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/8.png" alt=""><br>Beam search is maximizing this probability. And this product here is just expressing the observation that P(y1) up to y(Ty), given x, can be expressed as P(y1) given x times P(y2), given x and y1 times dot dot dot, up to I guess p of y Ty given x and y1 up to y t1-1. Maybe this notation is a bit more scary and more intimidating than it needs to be, but this is that probabilities that you see previously. Now, if you’re implementing these, these probabilities are all numbers less than 1. Often they’re much less than 1. And multiplying a lot of numbers less than 1 will result in a tiny, tiny, tiny number, which can result in numerical underflow. Meaning that it’s too small for the floating part representation in your computer to store accurately. So in practice, instead of maximizing this product, we will take logs. And if you insert a log there, then log of a product becomes a sum of a log, and maximizing this sum of log probabilities should give you the same results in terms of selecting the most likely sentence y. So by taking logs, you end up with a more numerically stable algorithm that is less prone to rounding errors, numerical rounding errors, or to really numerical underflow. And because the log function, that’s the logarithmic function, this is strictly monotonically increasing function, maximizing P(y). And because the logarithmic function, here’s the log function, is a strictly monotonically increasing function, we know that maximizing log P(y) given x should give you the same result as maximizing P(y) given x. As in the same value of y that maximizes this should also maximize that. So in most implementations, you keep track of the sum of logs of the probabilities rather than the protocol of probabilities. Now, there’s one other change to this objective function that makes the machine translation algorithm work even better. Which is that, if you referred to this original objective up here, if you have a very long sentence, the probability of that sentence is going to be low, because you’re multiplying as many terms here. Lots of numbers are less than 1 to estimate the probability of that sentence. And so if you multiply all the numbers that are less than 1 together, you just tend to end up with a smaller probability. And so this objective function has an undesirable effect, that maybe it unnaturally tends to prefer very short translations. It tends to prefer very short outputs. Because the probability of a short sentence is determined just by multiplying fewer of these numbers are less than 1. And so the product would just be not quite as small. And by the way, the same thing is true for this. The log of our probability is always less than or equal to 1. You’re actually in this range of the log. So the more terms you have together, the more negative this thing becomes. So there’s one other change to the algorithm that makes it work better, which is instead of using this as the objective you’re trying to maximize, one thing you could do is normalize this by the number of words in your translation. And so this takes the average of the log of the probability of each word. And this significantly reduces the penalty for outputting longer translations. And in practice, as a heuristic instead of dividing by Ty, by the number of words in the output sentence, sometimes you use a softer approach. We have Ty to the power of alpha, where maybe alpha is equal to 0.7. So if alpha was equal to 1, then yeah, completely normalizing by length. If alpha was equal to 0, then, well, Ty to the 0 would be 1, then you’re just not normalizing at all. And this is somewhat in between full normalization, and no normalization, and alpha’s another hyper parameter you have within that you can tune to try to get the best results. And have to admit, using alpha this way, this is a heuristic or this is a hack. There isn’t a great theoretical justification for it, but people have found this works well. People have found that it works well in practice, so many groups will do this. And you can try out different values of alpha and see which one gives you the best result. </p>
<p>So just to wrap up how you run beam search, as you run beam search you see a lot of sentences with length equal 1, a lot of sentences with length equal 2, a lot of sentences with length equals 3. And so on, and maybe you run beam search for 30 steps and you consider output sentences up to length 30, let’s say. And so with beam with a 3, you will be keeping track of the top three possibilities for each of these possible sentence lengths, 1, 2, 3, 4 and so on, up to 30. Then, you would look at all of the output sentences and score them against this score. And so you can take your top sentences and just compute this objective function onto sentences that you have seen through the beam search process. And then finally, of all of these sentences that you validate this way, you pick the one that achieves the highest value on this normalized log probability objective. Sometimes it’s called a normalized log likelihood objective. And then that would be the final translation, your outputs. So that’s how you implement beam search, and you get to play this yourself in this week’s problem exercise. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/9.png" alt=""><br>Finally, a few implementational details, how do you choose the beam width B? The larger B is, the more possibilities you’re considering, and does the better the sentence you probably find. But the larger B is, the more computationally expensive your algorithm is, because you’re also keeping a lot more possibilities around. All right, so finally, let’s just wrap up with some thoughts on how to choose the beam width B. So here are the pros and cons of setting B to be very large versus very small. If the beam width is very large, then you consider a lot of possibilities, and so you tend to get a better result because you are consuming a lot of different options, but it will be slower. And the memory requirements will also grow, will also be compositionally slower. Whereas if you use a very small beam width, then you get a worse result because you’re just keeping less possibilities in mind as the algorithm is running. But you get a result faster and the memory requirements will also be lower. So in the previous video, we used in our running example a beam width of three, so we’re keeping three possibilities in mind. In practice, that is on the small side. In production systems, it’s not uncommon to see a beam width maybe around 10, and I think beam width of 100 would be considered very large for a production system, depending on the application. But for research systems where people want to squeeze out every last drop of performance in order to publish the paper with the best possible result. It’s not uncommon to see people use beam widths of 1,000 or 3,000, but this is very application, that’s why it’s a domain dependent. So I would say try other variety of values of B as you work through your application. But when B gets very large, there is often diminishing returns. So for many applications, I would expect to see a huge gain as you go from a beam widht of 1, which is very greedy search, to 3, to maybe 10. But the gains as you go from 1,000 to 3,000 in beam width might not be as big. And for those of you that have taken maybe a lot of computer science courses before, if you’re familiar with computer science search algorithms like BFS, Breadth First Search, or DFS, Depth First Search. The way to think about beam search is that, unlike those other algorithms which you have learned about in a computer science algorithms course, and don’t worry about it if you’ve not heard of these algorithms. But if you’ve heard of Breadth First Search and Depth First Search then unlike those algorithms, which are exact search algorithms. Beam search runs much faster but does not guarantee to find the exact maximum for this argmax that you would like to find. If you haven’t heard of breadth first search or depth first search, don’t worry about it, it’s not important for our purposes. But if you have, this is how beam search relates to those algorithms. </p>
<p>So that’s it for beam search, which is a widely used algorithm in many production systems, or in many commercial systems. Now, in the circles in the sequence of courses of deep learning, we talked a lot about error analysis. It turns out, one of the most useful tools I’ve found is to be able to do error analysis on beam search. So you sometimes wonder, should I increase my beam width? Is my beam width working well enough? And there’s some simple things you can compute to give you guidance on whether you need to work on improving your search algorithm. Let’s talk about that in the next video.</p>
<h3 id="05-error-analysis-in-beam-search"><a href="#05-error-analysis-in-beam-search" class="headerlink" title="05_error-analysis-in-beam-search"></a>05_error-analysis-in-beam-search</h3><p>In the third course of this sequence of five courses, you saw how error analysis can help you focus your time on doing the most useful work for your project. Now, beam search is an approximate search algorithm, also called a heuristic search algorithm. And so it doesn’t always output the most likely sentence. It’s only keeping track of B equals 3 or 10 or 100 top possibilities. So what if beam search makes a mistake? In this video, you’ll learn how error analysis interacts with beam search and how you can figure out whether it is the beam search algorithm that’s causing problems and worth spending time on. Or whether it might be your RNN model that is causing problems and worth spending time on. Let’s take a look at how to do error analysis with beam search. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/10.png" alt=""><br>Let’s use this example of Jane visite l’Afrique en septembre. So let’s say that in your machine translation dev set, your development set, the human provided this translation and Jane visits Africa in September, and I’m going to call this y<em>. So it is a pretty good translation written by a human. Then let’s say that when you run beam search on your learned RNN model and your learned translation model, it ends up with this translation, which we will call y-hat, Jane visited Africa last September, which is a much worse translation of the French sentence. It actually changes the meaning, so it’s not a good translation. Now, your model has two main components. There is a neural network model, the sequence to sequence model. We shall just call this your RNN model. It’s really an encoder and a decoder. And you have your beam search algorithm, which you’re running with some beam width b. And wouldn’t it be nice if you could attribute this error, this not very good translation, to one of these two components? Was it the RNN or really the neural network that is more to blame, or is it the beam search algorithm, that is more to blame? And what you saw in the third course of the sequence is that it’s always tempting to collect more training data that never hurts. So in similar way, it’s always tempting to increase the beam width that never hurts or pretty much never hurts. But just as getting more training data by itself might not get you to the level of performance you want. In the same way, increasing the beam width by itself might not get you to where you want to go. But how do you decide whether or not improving the search algorithm is a good use of your time? So just how you can break the problem down and figure out what’s actually a good use of your time. Now, the RNN, the neural network, what was called RNN really means the encoder and the decoder. It computes P(y given x). So for example, for a sentence, Jane visits Africa in September, you plug in Jane visits Africa. Again, I’m ignoring upper versus lowercase now, right, and so on. And this computes P(y given x). So it turns out that the most useful thing for you to do at this point is to compute using this model to compute P(y</em> given x) as well as to compute P(y-hat given x) using your RNN model. And then to see which of these two is bigger. So it’s possible that the left side is bigger than the right hand side. It’s also possible that P(y*) is less than P(y-hat) actually, or less than or equal to, right? Depending on which of these two cases hold true, you’d be able to more clearly ascribe this particular error, this particular bad translation to one of the RNN or the beam search algorithm being had greater fault. So let’s take out the logic behind this. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/11.png" alt=""><br>Here are the two sentences from the previous slide. And remember, we’re going to compute P(y* given x) and P(y-hat given x) and see which of these two is bigger. So there are going to be two cases. In case 1, P(y* given x) as output by the RNN model is greater than P(y-hat given x). What does this mean? Well, the beam search algorithm chose y-hat, right? The way you got y-hat was you had an RNN that was computing P(y given x). And beam search’s job was to try to find a value of y that gives that arg max. But in this case, y* actually attains a higher value for P(y given x) than the y-hat. So what this allows you to conclude is beam search is failing to actually give you the value of y that maximizes P(y given x) because the one job that beam search had was to find the value of y that makes this really big. But it chose y-hat, the y* actually gets a much bigger value. So in this case, you could conclude that beam search is at fault. Now, how about the other case? In case 2, P(y* given x) is less than or equal to P(y-hat given x), right? And then either this or this has gotta be true. So either case 1 or case 2 has to hold true. What do you conclude under case 2? Well, in our example, y* is a better translation than y-hat. But according to the RNN, P(y<em>) is less than P(y-hat), so saying that y</em> is a less likely output than y-hat. So in this case, it seems that the RNN model is at fault and it might be worth spending more time working on the RNN. There’s some subtleties here pertaining to length normalizations that I’m glossing over. There’s some subtleties pertaining to length normalizations that I’m glossing over. And if you are using some sort of length normalization, instead of evaluating these probabilities, you should be evaluating the optimization objective that takes into account length normalization. But ignoring that complication for now, in this case, what this tells you is that even though y* is a better translation, the RNN ascribed y* in lower probability than the inferior translation. So in this case, I will say the RNN model is at fault. So the error analysis process looks as follows. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/12.png" alt=""><br>You go through the development set and find the mistakes that the algorithm made in the development set. And so in this example, let’s say that P(y* given x) was 2 x 10 to the -10, whereas, P(y-hat given x) was 1 x 10 to the -10. Using the logic from the previous slide, in this case, we see that beam search actually chose y-hat, which has a lower probability than y<em>. So I will say beam search is at fault. So I’ll abbreviate that B. And then you go through a second mistake or second bad output by the algorithm, look at these probabilities. And maybe for the second example, you think the model is at fault. I’m going to abbreviate the RNN model with R. And you go through more examples. And sometimes the beam search is at fault, sometimes the model is at fault, and so on. *</em>And through this process, you can then carry out error analysis to figure out what fraction of errors are due to beam search versus the RNN model<strong>. And with an error analysis process like this, for every example in your dev sets, where the algorithm gives a much worse output than the human translation, you can try to ascribe the error to either the search algorithm or to the objective function, or to the RNN model that generates the objective function that beam search is supposed to be maximizing. **And through this, you can try to figure out which of these two components is responsible for more errors. And only if you find that beam search is responsible for a lot of errors, then maybe is we’re working hard to increase the beam width. Whereas in contrast, if you find that the RNN model is at fault, then you could do a deeper layer of analysis to try to figure out if you want to add regularization, or get more training data, or try a different network architecture, or something else. And so a lot of the techniques that you saw in the third course in the sequence will be applicable there.</strong> </p>
<p>So that’s it for error analysis using beam search. I found this particular error analysis process very useful whenever you have an approximate optimization algorithm, such as beam search that is working to optimize some sort of objective, some sort of cost function that is output by a learning algorithm, such as a sequence-to-sequence model or a sequence-to-sequence RNN that we’ve been discussing in these lectures. So with that, I hope that you’ll be more efficient at making these types of models work well for your applications.</p>
<h3 id="06-bleu-score-optional"><a href="#06-bleu-score-optional" class="headerlink" title="06_bleu-score-optional"></a>06_bleu-score-optional</h3><p>One of the challenges of machine translation is that, given a French sentence, there could be multiple English translations that are equally good translations of that French sentence. So how do you evaluate a machine translation system if there are multiple equally good answers, unlike, say, image recognition where there’s one right answer? You just measure accuracy. If there are multiple great answers, how do you measure accuracy? The way this is done conventionally is through something called the BLEU score. So, in this optional video, I want to share with you, I want to give you a sense of how the BLEU score works. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/13.png" alt=""><br>Let’s say you are given a French sentence Le chat est sur le tapis. And you are given a reference, human generated translation of this, which is the the cat is on the mat. But there are multiple, pretty good translations of this. So a different human, different person might translate it as there is a cat on the mat. And both of these are actually just perfectly fine translations of the French sentence. What the BLEU score does is given a machine generated translation, it allows you to automatically compute a score that measures how good is that machine translation. And the intuition is so long as the machine generated translation is pretty close to any of the references provided by humans, then it will get a high <strong>BLEU</strong> score. BLEU, by the way, stands for <strong>bilingual evaluation, Understudy</strong>. So in the theater world, an understudy is someone that learns the role of a more senior actor so they can take over the role of the more senior actor, if necessary. And motivation for BLEU is that, whereas you could ask human evaluators to evaluate the machine translation system, the BLEU score is an understudy, could be a substitute for having humans evaluate every output of a machine translation system. So the BLEU score was due to Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. This paper has been incredibly influential, and is, actually, quite a readable paper. So I encourage you to take a look if you have time. <strong>So, the intuition behind the BLEU score is we’re going to look at the machine generated output and see if the types of words it generates appear in at least one of the human generated references. And so these human generated references would be provided as part of the depth set or as part of the test set</strong>. Now, let’s look at a somewhat extreme example. Let’s say that the machine translation system abbreviating machine translation is MT. So the machine translation, or the MT output, is the the the the the the the. So this is clearly a pretty terrible translation. So one way to measure how good the machine translation output is, is to look at each the words in the output and see if it appears in the references. And so, this would be called <strong>a precision of the machine translation output</strong>. And in this case, there are seven words in the machine translation output. And every one of these 7 words appears in either Reference 1 or Reference 2, right? So the word the appears in both references. So each of these words looks like a pretty good word to include. So this will have a precision of 7 over 7. It looks like it was a great precision. So this is why the basic precision measure of what fraction of the words in the MT output also appear in the references. <strong>This is not a particularly useful measure, because it seems to imply that this MT output has very high precision. So instead, what we’re going to use is a modified precision measure in which we will give each word credit only up to the maximum number of times it appears in the reference sentences.</strong> So in Reference 1, the word, the, appears twice. In Reference 2, the word, the, appears just once. So 2 is bigger than 1, and so we’re going to say that the word, the, gets credit up to twice. So, with a modified precision, we will say that, it gets a score of 2 out of 7, because out of 7 words, we’ll give it a 2 credits for appearing. So here, the denominator is the count of the number of times the word, the, appears of 7 words in total. And the numerator is the count of the number of times the word, the, appears. We clip this count, we take a max, or we clip this count, at 2. <strong>So this gives us the modified precision measure. Now, so far, we’ve been looking at words in isolation. In the BLEU score, you don’t want to just look at isolated words. You maybe want to look at pairs of words as well</strong>. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/14.png" alt=""><br>Let’s define a portion of the BLEU score on bigrams. And <strong>bigrams just means pairs of words appearing next to each other</strong>. So now, let’s see how we could use bigrams to define the BLEU score. And this will just be a portion of the final BLEU score. <strong>And we’ll take unigrams, or single words, as well as bigrams, which means pairs of words into account as well as maybe even longer sequences of words, such as trigrams, which means three words pairing together.</strong> So, let’s continue our example from before. We have to same Reference 1 and Reference 2. But now let’s say the machine translation or the MT System has a slightly better output. The cat the cat on the mat. Still not a great translation, but maybe better than the last one. So here, the possible bigrams are, well there’s the cat, but ignore case. And then there’s cat the, that’s another bigram. And then there’s the cat again, but I’ve already had that, so let’s skip that. And then cat on is the next one. And then on the, and the mat. So these are the bigrams in the machine translation output. And so let’s count up, How many times each of these bigrams appear. The cat appears twice, cat the appears once, and the others all appear just once. <strong>And then finally, let’s define the clipped count, so count, and then subscript clip. And to define that, let’s take this column of numbers, but give our algorithm credit only up to the maximum number of times that that bigram appears in either Reference 1 or Reference 2.</strong> So the cat appears a maximum of once in either of the references. So I’m going to clip that count to 1. Cat the, well, it doesn’t appear in Reference 1 or Reference 2, so I clip that to 0. Cat on, yep, that appears once. We give it credit for once. On the appears once, give that credit for once, and the mat appears once. So these are the clipped counts. <strong>We’re taking all the counts and clipping them, really reducing them to be no more than the number of times that bigram appears in at least one of the references. And then, finally, our modified bigram precision will be the sum of the count clipped.</strong> So that’s 1, 2, 3, 4 divided by the total number of bigrams. That’s 2, 3, 4, 5, 6, so 4 out of 6 or two-thirds is the modified precision on bigrams. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/15.png" alt=""><br>So let’s just formalize this a little bit further. <strong>With what we had developed on unigrams, we defined this modified precision computed on unigrams as P subscript 1. The P stands for precision and the subscript 1 here means that we’re referring to unigrams</strong>. But that is defined as sum over the unigrams. So that just means sum over the words that appear in the machine translation output. So this is called y hat of count clip, Of that unigram. Divided by sum of our unigrams in the machine translation output of count, number of counts of that unigram, right? And so this is what we had gotten I guess is 2 out of 7, 2 slides back. So the 1 here refers to unigram, meaning we’re looking at single words in isolation. You can also define Pn as the n-gram version, Instead of unigram, for n-gram. So this would be sum over the n-grams in the machine translation output of count clip of that n-gram divided by sum over n-grams of the count of that n-gram. And so these precisions, or these modified precision scores, measured on unigrams or on bigrams, which we did on a previous slide, or on trigrams, which are triples of words, or even higher values of n for other n-grams. This allows you to measure the degree to which the machine translation output is similar or maybe overlaps with the references. And one thing that you could probably convince yourself of is if the MT output is exactly the same as either Reference 1 or Reference 2, then all of these values P1, and P2 and so on, they’ll all be equal to 1.0. So to get a modified precision of 1.0, you just have to be exactly equal to one of the references. And sometimes it’s possible to achieve this even if you aren’t exactly the same as any of the references. But you kind of combine them in a way that hopefully still results in a good translation. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/16.png" alt=""><br>Finally, Finally, let’s put this together to form the final BLEU score. <strong>So P subscript n is the BLEU score computed on n-grams only. Also the modified precision computed on n-grams only</strong>. And by convention to compute one number, you compute P1, P2, P3 and P4, and combine them together using the following formula. <strong>It’s going to be the average, so sum from n = 1 to 4 of Pn and divide that by 4. So basically taking the average. By convention the BLEU score is defined as, e to the this, then exponentiations, and linear operate, exponentiation is strictly monotonically increasing operation and then we actually adjust this with one more factor called the, BP penalty. So BP, Stands for brevity penalty. The details maybe aren’t super important. But to just give you a sense, it turns out that if you output very short translations, it’s easier to get high precision. Because probably most of the words you output appear in the references. But we don’t want translations that are very short. So the BP, or the brevity penalty, is an adjustment factor that penalizes translation systems that output translations that are too short. So the formula for the brevity penalty is the following.</strong> </p>

$${P_n}{\rm{ = }}\frac{{\sum\limits_{n - gram \in \widehat y} {Coun{t_{clip}}(n - gram)} }}{{\sum\limits_{n - gram \in \widehat y} {Count(n - gram)} }}$$
$$BP \exp(\dfrac{1}{4}\sum_{n=1}^{4}P_{n})$$
$$BP = \left\{ \begin{array}{l} 1,  if{\kern 1pt} {\kern 1pt} MT\_length > reference\_length{\kern 1pt} {\kern 1pt} \\
\exp (1 - MT\_length/reference\_length), otherwise
\end{array} \right.$$


<p>It’s equal to 1 if your machine translation system actually outputs things that are longer than the human generated reference outputs. And otherwise is some formula like that that overall penalizes shorter translations. So, in the details you can find in this paper. </p>
<p><strong>So, once again, earlier in this set of courses, you saw the importance of having a single real number evaluation metric. Because it allows you to try out two ideas, see which one achieves a higher score, and then try to stick with the one that achieved the higher score. So the reason the BLEU score was revolutionary for machine translation was because this gave a pretty good, by no means perfect, but pretty good single real number evaluation metric. And so that accelerated the progress of the entire field of machine translation. I hope this video gave you a sense of how the BLEU score works.</strong> </p>
<p><strong>In practice, few people would implement a BLEU score from scratch. There are open source implementations that you can download and just use to evaluate your own system. But today, BLEU score is used to evaluate many systems that generate text, such as machine translation systems, as well as the example I showed briefly earlier of image captioning systems where you would have a system, have a neural network generated image caption.</strong> And then use the BLEU score to see how much that overlaps with maybe a reference caption or multiple reference captions that were generated by people. <strong>So the BLEU score is a useful single real number evaluation metric to use whenever you want your algorithm to generate a piece of text. And you want to see whether it has similar meaning as a reference piece of text generated by humans. This is not used for speech recognition, because in speech recognition, there’s usually one ground truth. And you just use other measures to see if you got the speech transcription on pretty much, exactly word for word correct.</strong> But for things like image captioning, and multiple captions for a picture, it could be about equally good or for machine translations. There are multiple translations, but equally good. The BLEU score gives you a way to evaluate that automatically and therefore speed up your development. So with that, I hope you have a sense of how the BLEU score works.</p>
<h3 id="07-attention-model-intuition"><a href="#07-attention-model-intuition" class="headerlink" title="07_attention-model-intuition"></a>07_attention-model-intuition</h3><p>For most of this week, you’ve been using a Encoder-Decoder architecture for machine translation. Where one RNN reads in a sentence and then different one outputs a sentence. There’s a modification to this called <strong>the Attention Model</strong>, that makes all this work much better. The attention algorithm, the attention idea has been one of the most influential ideas in deep learning. Let’s take a look at how that works. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/17.png" alt=""><br>Get a very long French sentence like this. What we are asking this green encoder in your network to do is, to read in the whole sentence and then memorize the whole sentences and store it in the activations conveyed here. Then for the purple network, the decoder network till then generate the English translation. Jane went to Africa last September and enjoyed the culture and met many wonderful people; she came back raving about how wonderful her trip was, and is tempting me to go too. <strong>Now, the way a human translator would translate this sentence is not to first read the whole French sentence and then memorize the whole thing and then regurgitate an English sentence from scratch. Instead, what the human translator would do is read the first part of it, maybe generate part of the translation. Look at the second part, generate a few more words, look at a few more words, generate a few more words and so on. You kind of work part by part through the sentence, because it’s just really difficult to memorize the whole long sentence like that. What you see for the Encoder-Decoder architecture above is that, it works quite well for short sentences, so we might achieve a relatively high Bleu score, but for very long sentences, maybe longer than 30 or 40 words, the performance comes down. The Bleu score might look like this as the sentence that varies and short sentences are just hard to translate, hard to get all the words, right? Long sentences, it doesn’t do well on because it’s just difficult to get in your network to memorize a super long sentence.</strong> </p>
<p><strong>In this and the next video, you’ll see the Attention Model which translates maybe a bit more like humans might, looking at part of the sentence at a time and with an Attention Model, machine translation systems performance can look like this, because by working one part of the sentence at a time, you don’t see this huge dip which is really measuring the ability of a neural network to memorize a long sentence which maybe isn’t what we most badly need a neural network to do</strong>. In this video, I want to just give you some intuition about how attention works and then we’ll flesh out the details in the next video. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/18.png" alt=""><br>The Attention Model was due to Dimitri, Bahdanau, Camcrun Cho, Yoshe Bengio and even though it was obviously developed for machine translation, it spread to many other application areas as well. This is really a very influential, I think very seminal paper in the deep learning literature. Let’s illustrate this with a short sentence, even though these ideas were maybe developed more for long sentences, but it’ll be easier to illustrate these ideas with a simpler example. We have our usual sentence, Jane visite l’Afrique en Septembre. Let’s say that we use a R and N, and in this case, I’m going to use a bidirectional R and N, in order to compute some set of features for each of the input words and you have to understand it, bidirectional RNN with outputs Y1 to Y3 and so on up to Y5 but we’re not doing a word for word translation, let me get rid of the Y’s on top. But using a bidirectional R and N, what we’ve done is for each other words, really for each of the five positions into sentence, you can compute a very rich set of features about the words in the sentence and maybe surrounding words in every position. Now, let’s go ahead and generate the English translation. We’re going to use another RNN to generate the English translations. <strong>Here’s my RNN note as usual and instead of using A to denote the activation, in order to avoid confusion with the activations down here, I’m just going to use a different notation, I’m going to use S to denote the hidden state in this RNN up here, so instead of writing A1 I’m going to right S1 and so we hope in this model that the first word it generates will be Jane, to generate Jane visits Africa in September. Now, the question is, when you’re trying to generate this first word, this output, what part of the input French sentence should you be looking at? Seems like you should be looking primarily at this first word, maybe a few other words close by, but you don’t need to be looking way at the end of the sentence. What the Attention Model would be computing is a set of attention weights</strong> and we’re going to use $\alpha^{&lt;1, 1&gt;}$ to denote when you’re generating the first words, how much should you be paying attention to this first piece of information here. And then we’ll also come up with a second that’s called Attention Weight, $\alpha^{&lt;1, 2&gt;}$ which tells us what we’re trying to compute the first work of Jane, how much attention we’re paying to this second work from the inputs and so on and the $\alpha^{&lt;1, 3&gt;}$ and so on, and together this will tell us what is exactly the context from denoter C that we should be paying attention to, and that is input to this RNN unit to then try to generate the first words. That’s one step of the R and N, we will flesh out all these details in the next video. For the second step of this R and N, we’re going to have a new hidden state S two and we’re going to have a new set of the attention weights. We’re going to have $\alpha^{&lt;2, 1&gt;}$ to tell us when we generate in the second word. I guess this will be visits maybe that being the ground trip label. How much should we paying attention to the first word in the french input and also, $\alpha^{&lt;2, 2&gt;}$ and so on. How much should we paying attention the word visite, how much should we pay attention to the free and so on. And of course, the first word we generate in Jane is also an input to this, and then we have some context that we’re paying attention to and the second step, there’s also an input and that together will generate the second word and that leads us to the third step, S three, where this is an input and we have some new context C that depends on the various $\alpha^{&lt;3, t&gt;}$ for the different time sets, that tells us how much should we be paying attention to the different words from the input French sentence and so on. <strong>So, some things I haven’t specified yet, but that will go further into detail in the next video of this, how exactly this context defines and the goal of the context is for the third word is really should capture that maybe we should be looking around this part of the sentence. The formula you use to do that will defer to the next video as well as how do you compute these attention weights</strong>. And you see in the next video that $\alpha^{&lt;3, t&gt;}$, which is, when you’re trying to generate the third word, I guess this would be the Africa, just getting the right output. The amounts that this RNN step should be paying attention to the French word that time T, that depends on the activations of the bidirectional RNN at time T, I guess it depends on the fourth activations and the, backward activations at time T and it will depend on the state from the previous steps, it will depend on S two, and these things together will influence, how much you pay attention to a specific word in the input French sentence. <strong>But we’ll flesh out all these details in the next video. But the key intuition to take away is that this way the RNN marches forward generating one word at a time, until eventually it generates maybe the EOS and at every step, there are these attention weighs.</strong> $\alpha^{&lt;t, t’&gt;}$ that tells it, when you’re trying to generate the T, English word, how much should you be paying attention to the T prime French words.<strong>And this allows it on every time step to look only maybe within a local window of the French sentence to pay attention to, when generating a specific English word</strong>. </p>
<p>I hope this video conveys some intuition about Attention Model and that we now have a rough sense of, maybe how the algorithm works. Let’s go to the next video to flesh out the details of the Attention Model.</p>
<h3 id="08-attention-model"><a href="#08-attention-model" class="headerlink" title="08_attention-model"></a>08_attention-model</h3><p>In the last video, you saw how the attention model allows a neural network to pay attention to only part of an input sentence while it’s generating a translation, much like a human translator might. Let’s now formalize that intuition into the exact details of how you would implement an attention model. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/19.png" alt=""><br>So same as in the previous video, let’s assume you have an input sentence and you use a bidirectional RNN, or bidirectional GRU, or bidirectional LSTM to compute features on every word. In practice, GRUs and LSTMs are often used for this, with maybe LSTMs be more common. And so for the forward occurrence, you have a forward occurrence first time step. Activation backward occurrence, first time step. Activation forward occurrence, second time step. Activation backward and so on. For all of them in just a forward fifth time step a backwards fifth time step. We had a zero here technically we can also have I guess a backwards sixth as a factor of all zero, actually that’s a factor of all zeroes. And then to simplify the notation going forwards at every time step, even though you have the features computed from the forward occurrence and from the backward occurrence in the bidirectional RNN. <strong>I’m just going to use $a^{t’}$ to represent both of these concatenated together, $a^{&lt;t^{&lt;\prime&gt;}&gt;}=({\overrightarrow a^{&lt;t^{\prime}&gt;}},{\overleftarrow a^{&lt;t^{\prime}&gt;}})$</strong>. So a of t is going to be a feature vector for time step t. Although to be consistent with notation, we’re using second, I’m going to call this $t^\prime$. <strong>Actually, I’m going to use $t^{\prime}$ to index into the words in the French sentence</strong>. Next, we have our forward only, so it’s a single direction RNN with state s to generate the translation. And so the first time step, it should generate $y^{&lt;1&gt;}$ and just will have as input some context C. And if you want to index it with time I guess you could write a $C^{&lt;1&gt;}$ but sometimes I just right C without the superscript one. <strong>And this will depend on the attention parameters so $\alpha^{&lt;1,1&gt;}$, $\alpha^{&lt;1,2&gt;}$ and so on tells us how much attention. And so these alpha parameters tells us how much the context would depend on the features we’re getting or the activations we’re getting from the different time steps. And so the way we define the context is actually be a way to some of the features from the different time steps weighted by these attention weights</strong>. So more formally the attention weights will satisfy this that they are all be non-negative, so it will be a zero positive and they’ll sum to one. We’ll see later how to make sure this is true. And we will have the context or the context at time one often drop that superscript that’s going to be sum over $t^{\prime}$, all the values of $t^{\prime}$ of this weighted sum of these activations $c^{&lt;1&gt;} = \sum\alpha^{&lt;1, t^{\prime}&gt;}a^{&lt;t^{\prime}&gt;}$. So this term, $\alpha^{&lt;1, t^{\prime}&gt;}$, here are the attention weights and this term, $a^{&lt;t^{\prime}&gt;}$, here comes from here $a^{&lt;t^{\prime}&gt;}=({\overrightarrow a^{&lt;t^{\prime}&gt;}},{\overleftarrow a ^{&lt;t^{\prime}&gt;}})$. So $\alpha^{&lt;t, t^{\prime}&gt;}$ is the amount of attention that’s $y^t$ should pay to $a^{t^{\prime}}$. So in other words, when you’re generating the t of the output words, how much you should be paying attention to the $t^{\prime}$th input to word. So that’s one step of generating the output and then at the next time step, you generate the second output and is again done some of where now you have a new set of attention weights on they to find a new way to sum. That generates a new context. This, $y^{<t>}$, is also input and that allows you to generate the second word. Only now just this way to sum becomes the context of the second time step is $c^{&lt;2&gt;} = \sum\alpha^{&lt;2, t^{\prime}&gt;}a^{&lt;t^{\prime}&gt;}$. So using these context vectors. $c^{&lt;1&gt;}$ right there back, $c^{&lt;2&gt;}$, and so on. This network uo here, which circled in purple color, here looks like a pretty standard RNN sequence with the context vectors as output and we can just generate the translation one word at a time. We have also define how to compute the context vectors in terms of these attention ways and those features of the input sentence. So the only remaining thing to do is to define how to actually compute these attention weights. Let’s do that on the next slide. <strong>So just to recap, $\alpha^{&lt;t, t^{\prime}&gt;}$ is the amount of attention you should paid to $a^{&lt;t^{\prime}&gt;}$ when you’re trying to generate the $t^{th}$ words in the output translation</strong>. </p>
<p>So let me just write down the formula and we talk of how this works. This is formula you could use the compute $\alpha^{&lt;t, t^{\prime}&gt;}$ which is going to compute these terms $e^{&lt;t, t^{\prime}&gt;}$ and then use essentially a softmax to make sure that these weights sum to one if you sum over $t^{\prime}$. So for every fix value of t, these things,  ${\alpha^{<t,t^{\prime}>}} =\frac{{\exp({e^{<t,t^{\prime}>}})}}{{\sum\limits_{t^{\prime} = 1}^{{T_x}} {\exp({e^{<t,t^{\prime}>}})}}}$ , sum to one if you’re summing over $t^{\prime}$. And using this softmax prioritization, just ensures this properly sums to one. Now how do we compute these factors e. Well, one way to do so is to use a small neural network as follows. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/20.png" alt=""><br>So $s^{<t-1>}$ was the neural network state from the previous time step. So here is the network we have.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/21.png" alt=""><br>If you’re trying to generate $y^t$ then $s^{<t-1>}$ was the hidden state from the previous step that just fell into $s^t$ and that’s one input to very small neural network. Usually, one hidden layer in neural network because you need to compute these a lot. And then $a^{&lt;t^{\prime}&gt;}$ the features from time step $t^{\prime}$ is the other inputs. And the intuition is, if you want to decide how much attention to pay to the activation of $t^{\prime}$. Well, the things that seems like it should depend the most on is what is your own hidden state activation from the previous time step. You don’t have the current state activation yet because of context feeds into this so you haven’t computed that. But look at whatever you’re hidden stages of this RNN generating the upper translation and then for each of the positions, each of the words look at their features. So it seems pretty natural that $\alpha^{&lt;t, t^{\prime}&gt;}$ and $e^{&lt;t, t^{\prime}&gt;}$ should depend on these two quantities. But we don’t know what the function is. So one thing you could do is just train a very small neural network to learn whatever this function should be. And trust that back propagation trust gradient descent to learn the right function. And it turns out that if you implemented this whole model and train it with gradient descent, the whole thing actually works. This little neural network does a pretty decent job telling you how much attention $y^t$ should pay to $a^{&lt;t^{\prime}&gt;}$<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/22.png" alt=""><br>and this formula  ${\alpha^{<t,t^{\prime}>}} =\frac{{\exp({e^{<t,t^{\prime}>}})}}{{\sum\limits_{t^{\prime} = 1}^{{T_x}} {\exp({e^{<t,t^{\prime}>}})}}}$  makes sure that the attention weights sum to one and then as you chug along generating one word at a time, this neural network actually pays attention to the right parts of the input sentence that learns all this automatically using gradient descent.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/23.png" alt=""><br>Now, one downside to this algorithm is that it does take quadratic time or quadratic cost to run this algorithm. If you have $T_x$ words in the input and $T_y$ words in the output then the total number of these attention parameters are going to be $T_x$ times $T_y$. And <strong>so this algorithm runs in quadratic cost</strong>. <strong>Although in machine translation applications where neither input nor output sentences is usually that long maybe quadratic cost is actually acceptable. Although, there is some research work on trying to reduce costs as well</strong>. Now, so far up in describing the attention idea in the context of machine translation. Without going too much into detail this idea has been applied to other problems as well. So just image captioning. So in the image capturing problem the task is to look at the picture and write a caption for that picture. So in this paper set to the bottom by Kevin Chu, Jimmy Barr, Ryan Kiros, Kelvin Shaw, Aaron Korver, Russell Zarkutnov, Virta Zemo, and Andrew Benjo they also showed that you could have a very similar architecture. Look at the picture and pay attention only to parts of the picture at a time while you’re writing a caption for a picture. So if you’re interested, then I encourage you to take a look at that paper as well. And you get to play with all this and more in the programming exercise.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/24.png" alt=""><br>Whereas machine translation is a very complicated problem in the prior exercise you get to implement and play of the attention while you yourself for the date normalization problem. So the problem inputting a date like this. This actually has a date of the Apollo Moon landing and normalizing it into standard formats or a date like this and having a neural network a sequence, sequence model normalize it to this format. This by the way is the birthday of William Shakespeare. Also it’s believed to be. <strong>And what you see in prior exercises as you can train a neural network to input dates in any of these formats and have it use an attention model to generate a normalized format for these dates. One other thing that sometimes fun to do is to look at the visualizations of the attention weights.</strong> So here’s a machine translation example and here were plotted in different colors. the magnitude of the different attention weights. I don’t want to spend too much time on this but you find that the corresponding input and output words you find that the attention weights will tend to be high. Thus, suggesting that when it’s generating a specific word in output is, usually paying attention to the correct words in the input and all this including learning where to pay attention when was all learned using propagation with an attention model. </p>
<p>So that’s it for the attention model really one of the most powerful ideas in deep learning. I hope you enjoy implementing and playing with these ideas yourself later in this week’s programming exercises.</p>
<h2 id="02-speech-recognition-audio-data"><a href="#02-speech-recognition-audio-data" class="headerlink" title="02_speech-recognition-audio-data"></a>02_speech-recognition-audio-data</h2><h3 id="01-speech-recognition"><a href="#01-speech-recognition" class="headerlink" title="01_speech-recognition"></a>01_speech-recognition</h3><p>One of the most exciting developments were sequence-to-sequence models has been the rise of very accurate speech recognition. We’re nearing the end of the course, we want to take just a couple of videos to give you a sense of how these sequence-to-sequence models are applied to audio data, such as the speech. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/25.png" alt=""><br>So, what is the speech recognition problem? You’re given an audio clip, x, and your job is to automatically find a text transcript, y. So, an audio clip, if you plot it looks like this, the horizontal axis here is time, and what a microphone does is it really measures minuscule changes in air pressure, and the way you’re hearing my voice right now is that your ear is detecting little changes in air pressure, probably generated either by your speakers or by a headset. And some audio clips like this plots with the air pressure against time. And, if this audio clip is of me saying, “the quick brown fox”, then hopefully, a speech recognition algorithm can input that audio clip and output that transcript. And because even the human ear doesn’t process raw wave forms, but <strong>the human ear has physical structures that measures the amounts of intensity of different frequencies, there is, a common pre-processing step for audio data is to run your raw audio clip and generate a spectrogram. So, this is the plots where the horizontal axis is time, and the vertical axis is frequencies, and intensity of different colors shows the amount of energy</strong>. So, how loud is the sound at different frequencies? At different times? <strong>And so, these types of spectrograms, or you might also hear people talk about false blank outputs, is often commonly applied pre-processing step before audio is pass into in the running algorithm</strong>. And the human ear does a computation pretty similar to this pre-processing step. So, one of the most exciting trends in speech recognition is that, <strong>once upon a time, speech recognition systems used to be built using phonemes and this where, I want to say hand-engineered basic units of cells</strong>. So, the quick brown fox represented as phonemes. I’m going to simplify a bit, let say, “The” has a “de” and “e” sound and Quick, has a “ku” and “wu”, “ik”, “k” sound, and linguist used to write off these basic units of sound, and try the Greek language down to these basic units of sound. So, brown, this aren’t the official phonemes which are written with more complicated notation, but <strong>linguists use to hypothesize that writing down audio in terms of these basic units of sound called phonemes would be the best way to do speech recognition. But with end-to-end deep learning, we’re finding that phonemes representations are no longer necessary. But instead, you can built systems that input an audio clip and directly output a transcript without needing to use hand-engineered representations like these. One of the things that made this possible was going to much larger data sets</strong>. So, academic data sets on speech recognition might be as a 300 hours, and in academia, <strong>3000 hour data sets of transcribed audio would be considered reasonable size, so lot of research has been done</strong>, a lot of research papers that are written on data sets there are several thousand voice. <strong>But, the best commercial systems are now trains on over 10,000 hours and sometimes over a 100,000 hours of audio.</strong> And, it’s really moving to a much larger audio data sets, transcribe audio data sets were both x and y, together with deep learning algorithm, that has driven a lot of progress is speech recognition. So, how do you build a speech recognition system? </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/26.png" alt=""><br>In the last video, we’re talking about the attention model. So, one thing you could do is actually do that, where on the horizontal axis, you take in different time frames of the audio input, and then you have an attention model try to output the transcript like, “the quick brown fox”, or what it was said. </p>
<p>One other method that seems to work well is to use the CTC cost for speech recognition. CTC stands for Connection is Temporal Classification and is due to Alex Graves, Santiago Fernandes, Faustino Gomez, and Jürgen Schmidhuber. So, here’s the idea. Let’s say the audio clip was someone saying, “the quick brown fox”. We’re going to use a new network structured like this with an equal number of input x’s and output y’s, and I have drawn a simple of what uni-directional for the RNN for this, but in practice, this will usually be a bidirectional LSTM and bidirectional GRU and usually, a deeper model. <strong>But notice that the number of time steps here is very large and in speech recognition, usually the number of input time steps is much bigger than the number of output time steps</strong>. So, for example, if you have 10 seconds of audio and your features come at a 100 hertz so 100 samples per second, then a 10 second audio clip would end up with a thousand inputs. Right, so it’s 100 hertz times 10 seconds, and so with a thousand inputs. But your output might not have a thousand alphabets, might not have a thousand characters. So, what do you do? The CTC cost function allows the RNN to generate an output like this ttt, there’s a special character called the blank character, which we’re going to write as an underscore here, h_eee___, and then maybe a space, we’re going to write like this, so that a space and then <strong>_ qqq</strong>. And, this is considered a correct output for the first parts of the space, quick with the Q, and the basic rule for the CTC cost function is to collapse repeated characters not separated by “blank”. So, to be clear, I’m using this underscore to denote a special blank character and that’s different than the space character. So, there is a space here between the and quick, so I should output a space. But, by collapsing repeated characters, not separated by blank, it actually collapse the sequence into t, h, e, and then space, and q, and this allows your network to have a thousand outputs by repeating characters allow the times. So, inserting a bunch of blank characters and still ends up with a much shorter output text transcript. So, this phrase here “the quick brown fox” including spaces actually has 19 characters, and if somehow, the newer network is forced upwards of a thousand characters by allowing the network to insert blanks and repeated characters and can still represent this 19 character upwards with this 1000 outputs of values of Y. So, this paper by Alex Grace, as well as by those deep speech recognition system, which I was involved in, used this idea to build effective Speech recognition systems. </p>
<p>So, I hope that gives you a rough sense of how speech recognition models work. Attention like models work and CTC models work and present two different options of how to go about building these systems. Now, today, building effective where production skills speech recognition system is a pretty significant effort and requires a very large data set. But, what I like to do in the next video is share you, how you can build a trigger word detection system, where keyword detection system which is actually much easier and can be done with even a smaller or more reasonable amount of data. So, let’s talk about that in the next video.</p>
<h3 id="02-trigger-word-detection"><a href="#02-trigger-word-detection" class="headerlink" title="02_trigger-word-detection"></a>02_trigger-word-detection</h3><p>you’ve now learned so much about deep learning and sequence models that we can actually describe a trigger word system quite simply just on one slide as you see in this video but when the rise of speech recognition have been more and more devices you can wake up with your voice and those are sometimes called trigger word detection systems so let’s see how you can build a trigger word system. </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/27.png" alt=""><br>Examples of triggering systems include Amazon echo which is broken out with that word <strong>Alexa</strong>. The Baidu DuerOs part devices woken up with face <strong>xiaodunihao</strong>. Apple Siri working out with <strong>hey Siri</strong> and Google home woken up with <strong>Ok Google</strong>. So stands the trigger word detection that if you have say an Amazon echo in your living room, you can walk the living room and just say: “Alexa what time is it” and have it wake up. It’ll be triggered by the words of Alexa and answer your voice query. So if you can build a trigger word detection system maybe you can make your computer do something by telling it computer activate. One of my friends also works on turning on an offer particular lamp using a trigger word kind of as a fun project but what I want to show you is how you can build a trigger word detection system.</p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/28.png" alt=""><br>Now the trigger word detection literature is still evolving so there actually isn’t a single universally agreed on algorithm for trigger word detection yet <strong>the literature on trigger word detection algorithm is still evolving so there isn’t wide consensus yet on what’s the best algorithm for trigger word detection so I’m just going to show you one example of an algorithm you can use</strong>. now you’ve seen our ends like this and what we really do is take an audio clip maybe compute spectrogram features and that generates features $x^{&lt;1&gt;} x^{&lt;2&gt;} x^{&lt;3&gt;}$ or audio features $x^{&lt;1&gt;} x^{&lt;2&gt;} x^{&lt;3&gt;}$ that you pass through an RNN and so all that remains to be done is to define the target labels Y so if this point in the audio clip is when someone just finished saying the trigger word such as “Alexa”, “nihaobaidu” or “hey Siri” or “Okay Google” then in the training sets you can set the target labels to be zero for everything before that point and right after that to set the target label of one and then if a little bit later on you know the trigger word was set again and the trigger word said at this point then you can again set the target label to be one right after that now this type of labeling scheme for an RNN you know could work actually this won’t actually work reasonably well. <strong>One slight disadvantage of this is it creates a very imbalanced training set so if a lot more zeros than ones.</strong> </p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/29.png" alt=""><br>So one other thing you could do that it’s getting a little bit of a hack but could make them all the little bit easy to train is instead of setting only a single time step to output one you can actually make an output a few ones for several times or for a fixed period of time before reverting back to zero so and that slightly evens out the ratio of ones to zeros but this is a little bit of a hack. But if this is when in the audio clipper trigger where the set then right after that you can set the target label to one and if this is the trigger words said again, then right after that just when you want the RNN to output one so you get to play more of this as well in the programming exercise but so I think you should feel quite proud of yourself we’ve learned enough about the learning that it just takes one picture at one slide to this to describe something as complicated as trigger word detection and based on this I hope you’d be able to implement something that works and allows you to detect trigger words but you see more of this in the program exercise. </p>
<p>So that’s it for trigger words and I hope you feel quite proud of yourself for how much you’ve learned about deep learning that you can now describe trigger words in just one slide in a few minutes and that you’ve been hopeful II implemented and get it to work maybe even make it do something fun in your house that I’m like turn on or turn off um you could do something like a computer when you’re when someone else says they trigger words on this is the last technical video of this course and to wrap up in this course on sequence models you learned about rnns including both gr use and LS TMS and then in the second week you learned a lot about word embeddings and how they learn representations of words and then in this week you learned about the attention model as well as how to use it to process audio data and I hope you have fun implementing all of these ideas in this beast program sighs let’s go on to the last video.</p>
<h2 id="conclusion-and-thank-you"><a href="#conclusion-and-thank-you" class="headerlink" title="conclusion-and-thank-you"></a>conclusion-and-thank-you</h2><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/30.png" alt=""><br>congratulations on making it this far I just wanna wrap up and leave you with a few final thoughts we’ve been on quite a journey together but if you’ve taken the whole specialization then you’ve learned about new networks and deep learning how to improve deep neural networks of the structure machine learning projects convolutional neural networks and then in this most recent course sequence models and I know you work really hard and I also hope you feel very proud of yourself for your hard work and for how much you’ve done.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/31.png" alt=""><br>so I want to leave you one maybe important thought which is that I think deep learning is a superpower with deep learning algorithms you can make a computer see you can have a computer synthesize novel art or synthesized music or you can have a computer translate from one language to another maybe have it locally radiology image and render a medical diagnosis or build pieces of a car that can drive itself and if that isn’t a superpower I don’t know what is and as we wrap up this sequence of courses as we wrap up this specialization I hope that you will find ways to use these ideas to further your career to pursue your dreams but perhaps most important to do whatever you think is the best work you can do our humanity the world today has challenges but with the power of a on power of deep learning I think we can make it a much better place and now that you have this superpower I hope you will use it to go out there and make life better for yourself but also for other people and of course I also hope you feel very proud of your accomplishments in the power far you’ve come and of all that you’ve learned and when you complete this sequence of causes you should also share it on social media like Twitter or Facebook and let your friends know.</p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/lectures/week3/images/32.png" alt=""><br>and finally the very last thing I want to say to you is congratulations on Nikolas I hope you feel great about your accomplishments but also I want to thank you very much I know that you have a busy life but despite that spends a lot of time watching these videos and maybe spent a long time also working on the quizzes and the programming exercises I hope you enjoyed it and you got a lot out of the process but I’m also very grateful for all your time you spend and for all your hard work you put into learning these materials so thank you very much.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/06/02/Improvise+a+Jazz+Solo+with+an+LSTM+Network+-+v3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/02/Improvise+a+Jazz+Solo+with+an+LSTM+Network+-+v3/" class="post-title-link" itemprop="url">Improvise a Jazz Solo with an LSTM Network</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-06-02 00:00:00" itemprop="dateCreated datePublished" datetime="2018-06-02T00:00:00+05:30">2018-06-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 14:57:28" itemprop="dateModified" datetime="2020-04-09T14:57:28+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>159k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>2:24</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>This is one of my personal programming assignments after studying the course <a href="https://www.coursera.org/learn/nlp-sequence-models/" target="_blank" rel="noopener">nlp sequence models</a> at the 1st week and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.</p>
<h1 id="Improvise-a-Jazz-Solo-with-an-LSTM-Network"><a href="#Improvise-a-Jazz-Solo-with-an-LSTM-Network" class="headerlink" title="Improvise a Jazz Solo with an LSTM Network"></a>Improvise a Jazz Solo with an LSTM Network</h1><p>Welcome to your final programming assignment of this week! In this notebook, you will implement a model that uses an LSTM to generate music. You will even be able to listen to your own music at the end of the assignment. </p>
<p><strong>You will learn to:</strong></p>
<ul>
<li>Apply an LSTM to music generation.</li>
<li>Generate your own jazz music with deep learning.</li>
</ul>
<p>Please run the following cell to load all the packages required in this assignment. This may take a few minutes. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> IPython</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> music21 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> grammar <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> qa <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> preprocess <span class="keyword">import</span> * </span><br><span class="line"><span class="keyword">from</span> music_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> data_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model, Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector</span><br><span class="line"><span class="keyword">from</span> keras.initializers <span class="keyword">import</span> glorot_uniform</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br></pre></td></tr></table></figure>

<pre><code>Using TensorFlow backend.</code></pre><h2 id="1-Problem-statement"><a href="#1-Problem-statement" class="headerlink" title="1 - Problem statement"></a>1 - Problem statement</h2><p>You would like to create a jazz music piece specially for a friend’s birthday. However, you don’t know any instruments or music composition. Fortunately, you know deep learning and will solve this problem using an LSTM netwok.  </p>
<p>You will train a network to generate novel jazz solos in a style representative of a body of performed work.</p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/images/jazz.jpg" style="width:450;height:300px;">


<h3 id="1-1-Dataset"><a href="#1-1-Dataset" class="headerlink" title="1.1 - Dataset"></a>1.1 - Dataset</h3><p>You will train your algorithm on a corpus of Jazz music. Run the cell below to listen to a snippet of the audio from the training set:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IPython.display.Audio(<span class="string">'./data/30s_seq.mp3'</span>)</span><br></pre></td></tr></table></figure>


<pre><code>&lt;audio controls=&quot;controls&quot; &gt;
    &lt;source src=&quot;http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/data/30s_seq.mp3&quot; type=&quot;audio/mpeg&quot; /&gt;
    Your browser does not support the audio element.
&lt;/audio&gt;</code></pre><p>We have taken care of the preprocessing of the musical data to render it in terms of musical “values.” You can informally think of each “value” as a note, which comprises a pitch and a duration. For example, if you press down a specific piano key for 0.5 seconds, then you have just played a note. In music theory, a “value” is actually more complicated than this–specifically, it also captures the information needed to play multiple notes at the same time. For example, when playing a music piece, you might press down two piano keys at the same time (playng multiple notes at the same time generates what’s called a “chord”). But we don’t need to worry about the details of music theory for this assignment. For the purpose of this assignment, all you need to know is that we will obtain a dataset of values, and will learn an RNN model to generate sequences of values. </p>
<p>Our music generation system will use 78 unique values. Run the following code to load the raw music data and preprocess it into values. This might take a few minutes.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X, Y, n_values, indices_values = load_music_utils()</span><br><span class="line">print(<span class="string">'shape of X:'</span>, X.shape)</span><br><span class="line">print(<span class="string">'number of training examples:'</span>, X.shape[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">'Tx (length of sequence):'</span>, X.shape[<span class="number">1</span>])</span><br><span class="line">print(<span class="string">'total # of unique values:'</span>, n_values)</span><br><span class="line">print(<span class="string">'Shape of Y:'</span>, Y.shape)</span><br></pre></td></tr></table></figure>

<pre><code>shape of X: (60, 30, 78)
number of training examples: 60
Tx (length of sequence): 30
total # of unique values: 78
Shape of Y: (30, 60, 78)</code></pre><p>You have just loaded the following:</p>
<ul>
<li><p><code>X</code>: This is an (m, $T_x$, 78) dimensional array. We have m training examples, each of which is a snippet of $T_x =30$ musical values. At each time step, the input is one of 78 different possible values, represented as a one-hot vector. Thus for example, X[i,t,:] is a one-hot vector representating the value of the i-th example at time t. </p>
</li>
<li><p><code>Y</code>: This is essentially the same as <code>X</code>, but shifted one step to the left (to the past). Similar to the dinosaurus assignment, we’re interested in the network using the previous values to predict the next value, so our sequence model will try to predict $y^{\langle t \rangle}$ given $x^{\langle 1\rangle}, \ldots, x^{\langle t \rangle}$. However, the data in <code>Y</code> is reordered to be dimension $(T_y, m, 78)$, where $T_y = T_x$. This format makes it more convenient to feed to the LSTM later. </p>
</li>
<li><p><code>n_values</code>: The number of unique values in this dataset. This should be 78. </p>
</li>
<li><p><code>indices_values</code>: python dictionary mapping from 0-77 to musical values.</p>
</li>
</ul>
<h3 id="1-2-Overview-of-our-model"><a href="#1-2-Overview-of-our-model" class="headerlink" title="1.2 - Overview of our model"></a>1.2 - Overview of our model</h3><p>Here is the architecture of the model we will use. This is similar to the Dinosaurus model you had used in the previous notebook, except that in you will be implementing it in Keras. The architecture is as follows: </p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/images/music_generation.png" style="width:600;height:400px;">

<!--
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/images/djmodel.png" style="width:600;height:400px;">
<br>
<caption><center> **Figure 1**: LSTM model. $X = (x^{\langle 1 \rangle}, x^{\langle 2 \rangle}, ..., x^{\langle T_x \rangle})$ is a window of size $T_x$ scanned over the musical corpus. Each $x^{\langle t \rangle}$ is an index corresponding to a value (ex: "A,0.250,< m2,P-4 >") while $\hat{y}$ is the prediction for the next value  </center></caption>
!--> 

<p>We will be training the model on random snippets of 30 values taken from a much longer piece of music. Thus, we won’t bother to set the first input $x^{\langle 1 \rangle} = \vec{0}$, which we had done previously to denote the start of a dinosaur name, since now most of these snippets of audio start somewhere in the middle of a piece of music. We are setting each of the snippts to have the same length $T_x = 30$ to make vectorization easier. </p>
<h2 id="2-Building-the-model"><a href="#2-Building-the-model" class="headerlink" title="2 - Building the model"></a>2 - Building the model</h2><p>In this part you will build and train a model that will learn musical patterns. To do so, you will need to build a model that takes in X of shape $(m, T_x, 78)$ and Y of shape $(T_y, m, 78)$. We will use an LSTM with 64 dimensional hidden states. Lets set <code>n_a = 64</code>. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n_a = <span class="number">64</span></span><br></pre></td></tr></table></figure>


<p>Here’s how you can create a Keras model with multiple inputs and outputs. If you’re building an RNN where even at test time entire input sequence $x^{\langle 1 \rangle}, x^{\langle 2 \rangle}, \ldots, x^{\langle T_x \rangle}$ were <em>given in advance</em>, for example if the inputs were words and the output was a label, then Keras has simple built-in functions to build the model. However, for sequence generation, at test time we don’t know all the values of $x^{\langle t\rangle}$ in advance; instead we generate them one at a time using $x^{\langle t\rangle} = y^{\langle t-1 \rangle}$. So the code will be a bit more complicated, and you’ll need to implement your own for-loop to iterate over the different time steps. </p>
<p>The function <code>djmodel()</code> will call the LSTM layer $T_x$ times using a for-loop, and it is important that all $T_x$ copies have the same weights. I.e., it should not re-initiaiize the weights every time—the $T_x$ steps should have shared weights. The key steps for implementing layers with shareable weights in Keras are: </p>
<ol>
<li>Define the layer objects (we will use global variables for this).</li>
<li>Call these objects when propagating the input.</li>
</ol>
<p>We have defined the layers objects you need as global variables. Please run the next cell to create them. Please check the Keras documentation to make sure you understand what these layers are: <a href="https://keras.io/layers/core/#reshape" target="_blank" rel="noopener">Reshape()</a>, <a href="https://keras.io/layers/recurrent/#lstm" target="_blank" rel="noopener">LSTM()</a>, <a href="https://keras.io/layers/core/#dense" target="_blank" rel="noopener">Dense()</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reshapor = Reshape((<span class="number">1</span>, <span class="number">78</span>))                        <span class="comment"># Used in Step 2.B of djmodel(), below</span></span><br><span class="line">LSTM_cell = LSTM(n_a, return_state = <span class="literal">True</span>)         <span class="comment"># Used in Step 2.C</span></span><br><span class="line">densor = Dense(n_values, activation=<span class="string">'softmax'</span>)     <span class="comment"># Used in Step 2.D</span></span><br></pre></td></tr></table></figure>

<p>Each of <code>reshapor</code>, <code>LSTM_cell</code> and <code>densor</code> are now layer objects, and you can use them to implement <code>djmodel()</code>. In order to propagate a Keras tensor object X through one of these layers, use <code>layer_object(X)</code> (or <code>layer_object([X,Y])</code> if it requires multiple inputs.). For example, <code>reshapor(X)</code> will propagate X through the <code>Reshape((1,78))</code> layer defined above.</p>
<p><strong>Exercise</strong>: Implement <code>djmodel()</code>. You will need to carry out 2 steps:</p>
<ol>
<li><p>Create an empty list “outputs” to save the outputs of the LSTM Cell at every time step.</p>
</li>
<li><p>Loop for $t \in 1, \ldots, T_x$:</p>
<p> A. Select the “t”th time-step vector from X. The shape of this selection should be (78,). To do so, create a custom <a href="https://keras.io/layers/core/#lambda" target="_blank" rel="noopener">Lambda</a> layer in Keras by using this line of code:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">           x &#x3D; Lambda(lambda x: X[:,t,:])(X)</span><br><span class="line">&#96;&#96;&#96; </span><br><span class="line">Look over the Keras documentation to figure out what this does. It is creating a &quot;temporary&quot; or &quot;unnamed&quot; function (that&#39;s what Lambda functions are) that extracts out the appropriate one-hot vector, and making this function a Keras &#96;Layer&#96; object to apply to &#96;X&#96;. </span><br><span class="line"></span><br><span class="line">    B. Reshape x to be (1,78). You may find the &#96;reshapor()&#96; layer (defined below) helpful.</span><br><span class="line"></span><br><span class="line">    C. Run x through one step of LSTM_cell. Remember to initialize the LSTM_cell with the previous step&#39;s hidden state $a$ and cell state $c$. Use the following formatting:</span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">a, _, c &#x3D; LSTM_cell(input_x, initial_state&#x3D;[previous hidden state, previous cell state])</span><br></pre></td></tr></table></figure>

<p> D. Propagate the LSTM’s output activation value through a dense+softmax layer using <code>densor</code>. </p>
<p> E. Append the predicted value to the list of “outputs”</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: djmodel</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">djmodel</span><span class="params">(Tx, n_a, n_values)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the model</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    Tx -- length of the sequence in a corpus</span></span><br><span class="line"><span class="string">    n_a -- the number of activations used in our model</span></span><br><span class="line"><span class="string">    n_values -- number of unique values in the music data </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    model -- a keras model with the </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define the input of your model with a shape </span></span><br><span class="line">    X = Input(shape=(Tx, n_values))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define s0, initial hidden state for the decoder LSTM</span></span><br><span class="line">    a0 = Input(shape=(n_a,), name=<span class="string">'a0'</span>)</span><br><span class="line">    c0 = Input(shape=(n_a,), name=<span class="string">'c0'</span>)</span><br><span class="line">    a = a0</span><br><span class="line">    c = c0</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### </span></span><br><span class="line">    <span class="comment"># Step 1: Create empty list to append the outputs while you iterate (≈1 line)</span></span><br><span class="line">    outputs = [];</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Loop</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(Tx):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2.A: select the "t"th time step vector from X. </span></span><br><span class="line">        x = Lambda(<span class="keyword">lambda</span> x: X[:,t,:])(X);</span><br><span class="line">        <span class="comment"># Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)</span></span><br><span class="line">        x = reshapor(x);</span><br><span class="line">        <span class="comment"># Step 2.C: Perform one step of the LSTM_cell</span></span><br><span class="line">        a, _, c = LSTM_cell(x, initial_state=[a, c]);</span><br><span class="line">        <span class="comment"># Step 2.D: Apply densor to the hidden state output of LSTM_Cell</span></span><br><span class="line">        out = densor(a);</span><br><span class="line">        <span class="comment"># Step 2.E: add the output to "outputs"</span></span><br><span class="line">        p = outputs.append(out);</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Step 3: Create model instance</span></span><br><span class="line">    model = Model(input=[X, a0, c0], outputs = outputs);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<p>Run the following cell to define your model. We will use <code>Tx=30</code>, <code>n_a=64</code> (the dimension of the LSTM activations), and <code>n_values=78</code>. This cell may take a few seconds to run. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = djmodel(Tx = <span class="number">30</span> , n_a = <span class="number">64</span>, n_values = <span class="number">78</span>)</span><br></pre></td></tr></table></figure>

<pre><code>/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:44: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[&lt;tf.Tenso..., inputs=[&lt;tf.Tenso...)`</code></pre><p>You now need to compile your model to be trained. We will Adam and a categorical cross-entropy loss.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">opt = Adam(lr=<span class="number">0.01</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, decay=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=opt, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>

<p>Finally, lets initialize <code>a0</code> and <code>c0</code> for the LSTM’s initial state to be zero. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = <span class="number">60</span></span><br><span class="line">a0 = np.zeros((m, n_a))</span><br><span class="line">c0 = np.zeros((m, n_a))</span><br></pre></td></tr></table></figure>

<p>Lets now fit the model! We will turn <code>Y</code> to a list before doing so, since the cost function expects <code>Y</code> to be provided in this format (one list item per time-step). So <code>list(Y)</code> is a list with 30 items, where each of the list items is of shape (60,78). Lets train for 100 epochs. This will take a few minutes. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit([X, a0, c0], list(Y), epochs=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/100
60/60 [==============================] - 5s - loss: 125.8264 - dense_1_loss_1: 4.3545 - dense_1_loss_2: 4.3464 - dense_1_loss_3: 4.3425 - dense_1_loss_4: 4.3442 - dense_1_loss_5: 4.3421 - dense_1_loss_6: 4.3446 - dense_1_loss_7: 4.3401 - dense_1_loss_8: 4.3457 - dense_1_loss_9: 4.3314 - dense_1_loss_10: 4.3323 - dense_1_loss_11: 4.3423 - dense_1_loss_12: 4.3389 - dense_1_loss_13: 4.3364 - dense_1_loss_14: 4.3380 - dense_1_loss_15: 4.3371 - dense_1_loss_16: 4.3311 - dense_1_loss_17: 4.3417 - dense_1_loss_18: 4.3396 - dense_1_loss_19: 4.3346 - dense_1_loss_20: 4.3342 - dense_1_loss_21: 4.3366 - dense_1_loss_22: 4.3406 - dense_1_loss_23: 4.3338 - dense_1_loss_24: 4.3317 - dense_1_loss_25: 4.3376 - dense_1_loss_26: 4.3340 - dense_1_loss_27: 4.3329 - dense_1_loss_28: 4.3416 - dense_1_loss_29: 4.3399 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0000e+00 - dense_1_acc_2: 0.0500 - dense_1_acc_3: 0.0500 - dense_1_acc_4: 0.0167 - dense_1_acc_5: 0.0500 - dense_1_acc_6: 0.0333 - dense_1_acc_7: 0.0500 - dense_1_acc_8: 0.0000e+00 - dense_1_acc_9: 0.1000 - dense_1_acc_10: 0.0333 - dense_1_acc_11: 0.0167 - dense_1_acc_12: 0.0667 - dense_1_acc_13: 0.0500 - dense_1_acc_14: 0.0667 - dense_1_acc_15: 0.0667 - dense_1_acc_16: 0.0500 - dense_1_acc_17: 0.0500 - dense_1_acc_18: 0.0167 - dense_1_acc_19: 0.1000 - dense_1_acc_20: 0.0667 - dense_1_acc_21: 0.0500 - dense_1_acc_22: 0.0667 - dense_1_acc_23: 0.1167 - dense_1_acc_24: 0.1000 - dense_1_acc_25: 0.0333 - dense_1_acc_26: 0.1000 - dense_1_acc_27: 0.0500 - dense_1_acc_28: 0.0500 - dense_1_acc_29: 0.0833 - dense_1_acc_30: 0.0000e+00                                                                 
Epoch 2/100
60/60 [==============================] - 0s - loss: 122.6142 - dense_1_loss_1: 4.3317 - dense_1_loss_2: 4.2991 - dense_1_loss_3: 4.2729 - dense_1_loss_4: 4.2763 - dense_1_loss_5: 4.2523 - dense_1_loss_6: 4.2653 - dense_1_loss_7: 4.2464 - dense_1_loss_8: 4.2352 - dense_1_loss_9: 4.2288 - dense_1_loss_10: 4.2197 - dense_1_loss_11: 4.2248 - dense_1_loss_12: 4.2489 - dense_1_loss_13: 4.2078 - dense_1_loss_14: 4.2074 - dense_1_loss_15: 4.2073 - dense_1_loss_16: 4.1991 - dense_1_loss_17: 4.2009 - dense_1_loss_18: 4.2387 - dense_1_loss_19: 4.1921 - dense_1_loss_20: 4.2132 - dense_1_loss_21: 4.2112 - dense_1_loss_22: 4.1933 - dense_1_loss_23: 4.1941 - dense_1_loss_24: 4.2164 - dense_1_loss_25: 4.2240 - dense_1_loss_26: 4.1728 - dense_1_loss_27: 4.2027 - dense_1_loss_28: 4.2063 - dense_1_loss_29: 4.2258 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1333 - dense_1_acc_3: 0.1500 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.1167 - dense_1_acc_7: 0.1667 - dense_1_acc_8: 0.1167 - dense_1_acc_9: 0.1833 - dense_1_acc_10: 0.1667 - dense_1_acc_11: 0.2000 - dense_1_acc_12: 0.0667 - dense_1_acc_13: 0.1333 - dense_1_acc_14: 0.1333 - dense_1_acc_15: 0.1167 - dense_1_acc_16: 0.1833 - dense_1_acc_17: 0.2000 - dense_1_acc_18: 0.0667 - dense_1_acc_19: 0.1333 - dense_1_acc_20: 0.1667 - dense_1_acc_21: 0.1333 - dense_1_acc_22: 0.1000 - dense_1_acc_23: 0.1167 - dense_1_acc_24: 0.1333 - dense_1_acc_25: 0.1167 - dense_1_acc_26: 0.1833 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.1833 - dense_1_acc_29: 0.0833 - dense_1_acc_30: 0.0000e+00     
Epoch 3/100
60/60 [==============================] - 0s - loss: 116.8061 - dense_1_loss_1: 4.3093 - dense_1_loss_2: 4.2449 - dense_1_loss_3: 4.1836 - dense_1_loss_4: 4.1745 - dense_1_loss_5: 4.1156 - dense_1_loss_6: 4.1481 - dense_1_loss_7: 4.0958 - dense_1_loss_8: 4.0446 - dense_1_loss_9: 3.9897 - dense_1_loss_10: 3.8988 - dense_1_loss_11: 3.8989 - dense_1_loss_12: 4.1165 - dense_1_loss_13: 3.8994 - dense_1_loss_14: 3.8898 - dense_1_loss_15: 3.9828 - dense_1_loss_16: 3.9182 - dense_1_loss_17: 3.8867 - dense_1_loss_18: 4.2104 - dense_1_loss_19: 3.8670 - dense_1_loss_20: 4.0711 - dense_1_loss_21: 4.0630 - dense_1_loss_22: 3.9217 - dense_1_loss_23: 3.9589 - dense_1_loss_24: 4.0469 - dense_1_loss_25: 4.0823 - dense_1_loss_26: 3.7266 - dense_1_loss_27: 3.9689 - dense_1_loss_28: 3.9623 - dense_1_loss_29: 4.1299 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.1333 - dense_1_acc_5: 0.1833 - dense_1_acc_6: 0.1000 - dense_1_acc_7: 0.1167 - dense_1_acc_8: 0.0833 - dense_1_acc_9: 0.1167 - dense_1_acc_10: 0.1167 - dense_1_acc_11: 0.0833 - dense_1_acc_12: 0.0167 - dense_1_acc_13: 0.1000 - dense_1_acc_14: 0.1000 - dense_1_acc_15: 0.0500 - dense_1_acc_16: 0.0833 - dense_1_acc_17: 0.1000 - dense_1_acc_18: 0.0167 - dense_1_acc_19: 0.1000 - dense_1_acc_20: 0.0667 - dense_1_acc_21: 0.0667 - dense_1_acc_22: 0.0500 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.0833 - dense_1_acc_25: 0.0167 - dense_1_acc_26: 0.1167 - dense_1_acc_27: 0.0500 - dense_1_acc_28: 0.0667 - dense_1_acc_29: 0.0333 - dense_1_acc_30: 0.0000e+00             
Epoch 4/100
60/60 [==============================] - 0s - loss: 112.2963 - dense_1_loss_1: 4.2889 - dense_1_loss_2: 4.1981 - dense_1_loss_3: 4.0962 - dense_1_loss_4: 4.0810 - dense_1_loss_5: 3.9790 - dense_1_loss_6: 4.0129 - dense_1_loss_7: 3.9439 - dense_1_loss_8: 3.7697 - dense_1_loss_9: 3.8046 - dense_1_loss_10: 3.6386 - dense_1_loss_11: 3.7236 - dense_1_loss_12: 3.9783 - dense_1_loss_13: 3.7060 - dense_1_loss_14: 3.7075 - dense_1_loss_15: 3.7358 - dense_1_loss_16: 3.7286 - dense_1_loss_17: 3.8079 - dense_1_loss_18: 3.9018 - dense_1_loss_19: 3.6729 - dense_1_loss_20: 3.9865 - dense_1_loss_21: 3.9529 - dense_1_loss_22: 3.8378 - dense_1_loss_23: 3.7695 - dense_1_loss_24: 3.7576 - dense_1_loss_25: 3.9597 - dense_1_loss_26: 3.6666 - dense_1_loss_27: 3.6978 - dense_1_loss_28: 3.8733 - dense_1_loss_29: 4.0193 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2667 - dense_1_acc_6: 0.1333 - dense_1_acc_7: 0.1667 - dense_1_acc_8: 0.1833 - dense_1_acc_9: 0.1667 - dense_1_acc_10: 0.1667 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.1000 - dense_1_acc_13: 0.1500 - dense_1_acc_14: 0.2167 - dense_1_acc_15: 0.1000 - dense_1_acc_16: 0.1167 - dense_1_acc_17: 0.1000 - dense_1_acc_18: 0.1000 - dense_1_acc_19: 0.1500 - dense_1_acc_20: 0.0833 - dense_1_acc_21: 0.0667 - dense_1_acc_22: 0.1167 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.0000e+00 - dense_1_acc_25: 0.1000 - dense_1_acc_26: 0.1000 - dense_1_acc_27: 0.0833 - dense_1_acc_28: 0.1167 - dense_1_acc_29: 0.0667 - dense_1_acc_30: 0.0000e+00     
Epoch 5/100
60/60 [==============================] - 0s - loss: 110.0390 - dense_1_loss_1: 4.2729 - dense_1_loss_2: 4.1581 - dense_1_loss_3: 4.0292 - dense_1_loss_4: 4.0164 - dense_1_loss_5: 3.8981 - dense_1_loss_6: 3.9318 - dense_1_loss_7: 3.8775 - dense_1_loss_8: 3.6710 - dense_1_loss_9: 3.7225 - dense_1_loss_10: 3.5653 - dense_1_loss_11: 3.6287 - dense_1_loss_12: 3.8595 - dense_1_loss_13: 3.6459 - dense_1_loss_14: 3.6176 - dense_1_loss_15: 3.7001 - dense_1_loss_16: 3.6384 - dense_1_loss_17: 3.7419 - dense_1_loss_18: 3.7274 - dense_1_loss_19: 3.6644 - dense_1_loss_20: 3.8134 - dense_1_loss_21: 3.8085 - dense_1_loss_22: 3.7113 - dense_1_loss_23: 3.6167 - dense_1_loss_24: 3.6441 - dense_1_loss_25: 3.9445 - dense_1_loss_26: 3.7134 - dense_1_loss_27: 3.6405 - dense_1_loss_28: 3.8265 - dense_1_loss_29: 3.9533 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.1333 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.2000 - dense_1_acc_5: 0.1333 - dense_1_acc_6: 0.0333 - dense_1_acc_7: 0.1000 - dense_1_acc_8: 0.1500 - dense_1_acc_9: 0.0833 - dense_1_acc_10: 0.1000 - dense_1_acc_11: 0.1000 - dense_1_acc_12: 0.0667 - dense_1_acc_13: 0.1000 - dense_1_acc_14: 0.1500 - dense_1_acc_15: 0.0833 - dense_1_acc_16: 0.0500 - dense_1_acc_17: 0.0500 - dense_1_acc_18: 0.0833 - dense_1_acc_19: 0.0333 - dense_1_acc_20: 0.0500 - dense_1_acc_21: 0.0833 - dense_1_acc_22: 0.0833 - dense_1_acc_23: 0.1667 - dense_1_acc_24: 0.0500 - dense_1_acc_25: 0.0500 - dense_1_acc_26: 0.0500 - dense_1_acc_27: 0.0833 - dense_1_acc_28: 0.0167 - dense_1_acc_29: 0.0167 - dense_1_acc_30: 0.0000e+00     
Epoch 6/100
60/60 [==============================] - 0s - loss: 106.1460 - dense_1_loss_1: 4.2571 - dense_1_loss_2: 4.1230 - dense_1_loss_3: 3.9604 - dense_1_loss_4: 3.9405 - dense_1_loss_5: 3.8132 - dense_1_loss_6: 3.8401 - dense_1_loss_7: 3.7750 - dense_1_loss_8: 3.5455 - dense_1_loss_9: 3.5752 - dense_1_loss_10: 3.4639 - dense_1_loss_11: 3.5982 - dense_1_loss_12: 3.7733 - dense_1_loss_13: 3.5049 - dense_1_loss_14: 3.4641 - dense_1_loss_15: 3.5221 - dense_1_loss_16: 3.5189 - dense_1_loss_17: 3.5414 - dense_1_loss_18: 3.5307 - dense_1_loss_19: 3.5341 - dense_1_loss_20: 3.6316 - dense_1_loss_21: 3.6324 - dense_1_loss_22: 3.5577 - dense_1_loss_23: 3.5073 - dense_1_loss_24: 3.5296 - dense_1_loss_25: 3.8212 - dense_1_loss_26: 3.4278 - dense_1_loss_27: 3.4614 - dense_1_loss_28: 3.5999 - dense_1_loss_29: 3.6956 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1667 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.2000 - dense_1_acc_5: 0.2500 - dense_1_acc_6: 0.0833 - dense_1_acc_7: 0.0833 - dense_1_acc_8: 0.1667 - dense_1_acc_9: 0.1000 - dense_1_acc_10: 0.2000 - dense_1_acc_11: 0.1333 - dense_1_acc_12: 0.1000 - dense_1_acc_13: 0.1833 - dense_1_acc_14: 0.2167 - dense_1_acc_15: 0.1167 - dense_1_acc_16: 0.1167 - dense_1_acc_17: 0.1333 - dense_1_acc_18: 0.1667 - dense_1_acc_19: 0.1833 - dense_1_acc_20: 0.1167 - dense_1_acc_21: 0.1500 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.1833 - dense_1_acc_24: 0.1167 - dense_1_acc_25: 0.0667 - dense_1_acc_26: 0.2000 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.1500 - dense_1_acc_29: 0.0667 - dense_1_acc_30: 0.0000e+00     
Epoch 7/100
60/60 [==============================] - 0s - loss: 102.2579 - dense_1_loss_1: 4.2413 - dense_1_loss_2: 4.0875 - dense_1_loss_3: 3.8934 - dense_1_loss_4: 3.8654 - dense_1_loss_5: 3.7056 - dense_1_loss_6: 3.7368 - dense_1_loss_7: 3.6732 - dense_1_loss_8: 3.4290 - dense_1_loss_9: 3.4259 - dense_1_loss_10: 3.3381 - dense_1_loss_11: 3.4889 - dense_1_loss_12: 3.6443 - dense_1_loss_13: 3.3488 - dense_1_loss_14: 3.3007 - dense_1_loss_15: 3.3981 - dense_1_loss_16: 3.3846 - dense_1_loss_17: 3.3449 - dense_1_loss_18: 3.3858 - dense_1_loss_19: 3.4057 - dense_1_loss_20: 3.4521 - dense_1_loss_21: 3.4389 - dense_1_loss_22: 3.3936 - dense_1_loss_23: 3.4140 - dense_1_loss_24: 3.3620 - dense_1_loss_25: 3.6902 - dense_1_loss_26: 3.2316 - dense_1_loss_27: 3.3343 - dense_1_loss_28: 3.3640 - dense_1_loss_29: 3.4791 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1333 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2667 - dense_1_acc_6: 0.1667 - dense_1_acc_7: 0.1333 - dense_1_acc_8: 0.2333 - dense_1_acc_9: 0.1667 - dense_1_acc_10: 0.2000 - dense_1_acc_11: 0.1833 - dense_1_acc_12: 0.1333 - dense_1_acc_13: 0.1667 - dense_1_acc_14: 0.2667 - dense_1_acc_15: 0.1667 - dense_1_acc_16: 0.1500 - dense_1_acc_17: 0.1833 - dense_1_acc_18: 0.1167 - dense_1_acc_19: 0.1333 - dense_1_acc_20: 0.1833 - dense_1_acc_21: 0.1167 - dense_1_acc_22: 0.1333 - dense_1_acc_23: 0.1333 - dense_1_acc_24: 0.1500 - dense_1_acc_25: 0.0667 - dense_1_acc_26: 0.2167 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.1500 - dense_1_acc_29: 0.1833 - dense_1_acc_30: 0.0000e+00     
Epoch 8/100
60/60 [==============================] - 0s - loss: 98.0187 - dense_1_loss_1: 4.2277 - dense_1_loss_2: 4.0477 - dense_1_loss_3: 3.8258 - dense_1_loss_4: 3.7791 - dense_1_loss_5: 3.6089 - dense_1_loss_6: 3.6218 - dense_1_loss_7: 3.5396 - dense_1_loss_8: 3.2991 - dense_1_loss_9: 3.2584 - dense_1_loss_10: 3.1349 - dense_1_loss_11: 3.2992 - dense_1_loss_12: 3.4534 - dense_1_loss_13: 3.1133 - dense_1_loss_14: 3.0906 - dense_1_loss_15: 3.2273 - dense_1_loss_16: 3.2308 - dense_1_loss_17: 3.1062 - dense_1_loss_18: 3.2503 - dense_1_loss_19: 3.2314 - dense_1_loss_20: 3.2470 - dense_1_loss_21: 3.2910 - dense_1_loss_22: 3.2553 - dense_1_loss_23: 3.2761 - dense_1_loss_24: 3.2245 - dense_1_loss_25: 3.5042 - dense_1_loss_26: 3.0631 - dense_1_loss_27: 3.2291 - dense_1_loss_28: 3.2519 - dense_1_loss_29: 3.3307 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.1667 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.2667 - dense_1_acc_6: 0.1833 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.2667 - dense_1_acc_9: 0.1667 - dense_1_acc_10: 0.2333 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.1167 - dense_1_acc_13: 0.2833 - dense_1_acc_14: 0.2333 - dense_1_acc_15: 0.1500 - dense_1_acc_16: 0.2000 - dense_1_acc_17: 0.2167 - dense_1_acc_18: 0.1333 - dense_1_acc_19: 0.1667 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.1667 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.1500 - dense_1_acc_24: 0.1333 - dense_1_acc_25: 0.1167 - dense_1_acc_26: 0.2500 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.1500 - dense_1_acc_29: 0.1667 - dense_1_acc_30: 0.0000e+00         
Epoch 9/100
60/60 [==============================] - 0s - loss: 93.9753 - dense_1_loss_1: 4.2159 - dense_1_loss_2: 4.0105 - dense_1_loss_3: 3.7472 - dense_1_loss_4: 3.6921 - dense_1_loss_5: 3.4942 - dense_1_loss_6: 3.4897 - dense_1_loss_7: 3.4181 - dense_1_loss_8: 3.1503 - dense_1_loss_9: 3.1051 - dense_1_loss_10: 2.9563 - dense_1_loss_11: 3.1541 - dense_1_loss_12: 3.2926 - dense_1_loss_13: 2.9499 - dense_1_loss_14: 2.9662 - dense_1_loss_15: 3.0675 - dense_1_loss_16: 3.1146 - dense_1_loss_17: 2.9696 - dense_1_loss_18: 3.1479 - dense_1_loss_19: 3.0151 - dense_1_loss_20: 3.0469 - dense_1_loss_21: 3.0955 - dense_1_loss_22: 3.0573 - dense_1_loss_23: 3.1520 - dense_1_loss_24: 3.0335 - dense_1_loss_25: 3.3512 - dense_1_loss_26: 2.8350 - dense_1_loss_27: 3.1168 - dense_1_loss_28: 3.1114 - dense_1_loss_29: 3.2186 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.1500 - dense_1_acc_5: 0.2500 - dense_1_acc_6: 0.1833 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.1833 - dense_1_acc_9: 0.2667 - dense_1_acc_10: 0.2500 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.1500 - dense_1_acc_13: 0.3333 - dense_1_acc_14: 0.2333 - dense_1_acc_15: 0.2000 - dense_1_acc_16: 0.2333 - dense_1_acc_17: 0.3000 - dense_1_acc_18: 0.1333 - dense_1_acc_19: 0.2000 - dense_1_acc_20: 0.3333 - dense_1_acc_21: 0.1833 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.2000 - dense_1_acc_24: 0.2000 - dense_1_acc_25: 0.1167 - dense_1_acc_26: 0.2667 - dense_1_acc_27: 0.1667 - dense_1_acc_28: 0.1500 - dense_1_acc_29: 0.2000 - dense_1_acc_30: 0.0000e+00     
Epoch 10/100
60/60 [==============================] - 0s - loss: 89.7720 - dense_1_loss_1: 4.2048 - dense_1_loss_2: 3.9711 - dense_1_loss_3: 3.6677 - dense_1_loss_4: 3.6035 - dense_1_loss_5: 3.3800 - dense_1_loss_6: 3.3506 - dense_1_loss_7: 3.2899 - dense_1_loss_8: 3.0100 - dense_1_loss_9: 2.9501 - dense_1_loss_10: 2.7743 - dense_1_loss_11: 3.0100 - dense_1_loss_12: 3.0628 - dense_1_loss_13: 2.8252 - dense_1_loss_14: 2.8456 - dense_1_loss_15: 2.9193 - dense_1_loss_16: 2.9354 - dense_1_loss_17: 2.7749 - dense_1_loss_18: 3.0148 - dense_1_loss_19: 2.8805 - dense_1_loss_20: 2.8963 - dense_1_loss_21: 2.9775 - dense_1_loss_22: 2.8919 - dense_1_loss_23: 2.9468 - dense_1_loss_24: 2.8604 - dense_1_loss_25: 3.1973 - dense_1_loss_26: 2.6616 - dense_1_loss_27: 2.9519 - dense_1_loss_28: 2.9121 - dense_1_loss_29: 3.0059 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.0667 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.2000 - dense_1_acc_7: 0.2167 - dense_1_acc_8: 0.1833 - dense_1_acc_9: 0.3000 - dense_1_acc_10: 0.2500 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.1500 - dense_1_acc_13: 0.2833 - dense_1_acc_14: 0.2500 - dense_1_acc_15: 0.2500 - dense_1_acc_16: 0.2667 - dense_1_acc_17: 0.3000 - dense_1_acc_18: 0.1000 - dense_1_acc_19: 0.2167 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.2167 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.2333 - dense_1_acc_24: 0.1667 - dense_1_acc_25: 0.1167 - dense_1_acc_26: 0.2833 - dense_1_acc_27: 0.1667 - dense_1_acc_28: 0.2167 - dense_1_acc_29: 0.2167 - dense_1_acc_30: 0.0000e+00     
Epoch 11/100
60/60 [==============================] - 0s - loss: 85.6615 - dense_1_loss_1: 4.1942 - dense_1_loss_2: 3.9323 - dense_1_loss_3: 3.5914 - dense_1_loss_4: 3.5058 - dense_1_loss_5: 3.2599 - dense_1_loss_6: 3.2069 - dense_1_loss_7: 3.1536 - dense_1_loss_8: 2.8428 - dense_1_loss_9: 2.8446 - dense_1_loss_10: 2.6600 - dense_1_loss_11: 2.8793 - dense_1_loss_12: 2.8746 - dense_1_loss_13: 2.6513 - dense_1_loss_14: 2.6880 - dense_1_loss_15: 2.7775 - dense_1_loss_16: 2.8001 - dense_1_loss_17: 2.6575 - dense_1_loss_18: 2.8262 - dense_1_loss_19: 2.6729 - dense_1_loss_20: 2.7437 - dense_1_loss_21: 2.7738 - dense_1_loss_22: 2.7370 - dense_1_loss_23: 2.8320 - dense_1_loss_24: 2.6954 - dense_1_loss_25: 2.9728 - dense_1_loss_26: 2.5801 - dense_1_loss_27: 2.7190 - dense_1_loss_28: 2.7862 - dense_1_loss_29: 2.8024 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.0667 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.2167 - dense_1_acc_5: 0.2833 - dense_1_acc_6: 0.2167 - dense_1_acc_7: 0.2333 - dense_1_acc_8: 0.2833 - dense_1_acc_9: 0.2667 - dense_1_acc_10: 0.3167 - dense_1_acc_11: 0.1333 - dense_1_acc_12: 0.2000 - dense_1_acc_13: 0.3333 - dense_1_acc_14: 0.2333 - dense_1_acc_15: 0.2333 - dense_1_acc_16: 0.2500 - dense_1_acc_17: 0.2333 - dense_1_acc_18: 0.1500 - dense_1_acc_19: 0.2500 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.2333 - dense_1_acc_22: 0.2000 - dense_1_acc_23: 0.2333 - dense_1_acc_24: 0.2000 - dense_1_acc_25: 0.1667 - dense_1_acc_26: 0.3333 - dense_1_acc_27: 0.2000 - dense_1_acc_28: 0.2167 - dense_1_acc_29: 0.3500 - dense_1_acc_30: 0.0000e+00     
Epoch 12/100
60/60 [==============================] - 0s - loss: 81.9096 - dense_1_loss_1: 4.1837 - dense_1_loss_2: 3.8924 - dense_1_loss_3: 3.5047 - dense_1_loss_4: 3.4058 - dense_1_loss_5: 3.1285 - dense_1_loss_6: 3.0528 - dense_1_loss_7: 3.0213 - dense_1_loss_8: 2.6764 - dense_1_loss_9: 2.6832 - dense_1_loss_10: 2.5371 - dense_1_loss_11: 2.7424 - dense_1_loss_12: 2.7007 - dense_1_loss_13: 2.5169 - dense_1_loss_14: 2.5984 - dense_1_loss_15: 2.5748 - dense_1_loss_16: 2.6452 - dense_1_loss_17: 2.5546 - dense_1_loss_18: 2.6831 - dense_1_loss_19: 2.6039 - dense_1_loss_20: 2.6078 - dense_1_loss_21: 2.6546 - dense_1_loss_22: 2.5963 - dense_1_loss_23: 2.6691 - dense_1_loss_24: 2.6460 - dense_1_loss_25: 2.8278 - dense_1_loss_26: 2.3809 - dense_1_loss_27: 2.6169 - dense_1_loss_28: 2.5561 - dense_1_loss_29: 2.6480 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.2167 - dense_1_acc_5: 0.3000 - dense_1_acc_6: 0.2333 - dense_1_acc_7: 0.2833 - dense_1_acc_8: 0.3167 - dense_1_acc_9: 0.3167 - dense_1_acc_10: 0.3000 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.2500 - dense_1_acc_13: 0.4000 - dense_1_acc_14: 0.2833 - dense_1_acc_15: 0.2500 - dense_1_acc_16: 0.2500 - dense_1_acc_17: 0.2500 - dense_1_acc_18: 0.1500 - dense_1_acc_19: 0.2833 - dense_1_acc_20: 0.3167 - dense_1_acc_21: 0.2667 - dense_1_acc_22: 0.2333 - dense_1_acc_23: 0.2333 - dense_1_acc_24: 0.2500 - dense_1_acc_25: 0.1333 - dense_1_acc_26: 0.3833 - dense_1_acc_27: 0.3000 - dense_1_acc_28: 0.3167 - dense_1_acc_29: 0.3167 - dense_1_acc_30: 0.0000e+00     
Epoch 13/100
60/60 [==============================] - 0s - loss: 77.9424 - dense_1_loss_1: 4.1726 - dense_1_loss_2: 3.8520 - dense_1_loss_3: 3.4239 - dense_1_loss_4: 3.3049 - dense_1_loss_5: 3.0094 - dense_1_loss_6: 2.9040 - dense_1_loss_7: 2.8879 - dense_1_loss_8: 2.5388 - dense_1_loss_9: 2.5642 - dense_1_loss_10: 2.3932 - dense_1_loss_11: 2.5736 - dense_1_loss_12: 2.5587 - dense_1_loss_13: 2.3320 - dense_1_loss_14: 2.4560 - dense_1_loss_15: 2.4168 - dense_1_loss_16: 2.5107 - dense_1_loss_17: 2.3550 - dense_1_loss_18: 2.4863 - dense_1_loss_19: 2.4692 - dense_1_loss_20: 2.4468 - dense_1_loss_21: 2.5056 - dense_1_loss_22: 2.4056 - dense_1_loss_23: 2.4519 - dense_1_loss_24: 2.6144 - dense_1_loss_25: 2.6999 - dense_1_loss_26: 2.1690 - dense_1_loss_27: 2.4230 - dense_1_loss_28: 2.4840 - dense_1_loss_29: 2.5331 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.2500 - dense_1_acc_4: 0.2000 - dense_1_acc_5: 0.3167 - dense_1_acc_6: 0.2167 - dense_1_acc_7: 0.3000 - dense_1_acc_8: 0.3500 - dense_1_acc_9: 0.3333 - dense_1_acc_10: 0.3333 - dense_1_acc_11: 0.2833 - dense_1_acc_12: 0.2500 - dense_1_acc_13: 0.3667 - dense_1_acc_14: 0.2500 - dense_1_acc_15: 0.2667 - dense_1_acc_16: 0.2333 - dense_1_acc_17: 0.3167 - dense_1_acc_18: 0.1833 - dense_1_acc_19: 0.2667 - dense_1_acc_20: 0.3333 - dense_1_acc_21: 0.3000 - dense_1_acc_22: 0.3000 - dense_1_acc_23: 0.2833 - dense_1_acc_24: 0.2500 - dense_1_acc_25: 0.1833 - dense_1_acc_26: 0.4167 - dense_1_acc_27: 0.2500 - dense_1_acc_28: 0.2167 - dense_1_acc_29: 0.3167 - dense_1_acc_30: 0.0000e+00     
Epoch 14/100
60/60 [==============================] - 0s - loss: 74.5680 - dense_1_loss_1: 4.1639 - dense_1_loss_2: 3.8115 - dense_1_loss_3: 3.3439 - dense_1_loss_4: 3.1987 - dense_1_loss_5: 2.8879 - dense_1_loss_6: 2.7570 - dense_1_loss_7: 2.7657 - dense_1_loss_8: 2.4219 - dense_1_loss_9: 2.4471 - dense_1_loss_10: 2.2721 - dense_1_loss_11: 2.4152 - dense_1_loss_12: 2.4041 - dense_1_loss_13: 2.1848 - dense_1_loss_14: 2.3034 - dense_1_loss_15: 2.2661 - dense_1_loss_16: 2.3730 - dense_1_loss_17: 2.2420 - dense_1_loss_18: 2.3084 - dense_1_loss_19: 2.3039 - dense_1_loss_20: 2.3927 - dense_1_loss_21: 2.3191 - dense_1_loss_22: 2.2784 - dense_1_loss_23: 2.3497 - dense_1_loss_24: 2.4033 - dense_1_loss_25: 2.6364 - dense_1_loss_26: 2.1220 - dense_1_loss_27: 2.3866 - dense_1_loss_28: 2.4073 - dense_1_loss_29: 2.4020 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2500 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.3333 - dense_1_acc_6: 0.2833 - dense_1_acc_7: 0.2667 - dense_1_acc_8: 0.3167 - dense_1_acc_9: 0.3333 - dense_1_acc_10: 0.3667 - dense_1_acc_11: 0.3167 - dense_1_acc_12: 0.2333 - dense_1_acc_13: 0.4000 - dense_1_acc_14: 0.3500 - dense_1_acc_15: 0.3500 - dense_1_acc_16: 0.2833 - dense_1_acc_17: 0.3667 - dense_1_acc_18: 0.2000 - dense_1_acc_19: 0.2833 - dense_1_acc_20: 0.3000 - dense_1_acc_21: 0.2833 - dense_1_acc_22: 0.2833 - dense_1_acc_23: 0.3333 - dense_1_acc_24: 0.2333 - dense_1_acc_25: 0.1667 - dense_1_acc_26: 0.3833 - dense_1_acc_27: 0.2667 - dense_1_acc_28: 0.2333 - dense_1_acc_29: 0.2833 - dense_1_acc_30: 0.0000e+00     
Epoch 15/100
60/60 [==============================] - 0s - loss: 70.7818 - dense_1_loss_1: 4.1566 - dense_1_loss_2: 3.7716 - dense_1_loss_3: 3.2704 - dense_1_loss_4: 3.1003 - dense_1_loss_5: 2.7766 - dense_1_loss_6: 2.6157 - dense_1_loss_7: 2.6423 - dense_1_loss_8: 2.3160 - dense_1_loss_9: 2.3343 - dense_1_loss_10: 2.1863 - dense_1_loss_11: 2.3080 - dense_1_loss_12: 2.2695 - dense_1_loss_13: 2.0643 - dense_1_loss_14: 2.1616 - dense_1_loss_15: 2.2092 - dense_1_loss_16: 2.2644 - dense_1_loss_17: 2.1717 - dense_1_loss_18: 2.1806 - dense_1_loss_19: 2.1495 - dense_1_loss_20: 2.2528 - dense_1_loss_21: 2.0959 - dense_1_loss_22: 2.1184 - dense_1_loss_23: 2.2349 - dense_1_loss_24: 2.2799 - dense_1_loss_25: 2.4104 - dense_1_loss_26: 1.9154 - dense_1_loss_27: 2.1144 - dense_1_loss_28: 2.2116 - dense_1_loss_29: 2.1992 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2833 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3167 - dense_1_acc_6: 0.3167 - dense_1_acc_7: 0.3167 - dense_1_acc_8: 0.3500 - dense_1_acc_9: 0.4000 - dense_1_acc_10: 0.4000 - dense_1_acc_11: 0.2333 - dense_1_acc_12: 0.2333 - dense_1_acc_13: 0.4667 - dense_1_acc_14: 0.4167 - dense_1_acc_15: 0.2833 - dense_1_acc_16: 0.3167 - dense_1_acc_17: 0.3667 - dense_1_acc_18: 0.3167 - dense_1_acc_19: 0.3500 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.3500 - dense_1_acc_22: 0.3667 - dense_1_acc_23: 0.4000 - dense_1_acc_24: 0.3000 - dense_1_acc_25: 0.2000 - dense_1_acc_26: 0.5167 - dense_1_acc_27: 0.3833 - dense_1_acc_28: 0.4167 - dense_1_acc_29: 0.4333 - dense_1_acc_30: 0.0000e+00     
Epoch 16/100
60/60 [==============================] - 0s - loss: 67.6264 - dense_1_loss_1: 4.1490 - dense_1_loss_2: 3.7330 - dense_1_loss_3: 3.1997 - dense_1_loss_4: 2.9972 - dense_1_loss_5: 2.6689 - dense_1_loss_6: 2.4691 - dense_1_loss_7: 2.4959 - dense_1_loss_8: 2.2321 - dense_1_loss_9: 2.2149 - dense_1_loss_10: 2.0676 - dense_1_loss_11: 2.1944 - dense_1_loss_12: 2.0894 - dense_1_loss_13: 1.9174 - dense_1_loss_14: 2.0482 - dense_1_loss_15: 2.0521 - dense_1_loss_16: 2.1589 - dense_1_loss_17: 2.0443 - dense_1_loss_18: 2.0343 - dense_1_loss_19: 2.0277 - dense_1_loss_20: 2.0924 - dense_1_loss_21: 2.0356 - dense_1_loss_22: 2.0433 - dense_1_loss_23: 2.1854 - dense_1_loss_24: 2.1334 - dense_1_loss_25: 2.2683 - dense_1_loss_26: 1.8710 - dense_1_loss_27: 2.0543 - dense_1_loss_28: 2.0875 - dense_1_loss_29: 2.0611 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1833 - dense_1_acc_3: 0.3000 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3333 - dense_1_acc_6: 0.3167 - dense_1_acc_7: 0.3500 - dense_1_acc_8: 0.3833 - dense_1_acc_9: 0.3833 - dense_1_acc_10: 0.3500 - dense_1_acc_11: 0.2500 - dense_1_acc_12: 0.3667 - dense_1_acc_13: 0.4167 - dense_1_acc_14: 0.4167 - dense_1_acc_15: 0.3333 - dense_1_acc_16: 0.3833 - dense_1_acc_17: 0.4000 - dense_1_acc_18: 0.4000 - dense_1_acc_19: 0.3833 - dense_1_acc_20: 0.4167 - dense_1_acc_21: 0.3833 - dense_1_acc_22: 0.3333 - dense_1_acc_23: 0.3000 - dense_1_acc_24: 0.3333 - dense_1_acc_25: 0.2167 - dense_1_acc_26: 0.4667 - dense_1_acc_27: 0.3500 - dense_1_acc_28: 0.4333 - dense_1_acc_29: 0.4333 - dense_1_acc_30: 0.0000e+00     
Epoch 17/100
60/60 [==============================] - 0s - loss: 64.3102 - dense_1_loss_1: 4.1432 - dense_1_loss_2: 3.6922 - dense_1_loss_3: 3.1260 - dense_1_loss_4: 2.9039 - dense_1_loss_5: 2.5473 - dense_1_loss_6: 2.3139 - dense_1_loss_7: 2.3524 - dense_1_loss_8: 2.1075 - dense_1_loss_9: 2.1829 - dense_1_loss_10: 1.9446 - dense_1_loss_11: 2.1464 - dense_1_loss_12: 2.0344 - dense_1_loss_13: 1.8492 - dense_1_loss_14: 1.8603 - dense_1_loss_15: 1.9291 - dense_1_loss_16: 2.0644 - dense_1_loss_17: 1.9326 - dense_1_loss_18: 1.8428 - dense_1_loss_19: 1.9004 - dense_1_loss_20: 1.9474 - dense_1_loss_21: 1.9269 - dense_1_loss_22: 1.9244 - dense_1_loss_23: 1.9607 - dense_1_loss_24: 2.0257 - dense_1_loss_25: 2.1022 - dense_1_loss_26: 1.7460 - dense_1_loss_27: 1.8937 - dense_1_loss_28: 1.9563 - dense_1_loss_29: 1.9534 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2000 - dense_1_acc_3: 0.3500 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3333 - dense_1_acc_6: 0.3500 - dense_1_acc_7: 0.3500 - dense_1_acc_8: 0.3667 - dense_1_acc_9: 0.3667 - dense_1_acc_10: 0.4333 - dense_1_acc_11: 0.3000 - dense_1_acc_12: 0.3500 - dense_1_acc_13: 0.4333 - dense_1_acc_14: 0.4167 - dense_1_acc_15: 0.3667 - dense_1_acc_16: 0.3333 - dense_1_acc_17: 0.3833 - dense_1_acc_18: 0.4833 - dense_1_acc_19: 0.4500 - dense_1_acc_20: 0.4667 - dense_1_acc_21: 0.4167 - dense_1_acc_22: 0.3667 - dense_1_acc_23: 0.4167 - dense_1_acc_24: 0.3667 - dense_1_acc_25: 0.2833 - dense_1_acc_26: 0.5667 - dense_1_acc_27: 0.4500 - dense_1_acc_28: 0.4167 - dense_1_acc_29: 0.4667 - dense_1_acc_30: 0.0000e+00     
Epoch 18/100
60/60 [==============================] - 0s - loss: 60.9770 - dense_1_loss_1: 4.1352 - dense_1_loss_2: 3.6501 - dense_1_loss_3: 3.0557 - dense_1_loss_4: 2.8116 - dense_1_loss_5: 2.4615 - dense_1_loss_6: 2.2039 - dense_1_loss_7: 2.2144 - dense_1_loss_8: 1.9720 - dense_1_loss_9: 2.0354 - dense_1_loss_10: 1.8256 - dense_1_loss_11: 1.9682 - dense_1_loss_12: 1.8455 - dense_1_loss_13: 1.7386 - dense_1_loss_14: 1.7591 - dense_1_loss_15: 1.7897 - dense_1_loss_16: 1.9169 - dense_1_loss_17: 1.8054 - dense_1_loss_18: 1.8099 - dense_1_loss_19: 1.7484 - dense_1_loss_20: 1.7715 - dense_1_loss_21: 1.7874 - dense_1_loss_22: 1.8334 - dense_1_loss_23: 1.7951 - dense_1_loss_24: 1.9296 - dense_1_loss_25: 1.9762 - dense_1_loss_26: 1.6691 - dense_1_loss_27: 1.8107 - dense_1_loss_28: 1.8523 - dense_1_loss_29: 1.8047 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2167 - dense_1_acc_3: 0.3500 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.3667 - dense_1_acc_6: 0.3333 - dense_1_acc_7: 0.4000 - dense_1_acc_8: 0.4333 - dense_1_acc_9: 0.3667 - dense_1_acc_10: 0.4500 - dense_1_acc_11: 0.3833 - dense_1_acc_12: 0.4167 - dense_1_acc_13: 0.5333 - dense_1_acc_14: 0.4667 - dense_1_acc_15: 0.4667 - dense_1_acc_16: 0.3333 - dense_1_acc_17: 0.4000 - dense_1_acc_18: 0.3667 - dense_1_acc_19: 0.4000 - dense_1_acc_20: 0.4833 - dense_1_acc_21: 0.3833 - dense_1_acc_22: 0.4500 - dense_1_acc_23: 0.4833 - dense_1_acc_24: 0.3500 - dense_1_acc_25: 0.3500 - dense_1_acc_26: 0.5333 - dense_1_acc_27: 0.4333 - dense_1_acc_28: 0.4333 - dense_1_acc_29: 0.5500 - dense_1_acc_30: 0.0000e+00     
Epoch 19/100
60/60 [==============================] - 0s - loss: 58.1739 - dense_1_loss_1: 4.1267 - dense_1_loss_2: 3.6067 - dense_1_loss_3: 2.9783 - dense_1_loss_4: 2.7143 - dense_1_loss_5: 2.3603 - dense_1_loss_6: 2.1084 - dense_1_loss_7: 2.1157 - dense_1_loss_8: 1.8884 - dense_1_loss_9: 1.9336 - dense_1_loss_10: 1.7485 - dense_1_loss_11: 1.9035 - dense_1_loss_12: 1.7516 - dense_1_loss_13: 1.5965 - dense_1_loss_14: 1.6437 - dense_1_loss_15: 1.6844 - dense_1_loss_16: 1.8346 - dense_1_loss_17: 1.7095 - dense_1_loss_18: 1.7362 - dense_1_loss_19: 1.6973 - dense_1_loss_20: 1.6533 - dense_1_loss_21: 1.6370 - dense_1_loss_22: 1.7230 - dense_1_loss_23: 1.7123 - dense_1_loss_24: 1.7885 - dense_1_loss_25: 1.8111 - dense_1_loss_26: 1.6029 - dense_1_loss_27: 1.7325 - dense_1_loss_28: 1.7083 - dense_1_loss_29: 1.6667 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2167 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.3500 - dense_1_acc_6: 0.3833 - dense_1_acc_7: 0.4000 - dense_1_acc_8: 0.4167 - dense_1_acc_9: 0.4333 - dense_1_acc_10: 0.4500 - dense_1_acc_11: 0.3167 - dense_1_acc_12: 0.5000 - dense_1_acc_13: 0.6000 - dense_1_acc_14: 0.5000 - dense_1_acc_15: 0.5333 - dense_1_acc_16: 0.3833 - dense_1_acc_17: 0.4833 - dense_1_acc_18: 0.3833 - dense_1_acc_19: 0.4333 - dense_1_acc_20: 0.5000 - dense_1_acc_21: 0.5000 - dense_1_acc_22: 0.4833 - dense_1_acc_23: 0.4833 - dense_1_acc_24: 0.4167 - dense_1_acc_25: 0.4333 - dense_1_acc_26: 0.6333 - dense_1_acc_27: 0.5000 - dense_1_acc_28: 0.5167 - dense_1_acc_29: 0.5667 - dense_1_acc_30: 0.0000e+00     
Epoch 20/100
60/60 [==============================] - 0s - loss: 55.4761 - dense_1_loss_1: 4.1189 - dense_1_loss_2: 3.5637 - dense_1_loss_3: 2.9002 - dense_1_loss_4: 2.6177 - dense_1_loss_5: 2.2596 - dense_1_loss_6: 1.9893 - dense_1_loss_7: 2.0135 - dense_1_loss_8: 1.7673 - dense_1_loss_9: 1.8833 - dense_1_loss_10: 1.6986 - dense_1_loss_11: 1.7912 - dense_1_loss_12: 1.6945 - dense_1_loss_13: 1.5218 - dense_1_loss_14: 1.5522 - dense_1_loss_15: 1.6312 - dense_1_loss_16: 1.7254 - dense_1_loss_17: 1.6705 - dense_1_loss_18: 1.5892 - dense_1_loss_19: 1.6236 - dense_1_loss_20: 1.5906 - dense_1_loss_21: 1.5903 - dense_1_loss_22: 1.6394 - dense_1_loss_23: 1.5444 - dense_1_loss_24: 1.6563 - dense_1_loss_25: 1.7084 - dense_1_loss_26: 1.4733 - dense_1_loss_27: 1.5569 - dense_1_loss_28: 1.5812 - dense_1_loss_29: 1.5237 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.3833 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.3500 - dense_1_acc_6: 0.4000 - dense_1_acc_7: 0.4000 - dense_1_acc_8: 0.4167 - dense_1_acc_9: 0.4167 - dense_1_acc_10: 0.4667 - dense_1_acc_11: 0.4167 - dense_1_acc_12: 0.4000 - dense_1_acc_13: 0.6000 - dense_1_acc_14: 0.5500 - dense_1_acc_15: 0.4833 - dense_1_acc_16: 0.4667 - dense_1_acc_17: 0.4667 - dense_1_acc_18: 0.4833 - dense_1_acc_19: 0.5000 - dense_1_acc_20: 0.5833 - dense_1_acc_21: 0.5833 - dense_1_acc_22: 0.5167 - dense_1_acc_23: 0.6167 - dense_1_acc_24: 0.5333 - dense_1_acc_25: 0.4167 - dense_1_acc_26: 0.6500 - dense_1_acc_27: 0.6000 - dense_1_acc_28: 0.5167 - dense_1_acc_29: 0.6167 - dense_1_acc_30: 0.0000e+00     
Epoch 21/100
60/60 [==============================] - 0s - loss: 52.5952 - dense_1_loss_1: 4.1115 - dense_1_loss_2: 3.5210 - dense_1_loss_3: 2.8198 - dense_1_loss_4: 2.5191 - dense_1_loss_5: 2.1622 - dense_1_loss_6: 1.8718 - dense_1_loss_7: 1.8840 - dense_1_loss_8: 1.6437 - dense_1_loss_9: 1.7017 - dense_1_loss_10: 1.5723 - dense_1_loss_11: 1.6463 - dense_1_loss_12: 1.5608 - dense_1_loss_13: 1.3714 - dense_1_loss_14: 1.4084 - dense_1_loss_15: 1.4898 - dense_1_loss_16: 1.5919 - dense_1_loss_17: 1.5521 - dense_1_loss_18: 1.4812 - dense_1_loss_19: 1.4532 - dense_1_loss_20: 1.5159 - dense_1_loss_21: 1.4975 - dense_1_loss_22: 1.5416 - dense_1_loss_23: 1.4791 - dense_1_loss_24: 1.5756 - dense_1_loss_25: 1.6586 - dense_1_loss_26: 1.4051 - dense_1_loss_27: 1.5384 - dense_1_loss_28: 1.5311 - dense_1_loss_29: 1.4903 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.4000 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3500 - dense_1_acc_6: 0.4500 - dense_1_acc_7: 0.4500 - dense_1_acc_8: 0.5000 - dense_1_acc_9: 0.5167 - dense_1_acc_10: 0.5000 - dense_1_acc_11: 0.4333 - dense_1_acc_12: 0.4667 - dense_1_acc_13: 0.7167 - dense_1_acc_14: 0.6833 - dense_1_acc_15: 0.5167 - dense_1_acc_16: 0.5500 - dense_1_acc_17: 0.4833 - dense_1_acc_18: 0.5333 - dense_1_acc_19: 0.5333 - dense_1_acc_20: 0.4833 - dense_1_acc_21: 0.6167 - dense_1_acc_22: 0.5667 - dense_1_acc_23: 0.5667 - dense_1_acc_24: 0.4833 - dense_1_acc_25: 0.4500 - dense_1_acc_26: 0.6333 - dense_1_acc_27: 0.5500 - dense_1_acc_28: 0.5833 - dense_1_acc_29: 0.6500 - dense_1_acc_30: 0.0000e+00     
Epoch 22/100
60/60 [==============================] - 0s - loss: 50.2160 - dense_1_loss_1: 4.1047 - dense_1_loss_2: 3.4770 - dense_1_loss_3: 2.7407 - dense_1_loss_4: 2.4178 - dense_1_loss_5: 2.0648 - dense_1_loss_6: 1.7635 - dense_1_loss_7: 1.7659 - dense_1_loss_8: 1.5881 - dense_1_loss_9: 1.5796 - dense_1_loss_10: 1.4720 - dense_1_loss_11: 1.5638 - dense_1_loss_12: 1.4441 - dense_1_loss_13: 1.3000 - dense_1_loss_14: 1.3932 - dense_1_loss_15: 1.3870 - dense_1_loss_16: 1.5121 - dense_1_loss_17: 1.4827 - dense_1_loss_18: 1.3958 - dense_1_loss_19: 1.4016 - dense_1_loss_20: 1.4361 - dense_1_loss_21: 1.4005 - dense_1_loss_22: 1.5129 - dense_1_loss_23: 1.3737 - dense_1_loss_24: 1.4531 - dense_1_loss_25: 1.5305 - dense_1_loss_26: 1.3757 - dense_1_loss_27: 1.4563 - dense_1_loss_28: 1.4114 - dense_1_loss_29: 1.4113 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.4167 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.3667 - dense_1_acc_6: 0.5000 - dense_1_acc_7: 0.4667 - dense_1_acc_8: 0.5167 - dense_1_acc_9: 0.6000 - dense_1_acc_10: 0.5500 - dense_1_acc_11: 0.4333 - dense_1_acc_12: 0.5167 - dense_1_acc_13: 0.7000 - dense_1_acc_14: 0.6333 - dense_1_acc_15: 0.6000 - dense_1_acc_16: 0.5333 - dense_1_acc_17: 0.5500 - dense_1_acc_18: 0.5833 - dense_1_acc_19: 0.6333 - dense_1_acc_20: 0.6833 - dense_1_acc_21: 0.6500 - dense_1_acc_22: 0.6167 - dense_1_acc_23: 0.6833 - dense_1_acc_24: 0.5667 - dense_1_acc_25: 0.5333 - dense_1_acc_26: 0.6500 - dense_1_acc_27: 0.5167 - dense_1_acc_28: 0.7000 - dense_1_acc_29: 0.6667 - dense_1_acc_30: 0.0000e+00     
Epoch 23/100
60/60 [==============================] - 0s - loss: 47.6829 - dense_1_loss_1: 4.0972 - dense_1_loss_2: 3.4353 - dense_1_loss_3: 2.6637 - dense_1_loss_4: 2.3184 - dense_1_loss_5: 1.9563 - dense_1_loss_6: 1.6456 - dense_1_loss_7: 1.6569 - dense_1_loss_8: 1.4727 - dense_1_loss_9: 1.5131 - dense_1_loss_10: 1.3883 - dense_1_loss_11: 1.4958 - dense_1_loss_12: 1.3610 - dense_1_loss_13: 1.2473 - dense_1_loss_14: 1.3105 - dense_1_loss_15: 1.3116 - dense_1_loss_16: 1.3763 - dense_1_loss_17: 1.3985 - dense_1_loss_18: 1.3418 - dense_1_loss_19: 1.3085 - dense_1_loss_20: 1.3157 - dense_1_loss_21: 1.3183 - dense_1_loss_22: 1.4045 - dense_1_loss_23: 1.3021 - dense_1_loss_24: 1.3491 - dense_1_loss_25: 1.4308 - dense_1_loss_26: 1.2834 - dense_1_loss_27: 1.3413 - dense_1_loss_28: 1.3298 - dense_1_loss_29: 1.3091 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.4333 - dense_1_acc_4: 0.3333 - dense_1_acc_5: 0.4000 - dense_1_acc_6: 0.5000 - dense_1_acc_7: 0.5000 - dense_1_acc_8: 0.5667 - dense_1_acc_9: 0.6167 - dense_1_acc_10: 0.6167 - dense_1_acc_11: 0.5667 - dense_1_acc_12: 0.6167 - dense_1_acc_13: 0.7333 - dense_1_acc_14: 0.6167 - dense_1_acc_15: 0.5833 - dense_1_acc_16: 0.6000 - dense_1_acc_17: 0.6333 - dense_1_acc_18: 0.6500 - dense_1_acc_19: 0.6833 - dense_1_acc_20: 0.7667 - dense_1_acc_21: 0.6500 - dense_1_acc_22: 0.6500 - dense_1_acc_23: 0.7333 - dense_1_acc_24: 0.6667 - dense_1_acc_25: 0.5333 - dense_1_acc_26: 0.7333 - dense_1_acc_27: 0.6667 - dense_1_acc_28: 0.7167 - dense_1_acc_29: 0.7000 - dense_1_acc_30: 0.0000e+00     
Epoch 24/100
60/60 [==============================] - 0s - loss: 45.3187 - dense_1_loss_1: 4.0901 - dense_1_loss_2: 3.3922 - dense_1_loss_3: 2.5825 - dense_1_loss_4: 2.2373 - dense_1_loss_5: 1.8703 - dense_1_loss_6: 1.5549 - dense_1_loss_7: 1.5355 - dense_1_loss_8: 1.4056 - dense_1_loss_9: 1.3904 - dense_1_loss_10: 1.3019 - dense_1_loss_11: 1.3719 - dense_1_loss_12: 1.2736 - dense_1_loss_13: 1.1612 - dense_1_loss_14: 1.2376 - dense_1_loss_15: 1.2141 - dense_1_loss_16: 1.2789 - dense_1_loss_17: 1.3098 - dense_1_loss_18: 1.2803 - dense_1_loss_19: 1.2623 - dense_1_loss_20: 1.2124 - dense_1_loss_21: 1.2315 - dense_1_loss_22: 1.3501 - dense_1_loss_23: 1.2118 - dense_1_loss_24: 1.2614 - dense_1_loss_25: 1.3370 - dense_1_loss_26: 1.2148 - dense_1_loss_27: 1.2702 - dense_1_loss_28: 1.2633 - dense_1_loss_29: 1.2155 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.4500 - dense_1_acc_4: 0.3500 - dense_1_acc_5: 0.4000 - dense_1_acc_6: 0.6000 - dense_1_acc_7: 0.5500 - dense_1_acc_8: 0.6333 - dense_1_acc_9: 0.6333 - dense_1_acc_10: 0.6500 - dense_1_acc_11: 0.5333 - dense_1_acc_12: 0.6833 - dense_1_acc_13: 0.8000 - dense_1_acc_14: 0.6000 - dense_1_acc_15: 0.6000 - dense_1_acc_16: 0.6667 - dense_1_acc_17: 0.6833 - dense_1_acc_18: 0.7167 - dense_1_acc_19: 0.7333 - dense_1_acc_20: 0.7500 - dense_1_acc_21: 0.7500 - dense_1_acc_22: 0.7000 - dense_1_acc_23: 0.7667 - dense_1_acc_24: 0.7500 - dense_1_acc_25: 0.5000 - dense_1_acc_26: 0.7167 - dense_1_acc_27: 0.6667 - dense_1_acc_28: 0.7667 - dense_1_acc_29: 0.7667 - dense_1_acc_30: 0.0000e+00     
Epoch 25/100
60/60 [==============================] - 0s - loss: 43.0943 - dense_1_loss_1: 4.0826 - dense_1_loss_2: 3.3473 - dense_1_loss_3: 2.5037 - dense_1_loss_4: 2.1542 - dense_1_loss_5: 1.7748 - dense_1_loss_6: 1.4676 - dense_1_loss_7: 1.4258 - dense_1_loss_8: 1.3439 - dense_1_loss_9: 1.2775 - dense_1_loss_10: 1.2072 - dense_1_loss_11: 1.2504 - dense_1_loss_12: 1.1964 - dense_1_loss_13: 1.0910 - dense_1_loss_14: 1.1317 - dense_1_loss_15: 1.1530 - dense_1_loss_16: 1.1781 - dense_1_loss_17: 1.2662 - dense_1_loss_18: 1.2050 - dense_1_loss_19: 1.1581 - dense_1_loss_20: 1.1413 - dense_1_loss_21: 1.1878 - dense_1_loss_22: 1.2693 - dense_1_loss_23: 1.1599 - dense_1_loss_24: 1.1910 - dense_1_loss_25: 1.2612 - dense_1_loss_26: 1.1298 - dense_1_loss_27: 1.2135 - dense_1_loss_28: 1.1730 - dense_1_loss_29: 1.1530 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3000 - dense_1_acc_3: 0.4667 - dense_1_acc_4: 0.3500 - dense_1_acc_5: 0.4500 - dense_1_acc_6: 0.6000 - dense_1_acc_7: 0.5833 - dense_1_acc_8: 0.6500 - dense_1_acc_9: 0.6833 - dense_1_acc_10: 0.6833 - dense_1_acc_11: 0.6167 - dense_1_acc_12: 0.7167 - dense_1_acc_13: 0.8333 - dense_1_acc_14: 0.7167 - dense_1_acc_15: 0.7000 - dense_1_acc_16: 0.7167 - dense_1_acc_17: 0.6333 - dense_1_acc_18: 0.7000 - dense_1_acc_19: 0.8000 - dense_1_acc_20: 0.7833 - dense_1_acc_21: 0.7667 - dense_1_acc_22: 0.7000 - dense_1_acc_23: 0.7833 - dense_1_acc_24: 0.6833 - dense_1_acc_25: 0.5833 - dense_1_acc_26: 0.7500 - dense_1_acc_27: 0.6500 - dense_1_acc_28: 0.7833 - dense_1_acc_29: 0.7667 - dense_1_acc_30: 0.0000e+00     
Epoch 26/100
60/60 [==============================] - 0s - loss: 40.8022 - dense_1_loss_1: 4.0748 - dense_1_loss_2: 3.3002 - dense_1_loss_3: 2.4259 - dense_1_loss_4: 2.0715 - dense_1_loss_5: 1.6825 - dense_1_loss_6: 1.3776 - dense_1_loss_7: 1.3323 - dense_1_loss_8: 1.2728 - dense_1_loss_9: 1.2005 - dense_1_loss_10: 1.1305 - dense_1_loss_11: 1.1444 - dense_1_loss_12: 1.1230 - dense_1_loss_13: 1.0321 - dense_1_loss_14: 1.0275 - dense_1_loss_15: 1.0911 - dense_1_loss_16: 1.0935 - dense_1_loss_17: 1.1465 - dense_1_loss_18: 1.1157 - dense_1_loss_19: 1.0581 - dense_1_loss_20: 1.0947 - dense_1_loss_21: 1.1024 - dense_1_loss_22: 1.1725 - dense_1_loss_23: 1.0688 - dense_1_loss_24: 1.0804 - dense_1_loss_25: 1.1933 - dense_1_loss_26: 1.0530 - dense_1_loss_27: 1.1423 - dense_1_loss_28: 1.0956 - dense_1_loss_29: 1.0991 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5000 - dense_1_acc_4: 0.3833 - dense_1_acc_5: 0.5000 - dense_1_acc_6: 0.6833 - dense_1_acc_7: 0.7000 - dense_1_acc_8: 0.6167 - dense_1_acc_9: 0.7000 - dense_1_acc_10: 0.7833 - dense_1_acc_11: 0.7167 - dense_1_acc_12: 0.8000 - dense_1_acc_13: 0.8833 - dense_1_acc_14: 0.8667 - dense_1_acc_15: 0.7833 - dense_1_acc_16: 0.8167 - dense_1_acc_17: 0.8000 - dense_1_acc_18: 0.7333 - dense_1_acc_19: 0.8333 - dense_1_acc_20: 0.8167 - dense_1_acc_21: 0.8667 - dense_1_acc_22: 0.7667 - dense_1_acc_23: 0.8500 - dense_1_acc_24: 0.8000 - dense_1_acc_25: 0.7000 - dense_1_acc_26: 0.8667 - dense_1_acc_27: 0.7667 - dense_1_acc_28: 0.8333 - dense_1_acc_29: 0.8333 - dense_1_acc_30: 0.0000e+00     
Epoch 27/100
60/60 [==============================] - 0s - loss: 38.8025 - dense_1_loss_1: 4.0663 - dense_1_loss_2: 3.2536 - dense_1_loss_3: 2.3506 - dense_1_loss_4: 1.9905 - dense_1_loss_5: 1.5981 - dense_1_loss_6: 1.3005 - dense_1_loss_7: 1.2525 - dense_1_loss_8: 1.2083 - dense_1_loss_9: 1.1123 - dense_1_loss_10: 1.0546 - dense_1_loss_11: 1.0712 - dense_1_loss_12: 1.0661 - dense_1_loss_13: 0.9613 - dense_1_loss_14: 0.9802 - dense_1_loss_15: 1.0168 - dense_1_loss_16: 1.0461 - dense_1_loss_17: 1.0501 - dense_1_loss_18: 1.0304 - dense_1_loss_19: 1.0029 - dense_1_loss_20: 1.0419 - dense_1_loss_21: 1.0439 - dense_1_loss_22: 1.0489 - dense_1_loss_23: 1.0150 - dense_1_loss_24: 0.9941 - dense_1_loss_25: 1.1266 - dense_1_loss_26: 1.0159 - dense_1_loss_27: 1.0529 - dense_1_loss_28: 1.0263 - dense_1_loss_29: 1.0247 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5000 - dense_1_acc_4: 0.4000 - dense_1_acc_5: 0.5167 - dense_1_acc_6: 0.6667 - dense_1_acc_7: 0.7500 - dense_1_acc_8: 0.6500 - dense_1_acc_9: 0.7500 - dense_1_acc_10: 0.8333 - dense_1_acc_11: 0.7667 - dense_1_acc_12: 0.8167 - dense_1_acc_13: 0.8833 - dense_1_acc_14: 0.8667 - dense_1_acc_15: 0.8333 - dense_1_acc_16: 0.9000 - dense_1_acc_17: 0.8500 - dense_1_acc_18: 0.7500 - dense_1_acc_19: 0.8833 - dense_1_acc_20: 0.8500 - dense_1_acc_21: 0.8500 - dense_1_acc_22: 0.8833 - dense_1_acc_23: 0.8333 - dense_1_acc_24: 0.8667 - dense_1_acc_25: 0.7000 - dense_1_acc_26: 0.8500 - dense_1_acc_27: 0.8000 - dense_1_acc_28: 0.8333 - dense_1_acc_29: 0.8333 - dense_1_acc_30: 0.0000e+00     
Epoch 28/100
60/60 [==============================] - 0s - loss: 36.8764 - dense_1_loss_1: 4.0580 - dense_1_loss_2: 3.2063 - dense_1_loss_3: 2.2747 - dense_1_loss_4: 1.9115 - dense_1_loss_5: 1.5232 - dense_1_loss_6: 1.2318 - dense_1_loss_7: 1.1687 - dense_1_loss_8: 1.1294 - dense_1_loss_9: 1.0486 - dense_1_loss_10: 0.9668 - dense_1_loss_11: 1.0165 - dense_1_loss_12: 1.0011 - dense_1_loss_13: 0.8906 - dense_1_loss_14: 0.8915 - dense_1_loss_15: 0.9522 - dense_1_loss_16: 0.9425 - dense_1_loss_17: 0.9959 - dense_1_loss_18: 0.9568 - dense_1_loss_19: 0.9452 - dense_1_loss_20: 0.9827 - dense_1_loss_21: 0.9702 - dense_1_loss_22: 0.9839 - dense_1_loss_23: 0.9601 - dense_1_loss_24: 0.9256 - dense_1_loss_25: 1.0594 - dense_1_loss_26: 0.9498 - dense_1_loss_27: 1.0003 - dense_1_loss_28: 0.9784 - dense_1_loss_29: 0.9549 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5333 - dense_1_acc_4: 0.4500 - dense_1_acc_5: 0.5500 - dense_1_acc_6: 0.7167 - dense_1_acc_7: 0.8500 - dense_1_acc_8: 0.7167 - dense_1_acc_9: 0.8167 - dense_1_acc_10: 0.8833 - dense_1_acc_11: 0.7667 - dense_1_acc_12: 0.8500 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.8833 - dense_1_acc_15: 0.8500 - dense_1_acc_16: 0.9500 - dense_1_acc_17: 0.8333 - dense_1_acc_18: 0.7667 - dense_1_acc_19: 0.8667 - dense_1_acc_20: 0.8333 - dense_1_acc_21: 0.8500 - dense_1_acc_22: 0.9000 - dense_1_acc_23: 0.8833 - dense_1_acc_24: 0.8833 - dense_1_acc_25: 0.7667 - dense_1_acc_26: 0.8833 - dense_1_acc_27: 0.8167 - dense_1_acc_28: 0.8333 - dense_1_acc_29: 0.8833 - dense_1_acc_30: 0.0000e+00     
Epoch 29/100
60/60 [==============================] - 0s - loss: 34.8516 - dense_1_loss_1: 4.0505 - dense_1_loss_2: 3.1603 - dense_1_loss_3: 2.2028 - dense_1_loss_4: 1.8335 - dense_1_loss_5: 1.4395 - dense_1_loss_6: 1.1476 - dense_1_loss_7: 1.0989 - dense_1_loss_8: 1.0629 - dense_1_loss_9: 0.9678 - dense_1_loss_10: 0.9031 - dense_1_loss_11: 0.9193 - dense_1_loss_12: 0.9352 - dense_1_loss_13: 0.8223 - dense_1_loss_14: 0.8405 - dense_1_loss_15: 0.8826 - dense_1_loss_16: 0.8818 - dense_1_loss_17: 0.9120 - dense_1_loss_18: 0.8814 - dense_1_loss_19: 0.8926 - dense_1_loss_20: 0.9129 - dense_1_loss_21: 0.8975 - dense_1_loss_22: 0.9191 - dense_1_loss_23: 0.8582 - dense_1_loss_24: 0.8664 - dense_1_loss_25: 0.9873 - dense_1_loss_26: 0.8851 - dense_1_loss_27: 0.9208 - dense_1_loss_28: 0.8919 - dense_1_loss_29: 0.8781 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5333 - dense_1_acc_4: 0.4833 - dense_1_acc_5: 0.5833 - dense_1_acc_6: 0.7667 - dense_1_acc_7: 0.9000 - dense_1_acc_8: 0.7500 - dense_1_acc_9: 0.8000 - dense_1_acc_10: 0.8833 - dense_1_acc_11: 0.8500 - dense_1_acc_12: 0.9167 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.9500 - dense_1_acc_15: 0.8833 - dense_1_acc_16: 0.9667 - dense_1_acc_17: 0.9000 - dense_1_acc_18: 0.8833 - dense_1_acc_19: 0.8667 - dense_1_acc_20: 0.9000 - dense_1_acc_21: 0.9333 - dense_1_acc_22: 0.9167 - dense_1_acc_23: 0.9167 - dense_1_acc_24: 0.9167 - dense_1_acc_25: 0.8000 - dense_1_acc_26: 0.9167 - dense_1_acc_27: 0.9000 - dense_1_acc_28: 0.8667 - dense_1_acc_29: 0.8833 - dense_1_acc_30: 0.0000e+00     
Epoch 30/100
60/60 [==============================] - 0s - loss: 33.0396 - dense_1_loss_1: 4.0425 - dense_1_loss_2: 3.1119 - dense_1_loss_3: 2.1338 - dense_1_loss_4: 1.7691 - dense_1_loss_5: 1.3593 - dense_1_loss_6: 1.0798 - dense_1_loss_7: 1.0260 - dense_1_loss_8: 0.9722 - dense_1_loss_9: 0.8939 - dense_1_loss_10: 0.8502 - dense_1_loss_11: 0.8510 - dense_1_loss_12: 0.8728 - dense_1_loss_13: 0.7624 - dense_1_loss_14: 0.8034 - dense_1_loss_15: 0.8181 - dense_1_loss_16: 0.8146 - dense_1_loss_17: 0.8315 - dense_1_loss_18: 0.8346 - dense_1_loss_19: 0.8512 - dense_1_loss_20: 0.8402 - dense_1_loss_21: 0.8208 - dense_1_loss_22: 0.8591 - dense_1_loss_23: 0.7893 - dense_1_loss_24: 0.8128 - dense_1_loss_25: 0.9424 - dense_1_loss_26: 0.7967 - dense_1_loss_27: 0.8467 - dense_1_loss_28: 0.8232 - dense_1_loss_29: 0.8301 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5500 - dense_1_acc_4: 0.4833 - dense_1_acc_5: 0.6333 - dense_1_acc_6: 0.7833 - dense_1_acc_7: 0.9500 - dense_1_acc_8: 0.8000 - dense_1_acc_9: 0.8333 - dense_1_acc_10: 0.9000 - dense_1_acc_11: 0.9000 - dense_1_acc_12: 0.9333 - dense_1_acc_13: 0.9667 - dense_1_acc_14: 0.9500 - dense_1_acc_15: 0.8833 - dense_1_acc_16: 0.9667 - dense_1_acc_17: 0.9333 - dense_1_acc_18: 0.9000 - dense_1_acc_19: 0.9000 - dense_1_acc_20: 0.9167 - dense_1_acc_21: 0.9500 - dense_1_acc_22: 0.9333 - dense_1_acc_23: 0.9333 - dense_1_acc_24: 0.9667 - dense_1_acc_25: 0.8333 - dense_1_acc_26: 0.9500 - dense_1_acc_27: 0.9167 - dense_1_acc_28: 0.9000 - dense_1_acc_29: 0.8833 - dense_1_acc_30: 0.0000e+00     
Epoch 31/100
60/60 [==============================] - 0s - loss: 31.2115 - dense_1_loss_1: 4.0347 - dense_1_loss_2: 3.0670 - dense_1_loss_3: 2.0677 - dense_1_loss_4: 1.6894 - dense_1_loss_5: 1.2791 - dense_1_loss_6: 1.0036 - dense_1_loss_7: 0.9697 - dense_1_loss_8: 0.9078 - dense_1_loss_9: 0.8270 - dense_1_loss_10: 0.7842 - dense_1_loss_11: 0.7984 - dense_1_loss_12: 0.7919 - dense_1_loss_13: 0.6998 - dense_1_loss_14: 0.7360 - dense_1_loss_15: 0.7607 - dense_1_loss_16: 0.7495 - dense_1_loss_17: 0.7710 - dense_1_loss_18: 0.7747 - dense_1_loss_19: 0.7774 - dense_1_loss_20: 0.7782 - dense_1_loss_21: 0.7584 - dense_1_loss_22: 0.7907 - dense_1_loss_23: 0.7403 - dense_1_loss_24: 0.7389 - dense_1_loss_25: 0.8684 - dense_1_loss_26: 0.7347 - dense_1_loss_27: 0.7808 - dense_1_loss_28: 0.7643 - dense_1_loss_29: 0.7672 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5667 - dense_1_acc_4: 0.4833 - dense_1_acc_5: 0.7000 - dense_1_acc_6: 0.8167 - dense_1_acc_7: 0.9333 - dense_1_acc_8: 0.8667 - dense_1_acc_9: 0.8500 - dense_1_acc_10: 0.9500 - dense_1_acc_11: 0.9000 - dense_1_acc_12: 0.9500 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9500 - dense_1_acc_15: 0.9167 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9333 - dense_1_acc_18: 0.9500 - dense_1_acc_19: 0.9500 - dense_1_acc_20: 0.9500 - dense_1_acc_21: 0.9333 - dense_1_acc_22: 0.9500 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9667 - dense_1_acc_25: 0.8500 - dense_1_acc_26: 0.9500 - dense_1_acc_27: 0.9500 - dense_1_acc_28: 0.9167 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0000e+00     
Epoch 32/100
60/60 [==============================] - 0s - loss: 29.5748 - dense_1_loss_1: 4.0282 - dense_1_loss_2: 3.0201 - dense_1_loss_3: 2.0028 - dense_1_loss_4: 1.6073 - dense_1_loss_5: 1.1976 - dense_1_loss_6: 0.9391 - dense_1_loss_7: 0.8996 - dense_1_loss_8: 0.8674 - dense_1_loss_9: 0.7689 - dense_1_loss_10: 0.7085 - dense_1_loss_11: 0.7296 - dense_1_loss_12: 0.7143 - dense_1_loss_13: 0.6478 - dense_1_loss_14: 0.6798 - dense_1_loss_15: 0.7037 - dense_1_loss_16: 0.6957 - dense_1_loss_17: 0.7155 - dense_1_loss_18: 0.7009 - dense_1_loss_19: 0.7276 - dense_1_loss_20: 0.7203 - dense_1_loss_21: 0.7206 - dense_1_loss_22: 0.7310 - dense_1_loss_23: 0.6957 - dense_1_loss_24: 0.6805 - dense_1_loss_25: 0.8066 - dense_1_loss_26: 0.6915 - dense_1_loss_27: 0.7420 - dense_1_loss_28: 0.7182 - dense_1_loss_29: 0.7141 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.5500 - dense_1_acc_4: 0.5500 - dense_1_acc_5: 0.7333 - dense_1_acc_6: 0.8000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.8167 - dense_1_acc_9: 0.8833 - dense_1_acc_10: 0.9167 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 0.9667 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9500 - dense_1_acc_15: 0.9500 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9500 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9667 - dense_1_acc_20: 0.9667 - dense_1_acc_21: 0.9667 - dense_1_acc_22: 0.9833 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.8667 - dense_1_acc_26: 0.9667 - dense_1_acc_27: 0.9500 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0000e+00     
Epoch 33/100
60/60 [==============================] - 0s - loss: 27.9737 - dense_1_loss_1: 4.0216 - dense_1_loss_2: 2.9721 - dense_1_loss_3: 1.9386 - dense_1_loss_4: 1.5331 - dense_1_loss_5: 1.1200 - dense_1_loss_6: 0.8744 - dense_1_loss_7: 0.8335 - dense_1_loss_8: 0.7904 - dense_1_loss_9: 0.7247 - dense_1_loss_10: 0.6550 - dense_1_loss_11: 0.6820 - dense_1_loss_12: 0.6602 - dense_1_loss_13: 0.6051 - dense_1_loss_14: 0.6329 - dense_1_loss_15: 0.6448 - dense_1_loss_16: 0.6574 - dense_1_loss_17: 0.6564 - dense_1_loss_18: 0.6470 - dense_1_loss_19: 0.6808 - dense_1_loss_20: 0.6682 - dense_1_loss_21: 0.6471 - dense_1_loss_22: 0.6879 - dense_1_loss_23: 0.6490 - dense_1_loss_24: 0.6138 - dense_1_loss_25: 0.7459 - dense_1_loss_26: 0.6281 - dense_1_loss_27: 0.6810 - dense_1_loss_28: 0.6606 - dense_1_loss_29: 0.6623 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3000 - dense_1_acc_3: 0.5500 - dense_1_acc_4: 0.5667 - dense_1_acc_5: 0.7500 - dense_1_acc_6: 0.8333 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9167 - dense_1_acc_9: 0.9000 - dense_1_acc_10: 0.9833 - dense_1_acc_11: 0.9167 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9667 - dense_1_acc_15: 0.9667 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9667 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9667 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 0.9833 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0000e+00     
Epoch 34/100
60/60 [==============================] - 0s - loss: 26.4537 - dense_1_loss_1: 4.0143 - dense_1_loss_2: 2.9284 - dense_1_loss_3: 1.8764 - dense_1_loss_4: 1.4577 - dense_1_loss_5: 1.0544 - dense_1_loss_6: 0.8088 - dense_1_loss_7: 0.7924 - dense_1_loss_8: 0.7171 - dense_1_loss_9: 0.6815 - dense_1_loss_10: 0.6032 - dense_1_loss_11: 0.6289 - dense_1_loss_12: 0.6122 - dense_1_loss_13: 0.5585 - dense_1_loss_14: 0.5847 - dense_1_loss_15: 0.6003 - dense_1_loss_16: 0.5864 - dense_1_loss_17: 0.6140 - dense_1_loss_18: 0.6007 - dense_1_loss_19: 0.6066 - dense_1_loss_20: 0.6227 - dense_1_loss_21: 0.6074 - dense_1_loss_22: 0.6242 - dense_1_loss_23: 0.5913 - dense_1_loss_24: 0.5784 - dense_1_loss_25: 0.6959 - dense_1_loss_26: 0.5685 - dense_1_loss_27: 0.6152 - dense_1_loss_28: 0.6178 - dense_1_loss_29: 0.6057 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3000 - dense_1_acc_3: 0.5667 - dense_1_acc_4: 0.6167 - dense_1_acc_5: 0.7833 - dense_1_acc_6: 0.8333 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9167 - dense_1_acc_9: 0.9167 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 0.9667 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9667 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9333 - dense_1_acc_30: 0.0000e+00     
Epoch 35/100
60/60 [==============================] - 0s - loss: 25.3020 - dense_1_loss_1: 4.0076 - dense_1_loss_2: 2.8809 - dense_1_loss_3: 1.8127 - dense_1_loss_4: 1.3818 - dense_1_loss_5: 0.9883 - dense_1_loss_6: 0.7545 - dense_1_loss_7: 0.7398 - dense_1_loss_8: 0.6632 - dense_1_loss_9: 0.6211 - dense_1_loss_10: 0.5547 - dense_1_loss_11: 0.5828 - dense_1_loss_12: 0.5680 - dense_1_loss_13: 0.5074 - dense_1_loss_14: 0.5488 - dense_1_loss_15: 0.5518 - dense_1_loss_16: 0.5706 - dense_1_loss_17: 0.5637 - dense_1_loss_18: 0.5603 - dense_1_loss_19: 0.5770 - dense_1_loss_20: 0.5882 - dense_1_loss_21: 0.5975 - dense_1_loss_22: 0.5684 - dense_1_loss_23: 0.5613 - dense_1_loss_24: 0.5658 - dense_1_loss_25: 0.6647 - dense_1_loss_26: 0.5433 - dense_1_loss_27: 0.6020 - dense_1_loss_28: 0.5876 - dense_1_loss_29: 0.5882 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.6000 - dense_1_acc_4: 0.6500 - dense_1_acc_5: 0.7833 - dense_1_acc_6: 0.8667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9500 - dense_1_acc_9: 0.9000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9667 - dense_1_acc_15: 0.9833 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9667 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 0.9833 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.8833 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 0.9833 - dense_1_acc_28: 0.9667 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0000e+00     
Epoch 36/100
60/60 [==============================] - 0s - loss: 24.0212 - dense_1_loss_1: 4.0018 - dense_1_loss_2: 2.8350 - dense_1_loss_3: 1.7567 - dense_1_loss_4: 1.3129 - dense_1_loss_5: 0.9261 - dense_1_loss_6: 0.7048 - dense_1_loss_7: 0.7056 - dense_1_loss_8: 0.5899 - dense_1_loss_9: 0.5723 - dense_1_loss_10: 0.5290 - dense_1_loss_11: 0.5672 - dense_1_loss_12: 0.5433 - dense_1_loss_13: 0.4691 - dense_1_loss_14: 0.5052 - dense_1_loss_15: 0.5154 - dense_1_loss_16: 0.5191 - dense_1_loss_17: 0.5147 - dense_1_loss_18: 0.5275 - dense_1_loss_19: 0.5322 - dense_1_loss_20: 0.5460 - dense_1_loss_21: 0.5364 - dense_1_loss_22: 0.5149 - dense_1_loss_23: 0.5171 - dense_1_loss_24: 0.5470 - dense_1_loss_25: 0.6014 - dense_1_loss_26: 0.5223 - dense_1_loss_27: 0.5298 - dense_1_loss_28: 0.5323 - dense_1_loss_29: 0.5465 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.6500 - dense_1_acc_5: 0.8000 - dense_1_acc_6: 0.8833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9500 - dense_1_acc_9: 0.9333 - dense_1_acc_10: 0.9833 - dense_1_acc_11: 0.9333 - dense_1_acc_12: 0.9667 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 0.9833 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9333 - dense_1_acc_26: 0.9667 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9333 - dense_1_acc_30: 0.0000e+00     
Epoch 37/100
60/60 [==============================] - 0s - loss: 22.7911 - dense_1_loss_1: 3.9958 - dense_1_loss_2: 2.7889 - dense_1_loss_3: 1.6957 - dense_1_loss_4: 1.2449 - dense_1_loss_5: 0.8664 - dense_1_loss_6: 0.6546 - dense_1_loss_7: 0.6433 - dense_1_loss_8: 0.5611 - dense_1_loss_9: 0.5342 - dense_1_loss_10: 0.4752 - dense_1_loss_11: 0.4942 - dense_1_loss_12: 0.4948 - dense_1_loss_13: 0.4327 - dense_1_loss_14: 0.4618 - dense_1_loss_15: 0.4805 - dense_1_loss_16: 0.4725 - dense_1_loss_17: 0.4893 - dense_1_loss_18: 0.4711 - dense_1_loss_19: 0.5226 - dense_1_loss_20: 0.4978 - dense_1_loss_21: 0.4973 - dense_1_loss_22: 0.5085 - dense_1_loss_23: 0.4918 - dense_1_loss_24: 0.4780 - dense_1_loss_25: 0.5687 - dense_1_loss_26: 0.5094 - dense_1_loss_27: 0.4872 - dense_1_loss_28: 0.4759 - dense_1_loss_29: 0.4969 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.6833 - dense_1_acc_5: 0.8333 - dense_1_acc_6: 0.9167 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 0.9667 - dense_1_acc_21: 0.9500 - dense_1_acc_22: 0.9833 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9333 - dense_1_acc_26: 0.9500 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     
Epoch 38/100
60/60 [==============================] - 0s - loss: 21.5434 - dense_1_loss_1: 3.9901 - dense_1_loss_2: 2.7436 - dense_1_loss_3: 1.6372 - dense_1_loss_4: 1.1774 - dense_1_loss_5: 0.8135 - dense_1_loss_6: 0.6036 - dense_1_loss_7: 0.5891 - dense_1_loss_8: 0.5241 - dense_1_loss_9: 0.4945 - dense_1_loss_10: 0.4275 - dense_1_loss_11: 0.4470 - dense_1_loss_12: 0.4405 - dense_1_loss_13: 0.3920 - dense_1_loss_14: 0.4135 - dense_1_loss_15: 0.4474 - dense_1_loss_16: 0.4103 - dense_1_loss_17: 0.4569 - dense_1_loss_18: 0.4348 - dense_1_loss_19: 0.4566 - dense_1_loss_20: 0.4556 - dense_1_loss_21: 0.4633 - dense_1_loss_22: 0.4516 - dense_1_loss_23: 0.4803 - dense_1_loss_24: 0.4165 - dense_1_loss_25: 0.5328 - dense_1_loss_26: 0.4615 - dense_1_loss_27: 0.4715 - dense_1_loss_28: 0.4605 - dense_1_loss_29: 0.4501 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.7500 - dense_1_acc_5: 0.9000 - dense_1_acc_6: 0.9333 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9667 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 39/100
60/60 [==============================] - 0s - loss: 20.4096 - dense_1_loss_1: 3.9847 - dense_1_loss_2: 2.6981 - dense_1_loss_3: 1.5830 - dense_1_loss_4: 1.1062 - dense_1_loss_5: 0.7642 - dense_1_loss_6: 0.5615 - dense_1_loss_7: 0.5547 - dense_1_loss_8: 0.4929 - dense_1_loss_9: 0.4626 - dense_1_loss_10: 0.3892 - dense_1_loss_11: 0.4192 - dense_1_loss_12: 0.4008 - dense_1_loss_13: 0.3720 - dense_1_loss_14: 0.3958 - dense_1_loss_15: 0.4000 - dense_1_loss_16: 0.3839 - dense_1_loss_17: 0.4178 - dense_1_loss_18: 0.4045 - dense_1_loss_19: 0.4057 - dense_1_loss_20: 0.4201 - dense_1_loss_21: 0.4235 - dense_1_loss_22: 0.3947 - dense_1_loss_23: 0.4373 - dense_1_loss_24: 0.3695 - dense_1_loss_25: 0.4961 - dense_1_loss_26: 0.4024 - dense_1_loss_27: 0.4213 - dense_1_loss_28: 0.4212 - dense_1_loss_29: 0.4268 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.7667 - dense_1_acc_5: 0.9000 - dense_1_acc_6: 0.9500 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9833 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 40/100
60/60 [==============================] - 0s - loss: 19.3388 - dense_1_loss_1: 3.9784 - dense_1_loss_2: 2.6535 - dense_1_loss_3: 1.5344 - dense_1_loss_4: 1.0452 - dense_1_loss_5: 0.7121 - dense_1_loss_6: 0.5257 - dense_1_loss_7: 0.5184 - dense_1_loss_8: 0.4365 - dense_1_loss_9: 0.4269 - dense_1_loss_10: 0.3572 - dense_1_loss_11: 0.3919 - dense_1_loss_12: 0.3681 - dense_1_loss_13: 0.3411 - dense_1_loss_14: 0.3671 - dense_1_loss_15: 0.3574 - dense_1_loss_16: 0.3562 - dense_1_loss_17: 0.3790 - dense_1_loss_18: 0.3677 - dense_1_loss_19: 0.3747 - dense_1_loss_20: 0.3929 - dense_1_loss_21: 0.3757 - dense_1_loss_22: 0.3625 - dense_1_loss_23: 0.3857 - dense_1_loss_24: 0.3530 - dense_1_loss_25: 0.4471 - dense_1_loss_26: 0.3708 - dense_1_loss_27: 0.3588 - dense_1_loss_28: 0.3926 - dense_1_loss_29: 0.4082 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.7833 - dense_1_acc_5: 0.9000 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 41/100
60/60 [==============================] - 0s - loss: 18.4427 - dense_1_loss_1: 3.9727 - dense_1_loss_2: 2.6086 - dense_1_loss_3: 1.4855 - dense_1_loss_4: 0.9911 - dense_1_loss_5: 0.6693 - dense_1_loss_6: 0.4911 - dense_1_loss_7: 0.4898 - dense_1_loss_8: 0.3894 - dense_1_loss_9: 0.3934 - dense_1_loss_10: 0.3294 - dense_1_loss_11: 0.3655 - dense_1_loss_12: 0.3469 - dense_1_loss_13: 0.3107 - dense_1_loss_14: 0.3240 - dense_1_loss_15: 0.3409 - dense_1_loss_16: 0.3289 - dense_1_loss_17: 0.3514 - dense_1_loss_18: 0.3306 - dense_1_loss_19: 0.3551 - dense_1_loss_20: 0.3632 - dense_1_loss_21: 0.3502 - dense_1_loss_22: 0.3416 - dense_1_loss_23: 0.3415 - dense_1_loss_24: 0.3464 - dense_1_loss_25: 0.4083 - dense_1_loss_26: 0.3446 - dense_1_loss_27: 0.3314 - dense_1_loss_28: 0.3591 - dense_1_loss_29: 0.3821 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6333 - dense_1_acc_4: 0.7833 - dense_1_acc_5: 0.9167 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 0.9833 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 42/100
60/60 [==============================] - 0s - loss: 17.5646 - dense_1_loss_1: 3.9672 - dense_1_loss_2: 2.5679 - dense_1_loss_3: 1.4368 - dense_1_loss_4: 0.9286 - dense_1_loss_5: 0.6270 - dense_1_loss_6: 0.4565 - dense_1_loss_7: 0.4589 - dense_1_loss_8: 0.3703 - dense_1_loss_9: 0.3668 - dense_1_loss_10: 0.3025 - dense_1_loss_11: 0.3322 - dense_1_loss_12: 0.3195 - dense_1_loss_13: 0.2819 - dense_1_loss_14: 0.2898 - dense_1_loss_15: 0.3175 - dense_1_loss_16: 0.3034 - dense_1_loss_17: 0.3205 - dense_1_loss_18: 0.3035 - dense_1_loss_19: 0.3269 - dense_1_loss_20: 0.3342 - dense_1_loss_21: 0.3339 - dense_1_loss_22: 0.3222 - dense_1_loss_23: 0.3123 - dense_1_loss_24: 0.3104 - dense_1_loss_25: 0.3722 - dense_1_loss_26: 0.3139 - dense_1_loss_27: 0.3122 - dense_1_loss_28: 0.3210 - dense_1_loss_29: 0.3546 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6333 - dense_1_acc_4: 0.8167 - dense_1_acc_5: 0.9333 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 43/100
60/60 [==============================] - 0s - loss: 16.7271 - dense_1_loss_1: 3.9624 - dense_1_loss_2: 2.5229 - dense_1_loss_3: 1.3891 - dense_1_loss_4: 0.8766 - dense_1_loss_5: 0.5865 - dense_1_loss_6: 0.4224 - dense_1_loss_7: 0.4348 - dense_1_loss_8: 0.3382 - dense_1_loss_9: 0.3413 - dense_1_loss_10: 0.2778 - dense_1_loss_11: 0.3062 - dense_1_loss_12: 0.2913 - dense_1_loss_13: 0.2632 - dense_1_loss_14: 0.2670 - dense_1_loss_15: 0.2825 - dense_1_loss_16: 0.2767 - dense_1_loss_17: 0.2871 - dense_1_loss_18: 0.2843 - dense_1_loss_19: 0.2982 - dense_1_loss_20: 0.2984 - dense_1_loss_21: 0.3035 - dense_1_loss_22: 0.2955 - dense_1_loss_23: 0.2923 - dense_1_loss_24: 0.2757 - dense_1_loss_25: 0.3403 - dense_1_loss_26: 0.2941 - dense_1_loss_27: 0.2997 - dense_1_loss_28: 0.2961 - dense_1_loss_29: 0.3230 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.8500 - dense_1_acc_5: 0.9333 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     
Epoch 44/100
60/60 [==============================] - 0s - loss: 16.0275 - dense_1_loss_1: 3.9571 - dense_1_loss_2: 2.4818 - dense_1_loss_3: 1.3443 - dense_1_loss_4: 0.8290 - dense_1_loss_5: 0.5499 - dense_1_loss_6: 0.3926 - dense_1_loss_7: 0.4075 - dense_1_loss_8: 0.3038 - dense_1_loss_9: 0.3181 - dense_1_loss_10: 0.2565 - dense_1_loss_11: 0.2853 - dense_1_loss_12: 0.2629 - dense_1_loss_13: 0.2446 - dense_1_loss_14: 0.2522 - dense_1_loss_15: 0.2562 - dense_1_loss_16: 0.2535 - dense_1_loss_17: 0.2654 - dense_1_loss_18: 0.2687 - dense_1_loss_19: 0.2804 - dense_1_loss_20: 0.2723 - dense_1_loss_21: 0.2774 - dense_1_loss_22: 0.2747 - dense_1_loss_23: 0.2851 - dense_1_loss_24: 0.2579 - dense_1_loss_25: 0.3207 - dense_1_loss_26: 0.2677 - dense_1_loss_27: 0.2866 - dense_1_loss_28: 0.2823 - dense_1_loss_29: 0.2931 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9333 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 45/100
60/60 [==============================] - 0s - loss: 15.2892 - dense_1_loss_1: 3.9528 - dense_1_loss_2: 2.4409 - dense_1_loss_3: 1.2989 - dense_1_loss_4: 0.7792 - dense_1_loss_5: 0.5144 - dense_1_loss_6: 0.3656 - dense_1_loss_7: 0.3803 - dense_1_loss_8: 0.2880 - dense_1_loss_9: 0.2896 - dense_1_loss_10: 0.2389 - dense_1_loss_11: 0.2588 - dense_1_loss_12: 0.2401 - dense_1_loss_13: 0.2234 - dense_1_loss_14: 0.2316 - dense_1_loss_15: 0.2370 - dense_1_loss_16: 0.2391 - dense_1_loss_17: 0.2397 - dense_1_loss_18: 0.2462 - dense_1_loss_19: 0.2602 - dense_1_loss_20: 0.2470 - dense_1_loss_21: 0.2554 - dense_1_loss_22: 0.2459 - dense_1_loss_23: 0.2618 - dense_1_loss_24: 0.2310 - dense_1_loss_25: 0.2938 - dense_1_loss_26: 0.2389 - dense_1_loss_27: 0.2560 - dense_1_loss_28: 0.2606 - dense_1_loss_29: 0.2741 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9500 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 46/100
60/60 [==============================] - 0s - loss: 14.6790 - dense_1_loss_1: 3.9472 - dense_1_loss_2: 2.3999 - dense_1_loss_3: 1.2582 - dense_1_loss_4: 0.7286 - dense_1_loss_5: 0.4830 - dense_1_loss_6: 0.3464 - dense_1_loss_7: 0.3574 - dense_1_loss_8: 0.2724 - dense_1_loss_9: 0.2679 - dense_1_loss_10: 0.2224 - dense_1_loss_11: 0.2386 - dense_1_loss_12: 0.2260 - dense_1_loss_13: 0.2022 - dense_1_loss_14: 0.2122 - dense_1_loss_15: 0.2253 - dense_1_loss_16: 0.2226 - dense_1_loss_17: 0.2267 - dense_1_loss_18: 0.2232 - dense_1_loss_19: 0.2375 - dense_1_loss_20: 0.2378 - dense_1_loss_21: 0.2357 - dense_1_loss_22: 0.2314 - dense_1_loss_23: 0.2384 - dense_1_loss_24: 0.2123 - dense_1_loss_25: 0.2717 - dense_1_loss_26: 0.2229 - dense_1_loss_27: 0.2288 - dense_1_loss_28: 0.2388 - dense_1_loss_29: 0.2635 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4333 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 47/100
60/60 [==============================] - 0s - loss: 14.0970 - dense_1_loss_1: 3.9425 - dense_1_loss_2: 2.3600 - dense_1_loss_3: 1.2195 - dense_1_loss_4: 0.6886 - dense_1_loss_5: 0.4519 - dense_1_loss_6: 0.3266 - dense_1_loss_7: 0.3332 - dense_1_loss_8: 0.2453 - dense_1_loss_9: 0.2445 - dense_1_loss_10: 0.2051 - dense_1_loss_11: 0.2236 - dense_1_loss_12: 0.2130 - dense_1_loss_13: 0.1839 - dense_1_loss_14: 0.1961 - dense_1_loss_15: 0.2109 - dense_1_loss_16: 0.2001 - dense_1_loss_17: 0.2142 - dense_1_loss_18: 0.2039 - dense_1_loss_19: 0.2189 - dense_1_loss_20: 0.2237 - dense_1_loss_21: 0.2180 - dense_1_loss_22: 0.2095 - dense_1_loss_23: 0.2203 - dense_1_loss_24: 0.2009 - dense_1_loss_25: 0.2488 - dense_1_loss_26: 0.2097 - dense_1_loss_27: 0.2100 - dense_1_loss_28: 0.2275 - dense_1_loss_29: 0.2467 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.6667 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 48/100
60/60 [==============================] - 0s - loss: 13.5650 - dense_1_loss_1: 3.9380 - dense_1_loss_2: 2.3213 - dense_1_loss_3: 1.1828 - dense_1_loss_4: 0.6479 - dense_1_loss_5: 0.4232 - dense_1_loss_6: 0.3065 - dense_1_loss_7: 0.3102 - dense_1_loss_8: 0.2231 - dense_1_loss_9: 0.2256 - dense_1_loss_10: 0.1906 - dense_1_loss_11: 0.2100 - dense_1_loss_12: 0.1964 - dense_1_loss_13: 0.1716 - dense_1_loss_14: 0.1827 - dense_1_loss_15: 0.1923 - dense_1_loss_16: 0.1898 - dense_1_loss_17: 0.1986 - dense_1_loss_18: 0.1855 - dense_1_loss_19: 0.2080 - dense_1_loss_20: 0.2070 - dense_1_loss_21: 0.1993 - dense_1_loss_22: 0.1943 - dense_1_loss_23: 0.2010 - dense_1_loss_24: 0.1894 - dense_1_loss_25: 0.2308 - dense_1_loss_26: 0.1998 - dense_1_loss_27: 0.2002 - dense_1_loss_28: 0.2135 - dense_1_loss_29: 0.2255 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 49/100
60/60 [==============================] - 0s - loss: 13.0597 - dense_1_loss_1: 3.9339 - dense_1_loss_2: 2.2832 - dense_1_loss_3: 1.1444 - dense_1_loss_4: 0.6110 - dense_1_loss_5: 0.3977 - dense_1_loss_6: 0.2916 - dense_1_loss_7: 0.2918 - dense_1_loss_8: 0.2103 - dense_1_loss_9: 0.2145 - dense_1_loss_10: 0.1770 - dense_1_loss_11: 0.1955 - dense_1_loss_12: 0.1818 - dense_1_loss_13: 0.1640 - dense_1_loss_14: 0.1702 - dense_1_loss_15: 0.1761 - dense_1_loss_16: 0.1776 - dense_1_loss_17: 0.1823 - dense_1_loss_18: 0.1722 - dense_1_loss_19: 0.1921 - dense_1_loss_20: 0.1922 - dense_1_loss_21: 0.1825 - dense_1_loss_22: 0.1838 - dense_1_loss_23: 0.1810 - dense_1_loss_24: 0.1717 - dense_1_loss_25: 0.2133 - dense_1_loss_26: 0.1796 - dense_1_loss_27: 0.1877 - dense_1_loss_28: 0.1932 - dense_1_loss_29: 0.2074 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7167 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 50/100
60/60 [==============================] - 0s - loss: 12.6026 - dense_1_loss_1: 3.9298 - dense_1_loss_2: 2.2459 - dense_1_loss_3: 1.1076 - dense_1_loss_4: 0.5701 - dense_1_loss_5: 0.3745 - dense_1_loss_6: 0.2743 - dense_1_loss_7: 0.2741 - dense_1_loss_8: 0.1958 - dense_1_loss_9: 0.2036 - dense_1_loss_10: 0.1632 - dense_1_loss_11: 0.1818 - dense_1_loss_12: 0.1658 - dense_1_loss_13: 0.1562 - dense_1_loss_14: 0.1593 - dense_1_loss_15: 0.1637 - dense_1_loss_16: 0.1626 - dense_1_loss_17: 0.1675 - dense_1_loss_18: 0.1637 - dense_1_loss_19: 0.1737 - dense_1_loss_20: 0.1801 - dense_1_loss_21: 0.1730 - dense_1_loss_22: 0.1703 - dense_1_loss_23: 0.1721 - dense_1_loss_24: 0.1558 - dense_1_loss_25: 0.1999 - dense_1_loss_26: 0.1673 - dense_1_loss_27: 0.1757 - dense_1_loss_28: 0.1815 - dense_1_loss_29: 0.1938 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7167 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 51/100
60/60 [==============================] - 0s - loss: 12.1969 - dense_1_loss_1: 3.9255 - dense_1_loss_2: 2.2080 - dense_1_loss_3: 1.0726 - dense_1_loss_4: 0.5390 - dense_1_loss_5: 0.3548 - dense_1_loss_6: 0.2577 - dense_1_loss_7: 0.2564 - dense_1_loss_8: 0.1868 - dense_1_loss_9: 0.1882 - dense_1_loss_10: 0.1529 - dense_1_loss_11: 0.1652 - dense_1_loss_12: 0.1568 - dense_1_loss_13: 0.1446 - dense_1_loss_14: 0.1448 - dense_1_loss_15: 0.1528 - dense_1_loss_16: 0.1549 - dense_1_loss_17: 0.1573 - dense_1_loss_18: 0.1558 - dense_1_loss_19: 0.1594 - dense_1_loss_20: 0.1655 - dense_1_loss_21: 0.1656 - dense_1_loss_22: 0.1577 - dense_1_loss_23: 0.1639 - dense_1_loss_24: 0.1475 - dense_1_loss_25: 0.1874 - dense_1_loss_26: 0.1574 - dense_1_loss_27: 0.1644 - dense_1_loss_28: 0.1717 - dense_1_loss_29: 0.1822 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 52/100
60/60 [==============================] - 0s - loss: 11.7999 - dense_1_loss_1: 3.9217 - dense_1_loss_2: 2.1720 - dense_1_loss_3: 1.0392 - dense_1_loss_4: 0.5107 - dense_1_loss_5: 0.3348 - dense_1_loss_6: 0.2429 - dense_1_loss_7: 0.2425 - dense_1_loss_8: 0.1760 - dense_1_loss_9: 0.1731 - dense_1_loss_10: 0.1442 - dense_1_loss_11: 0.1543 - dense_1_loss_12: 0.1459 - dense_1_loss_13: 0.1337 - dense_1_loss_14: 0.1360 - dense_1_loss_15: 0.1401 - dense_1_loss_16: 0.1463 - dense_1_loss_17: 0.1466 - dense_1_loss_18: 0.1444 - dense_1_loss_19: 0.1508 - dense_1_loss_20: 0.1517 - dense_1_loss_21: 0.1525 - dense_1_loss_22: 0.1483 - dense_1_loss_23: 0.1505 - dense_1_loss_24: 0.1387 - dense_1_loss_25: 0.1725 - dense_1_loss_26: 0.1485 - dense_1_loss_27: 0.1516 - dense_1_loss_28: 0.1598 - dense_1_loss_29: 0.1704 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 53/100
60/60 [==============================] - 0s - loss: 11.4567 - dense_1_loss_1: 3.9172 - dense_1_loss_2: 2.1361 - dense_1_loss_3: 1.0079 - dense_1_loss_4: 0.4832 - dense_1_loss_5: 0.3156 - dense_1_loss_6: 0.2311 - dense_1_loss_7: 0.2329 - dense_1_loss_8: 0.1637 - dense_1_loss_9: 0.1621 - dense_1_loss_10: 0.1354 - dense_1_loss_11: 0.1477 - dense_1_loss_12: 0.1379 - dense_1_loss_13: 0.1248 - dense_1_loss_14: 0.1295 - dense_1_loss_15: 0.1316 - dense_1_loss_16: 0.1364 - dense_1_loss_17: 0.1378 - dense_1_loss_18: 0.1345 - dense_1_loss_19: 0.1434 - dense_1_loss_20: 0.1433 - dense_1_loss_21: 0.1424 - dense_1_loss_22: 0.1385 - dense_1_loss_23: 0.1395 - dense_1_loss_24: 0.1307 - dense_1_loss_25: 0.1613 - dense_1_loss_26: 0.1397 - dense_1_loss_27: 0.1392 - dense_1_loss_28: 0.1497 - dense_1_loss_29: 0.1637 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.7833 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 54/100
60/60 [==============================] - 0s - loss: 11.1297 - dense_1_loss_1: 3.9131 - dense_1_loss_2: 2.1021 - dense_1_loss_3: 0.9777 - dense_1_loss_4: 0.4565 - dense_1_loss_5: 0.2980 - dense_1_loss_6: 0.2192 - dense_1_loss_7: 0.2220 - dense_1_loss_8: 0.1525 - dense_1_loss_9: 0.1522 - dense_1_loss_10: 0.1263 - dense_1_loss_11: 0.1413 - dense_1_loss_12: 0.1293 - dense_1_loss_13: 0.1164 - dense_1_loss_14: 0.1224 - dense_1_loss_15: 0.1257 - dense_1_loss_16: 0.1262 - dense_1_loss_17: 0.1297 - dense_1_loss_18: 0.1259 - dense_1_loss_19: 0.1343 - dense_1_loss_20: 0.1374 - dense_1_loss_21: 0.1325 - dense_1_loss_22: 0.1280 - dense_1_loss_23: 0.1302 - dense_1_loss_24: 0.1229 - dense_1_loss_25: 0.1515 - dense_1_loss_26: 0.1306 - dense_1_loss_27: 0.1295 - dense_1_loss_28: 0.1410 - dense_1_loss_29: 0.1554 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.7833 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 55/100
60/60 [==============================] - 0s - loss: 10.8305 - dense_1_loss_1: 3.9091 - dense_1_loss_2: 2.0676 - dense_1_loss_3: 0.9481 - dense_1_loss_4: 0.4333 - dense_1_loss_5: 0.2845 - dense_1_loss_6: 0.2080 - dense_1_loss_7: 0.2110 - dense_1_loss_8: 0.1461 - dense_1_loss_9: 0.1429 - dense_1_loss_10: 0.1194 - dense_1_loss_11: 0.1314 - dense_1_loss_12: 0.1221 - dense_1_loss_13: 0.1087 - dense_1_loss_14: 0.1134 - dense_1_loss_15: 0.1198 - dense_1_loss_16: 0.1214 - dense_1_loss_17: 0.1213 - dense_1_loss_18: 0.1185 - dense_1_loss_19: 0.1254 - dense_1_loss_20: 0.1298 - dense_1_loss_21: 0.1259 - dense_1_loss_22: 0.1191 - dense_1_loss_23: 0.1219 - dense_1_loss_24: 0.1151 - dense_1_loss_25: 0.1430 - dense_1_loss_26: 0.1220 - dense_1_loss_27: 0.1234 - dense_1_loss_28: 0.1338 - dense_1_loss_29: 0.1443 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8000 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 56/100
60/60 [==============================] - 0s - loss: 10.5476 - dense_1_loss_1: 3.9054 - dense_1_loss_2: 2.0361 - dense_1_loss_3: 0.9192 - dense_1_loss_4: 0.4097 - dense_1_loss_5: 0.2699 - dense_1_loss_6: 0.1966 - dense_1_loss_7: 0.1976 - dense_1_loss_8: 0.1380 - dense_1_loss_9: 0.1355 - dense_1_loss_10: 0.1130 - dense_1_loss_11: 0.1203 - dense_1_loss_12: 0.1168 - dense_1_loss_13: 0.1029 - dense_1_loss_14: 0.1052 - dense_1_loss_15: 0.1129 - dense_1_loss_16: 0.1181 - dense_1_loss_17: 0.1149 - dense_1_loss_18: 0.1110 - dense_1_loss_19: 0.1188 - dense_1_loss_20: 0.1210 - dense_1_loss_21: 0.1195 - dense_1_loss_22: 0.1123 - dense_1_loss_23: 0.1150 - dense_1_loss_24: 0.1095 - dense_1_loss_25: 0.1334 - dense_1_loss_26: 0.1156 - dense_1_loss_27: 0.1183 - dense_1_loss_28: 0.1270 - dense_1_loss_29: 0.1341 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 57/100
60/60 [==============================] - 0s - loss: 10.2853 - dense_1_loss_1: 3.9014 - dense_1_loss_2: 2.0034 - dense_1_loss_3: 0.8925 - dense_1_loss_4: 0.3899 - dense_1_loss_5: 0.2565 - dense_1_loss_6: 0.1892 - dense_1_loss_7: 0.1875 - dense_1_loss_8: 0.1288 - dense_1_loss_9: 0.1290 - dense_1_loss_10: 0.1055 - dense_1_loss_11: 0.1154 - dense_1_loss_12: 0.1096 - dense_1_loss_13: 0.0982 - dense_1_loss_14: 0.1008 - dense_1_loss_15: 0.1044 - dense_1_loss_16: 0.1075 - dense_1_loss_17: 0.1089 - dense_1_loss_18: 0.1047 - dense_1_loss_19: 0.1123 - dense_1_loss_20: 0.1138 - dense_1_loss_21: 0.1113 - dense_1_loss_22: 0.1068 - dense_1_loss_23: 0.1086 - dense_1_loss_24: 0.1038 - dense_1_loss_25: 0.1242 - dense_1_loss_26: 0.1097 - dense_1_loss_27: 0.1119 - dense_1_loss_28: 0.1217 - dense_1_loss_29: 0.1279 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 58/100
60/60 [==============================] - 0s - loss: 10.0500 - dense_1_loss_1: 3.8974 - dense_1_loss_2: 1.9716 - dense_1_loss_3: 0.8691 - dense_1_loss_4: 0.3699 - dense_1_loss_5: 0.2441 - dense_1_loss_6: 0.1818 - dense_1_loss_7: 0.1776 - dense_1_loss_8: 0.1225 - dense_1_loss_9: 0.1224 - dense_1_loss_10: 0.0987 - dense_1_loss_11: 0.1126 - dense_1_loss_12: 0.1019 - dense_1_loss_13: 0.0948 - dense_1_loss_14: 0.0996 - dense_1_loss_15: 0.0984 - dense_1_loss_16: 0.0987 - dense_1_loss_17: 0.1031 - dense_1_loss_18: 0.0995 - dense_1_loss_19: 0.1077 - dense_1_loss_20: 0.1079 - dense_1_loss_21: 0.1046 - dense_1_loss_22: 0.1028 - dense_1_loss_23: 0.1023 - dense_1_loss_24: 0.0975 - dense_1_loss_25: 0.1167 - dense_1_loss_26: 0.1035 - dense_1_loss_27: 0.1052 - dense_1_loss_28: 0.1159 - dense_1_loss_29: 0.1220 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 59/100
60/60 [==============================] - 0s - loss: 9.8203 - dense_1_loss_1: 3.8939 - dense_1_loss_2: 1.9422 - dense_1_loss_3: 0.8429 - dense_1_loss_4: 0.3533 - dense_1_loss_5: 0.2323 - dense_1_loss_6: 0.1734 - dense_1_loss_7: 0.1676 - dense_1_loss_8: 0.1176 - dense_1_loss_9: 0.1153 - dense_1_loss_10: 0.0942 - dense_1_loss_11: 0.1060 - dense_1_loss_12: 0.0960 - dense_1_loss_13: 0.0904 - dense_1_loss_14: 0.0930 - dense_1_loss_15: 0.0923 - dense_1_loss_16: 0.0952 - dense_1_loss_17: 0.0974 - dense_1_loss_18: 0.0942 - dense_1_loss_19: 0.1022 - dense_1_loss_20: 0.1018 - dense_1_loss_21: 0.0990 - dense_1_loss_22: 0.0968 - dense_1_loss_23: 0.0966 - dense_1_loss_24: 0.0918 - dense_1_loss_25: 0.1124 - dense_1_loss_26: 0.0959 - dense_1_loss_27: 0.1002 - dense_1_loss_28: 0.1087 - dense_1_loss_29: 0.1179 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 60/100
60/60 [==============================] - 0s - loss: 9.6102 - dense_1_loss_1: 3.8901 - dense_1_loss_2: 1.9130 - dense_1_loss_3: 0.8196 - dense_1_loss_4: 0.3378 - dense_1_loss_5: 0.2224 - dense_1_loss_6: 0.1642 - dense_1_loss_7: 0.1581 - dense_1_loss_8: 0.1135 - dense_1_loss_9: 0.1082 - dense_1_loss_10: 0.0912 - dense_1_loss_11: 0.0977 - dense_1_loss_12: 0.0921 - dense_1_loss_13: 0.0849 - dense_1_loss_14: 0.0853 - dense_1_loss_15: 0.0877 - dense_1_loss_16: 0.0951 - dense_1_loss_17: 0.0930 - dense_1_loss_18: 0.0896 - dense_1_loss_19: 0.0958 - dense_1_loss_20: 0.0967 - dense_1_loss_21: 0.0938 - dense_1_loss_22: 0.0912 - dense_1_loss_23: 0.0920 - dense_1_loss_24: 0.0874 - dense_1_loss_25: 0.1076 - dense_1_loss_26: 0.0912 - dense_1_loss_27: 0.0961 - dense_1_loss_28: 0.1043 - dense_1_loss_29: 0.1108 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 61/100
60/60 [==============================] - 0s - loss: 9.4133 - dense_1_loss_1: 3.8863 - dense_1_loss_2: 1.8849 - dense_1_loss_3: 0.7978 - dense_1_loss_4: 0.3220 - dense_1_loss_5: 0.2128 - dense_1_loss_6: 0.1572 - dense_1_loss_7: 0.1521 - dense_1_loss_8: 0.1070 - dense_1_loss_9: 0.1030 - dense_1_loss_10: 0.0857 - dense_1_loss_11: 0.0937 - dense_1_loss_12: 0.0873 - dense_1_loss_13: 0.0807 - dense_1_loss_14: 0.0805 - dense_1_loss_15: 0.0843 - dense_1_loss_16: 0.0901 - dense_1_loss_17: 0.0880 - dense_1_loss_18: 0.0856 - dense_1_loss_19: 0.0903 - dense_1_loss_20: 0.0918 - dense_1_loss_21: 0.0891 - dense_1_loss_22: 0.0861 - dense_1_loss_23: 0.0880 - dense_1_loss_24: 0.0832 - dense_1_loss_25: 0.1017 - dense_1_loss_26: 0.0877 - dense_1_loss_27: 0.0909 - dense_1_loss_28: 0.1005 - dense_1_loss_29: 0.1050 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 62/100
60/60 [==============================] - 0s - loss: 9.2328 - dense_1_loss_1: 3.8825 - dense_1_loss_2: 1.8573 - dense_1_loss_3: 0.7768 - dense_1_loss_4: 0.3090 - dense_1_loss_5: 0.2032 - dense_1_loss_6: 0.1514 - dense_1_loss_7: 0.1455 - dense_1_loss_8: 0.1013 - dense_1_loss_9: 0.0986 - dense_1_loss_10: 0.0806 - dense_1_loss_11: 0.0914 - dense_1_loss_12: 0.0821 - dense_1_loss_13: 0.0775 - dense_1_loss_14: 0.0791 - dense_1_loss_15: 0.0815 - dense_1_loss_16: 0.0832 - dense_1_loss_17: 0.0835 - dense_1_loss_18: 0.0818 - dense_1_loss_19: 0.0859 - dense_1_loss_20: 0.0878 - dense_1_loss_21: 0.0853 - dense_1_loss_22: 0.0816 - dense_1_loss_23: 0.0841 - dense_1_loss_24: 0.0788 - dense_1_loss_25: 0.0971 - dense_1_loss_26: 0.0838 - dense_1_loss_27: 0.0861 - dense_1_loss_28: 0.0956 - dense_1_loss_29: 0.1004 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 63/100
60/60 [==============================] - 0s - loss: 9.0548 - dense_1_loss_1: 3.8792 - dense_1_loss_2: 1.8308 - dense_1_loss_3: 0.7560 - dense_1_loss_4: 0.2950 - dense_1_loss_5: 0.1932 - dense_1_loss_6: 0.1463 - dense_1_loss_7: 0.1384 - dense_1_loss_8: 0.0973 - dense_1_loss_9: 0.0945 - dense_1_loss_10: 0.0765 - dense_1_loss_11: 0.0868 - dense_1_loss_12: 0.0783 - dense_1_loss_13: 0.0737 - dense_1_loss_14: 0.0760 - dense_1_loss_15: 0.0766 - dense_1_loss_16: 0.0795 - dense_1_loss_17: 0.0796 - dense_1_loss_18: 0.0771 - dense_1_loss_19: 0.0826 - dense_1_loss_20: 0.0834 - dense_1_loss_21: 0.0810 - dense_1_loss_22: 0.0785 - dense_1_loss_23: 0.0788 - dense_1_loss_24: 0.0750 - dense_1_loss_25: 0.0926 - dense_1_loss_26: 0.0799 - dense_1_loss_27: 0.0815 - dense_1_loss_28: 0.0906 - dense_1_loss_29: 0.0961 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 64/100
60/60 [==============================] - 0s - loss: 8.8914 - dense_1_loss_1: 3.8755 - dense_1_loss_2: 1.8055 - dense_1_loss_3: 0.7353 - dense_1_loss_4: 0.2827 - dense_1_loss_5: 0.1841 - dense_1_loss_6: 0.1409 - dense_1_loss_7: 0.1301 - dense_1_loss_8: 0.0936 - dense_1_loss_9: 0.0905 - dense_1_loss_10: 0.0738 - dense_1_loss_11: 0.0813 - dense_1_loss_12: 0.0759 - dense_1_loss_13: 0.0702 - dense_1_loss_14: 0.0716 - dense_1_loss_15: 0.0723 - dense_1_loss_16: 0.0781 - dense_1_loss_17: 0.0761 - dense_1_loss_18: 0.0736 - dense_1_loss_19: 0.0786 - dense_1_loss_20: 0.0793 - dense_1_loss_21: 0.0781 - dense_1_loss_22: 0.0746 - dense_1_loss_23: 0.0752 - dense_1_loss_24: 0.0720 - dense_1_loss_25: 0.0887 - dense_1_loss_26: 0.0761 - dense_1_loss_27: 0.0778 - dense_1_loss_28: 0.0867 - dense_1_loss_29: 0.0931 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5500 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 65/100
60/60 [==============================] - 0s - loss: 8.7391 - dense_1_loss_1: 3.8723 - dense_1_loss_2: 1.7804 - dense_1_loss_3: 0.7166 - dense_1_loss_4: 0.2720 - dense_1_loss_5: 0.1767 - dense_1_loss_6: 0.1358 - dense_1_loss_7: 0.1244 - dense_1_loss_8: 0.0892 - dense_1_loss_9: 0.0861 - dense_1_loss_10: 0.0708 - dense_1_loss_11: 0.0780 - dense_1_loss_12: 0.0725 - dense_1_loss_13: 0.0674 - dense_1_loss_14: 0.0686 - dense_1_loss_15: 0.0695 - dense_1_loss_16: 0.0742 - dense_1_loss_17: 0.0727 - dense_1_loss_18: 0.0706 - dense_1_loss_19: 0.0747 - dense_1_loss_20: 0.0758 - dense_1_loss_21: 0.0747 - dense_1_loss_22: 0.0707 - dense_1_loss_23: 0.0721 - dense_1_loss_24: 0.0693 - dense_1_loss_25: 0.0842 - dense_1_loss_26: 0.0727 - dense_1_loss_27: 0.0748 - dense_1_loss_28: 0.0830 - dense_1_loss_29: 0.0892 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5500 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 66/100
60/60 [==============================] - 0s - loss: 8.5942 - dense_1_loss_1: 3.8689 - dense_1_loss_2: 1.7559 - dense_1_loss_3: 0.6982 - dense_1_loss_4: 0.2609 - dense_1_loss_5: 0.1701 - dense_1_loss_6: 0.1306 - dense_1_loss_7: 0.1191 - dense_1_loss_8: 0.0851 - dense_1_loss_9: 0.0818 - dense_1_loss_10: 0.0680 - dense_1_loss_11: 0.0746 - dense_1_loss_12: 0.0693 - dense_1_loss_13: 0.0646 - dense_1_loss_14: 0.0660 - dense_1_loss_15: 0.0671 - dense_1_loss_16: 0.0708 - dense_1_loss_17: 0.0694 - dense_1_loss_18: 0.0676 - dense_1_loss_19: 0.0714 - dense_1_loss_20: 0.0726 - dense_1_loss_21: 0.0712 - dense_1_loss_22: 0.0675 - dense_1_loss_23: 0.0694 - dense_1_loss_24: 0.0669 - dense_1_loss_25: 0.0796 - dense_1_loss_26: 0.0696 - dense_1_loss_27: 0.0718 - dense_1_loss_28: 0.0809 - dense_1_loss_29: 0.0853 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5667 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 67/100
60/60 [==============================] - 0s - loss: 8.4597 - dense_1_loss_1: 3.8653 - dense_1_loss_2: 1.7322 - dense_1_loss_3: 0.6813 - dense_1_loss_4: 0.2504 - dense_1_loss_5: 0.1646 - dense_1_loss_6: 0.1260 - dense_1_loss_7: 0.1150 - dense_1_loss_8: 0.0816 - dense_1_loss_9: 0.0788 - dense_1_loss_10: 0.0654 - dense_1_loss_11: 0.0715 - dense_1_loss_12: 0.0665 - dense_1_loss_13: 0.0620 - dense_1_loss_14: 0.0631 - dense_1_loss_15: 0.0643 - dense_1_loss_16: 0.0678 - dense_1_loss_17: 0.0667 - dense_1_loss_18: 0.0647 - dense_1_loss_19: 0.0686 - dense_1_loss_20: 0.0697 - dense_1_loss_21: 0.0677 - dense_1_loss_22: 0.0649 - dense_1_loss_23: 0.0665 - dense_1_loss_24: 0.0640 - dense_1_loss_25: 0.0765 - dense_1_loss_26: 0.0670 - dense_1_loss_27: 0.0691 - dense_1_loss_28: 0.0773 - dense_1_loss_29: 0.0814 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5833 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 68/100
60/60 [==============================] - 0s - loss: 8.3313 - dense_1_loss_1: 3.8621 - dense_1_loss_2: 1.7093 - dense_1_loss_3: 0.6644 - dense_1_loss_4: 0.2410 - dense_1_loss_5: 0.1584 - dense_1_loss_6: 0.1217 - dense_1_loss_7: 0.1098 - dense_1_loss_8: 0.0788 - dense_1_loss_9: 0.0759 - dense_1_loss_10: 0.0629 - dense_1_loss_11: 0.0685 - dense_1_loss_12: 0.0640 - dense_1_loss_13: 0.0594 - dense_1_loss_14: 0.0603 - dense_1_loss_15: 0.0613 - dense_1_loss_16: 0.0656 - dense_1_loss_17: 0.0639 - dense_1_loss_18: 0.0619 - dense_1_loss_19: 0.0660 - dense_1_loss_20: 0.0670 - dense_1_loss_21: 0.0648 - dense_1_loss_22: 0.0628 - dense_1_loss_23: 0.0633 - dense_1_loss_24: 0.0610 - dense_1_loss_25: 0.0739 - dense_1_loss_26: 0.0641 - dense_1_loss_27: 0.0664 - dense_1_loss_28: 0.0742 - dense_1_loss_29: 0.0783 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 69/100
60/60 [==============================] - 0s - loss: 8.2080 - dense_1_loss_1: 3.8588 - dense_1_loss_2: 1.6867 - dense_1_loss_3: 0.6497 - dense_1_loss_4: 0.2312 - dense_1_loss_5: 0.1523 - dense_1_loss_6: 0.1170 - dense_1_loss_7: 0.1045 - dense_1_loss_8: 0.0760 - dense_1_loss_9: 0.0730 - dense_1_loss_10: 0.0605 - dense_1_loss_11: 0.0660 - dense_1_loss_12: 0.0614 - dense_1_loss_13: 0.0570 - dense_1_loss_14: 0.0581 - dense_1_loss_15: 0.0590 - dense_1_loss_16: 0.0633 - dense_1_loss_17: 0.0611 - dense_1_loss_18: 0.0595 - dense_1_loss_19: 0.0633 - dense_1_loss_20: 0.0644 - dense_1_loss_21: 0.0625 - dense_1_loss_22: 0.0602 - dense_1_loss_23: 0.0608 - dense_1_loss_24: 0.0586 - dense_1_loss_25: 0.0714 - dense_1_loss_26: 0.0612 - dense_1_loss_27: 0.0638 - dense_1_loss_28: 0.0713 - dense_1_loss_29: 0.0755 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 70/100
60/60 [==============================] - 0s - loss: 8.0932 - dense_1_loss_1: 3.8554 - dense_1_loss_2: 1.6644 - dense_1_loss_3: 0.6344 - dense_1_loss_4: 0.2231 - dense_1_loss_5: 0.1467 - dense_1_loss_6: 0.1132 - dense_1_loss_7: 0.1002 - dense_1_loss_8: 0.0731 - dense_1_loss_9: 0.0704 - dense_1_loss_10: 0.0579 - dense_1_loss_11: 0.0641 - dense_1_loss_12: 0.0590 - dense_1_loss_13: 0.0547 - dense_1_loss_14: 0.0564 - dense_1_loss_15: 0.0570 - dense_1_loss_16: 0.0605 - dense_1_loss_17: 0.0586 - dense_1_loss_18: 0.0574 - dense_1_loss_19: 0.0612 - dense_1_loss_20: 0.0617 - dense_1_loss_21: 0.0602 - dense_1_loss_22: 0.0581 - dense_1_loss_23: 0.0583 - dense_1_loss_24: 0.0565 - dense_1_loss_25: 0.0686 - dense_1_loss_26: 0.0590 - dense_1_loss_27: 0.0614 - dense_1_loss_28: 0.0689 - dense_1_loss_29: 0.0725 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 71/100
60/60 [==============================] - 0s - loss: 7.9833 - dense_1_loss_1: 3.8521 - dense_1_loss_2: 1.6440 - dense_1_loss_3: 0.6199 - dense_1_loss_4: 0.2144 - dense_1_loss_5: 0.1410 - dense_1_loss_6: 0.1097 - dense_1_loss_7: 0.0962 - dense_1_loss_8: 0.0707 - dense_1_loss_9: 0.0678 - dense_1_loss_10: 0.0558 - dense_1_loss_11: 0.0620 - dense_1_loss_12: 0.0569 - dense_1_loss_13: 0.0526 - dense_1_loss_14: 0.0543 - dense_1_loss_15: 0.0549 - dense_1_loss_16: 0.0583 - dense_1_loss_17: 0.0564 - dense_1_loss_18: 0.0554 - dense_1_loss_19: 0.0587 - dense_1_loss_20: 0.0594 - dense_1_loss_21: 0.0580 - dense_1_loss_22: 0.0557 - dense_1_loss_23: 0.0561 - dense_1_loss_24: 0.0546 - dense_1_loss_25: 0.0658 - dense_1_loss_26: 0.0568 - dense_1_loss_27: 0.0590 - dense_1_loss_28: 0.0666 - dense_1_loss_29: 0.0701 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 72/100
60/60 [==============================] - 0s - loss: 7.8793 - dense_1_loss_1: 3.8491 - dense_1_loss_2: 1.6233 - dense_1_loss_3: 0.6055 - dense_1_loss_4: 0.2075 - dense_1_loss_5: 0.1360 - dense_1_loss_6: 0.1063 - dense_1_loss_7: 0.0922 - dense_1_loss_8: 0.0684 - dense_1_loss_9: 0.0655 - dense_1_loss_10: 0.0538 - dense_1_loss_11: 0.0597 - dense_1_loss_12: 0.0548 - dense_1_loss_13: 0.0509 - dense_1_loss_14: 0.0519 - dense_1_loss_15: 0.0528 - dense_1_loss_16: 0.0567 - dense_1_loss_17: 0.0545 - dense_1_loss_18: 0.0533 - dense_1_loss_19: 0.0564 - dense_1_loss_20: 0.0573 - dense_1_loss_21: 0.0558 - dense_1_loss_22: 0.0536 - dense_1_loss_23: 0.0542 - dense_1_loss_24: 0.0528 - dense_1_loss_25: 0.0632 - dense_1_loss_26: 0.0548 - dense_1_loss_27: 0.0568 - dense_1_loss_28: 0.0645 - dense_1_loss_29: 0.0678 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 73/100
60/60 [==============================] - 0s - loss: 7.7824 - dense_1_loss_1: 3.8456 - dense_1_loss_2: 1.6041 - dense_1_loss_3: 0.5923 - dense_1_loss_4: 0.2004 - dense_1_loss_5: 0.1317 - dense_1_loss_6: 0.1029 - dense_1_loss_7: 0.0889 - dense_1_loss_8: 0.0664 - dense_1_loss_9: 0.0632 - dense_1_loss_10: 0.0521 - dense_1_loss_11: 0.0574 - dense_1_loss_12: 0.0529 - dense_1_loss_13: 0.0493 - dense_1_loss_14: 0.0501 - dense_1_loss_15: 0.0510 - dense_1_loss_16: 0.0550 - dense_1_loss_17: 0.0527 - dense_1_loss_18: 0.0514 - dense_1_loss_19: 0.0545 - dense_1_loss_20: 0.0553 - dense_1_loss_21: 0.0539 - dense_1_loss_22: 0.0516 - dense_1_loss_23: 0.0523 - dense_1_loss_24: 0.0509 - dense_1_loss_25: 0.0612 - dense_1_loss_26: 0.0528 - dense_1_loss_27: 0.0548 - dense_1_loss_28: 0.0620 - dense_1_loss_29: 0.0656 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 74/100
60/60 [==============================] - 0s - loss: 7.6862 - dense_1_loss_1: 3.8425 - dense_1_loss_2: 1.5849 - dense_1_loss_3: 0.5793 - dense_1_loss_4: 0.1927 - dense_1_loss_5: 0.1273 - dense_1_loss_6: 0.0993 - dense_1_loss_7: 0.0849 - dense_1_loss_8: 0.0644 - dense_1_loss_9: 0.0610 - dense_1_loss_10: 0.0502 - dense_1_loss_11: 0.0555 - dense_1_loss_12: 0.0509 - dense_1_loss_13: 0.0478 - dense_1_loss_14: 0.0484 - dense_1_loss_15: 0.0494 - dense_1_loss_16: 0.0531 - dense_1_loss_17: 0.0509 - dense_1_loss_18: 0.0496 - dense_1_loss_19: 0.0527 - dense_1_loss_20: 0.0534 - dense_1_loss_21: 0.0521 - dense_1_loss_22: 0.0499 - dense_1_loss_23: 0.0506 - dense_1_loss_24: 0.0491 - dense_1_loss_25: 0.0593 - dense_1_loss_26: 0.0512 - dense_1_loss_27: 0.0528 - dense_1_loss_28: 0.0598 - dense_1_loss_29: 0.0633 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 75/100
60/60 [==============================] - 0s - loss: 7.5985 - dense_1_loss_1: 3.8396 - dense_1_loss_2: 1.5661 - dense_1_loss_3: 0.5669 - dense_1_loss_4: 0.1867 - dense_1_loss_5: 0.1231 - dense_1_loss_6: 0.0963 - dense_1_loss_7: 0.0820 - dense_1_loss_8: 0.0623 - dense_1_loss_9: 0.0592 - dense_1_loss_10: 0.0486 - dense_1_loss_11: 0.0536 - dense_1_loss_12: 0.0492 - dense_1_loss_13: 0.0461 - dense_1_loss_14: 0.0469 - dense_1_loss_15: 0.0479 - dense_1_loss_16: 0.0513 - dense_1_loss_17: 0.0492 - dense_1_loss_18: 0.0480 - dense_1_loss_19: 0.0510 - dense_1_loss_20: 0.0517 - dense_1_loss_21: 0.0506 - dense_1_loss_22: 0.0483 - dense_1_loss_23: 0.0489 - dense_1_loss_24: 0.0476 - dense_1_loss_25: 0.0574 - dense_1_loss_26: 0.0496 - dense_1_loss_27: 0.0511 - dense_1_loss_28: 0.0580 - dense_1_loss_29: 0.0615 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 76/100
60/60 [==============================] - 0s - loss: 7.5125 - dense_1_loss_1: 3.8364 - dense_1_loss_2: 1.5483 - dense_1_loss_3: 0.5546 - dense_1_loss_4: 0.1802 - dense_1_loss_5: 0.1192 - dense_1_loss_6: 0.0934 - dense_1_loss_7: 0.0791 - dense_1_loss_8: 0.0603 - dense_1_loss_9: 0.0576 - dense_1_loss_10: 0.0469 - dense_1_loss_11: 0.0519 - dense_1_loss_12: 0.0477 - dense_1_loss_13: 0.0446 - dense_1_loss_14: 0.0454 - dense_1_loss_15: 0.0463 - dense_1_loss_16: 0.0498 - dense_1_loss_17: 0.0475 - dense_1_loss_18: 0.0464 - dense_1_loss_19: 0.0493 - dense_1_loss_20: 0.0500 - dense_1_loss_21: 0.0490 - dense_1_loss_22: 0.0467 - dense_1_loss_23: 0.0472 - dense_1_loss_24: 0.0460 - dense_1_loss_25: 0.0555 - dense_1_loss_26: 0.0479 - dense_1_loss_27: 0.0494 - dense_1_loss_28: 0.0563 - dense_1_loss_29: 0.0593 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 77/100
60/60 [==============================] - 0s - loss: 7.4341 - dense_1_loss_1: 3.8334 - dense_1_loss_2: 1.5311 - dense_1_loss_3: 0.5435 - dense_1_loss_4: 0.1750 - dense_1_loss_5: 0.1158 - dense_1_loss_6: 0.0910 - dense_1_loss_7: 0.0767 - dense_1_loss_8: 0.0585 - dense_1_loss_9: 0.0560 - dense_1_loss_10: 0.0454 - dense_1_loss_11: 0.0504 - dense_1_loss_12: 0.0463 - dense_1_loss_13: 0.0432 - dense_1_loss_14: 0.0440 - dense_1_loss_15: 0.0450 - dense_1_loss_16: 0.0483 - dense_1_loss_17: 0.0461 - dense_1_loss_18: 0.0450 - dense_1_loss_19: 0.0478 - dense_1_loss_20: 0.0483 - dense_1_loss_21: 0.0475 - dense_1_loss_22: 0.0451 - dense_1_loss_23: 0.0458 - dense_1_loss_24: 0.0446 - dense_1_loss_25: 0.0535 - dense_1_loss_26: 0.0465 - dense_1_loss_27: 0.0480 - dense_1_loss_28: 0.0547 - dense_1_loss_29: 0.0576 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 78/100
60/60 [==============================] - 0s - loss: 7.3557 - dense_1_loss_1: 3.8301 - dense_1_loss_2: 1.5137 - dense_1_loss_3: 0.5326 - dense_1_loss_4: 0.1695 - dense_1_loss_5: 0.1125 - dense_1_loss_6: 0.0882 - dense_1_loss_7: 0.0739 - dense_1_loss_8: 0.0568 - dense_1_loss_9: 0.0543 - dense_1_loss_10: 0.0441 - dense_1_loss_11: 0.0487 - dense_1_loss_12: 0.0448 - dense_1_loss_13: 0.0419 - dense_1_loss_14: 0.0426 - dense_1_loss_15: 0.0435 - dense_1_loss_16: 0.0469 - dense_1_loss_17: 0.0447 - dense_1_loss_18: 0.0435 - dense_1_loss_19: 0.0463 - dense_1_loss_20: 0.0468 - dense_1_loss_21: 0.0460 - dense_1_loss_22: 0.0437 - dense_1_loss_23: 0.0444 - dense_1_loss_24: 0.0434 - dense_1_loss_25: 0.0519 - dense_1_loss_26: 0.0451 - dense_1_loss_27: 0.0468 - dense_1_loss_28: 0.0532 - dense_1_loss_29: 0.0558 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 79/100
60/60 [==============================] - 0s - loss: 7.2792 - dense_1_loss_1: 3.8274 - dense_1_loss_2: 1.4976 - dense_1_loss_3: 0.5203 - dense_1_loss_4: 0.1640 - dense_1_loss_5: 0.1092 - dense_1_loss_6: 0.0854 - dense_1_loss_7: 0.0712 - dense_1_loss_8: 0.0553 - dense_1_loss_9: 0.0525 - dense_1_loss_10: 0.0428 - dense_1_loss_11: 0.0473 - dense_1_loss_12: 0.0433 - dense_1_loss_13: 0.0407 - dense_1_loss_14: 0.0412 - dense_1_loss_15: 0.0423 - dense_1_loss_16: 0.0455 - dense_1_loss_17: 0.0433 - dense_1_loss_18: 0.0422 - dense_1_loss_19: 0.0449 - dense_1_loss_20: 0.0454 - dense_1_loss_21: 0.0445 - dense_1_loss_22: 0.0423 - dense_1_loss_23: 0.0432 - dense_1_loss_24: 0.0420 - dense_1_loss_25: 0.0507 - dense_1_loss_26: 0.0437 - dense_1_loss_27: 0.0455 - dense_1_loss_28: 0.0514 - dense_1_loss_29: 0.0542 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 80/100
60/60 [==============================] - 0s - loss: 7.2088 - dense_1_loss_1: 3.8242 - dense_1_loss_2: 1.4811 - dense_1_loss_3: 0.5108 - dense_1_loss_4: 0.1594 - dense_1_loss_5: 0.1063 - dense_1_loss_6: 0.0832 - dense_1_loss_7: 0.0692 - dense_1_loss_8: 0.0537 - dense_1_loss_9: 0.0511 - dense_1_loss_10: 0.0415 - dense_1_loss_11: 0.0459 - dense_1_loss_12: 0.0420 - dense_1_loss_13: 0.0396 - dense_1_loss_14: 0.0399 - dense_1_loss_15: 0.0412 - dense_1_loss_16: 0.0442 - dense_1_loss_17: 0.0419 - dense_1_loss_18: 0.0410 - dense_1_loss_19: 0.0436 - dense_1_loss_20: 0.0441 - dense_1_loss_21: 0.0431 - dense_1_loss_22: 0.0411 - dense_1_loss_23: 0.0420 - dense_1_loss_24: 0.0408 - dense_1_loss_25: 0.0494 - dense_1_loss_26: 0.0423 - dense_1_loss_27: 0.0441 - dense_1_loss_28: 0.0497 - dense_1_loss_29: 0.0524 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 81/100
60/60 [==============================] - 0s - loss: 7.1396 - dense_1_loss_1: 3.8213 - dense_1_loss_2: 1.4653 - dense_1_loss_3: 0.5001 - dense_1_loss_4: 0.1549 - dense_1_loss_5: 0.1030 - dense_1_loss_6: 0.0809 - dense_1_loss_7: 0.0669 - dense_1_loss_8: 0.0520 - dense_1_loss_9: 0.0497 - dense_1_loss_10: 0.0404 - dense_1_loss_11: 0.0447 - dense_1_loss_12: 0.0409 - dense_1_loss_13: 0.0384 - dense_1_loss_14: 0.0388 - dense_1_loss_15: 0.0400 - dense_1_loss_16: 0.0428 - dense_1_loss_17: 0.0407 - dense_1_loss_18: 0.0398 - dense_1_loss_19: 0.0422 - dense_1_loss_20: 0.0428 - dense_1_loss_21: 0.0420 - dense_1_loss_22: 0.0400 - dense_1_loss_23: 0.0406 - dense_1_loss_24: 0.0398 - dense_1_loss_25: 0.0478 - dense_1_loss_26: 0.0411 - dense_1_loss_27: 0.0429 - dense_1_loss_28: 0.0486 - dense_1_loss_29: 0.0511 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 82/100
60/60 [==============================] - 0s - loss: 7.0758 - dense_1_loss_1: 3.8183 - dense_1_loss_2: 1.4507 - dense_1_loss_3: 0.4906 - dense_1_loss_4: 0.1508 - dense_1_loss_5: 0.1003 - dense_1_loss_6: 0.0791 - dense_1_loss_7: 0.0651 - dense_1_loss_8: 0.0507 - dense_1_loss_9: 0.0485 - dense_1_loss_10: 0.0393 - dense_1_loss_11: 0.0435 - dense_1_loss_12: 0.0398 - dense_1_loss_13: 0.0374 - dense_1_loss_14: 0.0377 - dense_1_loss_15: 0.0388 - dense_1_loss_16: 0.0418 - dense_1_loss_17: 0.0396 - dense_1_loss_18: 0.0386 - dense_1_loss_19: 0.0410 - dense_1_loss_20: 0.0417 - dense_1_loss_21: 0.0407 - dense_1_loss_22: 0.0388 - dense_1_loss_23: 0.0395 - dense_1_loss_24: 0.0387 - dense_1_loss_25: 0.0460 - dense_1_loss_26: 0.0400 - dense_1_loss_27: 0.0417 - dense_1_loss_28: 0.0475 - dense_1_loss_29: 0.0497 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 83/100
60/60 [==============================] - 0s - loss: 7.0105 - dense_1_loss_1: 3.8154 - dense_1_loss_2: 1.4350 - dense_1_loss_3: 0.4811 - dense_1_loss_4: 0.1461 - dense_1_loss_5: 0.0975 - dense_1_loss_6: 0.0767 - dense_1_loss_7: 0.0629 - dense_1_loss_8: 0.0494 - dense_1_loss_9: 0.0473 - dense_1_loss_10: 0.0382 - dense_1_loss_11: 0.0422 - dense_1_loss_12: 0.0388 - dense_1_loss_13: 0.0363 - dense_1_loss_14: 0.0366 - dense_1_loss_15: 0.0375 - dense_1_loss_16: 0.0410 - dense_1_loss_17: 0.0385 - dense_1_loss_18: 0.0375 - dense_1_loss_19: 0.0398 - dense_1_loss_20: 0.0405 - dense_1_loss_21: 0.0396 - dense_1_loss_22: 0.0378 - dense_1_loss_23: 0.0382 - dense_1_loss_24: 0.0377 - dense_1_loss_25: 0.0446 - dense_1_loss_26: 0.0389 - dense_1_loss_27: 0.0406 - dense_1_loss_28: 0.0463 - dense_1_loss_29: 0.0484 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 84/100
60/60 [==============================] - 0s - loss: 6.9501 - dense_1_loss_1: 3.8125 - dense_1_loss_2: 1.4203 - dense_1_loss_3: 0.4719 - dense_1_loss_4: 0.1424 - dense_1_loss_5: 0.0951 - dense_1_loss_6: 0.0747 - dense_1_loss_7: 0.0612 - dense_1_loss_8: 0.0482 - dense_1_loss_9: 0.0460 - dense_1_loss_10: 0.0372 - dense_1_loss_11: 0.0412 - dense_1_loss_12: 0.0377 - dense_1_loss_13: 0.0353 - dense_1_loss_14: 0.0357 - dense_1_loss_15: 0.0366 - dense_1_loss_16: 0.0398 - dense_1_loss_17: 0.0374 - dense_1_loss_18: 0.0365 - dense_1_loss_19: 0.0388 - dense_1_loss_20: 0.0393 - dense_1_loss_21: 0.0385 - dense_1_loss_22: 0.0368 - dense_1_loss_23: 0.0372 - dense_1_loss_24: 0.0367 - dense_1_loss_25: 0.0435 - dense_1_loss_26: 0.0379 - dense_1_loss_27: 0.0395 - dense_1_loss_28: 0.0449 - dense_1_loss_29: 0.0473 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 85/100
60/60 [==============================] - 0s - loss: 6.8908 - dense_1_loss_1: 3.8096 - dense_1_loss_2: 1.4065 - dense_1_loss_3: 0.4622 - dense_1_loss_4: 0.1385 - dense_1_loss_5: 0.0926 - dense_1_loss_6: 0.0726 - dense_1_loss_7: 0.0596 - dense_1_loss_8: 0.0470 - dense_1_loss_9: 0.0448 - dense_1_loss_10: 0.0362 - dense_1_loss_11: 0.0401 - dense_1_loss_12: 0.0367 - dense_1_loss_13: 0.0344 - dense_1_loss_14: 0.0348 - dense_1_loss_15: 0.0358 - dense_1_loss_16: 0.0387 - dense_1_loss_17: 0.0364 - dense_1_loss_18: 0.0355 - dense_1_loss_19: 0.0379 - dense_1_loss_20: 0.0381 - dense_1_loss_21: 0.0375 - dense_1_loss_22: 0.0358 - dense_1_loss_23: 0.0363 - dense_1_loss_24: 0.0357 - dense_1_loss_25: 0.0427 - dense_1_loss_26: 0.0369 - dense_1_loss_27: 0.0384 - dense_1_loss_28: 0.0436 - dense_1_loss_29: 0.0460 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 86/100
60/60 [==============================] - 0s - loss: 6.8355 - dense_1_loss_1: 3.8069 - dense_1_loss_2: 1.3923 - dense_1_loss_3: 0.4541 - dense_1_loss_4: 0.1352 - dense_1_loss_5: 0.0904 - dense_1_loss_6: 0.0708 - dense_1_loss_7: 0.0582 - dense_1_loss_8: 0.0458 - dense_1_loss_9: 0.0436 - dense_1_loss_10: 0.0352 - dense_1_loss_11: 0.0392 - dense_1_loss_12: 0.0357 - dense_1_loss_13: 0.0335 - dense_1_loss_14: 0.0339 - dense_1_loss_15: 0.0349 - dense_1_loss_16: 0.0376 - dense_1_loss_17: 0.0355 - dense_1_loss_18: 0.0347 - dense_1_loss_19: 0.0370 - dense_1_loss_20: 0.0371 - dense_1_loss_21: 0.0366 - dense_1_loss_22: 0.0349 - dense_1_loss_23: 0.0354 - dense_1_loss_24: 0.0348 - dense_1_loss_25: 0.0417 - dense_1_loss_26: 0.0360 - dense_1_loss_27: 0.0373 - dense_1_loss_28: 0.0424 - dense_1_loss_29: 0.0448 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 87/100
60/60 [==============================] - 0s - loss: 6.7820 - dense_1_loss_1: 3.8038 - dense_1_loss_2: 1.3795 - dense_1_loss_3: 0.4460 - dense_1_loss_4: 0.1318 - dense_1_loss_5: 0.0884 - dense_1_loss_6: 0.0693 - dense_1_loss_7: 0.0568 - dense_1_loss_8: 0.0447 - dense_1_loss_9: 0.0426 - dense_1_loss_10: 0.0343 - dense_1_loss_11: 0.0381 - dense_1_loss_12: 0.0348 - dense_1_loss_13: 0.0326 - dense_1_loss_14: 0.0330 - dense_1_loss_15: 0.0340 - dense_1_loss_16: 0.0367 - dense_1_loss_17: 0.0346 - dense_1_loss_18: 0.0337 - dense_1_loss_19: 0.0359 - dense_1_loss_20: 0.0362 - dense_1_loss_21: 0.0356 - dense_1_loss_22: 0.0339 - dense_1_loss_23: 0.0346 - dense_1_loss_24: 0.0339 - dense_1_loss_25: 0.0404 - dense_1_loss_26: 0.0351 - dense_1_loss_27: 0.0364 - dense_1_loss_28: 0.0414 - dense_1_loss_29: 0.0438 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 88/100
60/60 [==============================] - 0s - loss: 6.7287 - dense_1_loss_1: 3.8010 - dense_1_loss_2: 1.3661 - dense_1_loss_3: 0.4374 - dense_1_loss_4: 0.1286 - dense_1_loss_5: 0.0861 - dense_1_loss_6: 0.0677 - dense_1_loss_7: 0.0553 - dense_1_loss_8: 0.0436 - dense_1_loss_9: 0.0417 - dense_1_loss_10: 0.0335 - dense_1_loss_11: 0.0371 - dense_1_loss_12: 0.0341 - dense_1_loss_13: 0.0317 - dense_1_loss_14: 0.0321 - dense_1_loss_15: 0.0331 - dense_1_loss_16: 0.0360 - dense_1_loss_17: 0.0338 - dense_1_loss_18: 0.0329 - dense_1_loss_19: 0.0350 - dense_1_loss_20: 0.0353 - dense_1_loss_21: 0.0347 - dense_1_loss_22: 0.0330 - dense_1_loss_23: 0.0336 - dense_1_loss_24: 0.0331 - dense_1_loss_25: 0.0393 - dense_1_loss_26: 0.0341 - dense_1_loss_27: 0.0356 - dense_1_loss_28: 0.0406 - dense_1_loss_29: 0.0427 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 89/100
60/60 [==============================] - 0s - loss: 6.6773 - dense_1_loss_1: 3.7981 - dense_1_loss_2: 1.3530 - dense_1_loss_3: 0.4293 - dense_1_loss_4: 0.1254 - dense_1_loss_5: 0.0840 - dense_1_loss_6: 0.0658 - dense_1_loss_7: 0.0538 - dense_1_loss_8: 0.0427 - dense_1_loss_9: 0.0406 - dense_1_loss_10: 0.0327 - dense_1_loss_11: 0.0361 - dense_1_loss_12: 0.0332 - dense_1_loss_13: 0.0309 - dense_1_loss_14: 0.0313 - dense_1_loss_15: 0.0324 - dense_1_loss_16: 0.0353 - dense_1_loss_17: 0.0330 - dense_1_loss_18: 0.0321 - dense_1_loss_19: 0.0341 - dense_1_loss_20: 0.0345 - dense_1_loss_21: 0.0339 - dense_1_loss_22: 0.0322 - dense_1_loss_23: 0.0328 - dense_1_loss_24: 0.0324 - dense_1_loss_25: 0.0384 - dense_1_loss_26: 0.0333 - dense_1_loss_27: 0.0348 - dense_1_loss_28: 0.0397 - dense_1_loss_29: 0.0417 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 90/100
60/60 [==============================] - 0s - loss: 6.6297 - dense_1_loss_1: 3.7953 - dense_1_loss_2: 1.3410 - dense_1_loss_3: 0.4219 - dense_1_loss_4: 0.1224 - dense_1_loss_5: 0.0822 - dense_1_loss_6: 0.0643 - dense_1_loss_7: 0.0526 - dense_1_loss_8: 0.0418 - dense_1_loss_9: 0.0397 - dense_1_loss_10: 0.0319 - dense_1_loss_11: 0.0354 - dense_1_loss_12: 0.0324 - dense_1_loss_13: 0.0302 - dense_1_loss_14: 0.0305 - dense_1_loss_15: 0.0317 - dense_1_loss_16: 0.0344 - dense_1_loss_17: 0.0321 - dense_1_loss_18: 0.0313 - dense_1_loss_19: 0.0334 - dense_1_loss_20: 0.0336 - dense_1_loss_21: 0.0331 - dense_1_loss_22: 0.0315 - dense_1_loss_23: 0.0320 - dense_1_loss_24: 0.0315 - dense_1_loss_25: 0.0376 - dense_1_loss_26: 0.0325 - dense_1_loss_27: 0.0340 - dense_1_loss_28: 0.0387 - dense_1_loss_29: 0.0407 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 91/100
60/60 [==============================] - 0s - loss: 6.5828 - dense_1_loss_1: 3.7927 - dense_1_loss_2: 1.3288 - dense_1_loss_3: 0.4146 - dense_1_loss_4: 0.1198 - dense_1_loss_5: 0.0803 - dense_1_loss_6: 0.0626 - dense_1_loss_7: 0.0514 - dense_1_loss_8: 0.0409 - dense_1_loss_9: 0.0387 - dense_1_loss_10: 0.0311 - dense_1_loss_11: 0.0347 - dense_1_loss_12: 0.0316 - dense_1_loss_13: 0.0295 - dense_1_loss_14: 0.0299 - dense_1_loss_15: 0.0311 - dense_1_loss_16: 0.0334 - dense_1_loss_17: 0.0313 - dense_1_loss_18: 0.0306 - dense_1_loss_19: 0.0326 - dense_1_loss_20: 0.0328 - dense_1_loss_21: 0.0323 - dense_1_loss_22: 0.0307 - dense_1_loss_23: 0.0313 - dense_1_loss_24: 0.0308 - dense_1_loss_25: 0.0368 - dense_1_loss_26: 0.0317 - dense_1_loss_27: 0.0332 - dense_1_loss_28: 0.0377 - dense_1_loss_29: 0.0397 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 92/100
60/60 [==============================] - 0s - loss: 6.5360 - dense_1_loss_1: 3.7898 - dense_1_loss_2: 1.3168 - dense_1_loss_3: 0.4072 - dense_1_loss_4: 0.1168 - dense_1_loss_5: 0.0785 - dense_1_loss_6: 0.0611 - dense_1_loss_7: 0.0502 - dense_1_loss_8: 0.0400 - dense_1_loss_9: 0.0379 - dense_1_loss_10: 0.0304 - dense_1_loss_11: 0.0339 - dense_1_loss_12: 0.0309 - dense_1_loss_13: 0.0289 - dense_1_loss_14: 0.0292 - dense_1_loss_15: 0.0304 - dense_1_loss_16: 0.0326 - dense_1_loss_17: 0.0306 - dense_1_loss_18: 0.0298 - dense_1_loss_19: 0.0319 - dense_1_loss_20: 0.0320 - dense_1_loss_21: 0.0315 - dense_1_loss_22: 0.0301 - dense_1_loss_23: 0.0306 - dense_1_loss_24: 0.0301 - dense_1_loss_25: 0.0358 - dense_1_loss_26: 0.0310 - dense_1_loss_27: 0.0324 - dense_1_loss_28: 0.0369 - dense_1_loss_29: 0.0387 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 93/100
60/60 [==============================] - 0s - loss: 6.4926 - dense_1_loss_1: 3.7870 - dense_1_loss_2: 1.3053 - dense_1_loss_3: 0.4006 - dense_1_loss_4: 0.1143 - dense_1_loss_5: 0.0767 - dense_1_loss_6: 0.0598 - dense_1_loss_7: 0.0491 - dense_1_loss_8: 0.0391 - dense_1_loss_9: 0.0371 - dense_1_loss_10: 0.0297 - dense_1_loss_11: 0.0331 - dense_1_loss_12: 0.0302 - dense_1_loss_13: 0.0282 - dense_1_loss_14: 0.0286 - dense_1_loss_15: 0.0296 - dense_1_loss_16: 0.0320 - dense_1_loss_17: 0.0299 - dense_1_loss_18: 0.0292 - dense_1_loss_19: 0.0311 - dense_1_loss_20: 0.0313 - dense_1_loss_21: 0.0307 - dense_1_loss_22: 0.0295 - dense_1_loss_23: 0.0299 - dense_1_loss_24: 0.0295 - dense_1_loss_25: 0.0349 - dense_1_loss_26: 0.0304 - dense_1_loss_27: 0.0317 - dense_1_loss_28: 0.0362 - dense_1_loss_29: 0.0379 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 94/100
60/60 [==============================] - 0s - loss: 6.4500 - dense_1_loss_1: 3.7845 - dense_1_loss_2: 1.2939 - dense_1_loss_3: 0.3931 - dense_1_loss_4: 0.1121 - dense_1_loss_5: 0.0750 - dense_1_loss_6: 0.0586 - dense_1_loss_7: 0.0481 - dense_1_loss_8: 0.0383 - dense_1_loss_9: 0.0363 - dense_1_loss_10: 0.0291 - dense_1_loss_11: 0.0323 - dense_1_loss_12: 0.0296 - dense_1_loss_13: 0.0275 - dense_1_loss_14: 0.0280 - dense_1_loss_15: 0.0289 - dense_1_loss_16: 0.0315 - dense_1_loss_17: 0.0293 - dense_1_loss_18: 0.0285 - dense_1_loss_19: 0.0305 - dense_1_loss_20: 0.0306 - dense_1_loss_21: 0.0300 - dense_1_loss_22: 0.0288 - dense_1_loss_23: 0.0292 - dense_1_loss_24: 0.0289 - dense_1_loss_25: 0.0341 - dense_1_loss_26: 0.0297 - dense_1_loss_27: 0.0311 - dense_1_loss_28: 0.0354 - dense_1_loss_29: 0.0371 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 95/100
60/60 [==============================] - 0s - loss: 6.4081 - dense_1_loss_1: 3.7817 - dense_1_loss_2: 1.2828 - dense_1_loss_3: 0.3861 - dense_1_loss_4: 0.1097 - dense_1_loss_5: 0.0733 - dense_1_loss_6: 0.0572 - dense_1_loss_7: 0.0471 - dense_1_loss_8: 0.0375 - dense_1_loss_9: 0.0355 - dense_1_loss_10: 0.0285 - dense_1_loss_11: 0.0317 - dense_1_loss_12: 0.0289 - dense_1_loss_13: 0.0269 - dense_1_loss_14: 0.0273 - dense_1_loss_15: 0.0283 - dense_1_loss_16: 0.0308 - dense_1_loss_17: 0.0286 - dense_1_loss_18: 0.0279 - dense_1_loss_19: 0.0297 - dense_1_loss_20: 0.0300 - dense_1_loss_21: 0.0294 - dense_1_loss_22: 0.0282 - dense_1_loss_23: 0.0286 - dense_1_loss_24: 0.0283 - dense_1_loss_25: 0.0334 - dense_1_loss_26: 0.0291 - dense_1_loss_27: 0.0304 - dense_1_loss_28: 0.0348 - dense_1_loss_29: 0.0364 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 96/100
60/60 [==============================] - 0s - loss: 6.3681 - dense_1_loss_1: 3.7790 - dense_1_loss_2: 1.2717 - dense_1_loss_3: 0.3798 - dense_1_loss_4: 0.1075 - dense_1_loss_5: 0.0719 - dense_1_loss_6: 0.0562 - dense_1_loss_7: 0.0461 - dense_1_loss_8: 0.0367 - dense_1_loss_9: 0.0348 - dense_1_loss_10: 0.0279 - dense_1_loss_11: 0.0311 - dense_1_loss_12: 0.0283 - dense_1_loss_13: 0.0264 - dense_1_loss_14: 0.0268 - dense_1_loss_15: 0.0278 - dense_1_loss_16: 0.0301 - dense_1_loss_17: 0.0280 - dense_1_loss_18: 0.0273 - dense_1_loss_19: 0.0291 - dense_1_loss_20: 0.0293 - dense_1_loss_21: 0.0287 - dense_1_loss_22: 0.0275 - dense_1_loss_23: 0.0279 - dense_1_loss_24: 0.0277 - dense_1_loss_25: 0.0327 - dense_1_loss_26: 0.0284 - dense_1_loss_27: 0.0298 - dense_1_loss_28: 0.0339 - dense_1_loss_29: 0.0356 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 97/100
60/60 [==============================] - 0s - loss: 6.3282 - dense_1_loss_1: 3.7764 - dense_1_loss_2: 1.2606 - dense_1_loss_3: 0.3734 - dense_1_loss_4: 0.1054 - dense_1_loss_5: 0.0702 - dense_1_loss_6: 0.0549 - dense_1_loss_7: 0.0451 - dense_1_loss_8: 0.0359 - dense_1_loss_9: 0.0341 - dense_1_loss_10: 0.0273 - dense_1_loss_11: 0.0305 - dense_1_loss_12: 0.0276 - dense_1_loss_13: 0.0258 - dense_1_loss_14: 0.0263 - dense_1_loss_15: 0.0273 - dense_1_loss_16: 0.0293 - dense_1_loss_17: 0.0274 - dense_1_loss_18: 0.0268 - dense_1_loss_19: 0.0285 - dense_1_loss_20: 0.0287 - dense_1_loss_21: 0.0282 - dense_1_loss_22: 0.0270 - dense_1_loss_23: 0.0274 - dense_1_loss_24: 0.0271 - dense_1_loss_25: 0.0320 - dense_1_loss_26: 0.0278 - dense_1_loss_27: 0.0292 - dense_1_loss_28: 0.0332 - dense_1_loss_29: 0.0348 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 98/100
60/60 [==============================] - 0s - loss: 6.2921 - dense_1_loss_1: 3.7737 - dense_1_loss_2: 1.2509 - dense_1_loss_3: 0.3680 - dense_1_loss_4: 0.1033 - dense_1_loss_5: 0.0688 - dense_1_loss_6: 0.0540 - dense_1_loss_7: 0.0442 - dense_1_loss_8: 0.0352 - dense_1_loss_9: 0.0335 - dense_1_loss_10: 0.0267 - dense_1_loss_11: 0.0299 - dense_1_loss_12: 0.0271 - dense_1_loss_13: 0.0253 - dense_1_loss_14: 0.0257 - dense_1_loss_15: 0.0267 - dense_1_loss_16: 0.0288 - dense_1_loss_17: 0.0268 - dense_1_loss_18: 0.0263 - dense_1_loss_19: 0.0279 - dense_1_loss_20: 0.0281 - dense_1_loss_21: 0.0276 - dense_1_loss_22: 0.0264 - dense_1_loss_23: 0.0268 - dense_1_loss_24: 0.0265 - dense_1_loss_25: 0.0313 - dense_1_loss_26: 0.0272 - dense_1_loss_27: 0.0286 - dense_1_loss_28: 0.0326 - dense_1_loss_29: 0.0341 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 99/100
60/60 [==============================] - 0s - loss: 6.2552 - dense_1_loss_1: 3.7710 - dense_1_loss_2: 1.2403 - dense_1_loss_3: 0.3620 - dense_1_loss_4: 0.1015 - dense_1_loss_5: 0.0674 - dense_1_loss_6: 0.0530 - dense_1_loss_7: 0.0433 - dense_1_loss_8: 0.0346 - dense_1_loss_9: 0.0329 - dense_1_loss_10: 0.0262 - dense_1_loss_11: 0.0292 - dense_1_loss_12: 0.0266 - dense_1_loss_13: 0.0247 - dense_1_loss_14: 0.0251 - dense_1_loss_15: 0.0261 - dense_1_loss_16: 0.0285 - dense_1_loss_17: 0.0263 - dense_1_loss_18: 0.0257 - dense_1_loss_19: 0.0273 - dense_1_loss_20: 0.0275 - dense_1_loss_21: 0.0270 - dense_1_loss_22: 0.0258 - dense_1_loss_23: 0.0263 - dense_1_loss_24: 0.0260 - dense_1_loss_25: 0.0307 - dense_1_loss_26: 0.0267 - dense_1_loss_27: 0.0280 - dense_1_loss_28: 0.0320 - dense_1_loss_29: 0.0334 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     
Epoch 100/100
60/60 [==============================] - 0s - loss: 6.2195 - dense_1_loss_1: 3.7686 - dense_1_loss_2: 1.2304 - dense_1_loss_3: 0.3562 - dense_1_loss_4: 0.0996 - dense_1_loss_5: 0.0661 - dense_1_loss_6: 0.0518 - dense_1_loss_7: 0.0425 - dense_1_loss_8: 0.0339 - dense_1_loss_9: 0.0322 - dense_1_loss_10: 0.0257 - dense_1_loss_11: 0.0285 - dense_1_loss_12: 0.0261 - dense_1_loss_13: 0.0242 - dense_1_loss_14: 0.0246 - dense_1_loss_15: 0.0256 - dense_1_loss_16: 0.0281 - dense_1_loss_17: 0.0257 - dense_1_loss_18: 0.0252 - dense_1_loss_19: 0.0267 - dense_1_loss_20: 0.0269 - dense_1_loss_21: 0.0265 - dense_1_loss_22: 0.0253 - dense_1_loss_23: 0.0257 - dense_1_loss_24: 0.0255 - dense_1_loss_25: 0.0301 - dense_1_loss_26: 0.0261 - dense_1_loss_27: 0.0275 - dense_1_loss_28: 0.0314 - dense_1_loss_29: 0.0328 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6500 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     





&lt;keras.callbacks.History at 0x7fcff481d908&gt;</code></pre><p>You should see the model loss going down. Now that you have trained a model, lets go on the the final section to implement an inference algorithm, and generate some music! </p>
<h2 id="3-Generating-music"><a href="#3-Generating-music" class="headerlink" title="3 - Generating music"></a>3 - Generating music</h2><p>You now have a trained model which has learned the patterns of the jazz soloist. Lets now use this model to synthesize new music. </p>
<h4 id="3-1-Predicting-amp-Sampling"><a href="#3-1-Predicting-amp-Sampling" class="headerlink" title="3.1 - Predicting &amp; Sampling"></a>3.1 - Predicting &amp; Sampling</h4><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/images/music_gen.png" style="width:600;height:400px;">

<p>At each step of sampling, you will take as input the activation <code>a</code> and cell state <code>c</code> from the previous state of the LSTM, forward propagate by one step, and get a new output activation as well as cell state. The new activation <code>a</code> can then be used to generate the output, using <code>densor</code> as before. </p>
<p>To start off the model, we will initialize <code>x0</code> as well as the LSTM activation and and cell value <code>a0</code> and <code>c0</code> to be zeros. </p>
<!-- 
You are about to build a function that will do this inference for you. Your function takes in your previous model and the number of time steps `Ty` that you want to sample. It will return a keras model that would be able to generate sequences for you. Furthermore, the function takes in a dense layer of `78` units and the number of activations. 
!--> 


<p><strong>Exercise:</strong> Implement the function below to sample a sequence of musical values. Here are some of the key steps you’ll need to implement inside the for-loop that generates the $T_y$ output characters: </p>
<p>Step 2.A: Use <code>LSTM_Cell</code>, which inputs the previous step’s <code>c</code> and <code>a</code> to generate the current step’s <code>c</code> and <code>a</code>. </p>
<p>Step 2.B: Use <code>densor</code> (defined previously) to compute a softmax on <code>a</code> to get the output for the current step. </p>
<p>Step 2.C: Save the output you have just generated by appending it to <code>outputs</code>.</p>
<p>Step 2.D: Sample x to the be “out”‘s one-hot version (the prediction) so that you can pass it to the next LSTM’s step.  We have already provided this line of code, which uses a <a href="https://keras.io/layers/core/#lambda" target="_blank" rel="noopener">Lambda</a> function. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = Lambda(one_hot)(out)</span><br></pre></td></tr></table></figure>
<p>[Minor technical note: Rather than sampling a value at random according to the probabilities in <code>out</code>, this line of code actually chooses the single most likely note at each step using an argmax.]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: music_inference_model</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">music_inference_model</span><span class="params">(LSTM_cell, densor, n_values = <span class="number">78</span>, n_a = <span class="number">64</span>, Ty = <span class="number">100</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Uses the trained "LSTM_cell" and "densor" from model() to generate a sequence of values.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    LSTM_cell -- the trained "LSTM_cell" from model(), Keras layer object</span></span><br><span class="line"><span class="string">    densor -- the trained "densor" from model(), Keras layer object</span></span><br><span class="line"><span class="string">    n_values -- integer, umber of unique values</span></span><br><span class="line"><span class="string">    n_a -- number of units in the LSTM_cell</span></span><br><span class="line"><span class="string">    Ty -- integer, number of time steps to generate</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    inference_model -- Keras model instance</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define the input of your model with a shape </span></span><br><span class="line">    x0 = Input(shape=(<span class="number">1</span>, n_values))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define s0, initial hidden state for the decoder LSTM</span></span><br><span class="line">    a0 = Input(shape=(n_a,), name=<span class="string">'a0'</span>)</span><br><span class="line">    c0 = Input(shape=(n_a,), name=<span class="string">'c0'</span>)</span><br><span class="line">    a = a0</span><br><span class="line">    c = c0</span><br><span class="line">    x = x0</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Step 1: Create an empty list of "outputs" to later store your predicted values (≈1 line)</span></span><br><span class="line">    outputs = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 2: Loop over Ty and generate a value at every time step</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(Ty):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2.A: Perform one step of LSTM_cell (≈1 line)</span></span><br><span class="line">        a, _, c = LSTM_cell(x, initial_state=[a, c]);</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)</span></span><br><span class="line">        out = densor(a);</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2.C: Append the prediction "out" to "outputs". out.shape = (None, 78) (≈1 line)</span></span><br><span class="line">        outputs.append(out);</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2.D: Select the next value according to "out", and set "x" to be the one-hot representation of the</span></span><br><span class="line">        <span class="comment">#           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided </span></span><br><span class="line">        <span class="comment">#           the line of code you need to do this. </span></span><br><span class="line">        x = Lambda(one_hot)(out);</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 3: Create model instance with the correct "inputs" and "outputs" (≈1 line)</span></span><br><span class="line">    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs);</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> inference_model</span><br></pre></td></tr></table></figure>

<p>Run the cell below to define your inference model. This model is hard coded to generate 50 values.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inference_model = music_inference_model(LSTM_cell, densor, n_values = <span class="number">78</span>, n_a = <span class="number">64</span>, Ty = <span class="number">50</span>)</span><br></pre></td></tr></table></figure>

<p>Finally, this creates the zero-valued vectors you will use to initialize <code>x</code> and the LSTM state variables <code>a</code> and <code>c</code>. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_initializer = np.zeros((<span class="number">1</span>, <span class="number">1</span>, <span class="number">78</span>))</span><br><span class="line">a_initializer = np.zeros((<span class="number">1</span>, n_a))</span><br><span class="line">c_initializer = np.zeros((<span class="number">1</span>, n_a))</span><br></pre></td></tr></table></figure>

<p><strong>Exercise</strong>: Implement <code>predict_and_sample()</code>. This function takes many arguments including the inputs [x_initializer, a_initializer, c_initializer]. In order to predict the output corresponding to this input, you will need to carry-out 3 steps:</p>
<ol>
<li>Use your inference model to predict an output given your set of inputs. The output <code>pred</code> should be a list of length $T_y$ where each element is a numpy-array of shape (1, n_values).</li>
<li>Convert <code>pred</code> into a numpy array of $T_y$ indices. Each index corresponds is computed by taking the <code>argmax</code> of an element of the <code>pred</code> list. <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html" target="_blank" rel="noopener">Hint</a>.</li>
<li>Convert the indices into their one-hot vector representations. <a href="https://keras.io/utils/#to_categorical" target="_blank" rel="noopener">Hint</a>.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: predict_and_sample</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_and_sample</span><span class="params">(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, </span></span></span><br><span class="line"><span class="function"><span class="params">                       c_initializer = c_initializer)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Predicts the next value of values using the inference model.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    inference_model -- Keras model instance for inference time</span></span><br><span class="line"><span class="string">    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation</span></span><br><span class="line"><span class="string">    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell</span></span><br><span class="line"><span class="string">    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated</span></span><br><span class="line"><span class="string">    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.</span></span><br><span class="line">    pred = inference_model.predict([x_initializer, a_initializer, c_initializer]);</span><br><span class="line">    <span class="comment"># Step 2: Convert "pred" into an np.array() of indices with the maximum probabilities</span></span><br><span class="line">    indices = np.argmax(np.array(pred), axis = <span class="number">-1</span>);</span><br><span class="line">    <span class="comment"># Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )</span></span><br><span class="line">    results = to_categorical(indices, num_classes = x_initializer.shape[<span class="number">-1</span>]);</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> results, indices</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)</span><br><span class="line">print(<span class="string">"np.argmax(results[12]) ="</span>, np.argmax(results[<span class="number">12</span>]))</span><br><span class="line">print(<span class="string">"np.argmax(results[17]) ="</span>, np.argmax(results[<span class="number">17</span>]))</span><br><span class="line">print(<span class="string">"list(indices[12:18]) ="</span>, list(indices[<span class="number">12</span>:<span class="number">18</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>np.argmax(results[12]) = 21
np.argmax(results[17]) = 7
list(indices[12:18]) = [array([21]), array([10]), array([57]), array([43]), array([12]), array([7])]</code></pre><p><strong>Expected Output</strong>: Your results may differ because Keras’ results are not completely predictable. However, if you have trained your LSTM_cell with model.fit() for exactly 100 epochs as described above, you should very likely observe a sequence of indices that are not all identical. Moreover, you should observe that: np.argmax(results[12]) is the first element of list(indices[12:18]) and np.argmax(results[17]) is the last element of list(indices[12:18]). </p>
<table>
    <tr>
        <td>
            **np.argmax(results[12])** =
        </td>
        <td>
        1
        </td>
    </tr>
    <tr>
        <td>
            **np.argmax(results[12])** =
        </td>
        <td>
        42
        </td>
    </tr>
    <tr>
        <td>
            **list(indices[12:18])** =
        </td>
        <td>
            [array([1]), array([42]), array([54]), array([17]), array([1]), array([42])]
        </td>
    </tr>
</table>

<h4 id="3-3-Generate-music"><a href="#3-3-Generate-music" class="headerlink" title="3.3 - Generate music"></a>3.3 - Generate music</h4><p>Finally, you are ready to generate music. Your RNN generates a sequence of values. The following code generates music by first calling your <code>predict_and_sample()</code> function. These values are then post-processed into musical chords (meaning that multiple values or notes can be played at the same time). </p>
<p>Most computational music algorithms use some post-processing because it is difficult to generate music that sounds good without such post-processing. The post-processing does things such as clean up the generated audio by making sure the same sound is not repeated too many times, that two successive notes are not too far from each other in pitch, and so on. One could argue that a lot of these post-processing steps are hacks; also, a lot the music generation literature has also focused on hand-crafting post-processors, and a lot of the output quality depends on the quality of the post-processing and not just the quality of the RNN. But this post-processing does make a huge difference, so lets use it in our implementation as well. </p>
<p>Lets make some music! </p>
<p>Run the following cell to generate music and record it into your <code>out_stream</code>. This can take a couple of minutes.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out_stream = generate_music(inference_model)</span><br></pre></td></tr></table></figure>

<pre><code>Predicting new values for different set of chords.
Generated 51 sounds using the predicted values for the set of chords (&quot;1&quot;) and after pruning
Generated 50 sounds using the predicted values for the set of chords (&quot;2&quot;) and after pruning
Generated 50 sounds using the predicted values for the set of chords (&quot;3&quot;) and after pruning
Generated 51 sounds using the predicted values for the set of chords (&quot;4&quot;) and after pruning
Generated 51 sounds using the predicted values for the set of chords (&quot;5&quot;) and after pruning
Your generated music is saved in output/my_music.midi</code></pre><p>To listen to your music, click File-&gt;Open… Then go to “output/“ and download “my_music.midi”. Either play it on your computer with an application that can read midi files if you have one, or use one of the free online “MIDI to mp3” conversion tools to convert this to mp3.  </p>
<p>As reference, here also is a 30sec audio clip we generated using this algorithm. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IPython.display.Audio(<span class="string">'./data/30s_trained_model.mp3'</span>)</span><br></pre></td></tr></table></figure>





<pre><code>&lt;audio controls=&quot;controls&quot; &gt;</code></pre><p>y                    <source src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/Jazz_improvisation_with_LSTM/data/30s_trained_model.mp3" type="audio/mpeg" /><br>                    Your browser does not support the audio element.<br>                </audio></p>
<h3 id="Congratulations"><a href="#Congratulations" class="headerlink" title="Congratulations!"></a>Congratulations!</h3><p>You have come to the end of the notebook. </p>
<font color="blue">
Here's what you should remember:
- A sequence model can be used to generate musical values, which are then post-processed into midi music. 
- Fairly similar models can be used to generate dinosaur names or to generate music, with the major difference being the input fed to the model.  
- In Keras, sequence generation involves defining layers with shared weights, which are then repeated for the different time steps $1, \ldots, T_x$. 

<p>Congratulations on completing this assignment and generating a jazz solo! </p>
<p><strong>References</strong></p>
<p>The ideas presented in this notebook came primarily from three computational music papers cited below. The implementation here also took significant inspiration and used many components from Ji-Sung Kim’s github repository.</p>
<ul>
<li>Ji-Sung Kim, 2016, <a href="https://github.com/jisungk/deepjazz" target="_blank" rel="noopener">deepjazz</a></li>
<li>Jon Gillick, Kevin Tang and Robert Keller, 2009. <a href="http://ai.stanford.edu/~kdtang/papers/smc09-jazzgrammar.pdf" target="_blank" rel="noopener">Learning Jazz Grammars</a></li>
<li>Robert Keller and David Morrison, 2007, <a href="http://smc07.uoa.gr/SMC07%20Proceedings/SMC07%20Paper%2055.pdf" target="_blank" rel="noopener">A Grammatical Approach to Automatic Improvisation</a></li>
<li>François Pachet, 1999, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.7473&rep=rep1&type=pdf" target="_blank" rel="noopener">Surprising Harmonies</a></li>
</ul>
<p>We’re also grateful to François Germain for valuable feedback.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/06/02/Building+a+Recurrent+Neural+Network+-+Step+by+Step+-+v3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/02/Building+a+Recurrent+Neural+Network+-+Step+by+Step+-+v3/" class="post-title-link" itemprop="url">Building a Recurrent Neural Network Step by Step</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-06-02 00:00:00" itemprop="dateCreated datePublished" datetime="2018-06-02T00:00:00+05:30">2018-06-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 14:57:16" itemprop="dateModified" datetime="2020-04-09T14:57:16+05:30">2020-04-09</time>
              </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>45k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>41 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>This is one of my personal programming assignments after studying the course <a href="https://www.coursera.org/learn/nlp-sequence-models/" target="_blank" rel="noopener">nlp sequence models</a> at the 1st week and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.</p>
<h1 id="Building-your-Recurrent-Neural-Network-Step-by-Step"><a href="#Building-your-Recurrent-Neural-Network-Step-by-Step" class="headerlink" title="Building your Recurrent Neural Network - Step by Step"></a>Building your Recurrent Neural Network - Step by Step</h1><p>Welcome to Course 5’s first assignment! In this assignment, you will implement your first Recurrent Neural Network in numpy.</p>
<p>Recurrent Neural Networks (RNN) are very effective for Natural Language Processing and other sequence tasks because they have “memory”. They can read inputs $x^{\langle t \rangle}$ (such as words) one at a time, and remember some information/context through the hidden layer activations that get passed from one time-step to the next. This allows a uni-directional RNN to take information from the past to process later inputs. A bidirection RNN can take context from both the past and the future. </p>
<p><strong>Notation</strong>:</p>
<ul>
<li><p>Superscript $[l]$ denotes an object associated with the $l^{th}$ layer. </p>
<ul>
<li>Example: $a^{[4]}$ is the $4^{th}$ layer activation. $W^{[5]}$ and $b^{[5]}$ are the $5^{th}$ layer parameters.</li>
</ul>
</li>
<li><p>Superscript $(i)$ denotes an object associated with the $i^{th}$ example. </p>
<ul>
<li>Example: $x^{(i)}$ is the $i^{th}$ training example input.</li>
</ul>
</li>
<li><p>Superscript $\langle t \rangle$ denotes an object at the $t^{th}$ time-step. </p>
<ul>
<li>Example: $x^{\langle t \rangle}$ is the input x at the $t^{th}$ time-step. $x^{(i)\langle t \rangle}$ is the input at the $t^{th}$ timestep of example $i$.</li>
</ul>
</li>
<li><p>Lowerscript $i$ denotes the $i^{th}$ entry of a vector.</p>
<ul>
<li>Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the activations in layer $l$.</li>
</ul>
</li>
</ul>
<p>We assume that you are already familiar with <code>numpy</code> and/or have completed the previous courses of the specialization. Let’s get started!</p>
<p>Let’s first import all the packages that you will need during this assignment.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> rnn_utils <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure>

<h2 id="1-Forward-propagation-for-the-basic-Recurrent-Neural-Network"><a href="#1-Forward-propagation-for-the-basic-Recurrent-Neural-Network" class="headerlink" title="1 - Forward propagation for the basic Recurrent Neural Network"></a>1 - Forward propagation for the basic Recurrent Neural Network</h2><p>Later this week, you will generate music using an RNN. The basic RNN that you will implement has the structure below. In this example, $T_x = T_y$. </p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/build_rnn/images/RNN.png" style="width:500;height:300px;">
<caption><center> **Figure 1**: Basic RNN model </center></caption>

<p>Here’s how you can implement an RNN: </p>
<p><strong>Steps</strong>:</p>
<ol>
<li>Implement the calculations needed for one time-step of the RNN.</li>
<li>Implement a loop over $T_x$ time-steps in order to process all the inputs, one at a time. </li>
</ol>
<p>Let’s go!</p>
<h2 id="1-1-RNN-cell"><a href="#1-1-RNN-cell" class="headerlink" title="1.1 - RNN cell"></a>1.1 - RNN cell</h2><p>A Recurrent neural network can be seen as the repetition of a single cell. You are first going to implement the computations for a single time-step. The following figure describes the operations for a single time-step of an RNN cell. </p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/build_rnn/images/rnn_step_forward.png" style="width:700px;height:300px;">
<caption><center> **Figure 2**: Basic RNN cell. Takes as input $x^{\langle t \rangle}$ (current input) and $a^{\langle t - 1\rangle}$ (previous hidden state containing information from the past), and outputs $a^{\langle t \rangle}$ which is given to the next RNN cell and also used to predict $y^{\langle t \rangle}$ </center></caption>

<p><strong>Exercise</strong>: Implement the RNN-cell described in Figure (2).</p>
<p><strong>Instructions</strong>:</p>
<ol>
<li>Compute the hidden state with tanh activation: $a^{\langle t \rangle} = \tanh(W_{aa} a^{\langle t-1 \rangle} + W_{ax} x^{\langle t \rangle} + b_a)$.</li>
<li>Using your new hidden state $a^{\langle t \rangle}$, compute the prediction $\hat{y}^{\langle t \rangle} = softmax(W_{ya} a^{\langle t \rangle} + b_y)$. We provided you a function: <code>softmax</code>.</li>
<li>Store $(a^{\langle t \rangle}, a^{\langle t-1 \rangle}, x^{\langle t \rangle}, parameters)$ in cache</li>
<li>Return $a^{\langle t \rangle}$ , $y^{\langle t \rangle}$ and cache</li>
</ol>
<p>We will vectorize over $m$ examples. Thus, $x^{\langle t \rangle}$ will have dimension $(n_x,m)$, and $a^{\langle t \rangle}$ will have dimension $(n_a,m)$. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: rnn_cell_forward</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_cell_forward</span><span class="params">(xt, a_prev, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements a single forward step of the RNN-cell as described in Figure (2)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    xt -- your input data at timestep "t", numpy array of shape (n_x, m).</span></span><br><span class="line"><span class="string">    a_prev -- Hidden state at timestep "t-1", numpy array of shape (n_a, m)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing:</span></span><br><span class="line"><span class="string">                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)</span></span><br><span class="line"><span class="string">                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)</span></span><br><span class="line"><span class="string">                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)</span></span><br><span class="line"><span class="string">                        ba --  Bias, numpy array of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    a_next -- next hidden state, of shape (n_a, m)</span></span><br><span class="line"><span class="string">    yt_pred -- prediction at timestep "t", numpy array of shape (n_y, m)</span></span><br><span class="line"><span class="string">    cache -- tuple of values needed for the backward pass, contains (a_next, a_prev, xt, parameters)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve parameters from "parameters"</span></span><br><span class="line">    Wax = parameters[<span class="string">"Wax"</span>]</span><br><span class="line">    Waa = parameters[<span class="string">"Waa"</span>]</span><br><span class="line">    Wya = parameters[<span class="string">"Wya"</span>]</span><br><span class="line">    ba = parameters[<span class="string">"ba"</span>]</span><br><span class="line">    by = parameters[<span class="string">"by"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈2 lines)</span></span><br><span class="line">    <span class="comment"># compute next activation state using the formula given above</span></span><br><span class="line">    a_next = np.tanh(np.dot(Wax, xt) + np.dot(Waa, a_prev) + ba);</span><br><span class="line">    <span class="comment"># compute output of the current cell using the formula given above</span></span><br><span class="line">    yt_pred = softmax(np.dot(Wya, a_next) + by);</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store values you need for backward propagation in cache</span></span><br><span class="line">    cache = (a_next, a_prev, xt, parameters)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> a_next, yt_pred, cache</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">xt = np.random.randn(<span class="number">3</span>,<span class="number">10</span>)</span><br><span class="line">a_prev = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">Waa = np.random.randn(<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line">Wax = np.random.randn(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">Wya = np.random.randn(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">ba = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">by = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">parameters = &#123;<span class="string">"Waa"</span>: Waa, <span class="string">"Wax"</span>: Wax, <span class="string">"Wya"</span>: Wya, <span class="string">"ba"</span>: ba, <span class="string">"by"</span>: by&#125;</span><br><span class="line"></span><br><span class="line">a_next, yt_pred, cache = rnn_cell_forward(xt, a_prev, parameters)</span><br><span class="line">print(<span class="string">"a_next[4] = "</span>, a_next[<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"a_next.shape = "</span>, a_next.shape)</span><br><span class="line">print(<span class="string">"yt_pred[1] ="</span>, yt_pred[<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"yt_pred.shape = "</span>, yt_pred.shape)</span><br></pre></td></tr></table></figure>

<pre><code>a_next[4] =  [ 0.59584544  0.18141802  0.61311866  0.99808218  0.85016201  0.99980978
 -0.18887155  0.99815551  0.6531151   0.82872037]
a_next.shape =  (5, 10)
yt_pred[1] = [ 0.9888161   0.01682021  0.21140899  0.36817467  0.98988387  0.88945212
  0.36920224  0.9966312   0.9982559   0.17746526]
yt_pred.shape =  (2, 10)</code></pre><p><strong>Expected Output</strong>: </p>
<table>
    <tr>
        <td>
            **a_next[4]**:
        </td>
        <td>
           [ 0.59584544  0.18141802  0.61311866  0.99808218  0.85016201  0.99980978
 -0.18887155  0.99815551  0.6531151   0.82872037]
        </td>
    </tr>
        <tr>
        <td>
            **a_next.shape**:
        </td>
        <td>
           (5, 10)
        </td>
    </tr>
        <tr>
        <td>
            **yt[1]**:
        </td>
        <td>
           [ 0.9888161   0.01682021  0.21140899  0.36817467  0.98988387  0.88945212
  0.36920224  0.9966312   0.9982559   0.17746526]
        </td>
    </tr>
        <tr>
        <td>
            **yt.shape**:
        </td>
        <td>
           (2, 10)
        </td>
    </tr>
</table>

<h2 id="1-2-RNN-forward-pass"><a href="#1-2-RNN-forward-pass" class="headerlink" title="1.2 - RNN forward pass"></a>1.2 - RNN forward pass</h2><p>You can see an RNN as the repetition of the cell you’ve just built. If your input sequence of data is carried over 10 time steps, then you will copy the RNN cell 10 times. Each cell takes as input the hidden state from the previous cell ($a^{\langle t-1 \rangle}$) and the current time-step’s input data ($x^{\langle t \rangle}$). It outputs a hidden state ($a^{\langle t \rangle}$) and a prediction ($y^{\langle t \rangle}$) for this time-step.</p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/build_rnn/images/rnn%281%29.png" style="width:800px;height:300px;">
<caption><center> **Figure 3**: Basic RNN. The input sequence $x = (x^{\langle 1 \rangle}, x^{\langle 2 \rangle}, ..., x^{\langle T_x \rangle})$  is carried over $T_x$ time steps. The network outputs $y = (y^{\langle 1 \rangle}, y^{\langle 2 \rangle}, ..., y^{\langle T_x \rangle})$. </center></caption>



<p><strong>Exercise</strong>: Code the forward propagation of the RNN described in Figure (3).</p>
<p><strong>Instructions</strong>:</p>
<ol>
<li>Create a vector of zeros ($a$) that will store all the hidden states computed by the RNN.</li>
<li>Initialize the “next” hidden state as $a_0$ (initial hidden state).</li>
<li>Start looping over each time step, your incremental index is $t$ :<ul>
<li>Update the “next” hidden state and the cache by running <code>rnn_cell_forward</code></li>
<li>Store the “next” hidden state in $a$ ($t^{th}$ position) </li>
<li>Store the prediction in y</li>
<li>Add the cache to the list of caches</li>
</ul>
</li>
<li>Return $a$, $y$ and caches</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: rnn_forward</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_forward</span><span class="params">(x, a0, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the forward propagation of the recurrent neural network described in Figure (3).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    x -- Input data for every time-step, of shape (n_x, m, T_x).</span></span><br><span class="line"><span class="string">    a0 -- Initial hidden state, of shape (n_a, m)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing:</span></span><br><span class="line"><span class="string">                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)</span></span><br><span class="line"><span class="string">                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)</span></span><br><span class="line"><span class="string">                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)</span></span><br><span class="line"><span class="string">                        ba --  Bias numpy array of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    a -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x)</span></span><br><span class="line"><span class="string">    y_pred -- Predictions for every time-step, numpy array of shape (n_y, m, T_x)</span></span><br><span class="line"><span class="string">    caches -- tuple of values needed for the backward pass, contains (list of caches, x)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize "caches" which will contain the list of all caches</span></span><br><span class="line">    caches = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from shapes of x and Wy</span></span><br><span class="line">    n_x, m, T_x = x.shape</span><br><span class="line">    n_y, n_a = parameters[<span class="string">"Wya"</span>].shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize "a" and "y" with zeros (≈2 lines)</span></span><br><span class="line">    a = np.zeros((n_a, m, T_x));</span><br><span class="line">    y_pred = np.zeros((n_y, m, T_x));</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize a_next (≈1 line)</span></span><br><span class="line">    a_next = a0;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># loop over all time-steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(T_x):</span><br><span class="line">        <span class="comment"># Update next hidden state, compute the prediction, get the cache (≈1 line)</span></span><br><span class="line">        a_next, yt_pred, cache = rnn_cell_forward(x[:, :, t], a_next, parameters);</span><br><span class="line">        <span class="comment"># Save the value of the new "next" hidden state in a (≈1 line)</span></span><br><span class="line">        a[:, :, t] = a_next;</span><br><span class="line">        <span class="comment"># Save the value of the prediction in y (≈1 line)</span></span><br><span class="line">        y_pred[:, :, t] = yt_pred;</span><br><span class="line">        <span class="comment"># Append "cache" to "caches" (≈1 line)</span></span><br><span class="line">        caches.append(cache);</span><br><span class="line">        </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store values needed for backward propagation in cache</span></span><br><span class="line">    caches = (caches, x)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> a, y_pred, caches</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">x = np.random.randn(<span class="number">3</span>,<span class="number">10</span>,<span class="number">4</span>)</span><br><span class="line">a0 = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">Waa = np.random.randn(<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line">Wax = np.random.randn(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">Wya = np.random.randn(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">ba = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">by = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">parameters = &#123;<span class="string">"Waa"</span>: Waa, <span class="string">"Wax"</span>: Wax, <span class="string">"Wya"</span>: Wya, <span class="string">"ba"</span>: ba, <span class="string">"by"</span>: by&#125;</span><br><span class="line"></span><br><span class="line">a, y_pred, caches = rnn_forward(x, a0, parameters)</span><br><span class="line">print(<span class="string">"a[4][1] = "</span>, a[<span class="number">4</span>][<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"a.shape = "</span>, a.shape)</span><br><span class="line">print(<span class="string">"y_pred[1][3] ="</span>, y_pred[<span class="number">1</span>][<span class="number">3</span>])</span><br><span class="line">print(<span class="string">"y_pred.shape = "</span>, y_pred.shape)</span><br><span class="line">print(<span class="string">"caches[1][1][3] ="</span>, caches[<span class="number">1</span>][<span class="number">1</span>][<span class="number">3</span>])</span><br><span class="line">print(<span class="string">"len(caches) = "</span>, len(caches))</span><br></pre></td></tr></table></figure>

<pre><code>a[4][1] =  [-0.99999375  0.77911235 -0.99861469 -0.99833267]
a.shape =  (5, 10, 4)
y_pred[1][3] = [ 0.79560373  0.86224861  0.11118257  0.81515947]
y_pred.shape =  (2, 10, 4)
caches[1][1][3] = [-1.1425182  -0.34934272 -0.20889423  0.58662319]
len(caches) =  2</code></pre><p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **a[4][1]**:
        </td>
        <td>
           [-0.99999375  0.77911235 -0.99861469 -0.99833267]
        </td>
    </tr>
        <tr>
        <td>
            **a.shape**:
        </td>
        <td>
           (5, 10, 4)
        </td>
    </tr>
        <tr>
        <td>
            **y[1][3]**:
        </td>
        <td>
           [ 0.79560373  0.86224861  0.11118257  0.81515947]
        </td>
    </tr>
        <tr>
        <td>
            **y.shape**:
        </td>
        <td>
           (2, 10, 4)
        </td>
    </tr>
        <tr>
        <td>
            **cache[1][1][3]**:
        </td>
        <td>
           [-1.1425182  -0.34934272 -0.20889423  0.58662319]
        </td>
    </tr>
        <tr>
        <td>
            **len(cache)**:
        </td>
        <td>
           2
        </td>
    </tr>
</table>

<p>Congratulations! You’ve successfully built the forward propagation of a recurrent neural network from scratch. This will work well enough for some applications, but it suffers from vanishing gradient problems. So it works best when each output $y^{\langle t \rangle}$ can be estimated using mainly “local” context (meaning information from inputs $x^{\langle t’ \rangle}$ where $t’$ is not too far from $t$). </p>
<p>In the next part, you will build a more complex LSTM model, which is better at addressing vanishing gradients. The LSTM will be better able to remember a piece of information and keep it saved for many timesteps. </p>
<h2 id="2-Long-Short-Term-Memory-LSTM-network"><a href="#2-Long-Short-Term-Memory-LSTM-network" class="headerlink" title="2 - Long Short-Term Memory (LSTM) network"></a>2 - Long Short-Term Memory (LSTM) network</h2><p>This following figure shows the operations of an LSTM-cell.</p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/build_rnn/images/LSTM.png" style="width:500;height:400px;">
<caption><center> **Figure 4**: LSTM-cell. This tracks and updates a "cell state" or memory variable $c^{\langle t \rangle}$ at every time-step, which can be different from $a^{\langle t \rangle}$. </center></caption>

<p>Similar to the RNN example above, you will start by implementing the LSTM cell for a single time-step. Then you can iteratively call it from inside a for-loop to have it process an input with $T_x$ time-steps. </p>
<h3 id="About-the-gates"><a href="#About-the-gates" class="headerlink" title="About the gates"></a>About the gates</h3><h4 id="Forget-gate"><a href="#Forget-gate" class="headerlink" title="- Forget gate"></a>- Forget gate</h4><p>For the sake of this illustration, lets assume we are reading words in a piece of text, and want use an LSTM to keep track of grammatical structures, such as whether the subject is singular or plural. If the subject changes from a singular word to a plural word, we need to find a way to get rid of our previously stored memory value of the singular/plural state. In an LSTM, the forget gate lets us do this: </p>
<p>$$\Gamma_f^{\langle t \rangle} = \sigma(W_f[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_f)\tag{1} $$</p>
<p>Here, $W_f$ are weights that govern the forget gate’s behavior. We concatenate $[a^{\langle t-1 \rangle}, x^{\langle t \rangle}]$ and multiply by $W_f$. The equation above results in a vector $\Gamma_f^{\langle t \rangle}$ with values between 0 and 1. This forget gate vector will be multiplied element-wise by the previous cell state $c^{\langle t-1 \rangle}$. So if one of the values of $\Gamma_f^{\langle t \rangle}$ is 0 (or close to 0) then it means that the LSTM should remove that piece of information (e.g. the singular subject) in the corresponding component of $c^{\langle t-1 \rangle}$. If one of the values is 1, then it will keep the information. </p>
<h4 id="Update-gate"><a href="#Update-gate" class="headerlink" title="- Update gate"></a>- Update gate</h4><p>Once we forget that the subject being discussed is singular, we need to find a way to update it to reflect that the new subject is now plural. Here is the formulat for the update gate: </p>
<p>$$\Gamma_u^{\langle t \rangle} = \sigma(W_u[a^{\langle t-1 \rangle}, x^] + b_u)\tag{2} $$ </p>
<p>Similar to the forget gate, here $\Gamma_u^{\langle t \rangle}$ is again a vector of values between 0 and 1. This will be multiplied element-wise with $\tilde{c}^{\langle t \rangle}$, in order to compute $c^{\langle t \rangle}$.</p>
<h4 id="Updating-the-cell"><a href="#Updating-the-cell" class="headerlink" title="- Updating the cell"></a>- Updating the cell</h4><p>To update the new subject we need to create a new vector of numbers that we can add to our previous cell state. The equation we use is: </p>
<p>$$ \tilde{c}^{\langle t \rangle} = \tanh(W_c[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_c)\tag{3} $$</p>
<p>Finally, the new cell state is: </p>

$$ c^{\langle t \rangle} = \Gamma_f^{\langle t \rangle}* c^{\langle t-1 \rangle} + \Gamma_u^{\langle t \rangle} *\tilde{c}^{\langle t \rangle} \tag{4} $$



<h4 id="Output-gate"><a href="#Output-gate" class="headerlink" title="- Output gate"></a>- Output gate</h4><p>To decide which outputs we will use, we will use the following two formulas: </p>
<p>$$ \Gamma_o^{\langle t \rangle}=  \sigma(W_o[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_o)\tag{5}$$<br>$$ a^{\langle t \rangle} = \Gamma_o^{\langle t \rangle}* \tanh(c^{\langle t \rangle})\tag{6} $$</p>
<p>Where in equation 5 you decide what to output using a sigmoid function and in equation 6 you multiply that by the $\tanh$ of the previous state. </p>
<h3 id="2-1-LSTM-cell"><a href="#2-1-LSTM-cell" class="headerlink" title="2.1 - LSTM cell"></a>2.1 - LSTM cell</h3><p><strong>Exercise</strong>: Implement the LSTM cell described in the Figure (3).</p>
<p><strong>Instructions</strong>:</p>
<ol>
<li>Concatenate $a^{\langle t-1 \rangle}$ and $x^{\langle t \rangle}$ in a single matrix: $concat = \begin{bmatrix} a^{\langle t-1 \rangle} \ x^{\langle t \rangle} \end{bmatrix}$</li>
<li>Compute all the formulas 1-6. You can use <code>sigmoid()</code> (provided) and <code>np.tanh()</code>.</li>
<li>Compute the prediction $y^{\langle t \rangle}$. You can use <code>softmax()</code> (provided).</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: lstm_cell_forward</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_cell_forward</span><span class="params">(xt, a_prev, c_prev, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement a single forward step of the LSTM-cell as described in Figure (4)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    xt -- your input data at timestep "t", numpy array of shape (n_x, m).</span></span><br><span class="line"><span class="string">    a_prev -- Hidden state at timestep "t-1", numpy array of shape (n_a, m)</span></span><br><span class="line"><span class="string">    c_prev -- Memory state at timestep "t-1", numpy array of shape (n_a, m)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing:</span></span><br><span class="line"><span class="string">                        Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        bf -- Bias of the forget gate, numpy array of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        Wi -- Weight matrix of the save gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        bi -- Bias of the save gate, numpy array of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        Wc -- Weight matrix of the first "tanh", numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        bc --  Bias of the first "tanh", numpy array of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        Wo -- Weight matrix of the focus gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        bo --  Bias of the focus gate, numpy array of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)</span></span><br><span class="line"><span class="string">                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)</span></span><br><span class="line"><span class="string">                        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    a_next -- next hidden state, of shape (n_a, m)</span></span><br><span class="line"><span class="string">    c_next -- next memory state, of shape (n_a, m)</span></span><br><span class="line"><span class="string">    yt_pred -- prediction at timestep "t", numpy array of shape (n_y, m)</span></span><br><span class="line"><span class="string">    cache -- tuple of values needed for the backward pass, contains (a_next, c_next, a_prev, c_prev, xt, parameters)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Note: ft/it/ot stand for the forget/update/output gates, cct stands for the candidate value (c tilda),</span></span><br><span class="line"><span class="string">          c stands for the memory value</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve parameters from "parameters"</span></span><br><span class="line">    Wf = parameters[<span class="string">"Wf"</span>]</span><br><span class="line">    bf = parameters[<span class="string">"bf"</span>]</span><br><span class="line">    Wi = parameters[<span class="string">"Wi"</span>]</span><br><span class="line">    bi = parameters[<span class="string">"bi"</span>]</span><br><span class="line">    Wc = parameters[<span class="string">"Wc"</span>]</span><br><span class="line">    bc = parameters[<span class="string">"bc"</span>]</span><br><span class="line">    Wo = parameters[<span class="string">"Wo"</span>]</span><br><span class="line">    bo = parameters[<span class="string">"bo"</span>]</span><br><span class="line">    Wy = parameters[<span class="string">"Wy"</span>]</span><br><span class="line">    by = parameters[<span class="string">"by"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from shapes of xt and Wy</span></span><br><span class="line">    n_x, m = xt.shape</span><br><span class="line">    n_y, n_a = Wy.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Concatenate a_prev and xt (≈3 lines)</span></span><br><span class="line">    concat = np.zeros((n_a + n_x, m));</span><br><span class="line">    concat[: n_a, :] = a_prev;</span><br><span class="line">    concat[n_a :, :] = xt;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute values for ft, it, cct, c_next, ot, a_next using the formulas given figure (4) (≈6 lines)</span></span><br><span class="line">    ft = sigmoid(np.dot(Wf, concat) + bf);</span><br><span class="line">    it = sigmoid(np.dot(Wi, concat) + bi);</span><br><span class="line">    cct = np.tanh(np.dot(Wc, concat) + bc);</span><br><span class="line">    c_next = ft * c_prev + it * cct;</span><br><span class="line">    ot = sigmoid(np.dot(Wo, concat) + bo);</span><br><span class="line">    a_next = ot * np.tanh(c_next);</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute prediction of the LSTM cell (≈1 line)</span></span><br><span class="line">    yt_pred = softmax(np.dot(Wy, a_next) + by);</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># store values needed for backward propagation in cache</span></span><br><span class="line">    cache = (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> a_next, c_next, yt_pred, cache</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">xt = np.random.randn(<span class="number">3</span>,<span class="number">10</span>)</span><br><span class="line">a_prev = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">c_prev = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">Wf = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bf = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wi = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bi = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wo = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bo = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wc = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bc = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wy = np.random.randn(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">by = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">parameters = &#123;<span class="string">"Wf"</span>: Wf, <span class="string">"Wi"</span>: Wi, <span class="string">"Wo"</span>: Wo, <span class="string">"Wc"</span>: Wc, <span class="string">"Wy"</span>: Wy, <span class="string">"bf"</span>: bf, <span class="string">"bi"</span>: bi, <span class="string">"bo"</span>: bo, <span class="string">"bc"</span>: bc, <span class="string">"by"</span>: by&#125;</span><br><span class="line"></span><br><span class="line">a_next, c_next, yt, cache = lstm_cell_forward(xt, a_prev, c_prev, parameters)</span><br><span class="line">print(<span class="string">"a_next[4] = "</span>, a_next[<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"a_next.shape = "</span>, c_next.shape)</span><br><span class="line">print(<span class="string">"c_next[2] = "</span>, c_next[<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"c_next.shape = "</span>, c_next.shape)</span><br><span class="line">print(<span class="string">"yt[1] ="</span>, yt[<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"yt.shape = "</span>, yt.shape)</span><br><span class="line">print(<span class="string">"cache[1][3] ="</span>, cache[<span class="number">1</span>][<span class="number">3</span>])</span><br><span class="line">print(<span class="string">"len(cache) = "</span>, len(cache))</span><br></pre></td></tr></table></figure>

<pre><code>a_next[4] =  [-0.66408471  0.0036921   0.02088357  0.22834167 -0.85575339  0.00138482
  0.76566531  0.34631421 -0.00215674  0.43827275]
a_next.shape =  (5, 10)
c_next[2] =  [ 0.63267805  1.00570849  0.35504474  0.20690913 -1.64566718  0.11832942
  0.76449811 -0.0981561  -0.74348425 -0.26810932]
c_next.shape =  (5, 10)
yt[1] = [ 0.79913913  0.15986619  0.22412122  0.15606108  0.97057211  0.31146381
  0.00943007  0.12666353  0.39380172  0.07828381]
yt.shape =  (2, 10)
cache[1][3] = [-0.16263996  1.03729328  0.72938082 -0.54101719  0.02752074 -0.30821874
  0.07651101 -1.03752894  1.41219977 -0.37647422]
len(cache) =  10</code></pre><p><strong>Expected Output</strong> :</p>
<table>
    <tr>
        <td>
           **a_next[4]**:
        </td>
        <td>
           [-0.66408471  0.0036921   0.02088357  0.22834167 -0.85575339  0.00138482
  0.76566531  0.34631421 -0.00215674  0.43827275]
        </td>
    </tr>
        <tr>
        <td>
            **a_next.shape**:
        </td>
        <td>
           (5, 10)
        </td>
    </tr>
        <tr>
        <td>
            **c_next[2]**:
        </td>
        <td>
           [ 0.63267805  1.00570849  0.35504474  0.20690913 -1.64566718  0.11832942
  0.76449811 -0.0981561  -0.74348425 -0.26810932]
        </td>
    </tr>
        <tr>
        <td>
            **c_next.shape**:
        </td>
        <td>
           (5, 10)
        </td>
    </tr>
        <tr>
        <td>
            **yt[1]**:
        </td>
        <td>
           [ 0.79913913  0.15986619  0.22412122  0.15606108  0.97057211  0.31146381
  0.00943007  0.12666353  0.39380172  0.07828381]
        </td>
    </tr>
        <tr>
        <td>
            **yt.shape**:
        </td>
        <td>
           (2, 10)
        </td>
    </tr>
    <tr>
        <td>
            **cache[1][3]**:
        </td>
        <td>
           [-0.16263996  1.03729328  0.72938082 -0.54101719  0.02752074 -0.30821874
  0.07651101 -1.03752894  1.41219977 -0.37647422]
        </td>
    </tr>
        <tr>
        <td>
            **len(cache)**:
        </td>
        <td>
           10
        </td>
    </tr>
</table>

<h3 id="2-2-Forward-pass-for-LSTM"><a href="#2-2-Forward-pass-for-LSTM" class="headerlink" title="2.2 - Forward pass for LSTM"></a>2.2 - Forward pass for LSTM</h3><p>Now that you have implemented one step of an LSTM, you can now iterate this over this using a for-loop to process a sequence of $T_x$ inputs. </p>
<img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/build_rnn/images/LSTM_rnn.png" style="width:500;height:300px;">
<caption><center> **Figure 4**: LSTM over multiple time-steps. </center></caption>

<p><strong>Exercise:</strong> Implement <code>lstm_forward()</code> to run an LSTM over $T_x$ time-steps. </p>
<p><strong>Note</strong>: $c^{\langle 0 \rangle}$ is initialized with zeros.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: lstm_forward</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_forward</span><span class="params">(x, a0, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the forward propagation of the recurrent neural network using an LSTM-cell described in Figure (3).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    x -- Input data for every time-step, of shape (n_x, m, T_x).</span></span><br><span class="line"><span class="string">    a0 -- Initial hidden state, of shape (n_a, m)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing:</span></span><br><span class="line"><span class="string">                        Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        bf -- Bias of the forget gate, numpy array of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        Wi -- Weight matrix of the save gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        bi -- Bias of the save gate, numpy array of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        Wc -- Weight matrix of the first "tanh", numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        bc -- Bias of the first "tanh", numpy array of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        Wo -- Weight matrix of the focus gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        bo -- Bias of the focus gate, numpy array of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)</span></span><br><span class="line"><span class="string">                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)</span></span><br><span class="line"><span class="string">                        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    a -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x)</span></span><br><span class="line"><span class="string">    y -- Predictions for every time-step, numpy array of shape (n_y, m, T_x)</span></span><br><span class="line"><span class="string">    caches -- tuple of values needed for the backward pass, contains (list of all the caches, x)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize "caches", which will track the list of all the caches</span></span><br><span class="line">    caches = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from shapes of xt and Wy (≈2 lines)</span></span><br><span class="line">    n_x, m, T_x = x.shape;</span><br><span class="line">    n_y, n_a = parameters[<span class="string">'Wy'</span>].shape;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize "a", "c" and "y" with zeros (≈3 lines)</span></span><br><span class="line">    a = np.zeros((n_a, m, T_x));</span><br><span class="line">    c = np.zeros((n_a, m, T_x));</span><br><span class="line">    y = np.zeros((n_y, m, T_x));</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize a_next and c_next (≈2 lines)</span></span><br><span class="line">    a_next = a0;</span><br><span class="line">    c_next = np.zeros((n_a, m));</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># loop over all time-steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(T_x):</span><br><span class="line">        <span class="comment"># Update next hidden state, next memory state, compute the prediction, get the cache (≈1 line)</span></span><br><span class="line">        a_next, c_next, yt_pred, cache = lstm_cell_forward(x[:, :, t], a_next, c_next, parameters);</span><br><span class="line">        <span class="comment"># Save the value of the new "next" hidden state in a (≈1 line)</span></span><br><span class="line">        a[:, :, t] = a_next;</span><br><span class="line">        <span class="comment"># Save the value of the prediction in y (≈1 line)</span></span><br><span class="line">        y[:, :, t] = yt_pred;</span><br><span class="line">        <span class="comment"># Save the value of the next cell state (≈1 line)</span></span><br><span class="line">        c[:, :, t] = c_next;</span><br><span class="line">        <span class="comment"># Append the cache into caches (≈1 line)</span></span><br><span class="line">        caches.append(cache);</span><br><span class="line">        </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store values needed for backward propagation in cache</span></span><br><span class="line">    caches = (caches, x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> a, y, c, caches</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">x = np.random.randn(<span class="number">3</span>,<span class="number">10</span>,<span class="number">7</span>)</span><br><span class="line">a0 = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">Wf = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bf = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wi = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bi = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wo = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bo = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wc = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bc = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wy = np.random.randn(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">by = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">parameters = &#123;<span class="string">"Wf"</span>: Wf, <span class="string">"Wi"</span>: Wi, <span class="string">"Wo"</span>: Wo, <span class="string">"Wc"</span>: Wc, <span class="string">"Wy"</span>: Wy, <span class="string">"bf"</span>: bf, <span class="string">"bi"</span>: bi, <span class="string">"bo"</span>: bo, <span class="string">"bc"</span>: bc, <span class="string">"by"</span>: by&#125;</span><br><span class="line"></span><br><span class="line">a, y, c, caches = lstm_forward(x, a0, parameters)</span><br><span class="line">print(<span class="string">"a[4][3][6] = "</span>, a[<span class="number">4</span>][<span class="number">3</span>][<span class="number">6</span>])</span><br><span class="line">print(<span class="string">"a.shape = "</span>, a.shape)</span><br><span class="line">print(<span class="string">"y[1][4][3] ="</span>, y[<span class="number">1</span>][<span class="number">4</span>][<span class="number">3</span>])</span><br><span class="line">print(<span class="string">"y.shape = "</span>, y.shape)</span><br><span class="line">print(<span class="string">"caches[1][1[1]] ="</span>, caches[<span class="number">1</span>][<span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"c[1][2][1]"</span>, c[<span class="number">1</span>][<span class="number">2</span>][<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"len(caches) = "</span>, len(caches))</span><br></pre></td></tr></table></figure>

<pre><code>a[4][3][6] =  0.172117767533
a.shape =  (5, 10, 7)
y[1][4][3] = 0.95087346185
y.shape =  (2, 10, 7)
caches[1][1[1]] = [ 0.82797464  0.23009474  0.76201118 -0.22232814 -0.20075807  0.18656139
  0.41005165]
c[1][2][1] -0.855544916718
len(caches) =  2</code></pre><p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **a[4][3][6]** =
        </td>
        <td>
           0.172117767533
        </td>
    </tr>
        <tr>
        <td>
            **a.shape** =
        </td>
        <td>
           (5, 10, 7)
        </td>
    </tr>
        <tr>
        <td>
            **y[1][4][3]** =
        </td>
        <td>
           0.95087346185
        </td>
    </tr>
        <tr>
        <td>
            **y.shape** =
        </td>
        <td>
           (2, 10, 7)
        </td>
    </tr>
        <tr>
        <td>
            **caches[1][1][1]** =
        </td>
        <td>
           [ 0.82797464  0.23009474  0.76201118 -0.22232814 -0.20075807  0.18656139
  0.41005165]
        </td>
     </tr>
        <tr>
        <td>
            **c[1][2][1]** =
        </td>
        <td>
           -0.855544916718
        </td>
    </tr>       
    </tr>
        <tr>
        <td>
            **len(caches)** =
        </td>
        <td>
           2
        </td>
    </tr>
</table>

<p>Congratulations! You have now implemented the forward passes for the basic RNN and the LSTM. When using a deep learning framework, implementing the forward pass is sufficient to build systems that achieve great performance. </p>
<p>The rest of this notebook is optional, and will not be graded.</p>
<h2 id="3-Backpropagation-in-recurrent-neural-networks-OPTIONAL-UNGRADED"><a href="#3-Backpropagation-in-recurrent-neural-networks-OPTIONAL-UNGRADED" class="headerlink" title="3 - Backpropagation in recurrent neural networks (OPTIONAL / UNGRADED)"></a>3 - Backpropagation in recurrent neural networks (OPTIONAL / UNGRADED)</h2><p>In modern deep learning frameworks, you only have to implement the forward pass, and the framework takes care of the backward pass, so most deep learning engineers do not need to bother with the details of the backward pass. If however you are an expert in calculus and want to see the details of backprop in RNNs, you can work through this optional portion of the notebook. </p>
<p>When in an earlier course you implemented a simple (fully connected) neural network, you used backpropagation to compute the derivatives with respect to the cost to update the parameters. Similarly, in recurrent neural networks you can to calculate the derivatives with respect to the cost in order to update the parameters. The backprop equations are quite complicated and we did not derive them in lecture. However, we will briefly present them below. </p>
<h3 id="3-1-Basic-RNN-backward-pass"><a href="#3-1-Basic-RNN-backward-pass" class="headerlink" title="3.1 - Basic RNN  backward pass"></a>3.1 - Basic RNN  backward pass</h3><p>We will start by computing the backward pass for the basic RNN-cell.</p>
<p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/nlp-sequence-models/jupter/week1/build_rnn/images/rnn_cell_backprop.png" style="width:500;height:300px;"> <br></p>
<caption><center> **Figure 5**: RNN-cell's backward pass. Just like in a fully-connected neural network, the derivative of the cost function $J$ backpropagates through the RNN by following the chain-rule from calculas. The chain-rule is also used to calculate $(\frac{\partial J}{\partial W_{ax}},\frac{\partial J}{\partial W_{aa}},\frac{\partial J}{\partial b})$ to update the parameters $(W_{ax}, W_{aa}, b_a)$. </center></caption>

<h4 id="Deriving-the-one-step-backward-functions"><a href="#Deriving-the-one-step-backward-functions" class="headerlink" title="Deriving the one step backward functions:"></a>Deriving the one step backward functions:</h4><p>To compute the <code>rnn_cell_backward</code> you need to compute the following equations. It is a good exercise to derive them by hand. </p>
<p>The derivative of $\tanh$ is $1-\tanh(x)^2$. You can find the complete proof <a href="https://www.wyzant.com/resources/lessons/math/calculus/derivative_proofs/tanx" target="_blank" rel="noopener">here</a>. Note that: $ \text{sech}(x)^2 = 1 - \tanh(x)^2$</p>
<p>Similarly for $\frac{ \partial a^{\langle t \rangle} } {\partial W_{ax}}, \frac{ \partial a^{\langle t \rangle} } {\partial W_{aa}},  \frac{ \partial a^{\langle t \rangle} } {\partial b}$, the derivative of  $\tanh(u)$ is $(1-\tanh(u)^2)du$. </p>
<p>The final two equations also follow same rule and are derived using the $\tanh$ derivative. Note that the arrangement is done in a way to get the same dimensions to match.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_cell_backward</span><span class="params">(da_next, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the backward pass for the RNN-cell (single time-step).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    da_next -- Gradient of loss with respect to next hidden state</span></span><br><span class="line"><span class="string">    cache -- python dictionary containing useful values (output of rnn_step_forward())</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    gradients -- python dictionary containing:</span></span><br><span class="line"><span class="string">                        dx -- Gradients of input data, of shape (n_x, m)</span></span><br><span class="line"><span class="string">                        da_prev -- Gradients of previous hidden state, of shape (n_a, m)</span></span><br><span class="line"><span class="string">                        dWax -- Gradients of input-to-hidden weights, of shape (n_a, n_x)</span></span><br><span class="line"><span class="string">                        dWaa -- Gradients of hidden-to-hidden weights, of shape (n_a, n_a)</span></span><br><span class="line"><span class="string">                        dba -- Gradients of bias vector, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve values from cache</span></span><br><span class="line">    (a_next, a_prev, xt, parameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve values from parameters</span></span><br><span class="line">    Wax = parameters[<span class="string">"Wax"</span>]</span><br><span class="line">    Waa = parameters[<span class="string">"Waa"</span>]</span><br><span class="line">    Wya = parameters[<span class="string">"Wya"</span>]</span><br><span class="line">    ba = parameters[<span class="string">"ba"</span>]</span><br><span class="line">    by = parameters[<span class="string">"by"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># compute the gradient of tanh with respect to a_next (≈1 line)</span></span><br><span class="line">    dtanh = (<span class="number">1</span> - a_next * a_next) * da_next;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the gradient of the loss with respect to Wax (≈2 lines)</span></span><br><span class="line">    dWax = np.dot(dtanh, xt.T);</span><br><span class="line">    dxt = np.dot(Wax.T, dtanh);</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute the gradient with respect to Waa (≈2 lines)</span></span><br><span class="line">    dWaa = np.dot(dtanh, a_prev.T);</span><br><span class="line">    da_prev = np.dot(Waa.T, dtanh);</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># compute the gradient with respect to b (≈1 line)</span></span><br><span class="line">    dba = np.sum(dtanh, keepdims = <span class="literal">True</span>, axis = <span class="number">-1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Store the gradients in a python dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dxt"</span>: dxt, <span class="string">"da_prev"</span>: da_prev, <span class="string">"dWax"</span>: dWax, <span class="string">"dWaa"</span>: dWaa, <span class="string">"dba"</span>: dba&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">xt = np.random.randn(<span class="number">3</span>,<span class="number">10</span>)</span><br><span class="line">a_prev = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">Wax = np.random.randn(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">Waa = np.random.randn(<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line">Wya = np.random.randn(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">b = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">by = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">parameters = &#123;<span class="string">"Wax"</span>: Wax, <span class="string">"Waa"</span>: Waa, <span class="string">"Wya"</span>: Wya, <span class="string">"ba"</span>: ba, <span class="string">"by"</span>: by&#125;</span><br><span class="line"></span><br><span class="line">a_next, yt, cache = rnn_cell_forward(xt, a_prev, parameters)</span><br><span class="line"></span><br><span class="line">da_next = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">gradients = rnn_cell_backward(da_next, cache)</span><br><span class="line">print(<span class="string">"gradients[\"dxt\"][1][2] ="</span>, gradients[<span class="string">"dxt"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dxt\"].shape ="</span>, gradients[<span class="string">"dxt"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"da_prev\"][2][3] ="</span>, gradients[<span class="string">"da_prev"</span>][<span class="number">2</span>][<span class="number">3</span>])</span><br><span class="line">print(<span class="string">"gradients[\"da_prev\"].shape ="</span>, gradients[<span class="string">"da_prev"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWax\"][3][1] ="</span>, gradients[<span class="string">"dWax"</span>][<span class="number">3</span>][<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWax\"].shape ="</span>, gradients[<span class="string">"dWax"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWaa\"][1][2] ="</span>, gradients[<span class="string">"dWaa"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWaa\"].shape ="</span>, gradients[<span class="string">"dWaa"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dba\"][4] ="</span>, gradients[<span class="string">"dba"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dba\"].shape ="</span>, gradients[<span class="string">"dba"</span>].shape)</span><br></pre></td></tr></table></figure>

<pre><code>gradients[&quot;dxt&quot;][1][2] = -0.460564103059
gradients[&quot;dxt&quot;].shape = (3, 10)
gradients[&quot;da_prev&quot;][2][3] = 0.0842968653807
gradients[&quot;da_prev&quot;].shape = (5, 10)
gradients[&quot;dWax&quot;][3][1] = 0.393081873922
gradients[&quot;dWax&quot;].shape = (5, 3)
gradients[&quot;dWaa&quot;][1][2] = -0.28483955787
gradients[&quot;dWaa&quot;].shape = (5, 5)
gradients[&quot;dba&quot;][4] = [ 0.80517166]
gradients[&quot;dba&quot;].shape = (5, 1)</code></pre><p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **gradients["dxt"][1][2]** =
        </td>
        <td>
           -0.460564103059
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dxt"].shape** =
        </td>
        <td>
           (3, 10)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["da_prev"][2][3]** =
        </td>
        <td>
           0.0842968653807
        </td>
    </tr>
        <tr>
        <td>
            **gradients["da_prev"].shape** =
        </td>
        <td>
           (5, 10)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWax"][3][1]** =
        </td>
        <td>
           0.393081873922
        </td>
    </tr>
            <tr>
        <td>
            **gradients["dWax"].shape** =
        </td>
        <td>
           (5, 3)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWaa"][1][2]** = 
        </td>
        <td>
           -0.28483955787
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWaa"].shape** =
        </td>
        <td>
           (5, 5)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dba"][4]** = 
        </td>
        <td>
           [ 0.80517166]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dba"].shape** = 
        </td>
        <td>
           (5, 1)
        </td>
    </tr>
</table>

<h4 id="Backward-pass-through-the-RNN"><a href="#Backward-pass-through-the-RNN" class="headerlink" title="Backward pass through the RNN"></a>Backward pass through the RNN</h4><p>Computing the gradients of the cost with respect to $a^{\langle t \rangle}$ at every time-step $t$ is useful because it is what helps the gradient backpropagate to the previous RNN-cell. To do so, you need to iterate through all the time steps starting at the end, and at each step, you increment the overall $db_a$, $dW_{aa}$, $dW_{ax}$ and you store $dx$.</p>
<p><strong>Instructions</strong>:</p>
<p>Implement the <code>rnn_backward</code> function. Initialize the return variables with zeros first and then loop through all the time steps while calling the <code>rnn_cell_backward</code> at each time timestep, update the other variables accordingly.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_backward</span><span class="params">(da, caches)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward pass for a RNN over an entire sequence of input data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    da -- Upstream gradients of all hidden states, of shape (n_a, m, T_x)</span></span><br><span class="line"><span class="string">    caches -- tuple containing information from the forward pass (rnn_forward)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    gradients -- python dictionary containing:</span></span><br><span class="line"><span class="string">                        dx -- Gradient w.r.t. the input data, numpy-array of shape (n_x, m, T_x)</span></span><br><span class="line"><span class="string">                        da0 -- Gradient w.r.t the initial hidden state, numpy-array of shape (n_a, m)</span></span><br><span class="line"><span class="string">                        dWax -- Gradient w.r.t the input's weight matrix, numpy-array of shape (n_a, n_x)</span></span><br><span class="line"><span class="string">                        dWaa -- Gradient w.r.t the hidden state's weight matrix, numpy-arrayof shape (n_a, n_a)</span></span><br><span class="line"><span class="string">                        dba -- Gradient w.r.t the bias, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve values from the first cache (t=1) of caches (≈2 lines)</span></span><br><span class="line">    caches, x = caches;</span><br><span class="line">    a1, a0, x1, parameters = caches[<span class="number">0</span>];</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from da's and x1's shapes (≈2 lines)</span></span><br><span class="line">    n_a, m, T_x = da.shape;</span><br><span class="line">    n_x, m = x1.shape;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize the gradients with the right sizes (≈6 lines)</span></span><br><span class="line">    dx = np.zeros((n_x, m, T_x));</span><br><span class="line">    dWax = np.zeros((parameters[<span class="string">'Wax'</span>].shape));</span><br><span class="line">    dWaa = np.zeros((parameters[<span class="string">'Waa'</span>].shape));</span><br><span class="line">    dba = np.zeros((parameters[<span class="string">'ba'</span>].shape));</span><br><span class="line">    da0 = np.zeros(a0.shape);</span><br><span class="line">    da_prevt = np.zeros((n_a, m));</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop through all the time steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(T_x)):</span><br><span class="line">        <span class="comment"># Compute gradients at time step t. Choose wisely the "da_next" and the "cache" to use in the backward propagation step. (≈1 line)</span></span><br><span class="line">        gradients = rnn_cell_backward(da[:, :, t] + da_prevt, caches[t]);</span><br><span class="line">        <span class="comment"># Retrieve derivatives from gradients (≈ 1 line)</span></span><br><span class="line">        dxt, da_prevt, dWaxt, dWaat, dbat = gradients[<span class="string">'dxt'</span>], gradients[<span class="string">'da_prev'</span>], gradients[<span class="string">'dWax'</span>], gradients[<span class="string">'dWaa'</span>], gradients[<span class="string">'dba'</span>];</span><br><span class="line">        <span class="comment"># Increment global derivatives w.r.t parameters by adding their derivative at time-step t (≈4 lines)</span></span><br><span class="line">        dWax += dWaxt;</span><br><span class="line">        dWaa += dWaat;</span><br><span class="line">        dba += dbat;</span><br><span class="line">        dx[:, :, t] = dxt;</span><br><span class="line">    <span class="comment"># Set da0 to the gradient of a which has been backpropagated through all time-steps (≈1 line) </span></span><br><span class="line">    da0 = da_prevt;</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the gradients in a python dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dx"</span>: dx, <span class="string">"da0"</span>: da0, <span class="string">"dWax"</span>: dWax, <span class="string">"dWaa"</span>: dWaa,<span class="string">"dba"</span>: dba&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">x = np.random.randn(<span class="number">3</span>,<span class="number">10</span>,<span class="number">4</span>)</span><br><span class="line">a0 = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">Wax = np.random.randn(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">Waa = np.random.randn(<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line">Wya = np.random.randn(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">ba = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">by = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">parameters = &#123;<span class="string">"Wax"</span>: Wax, <span class="string">"Waa"</span>: Waa, <span class="string">"Wya"</span>: Wya, <span class="string">"ba"</span>: ba, <span class="string">"by"</span>: by&#125;</span><br><span class="line">a, y, caches = rnn_forward(x, a0, parameters)</span><br><span class="line">da = np.random.randn(<span class="number">5</span>, <span class="number">10</span>, <span class="number">4</span>)</span><br><span class="line">gradients = rnn_backward(da, caches)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"gradients[\"dx\"][1][2] ="</span>, gradients[<span class="string">"dx"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dx\"].shape ="</span>, gradients[<span class="string">"dx"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"da0\"][2][3] ="</span>, gradients[<span class="string">"da0"</span>][<span class="number">2</span>][<span class="number">3</span>])</span><br><span class="line">print(<span class="string">"gradients[\"da0\"].shape ="</span>, gradients[<span class="string">"da0"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWax\"][3][1] ="</span>, gradients[<span class="string">"dWax"</span>][<span class="number">3</span>][<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWax\"].shape ="</span>, gradients[<span class="string">"dWax"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWaa\"][1][2] ="</span>, gradients[<span class="string">"dWaa"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWaa\"].shape ="</span>, gradients[<span class="string">"dWaa"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dba\"][4] ="</span>, gradients[<span class="string">"dba"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dba\"].shape ="</span>, gradients[<span class="string">"dba"</span>].shape)</span><br></pre></td></tr></table></figure>

<pre><code>gradients[&quot;dx&quot;][1][2] = [-2.07101689 -0.59255627  0.02466855  0.01483317]
gradients[&quot;dx&quot;].shape = (3, 10, 4)
gradients[&quot;da0&quot;][2][3] = -0.314942375127
gradients[&quot;da0&quot;].shape = (5, 10)
gradients[&quot;dWax&quot;][3][1] = 11.2641044965
gradients[&quot;dWax&quot;].shape = (5, 3)
gradients[&quot;dWaa&quot;][1][2] = 2.30333312658
gradients[&quot;dWaa&quot;].shape = (5, 5)
gradients[&quot;dba&quot;][4] = [-0.74747722]
gradients[&quot;dba&quot;].shape = (5, 1)</code></pre><p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **gradients["dx"][1][2]** =
        </td>
        <td>
           [-2.07101689 -0.59255627  0.02466855  0.01483317]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dx"].shape** =
        </td>
        <td>
           (3, 10, 4)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["da0"][2][3]** =
        </td>
        <td>
           -0.314942375127
        </td>
    </tr>
        <tr>
        <td>
            **gradients["da0"].shape** =
        </td>
        <td>
           (5, 10)
        </td>
    </tr>
         <tr>
        <td>
            **gradients["dWax"][3][1]** =
        </td>
        <td>
           11.2641044965
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWax"].shape** =
        </td>
        <td>
           (5, 3)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWaa"][1][2]** = 
        </td>
        <td>
           2.30333312658
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWaa"].shape** =
        </td>
        <td>
           (5, 5)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dba"][4]** = 
        </td>
        <td>
           [-0.74747722]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dba"].shape** = 
        </td>
        <td>
           (5, 1)
        </td>
    </tr>
</table>

<h2 id="3-2-LSTM-backward-pass"><a href="#3-2-LSTM-backward-pass" class="headerlink" title="3.2 - LSTM backward pass"></a>3.2 - LSTM backward pass</h2><h3 id="3-2-1-One-Step-backward"><a href="#3-2-1-One-Step-backward" class="headerlink" title="3.2.1 One Step backward"></a>3.2.1 One Step backward</h3><p>The LSTM backward pass is slighltly more complicated than the forward one. We have provided you with all the equations for the LSTM backward pass below. (If you enjoy calculus exercises feel free to try deriving these from scratch yourself.) </p>
<h3 id="3-2-2-gate-derivatives"><a href="#3-2-2-gate-derivatives" class="headerlink" title="3.2.2 gate derivatives"></a>3.2.2 gate derivatives</h3>
$$d \Gamma_o^{\langle t \rangle} = da_{next}*\tanh(c_{next}) * \Gamma_o^{\langle t \rangle}*(1-\Gamma_o^{\langle t \rangle})\tag{7}$$

$$d\tilde c^{\langle t \rangle} = dc_{next}*\Gamma_u^{\langle t \rangle}+ \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) * i_t * da_{next} * \tilde c^{\langle t \rangle} * (1-\tanh(\tilde c)^2) \tag{8}$$

$$d\Gamma_u^{\langle t \rangle} = dc_{next}*\tilde c^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) * \tilde c^{\langle t \rangle} * da_{next}*\Gamma_u^{\langle t \rangle}*(1-\Gamma_u^{\langle t \rangle})\tag{9}$$

$$d\Gamma_f^{\langle t \rangle} = dc_{next}*\tilde c_{prev} + \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) * c_{prev} * da_{next}*\Gamma_f^{\langle t \rangle}*(1-\Gamma_f^{\langle t \rangle})\tag{10}$$


<h3 id="3-2-3-parameter-derivatives"><a href="#3-2-3-parameter-derivatives" class="headerlink" title="3.2.3 parameter derivatives"></a>3.2.3 parameter derivatives</h3>
$$ dW_f = d\Gamma_f^{\langle t \rangle} * \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{11} $$
$$ dW_u = d\Gamma_u^{\langle t \rangle} * \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{12} $$
$$ dW_c = d\tilde c^{\langle t \rangle} * \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{13} $$
$$ dW_o = d\Gamma_o^{\langle t \rangle} * \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{14}$$


To calculate $db_f, db_u, db_c, db_o$ you just need to sum across the horizontal (axis= 1) axis on $d\Gamma_f^{\langle t \rangle}, d\Gamma_u^{\langle t \rangle}, d\tilde c^{\langle t \rangle}, d\Gamma_o^{\langle t \rangle}$ respectively. Note that you should have the `keep_dims = True` option.

Finally, you will compute the derivative with respect to the previous hidden state, previous memory state, and input.


$$ da_{prev} = W_f^T*d\Gamma_f^{\langle t \rangle} + W_u^T * d\Gamma_u^{\langle t \rangle}+ W_c^T * d\tilde c^{\langle t \rangle} + W_o^T * d\Gamma_o^{\langle t \rangle} \tag{15}$$
Here, the weights for equations 13 are the first n_a, (i.e. $W_f = W_f[:n_a,:]$ etc...)

$$ dc_{prev} = dc_{next}\Gamma_f^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} * (1- \tanh(c_{next})^2)*\Gamma_f^{\langle t \rangle}*da_{next} \tag{16}$$
$$ dx^{\langle t \rangle} = W_f^T*d\Gamma_f^{\langle t \rangle} + W_u^T * d\Gamma_u^{\langle t \rangle}+ W_c^T * d\tilde c_t + W_o^T * d\Gamma_o^{\langle t \rangle}\tag{17} $$
where the weights for equation 15 are from n_a to the end, (i.e. $W_f = W_f[n_a:,:]$ etc...)

**Exercise:** Implement `lstm_cell_backward` by implementing equations $7-17$ below. Good luck! :)


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_cell_backward</span><span class="params">(da_next, dc_next, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward pass for the LSTM-cell (single time-step).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    da_next -- Gradients of next hidden state, of shape (n_a, m)</span></span><br><span class="line"><span class="string">    dc_next -- Gradients of next cell state, of shape (n_a, m)</span></span><br><span class="line"><span class="string">    cache -- cache storing information from the forward pass</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    gradients -- python dictionary containing:</span></span><br><span class="line"><span class="string">                        dxt -- Gradient of input data at time-step t, of shape (n_x, m)</span></span><br><span class="line"><span class="string">                        da_prev -- Gradient w.r.t. the previous hidden state, numpy array of shape (n_a, m)</span></span><br><span class="line"><span class="string">                        dc_prev -- Gradient w.r.t. the previous memory state, of shape (n_a, m, T_x)</span></span><br><span class="line"><span class="string">                        dWf -- Gradient w.r.t. the weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        dWi -- Gradient w.r.t. the weight matrix of the input gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        dWc -- Gradient w.r.t. the weight matrix of the memory gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        dWo -- Gradient w.r.t. the weight matrix of the save gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        dbf -- Gradient w.r.t. biases of the forget gate, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        dbi -- Gradient w.r.t. biases of the update gate, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        dbc -- Gradient w.r.t. biases of the memory gate, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        dbo -- Gradient w.r.t. biases of the save gate, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve information from "cache"</span></span><br><span class="line">    (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    n_a, m = a_next.shape;</span><br><span class="line">    n_x, m = xt.shape;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute gates related derivatives, you can find their values can be found by looking carefully at equations (7) to (10) (≈4 lines)</span></span><br><span class="line">    dot = da_next * np.tanh(c_next) * ot * (<span class="number">1</span> - ot);</span><br><span class="line">    dcct = (dc_next * it + ot * (<span class="number">1</span> - np.tanh(c_next) ** <span class="number">2</span>) * it * da_next) * (<span class="number">1</span> - cct ** <span class="number">2</span>);</span><br><span class="line">    dit = (dc_next * cct + ot * (<span class="number">1</span> - np.tanh(c_next) ** <span class="number">2</span>) * cct * da_next) * it * (<span class="number">1</span> - it);</span><br><span class="line">    dft = (dc_next * c_prev + ot * (<span class="number">1</span> - np.tanh(c_next) ** <span class="number">2</span>) * c_prev * da_next) * ft * (<span class="number">1</span> - ft);</span><br><span class="line">    <span class="comment">## Code equations (7) to (10) (≈4 lines)</span></span><br><span class="line">    <span class="comment">##dit = None</span></span><br><span class="line">    <span class="comment">##dft = None</span></span><br><span class="line">    <span class="comment">##dot = None</span></span><br><span class="line">    <span class="comment">##dcct = None</span></span><br><span class="line">    <span class="comment">##</span></span><br><span class="line">    <span class="comment"># Compute parameters related derivatives. Use equations (11)-(14) (≈8 lines)</span></span><br><span class="line">    concat = np.concatenate((a_prev, xt), axis = <span class="number">0</span>).T;</span><br><span class="line">    dWf = np.dot(dft, concat);</span><br><span class="line">    dWi = np.dot(dit, concat);</span><br><span class="line">    dWc = np.dot(dcct, concat);</span><br><span class="line">    dWo = np.dot(dot, concat);</span><br><span class="line">    dbf = np.sum(dft, keepdims = <span class="literal">True</span>, axis = <span class="number">-1</span>);</span><br><span class="line">    dbi = np.sum(dit, keepdims = <span class="literal">True</span>, axis = <span class="number">-1</span>);</span><br><span class="line">    dbc = np.sum(dcct, keepdims = <span class="literal">True</span>, axis = <span class="number">-1</span>);</span><br><span class="line">    dbo = np.sum(dot, keepdims = <span class="literal">True</span>, axis = <span class="number">-1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute derivatives w.r.t previous hidden state, previous memory state and input. Use equations (15)-(17). (≈3 lines)</span></span><br><span class="line">    da_prev = np.dot(parameters[<span class="string">'Wf'</span>][:, : n_a].T, dft) + np.dot(parameters[<span class="string">'Wi'</span>][:, : n_a].T, dit) + np.dot(parameters[<span class="string">'Wc'</span>][:, : n_a].T, dcct) + np.dot(parameters[<span class="string">'Wo'</span>][:, : n_a].T, dot);</span><br><span class="line">    dc_prev = dc_next * ft + ot * (<span class="number">1</span> - np.tanh(c_next) ** <span class="number">2</span>) * ft * da_next;</span><br><span class="line">    dxt = np.dot(parameters[<span class="string">'Wf'</span>][:, n_a :].T, dft) + np.dot(parameters[<span class="string">'Wi'</span>][:, n_a :].T, dit) + np.dot(parameters[<span class="string">'Wc'</span>][:, n_a :].T, dcct) + np.dot(parameters[<span class="string">'Wo'</span>][:, n_a :].T, dot);</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Save gradients in dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dxt"</span>: dxt, <span class="string">"da_prev"</span>: da_prev, <span class="string">"dc_prev"</span>: dc_prev, <span class="string">"dWf"</span>: dWf,<span class="string">"dbf"</span>: dbf, <span class="string">"dWi"</span>: dWi,<span class="string">"dbi"</span>: dbi,</span><br><span class="line">                <span class="string">"dWc"</span>: dWc,<span class="string">"dbc"</span>: dbc, <span class="string">"dWo"</span>: dWo,<span class="string">"dbo"</span>: dbo&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">xt = np.random.randn(<span class="number">3</span>,<span class="number">10</span>)</span><br><span class="line">a_prev = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">c_prev = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">Wf = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bf = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wi = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bi = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wo = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bo = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wc = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bc = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wy = np.random.randn(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">by = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">parameters = &#123;<span class="string">"Wf"</span>: Wf, <span class="string">"Wi"</span>: Wi, <span class="string">"Wo"</span>: Wo, <span class="string">"Wc"</span>: Wc, <span class="string">"Wy"</span>: Wy, <span class="string">"bf"</span>: bf, <span class="string">"bi"</span>: bi, <span class="string">"bo"</span>: bo, <span class="string">"bc"</span>: bc, <span class="string">"by"</span>: by&#125;</span><br><span class="line"></span><br><span class="line">a_next, c_next, yt, cache = lstm_cell_forward(xt, a_prev, c_prev, parameters)</span><br><span class="line"></span><br><span class="line">da_next = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">dc_next = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">gradients = lstm_cell_backward(da_next, dc_next, cache)</span><br><span class="line">print(<span class="string">"gradients[\"dxt\"][1][2] ="</span>, gradients[<span class="string">"dxt"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dxt\"].shape ="</span>, gradients[<span class="string">"dxt"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"da_prev\"][2][3] ="</span>, gradients[<span class="string">"da_prev"</span>][<span class="number">2</span>][<span class="number">3</span>])</span><br><span class="line">print(<span class="string">"gradients[\"da_prev\"].shape ="</span>, gradients[<span class="string">"da_prev"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dc_prev\"][2][3] ="</span>, gradients[<span class="string">"dc_prev"</span>][<span class="number">2</span>][<span class="number">3</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dc_prev\"].shape ="</span>, gradients[<span class="string">"dc_prev"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWf\"][3][1] ="</span>, gradients[<span class="string">"dWf"</span>][<span class="number">3</span>][<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWf\"].shape ="</span>, gradients[<span class="string">"dWf"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWi\"][1][2] ="</span>, gradients[<span class="string">"dWi"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWi\"].shape ="</span>, gradients[<span class="string">"dWi"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWc\"][3][1] ="</span>, gradients[<span class="string">"dWc"</span>][<span class="number">3</span>][<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWc\"].shape ="</span>, gradients[<span class="string">"dWc"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWo\"][1][2] ="</span>, gradients[<span class="string">"dWo"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWo\"].shape ="</span>, gradients[<span class="string">"dWo"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dbf\"][4] ="</span>, gradients[<span class="string">"dbf"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dbf\"].shape ="</span>, gradients[<span class="string">"dbf"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dbi\"][4] ="</span>, gradients[<span class="string">"dbi"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dbi\"].shape ="</span>, gradients[<span class="string">"dbi"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dbc\"][4] ="</span>, gradients[<span class="string">"dbc"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dbc\"].shape ="</span>, gradients[<span class="string">"dbc"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dbo\"][4] ="</span>, gradients[<span class="string">"dbo"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dbo\"].shape ="</span>, gradients[<span class="string">"dbo"</span>].shape)</span><br></pre></td></tr></table></figure>

<pre><code>gradients[&quot;dxt&quot;][1][2] = 3.23055911511
gradients[&quot;dxt&quot;].shape = (3, 10)
gradients[&quot;da_prev&quot;][2][3] = -0.0639621419711
gradients[&quot;da_prev&quot;].shape = (5, 10)
gradients[&quot;dc_prev&quot;][2][3] = 0.797522038797
gradients[&quot;dc_prev&quot;].shape = (5, 10)
gradients[&quot;dWf&quot;][3][1] = -0.147954838164
gradients[&quot;dWf&quot;].shape = (5, 8)
gradients[&quot;dWi&quot;][1][2] = 1.05749805523
gradients[&quot;dWi&quot;].shape = (5, 8)
gradients[&quot;dWc&quot;][3][1] = 2.30456216369
gradients[&quot;dWc&quot;].shape = (5, 8)
gradients[&quot;dWo&quot;][1][2] = 0.331311595289
gradients[&quot;dWo&quot;].shape = (5, 8)
gradients[&quot;dbf&quot;][4] = [ 0.18864637]
gradients[&quot;dbf&quot;].shape = (5, 1)
gradients[&quot;dbi&quot;][4] = [-0.40142491]
gradients[&quot;dbi&quot;].shape = (5, 1)
gradients[&quot;dbc&quot;][4] = [ 0.25587763]
gradients[&quot;dbc&quot;].shape = (5, 1)
gradients[&quot;dbo&quot;][4] = [ 0.13893342]
gradients[&quot;dbo&quot;].shape = (5, 1)</code></pre><p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **gradients["dxt"][1][2]** =
        </td>
        <td>
           3.23055911511
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dxt"].shape** =
        </td>
        <td>
           (3, 10)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["da_prev"][2][3]** =
        </td>
        <td>
           -0.0639621419711
        </td>
    </tr>
        <tr>
        <td>
            **gradients["da_prev"].shape** =
        </td>
        <td>
           (5, 10)
        </td>
    </tr>
         <tr>
        <td>
            **gradients["dc_prev"][2][3]** =
        </td>
        <td>
           0.797522038797
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dc_prev"].shape** =
        </td>
        <td>
           (5, 10)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWf"][3][1]** = 
        </td>
        <td>
           -0.147954838164
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWf"].shape** =
        </td>
        <td>
           (5, 8)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWi"][1][2]** = 
        </td>
        <td>
           1.05749805523
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWi"].shape** = 
        </td>
        <td>
           (5, 8)
        </td>
    </tr>
    <tr>
        <td>
            **gradients["dWc"][3][1]** = 
        </td>
        <td>
           2.30456216369
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWc"].shape** = 
        </td>
        <td>
           (5, 8)
        </td>
    </tr>
    <tr>
        <td>
            **gradients["dWo"][1][2]** = 
        </td>
        <td>
           0.331311595289
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWo"].shape** = 
        </td>
        <td>
           (5, 8)
        </td>
    </tr>
    <tr>
        <td>
            **gradients["dbf"][4]** = 
        </td>
        <td>
           [ 0.18864637]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbf"].shape** = 
        </td>
        <td>
           (5, 1)
        </td>
    </tr>
    <tr>
        <td>
            **gradients["dbi"][4]** = 
        </td>
        <td>
           [-0.40142491]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbi"].shape** = 
        </td>
        <td>
           (5, 1)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbc"][4]** = 
        </td>
        <td>
           [ 0.25587763]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbc"].shape** = 
        </td>
        <td>
           (5, 1)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbo"][4]** = 
        </td>
        <td>
           [ 0.13893342]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbo"].shape** = 
        </td>
        <td>
           (5, 1)
        </td>
    </tr>
</table>

<h3 id="3-3-Backward-pass-through-the-LSTM-RNN"><a href="#3-3-Backward-pass-through-the-LSTM-RNN" class="headerlink" title="3.3 Backward pass through the LSTM RNN"></a>3.3 Backward pass through the LSTM RNN</h3><p>This part is very similar to the <code>rnn_backward</code> function you implemented above. You will first create variables of the same dimension as your return variables. You will then iterate over all the time steps starting from the end and call the one step function you implemented for LSTM at each iteration. You will then update the parameters by summing them individually. Finally return a dictionary with the new gradients. </p>
<p><strong>Instructions</strong>: Implement the <code>lstm_backward</code> function. Create a for loop starting from $T_x$ and going backward. For each step call <code>lstm_cell_backward</code> and update the your old gradients by adding the new gradients to them. Note that <code>dxt</code> is not updated but is stored.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_backward</span><span class="params">(da, caches)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward pass for the RNN with LSTM-cell (over a whole sequence).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    da -- Gradients w.r.t the hidden states, numpy-array of shape (n_a, m, T_x)</span></span><br><span class="line"><span class="string">    dc -- Gradients w.r.t the memory states, numpy-array of shape (n_a, m, T_x)</span></span><br><span class="line"><span class="string">    caches -- cache storing information from the forward pass (lstm_forward)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    gradients -- python dictionary containing:</span></span><br><span class="line"><span class="string">                        dx -- Gradient of inputs, of shape (n_x, m, T_x)</span></span><br><span class="line"><span class="string">                        da0 -- Gradient w.r.t. the previous hidden state, numpy array of shape (n_a, m)</span></span><br><span class="line"><span class="string">                        dWf -- Gradient w.r.t. the weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        dWi -- Gradient w.r.t. the weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        dWc -- Gradient w.r.t. the weight matrix of the memory gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        dWo -- Gradient w.r.t. the weight matrix of the save gate, numpy array of shape (n_a, n_a + n_x)</span></span><br><span class="line"><span class="string">                        dbf -- Gradient w.r.t. biases of the forget gate, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        dbi -- Gradient w.r.t. biases of the update gate, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        dbc -- Gradient w.r.t. biases of the memory gate, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">                        dbo -- Gradient w.r.t. biases of the save gate, of shape (n_a, 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve values from the first cache (t=1) of caches.</span></span><br><span class="line">    (caches, x) = caches</span><br><span class="line">    (a1, c1, a0, c0, f1, i1, cc1, o1, x1, parameters) = caches[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from da's and x1's shapes (≈2 lines)</span></span><br><span class="line">    n_a, m, T_x = da.shape</span><br><span class="line">    n_x, m = x1.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize the gradients with the right sizes (≈12 lines)</span></span><br><span class="line">    dx = np.zeros([n_x, m, T_x])</span><br><span class="line">    da0 = np.zeros([n_a, m])</span><br><span class="line">    da_prevt = np.zeros([n_a, m])</span><br><span class="line">    dc_prevt = np.zeros([n_a, m])</span><br><span class="line">    dWf = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dWi = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dWc = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dWo = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dbf = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    dbi = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    dbc = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    dbo = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># loop back over the whole sequence</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(T_x)):</span><br><span class="line">        <span class="comment"># Compute all gradients using lstm_cell_backward</span></span><br><span class="line">        gradients = lstm_cell_backward(da[:,:,t],dc_prevt,caches[t])</span><br><span class="line">        <span class="comment"># da_prevt, dc_prevt = gradients['da_prev'], gradients["dc_prev"]</span></span><br><span class="line">        <span class="comment"># Store or add the gradient to the parameters' previous step's gradient</span></span><br><span class="line">        dx[:,:,t] = gradients[<span class="string">'dxt'</span>]</span><br><span class="line">        dWf = dWf+gradients[<span class="string">'dWf'</span>]</span><br><span class="line">        dWi = dWi+gradients[<span class="string">'dWi'</span>]</span><br><span class="line">        dWc = dWc+gradients[<span class="string">'dWc'</span>]</span><br><span class="line">        dWo = dWo+gradients[<span class="string">'dWo'</span>]</span><br><span class="line">        dbf = dbf+gradients[<span class="string">'dbf'</span>]</span><br><span class="line">        dbi = dbi+gradients[<span class="string">'dbi'</span>]</span><br><span class="line">        dbc = dbc+gradients[<span class="string">'dbc'</span>]</span><br><span class="line">        dbo = dbo+gradients[<span class="string">'dbo'</span>]</span><br><span class="line">    <span class="comment"># Set the first activation's gradient to the backpropagated gradient da_prev.</span></span><br><span class="line">    da0 = gradients[<span class="string">'da_prev'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the gradients in a python dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dx"</span>: dx, <span class="string">"da0"</span>: da0, <span class="string">"dWf"</span>: dWf,<span class="string">"dbf"</span>: dbf, <span class="string">"dWi"</span>: dWi,<span class="string">"dbi"</span>: dbi,</span><br><span class="line">                <span class="string">"dWc"</span>: dWc,<span class="string">"dbc"</span>: dbc, <span class="string">"dWo"</span>: dWo,<span class="string">"dbo"</span>: dbo&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">x = np.random.randn(<span class="number">3</span>,<span class="number">10</span>,<span class="number">7</span>)</span><br><span class="line">a0 = np.random.randn(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">Wf = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bf = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wi = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bi = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wo = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bo = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">Wc = np.random.randn(<span class="number">5</span>, <span class="number">5</span>+<span class="number">3</span>)</span><br><span class="line">bc = np.random.randn(<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">parameters = &#123;<span class="string">"Wf"</span>: Wf, <span class="string">"Wi"</span>: Wi, <span class="string">"Wo"</span>: Wo, <span class="string">"Wc"</span>: Wc, <span class="string">"Wy"</span>: Wy, <span class="string">"bf"</span>: bf, <span class="string">"bi"</span>: bi, <span class="string">"bo"</span>: bo, <span class="string">"bc"</span>: bc, <span class="string">"by"</span>: by&#125;</span><br><span class="line"></span><br><span class="line">a, y, c, caches = lstm_forward(x, a0, parameters)</span><br><span class="line"></span><br><span class="line">da = np.random.randn(<span class="number">5</span>, <span class="number">10</span>, <span class="number">4</span>)</span><br><span class="line">gradients = lstm_backward(da, caches)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"gradients[\"dx\"][1][2] ="</span>, gradients[<span class="string">"dx"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dx\"].shape ="</span>, gradients[<span class="string">"dx"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"da0\"][2][3] ="</span>, gradients[<span class="string">"da0"</span>][<span class="number">2</span>][<span class="number">3</span>])</span><br><span class="line">print(<span class="string">"gradients[\"da0\"].shape ="</span>, gradients[<span class="string">"da0"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWf\"][3][1] ="</span>, gradients[<span class="string">"dWf"</span>][<span class="number">3</span>][<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWf\"].shape ="</span>, gradients[<span class="string">"dWf"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWi\"][1][2] ="</span>, gradients[<span class="string">"dWi"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWi\"].shape ="</span>, gradients[<span class="string">"dWi"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWc\"][3][1] ="</span>, gradients[<span class="string">"dWc"</span>][<span class="number">3</span>][<span class="number">1</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWc\"].shape ="</span>, gradients[<span class="string">"dWc"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dWo\"][1][2] ="</span>, gradients[<span class="string">"dWo"</span>][<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dWo\"].shape ="</span>, gradients[<span class="string">"dWo"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dbf\"][4] ="</span>, gradients[<span class="string">"dbf"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dbf\"].shape ="</span>, gradients[<span class="string">"dbf"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dbi\"][4] ="</span>, gradients[<span class="string">"dbi"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dbi\"].shape ="</span>, gradients[<span class="string">"dbi"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dbc\"][4] ="</span>, gradients[<span class="string">"dbc"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dbc\"].shape ="</span>, gradients[<span class="string">"dbc"</span>].shape)</span><br><span class="line">print(<span class="string">"gradients[\"dbo\"][4] ="</span>, gradients[<span class="string">"dbo"</span>][<span class="number">4</span>])</span><br><span class="line">print(<span class="string">"gradients[\"dbo\"].shape ="</span>, gradients[<span class="string">"dbo"</span>].shape)</span><br></pre></td></tr></table></figure>

<pre><code>gradients[&quot;dx&quot;][1][2] = [-0.00173313  0.08287442 -0.30545663 -0.43281115]
gradients[&quot;dx&quot;].shape = (3, 10, 4)
gradients[&quot;da0&quot;][2][3] = -0.095911501954
gradients[&quot;da0&quot;].shape = (5, 10)
gradients[&quot;dWf&quot;][3][1] = -0.0698198561274
gradients[&quot;dWf&quot;].shape = (5, 8)
gradients[&quot;dWi&quot;][1][2] = 0.102371820249
gradients[&quot;dWi&quot;].shape = (5, 8)
gradients[&quot;dWc&quot;][3][1] = -0.0624983794927
gradients[&quot;dWc&quot;].shape = (5, 8)
gradients[&quot;dWo&quot;][1][2] = 0.0484389131444
gradients[&quot;dWo&quot;].shape = (5, 8)
gradients[&quot;dbf&quot;][4] = [-0.0565788]
gradients[&quot;dbf&quot;].shape = (5, 1)
gradients[&quot;dbi&quot;][4] = [-0.15399065]
gradients[&quot;dbi&quot;].shape = (5, 1)
gradients[&quot;dbc&quot;][4] = [-0.29691142]
gradients[&quot;dbc&quot;].shape = (5, 1)
gradients[&quot;dbo&quot;][4] = [-0.29798344]
gradients[&quot;dbo&quot;].shape = (5, 1)</code></pre><p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **gradients["dx"][1][2]** =
        </td>
        <td>
           [-0.00173313  0.08287442 -0.30545663 -0.43281115]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dx"].shape** =
        </td>
        <td>
           (3, 10, 4)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["da0"][2][3]** =
        </td>
        <td>
           -0.095911501954
        </td>
    </tr>
        <tr>
        <td>
            **gradients["da0"].shape** =
        </td>
        <td>
           (5, 10)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWf"][3][1]** = 
        </td>
        <td>
           -0.0698198561274
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWf"].shape** =
        </td>
        <td>
           (5, 8)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWi"][1][2]** = 
        </td>
        <td>
           0.102371820249
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWi"].shape** = 
        </td>
        <td>
           (5, 8)
        </td>
    </tr>
    <tr>
        <td>
            **gradients["dWc"][3][1]** = 
        </td>
        <td>
           -0.0624983794927
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWc"].shape** = 
        </td>
        <td>
           (5, 8)
        </td>
    </tr>
    <tr>
        <td>
            **gradients["dWo"][1][2]** = 
        </td>
        <td>
           0.0484389131444
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dWo"].shape** = 
        </td>
        <td>
           (5, 8)
        </td>
    </tr>
    <tr>
        <td>
            **gradients["dbf"][4]** = 
        </td>
        <td>
           [-0.0565788]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbf"].shape** = 
        </td>
        <td>
           (5, 1)
        </td>
    </tr>
    <tr>
        <td>
            **gradients["dbi"][4]** = 
        </td>
        <td>
           [-0.06997391]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbi"].shape** = 
        </td>
        <td>
           (5, 1)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbc"][4]** = 
        </td>
        <td>
           [-0.27441821]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbc"].shape** = 
        </td>
        <td>
           (5, 1)
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbo"][4]** = 
        </td>
        <td>
           [ 0.16532821]
        </td>
    </tr>
        <tr>
        <td>
            **gradients["dbo"].shape** = 
        </td>
        <td>
           (5, 1)
        </td>
    </tr>
</table>

<h3 id="Congratulations"><a href="#Congratulations" class="headerlink" title="Congratulations !"></a>Congratulations !</h3><p>Congratulations on completing this assignment. You now understand how recurrent neural networks work! </p>
<p>Lets go on to the next exercise, where you’ll use an RNN to build a character-level language model.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Karan"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Karan</p>
  <div class="site-description" itemprop="description">Refuse to Fall</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">87</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnNuYWtlY29kaW5nLnB5QGdtYWlsLmNvbQ==" title="Get In Touch → mailto:snakecoding.py@gmail.com"><i class="fa fa-envelope fa-fw"></i>Get In Touch</span>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Karan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">2.4m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">35:43</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  
  <script data-pjax>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


    </div>
</body>
</html>
