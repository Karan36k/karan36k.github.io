<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">

<script>
    (function(){
        if(''){
                         If (prompt('Please enter the article password') !== ''){
                                 Alert('Password error!');
                history.back();
            }
        }
    })();
</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"snakecoding.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":"flat","style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":false},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Refuse to Fall">
<meta property="og:type" content="website">
<meta property="og:title" content="Machine Learning">
<meta property="og:url" content="https://snakecoding.com/page/8/index.html">
<meta property="og:site_name" content="Machine Learning">
<meta property="og:description" content="Refuse to Fall">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Karan">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://snakecoding.com/page/8/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Machine Learning</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Machine Learning" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Machine Learning</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">60</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/yourname" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/03/02/OptimizationMethods/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/03/02/OptimizationMethods/" class="post-title-link" itemprop="url">Optimization Methods</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-03-02 00:00:00" itemprop="dateCreated datePublished" datetime="2018-03-02T00:00:00+05:30">2018-03-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-06 20:25:37" itemprop="dateModified" datetime="2020-04-06T20:25:37+05:30">2020-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>33k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>30 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>These are my personal programming assignments at the 2nd week after studying the course <a href="https://www.coursera.org/learn/deep-neural-network/" target="_blank" rel="noopener">Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</a> and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.</p><h1 id="Optimization-Methods"><a href="#Optimization-Methods" class="headerlink" title="Optimization Methods"></a>Optimization Methods</h1><p>Until now, you’ve always used Gradient Descent to update the parameters and minimize the cost. In this notebook, you will learn more advanced optimization methods that can speed up learning and perhaps even get you to a better final value for the cost function. Having a good optimization algorithm can be the difference between waiting days vs. just a few hours to get a good result.</p><p>Gradient descent goes “downhill” on a cost function $J$. Think of it as trying to do this:</p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/images/1.png" style="width:600px;height:400px"><caption><center><u>**Figure 1** </u>: ** : Minimizing the cost is like finding the lowest point in a hilly landscape()**<br>At each step of the training, you update your parameters following a certain direction to try to get to the lowest possible point.</center></caption><p><strong>Notations</strong>: As usual, $\frac{∂J}{∂a}= da$ for any variable $a$.</p><p>To get started, run the following code to import the libraries you will need.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy.io</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> opt_utils <span class="keyword">import</span> load_params_and_grads, initialize_parameters, forward_propagation, backward_propagation</span><br><span class="line"><span class="keyword">from</span> opt_utils <span class="keyword">import</span> compute_cost, predict, predict_dec, plot_decision_boundary, load_dataset</span><br><span class="line"><span class="keyword">from</span> testCases <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">7.0</span>, <span class="number">4.0</span>) <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></span><br></pre></td></tr></table></figure><h2 id="1-Gradient-Descent"><a href="#1-Gradient-Descent" class="headerlink" title="1. Gradient Descent"></a>1. Gradient Descent</h2><p>A simple optimization method in machine learning is gradient descent (GD). When you take gradient steps with respect to all $m$ examples on each step, it is also called Batch Gradient Descent.</p><p>Warm-up exercise: Implement the gradient descent update rule. The gradient descent rule is, for $l=1,…,L$:<br>$$W^{[l]} = W^{[l]} - \alpha \text{ } dW^{[l]} \tag{1}$$<br>$$b^{[l]} = b^{[l]} - \alpha \text{ } db^{[l]} \tag{2}$$</p><p>where $L$ is the number of layers and $α$ is the learning rate. All parameters should be stored in the parameters dictionary.</p><p>Note that the iterator $l$ starts at $0$ in the for loop while the first parameters are $W^{[1]}$ and $b^{[1]}$. You need to shift $l$ to $l+1$ when coding.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters_with_gd</span><span class="params">(parameters, grads, learning_rate)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Update parameters using one step of gradient descent</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters to be updated:</span></span><br><span class="line"><span class="string">                    parameters['W' + str(l)] = Wl</span></span><br><span class="line"><span class="string">                    parameters['b' + str(l)] = bl</span></span><br><span class="line"><span class="string">    grads -- python dictionary containing your gradients to update each parameters:</span></span><br><span class="line"><span class="string">                    grads['dW' + str(l)] = dWl</span></span><br><span class="line"><span class="string">                    grads['db' + str(l)] = dbl</span></span><br><span class="line"><span class="string">    learning_rate -- the learning rate, scalar.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your updated parameters </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    L = len(parameters) // <span class="number">2</span>; <span class="comment"># number of layers in the neural networks</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update rule for each parameter</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">        parameters[<span class="string">'W'</span> + str(l + <span class="number">1</span>)] -= learning_rate * grads[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)];</span><br><span class="line">        parameters[<span class="string">'b'</span> + str(l + <span class="number">1</span>)] -= learning_rate * grads[<span class="string">'db'</span> + str(l + <span class="number">1</span>)];</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">parameters, grads, learning_rate = update_parameters_with_gd_test_case();</span><br><span class="line"></span><br><span class="line">parameters = update_parameters_with_gd(parameters, grads, learning_rate);</span><br><span class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]));</span><br><span class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]));</span><br><span class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]));</span><br><span class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]));</span><br></pre></td></tr></table></figure><p><strong>Expected Output</strong>:</p><table><thead><tr><th><strong>variabale</strong></th><th>value</th></tr></thead><tbody><tr><td><strong>W1</strong></td><td>[[ 1.63535156 -0.62320365 -0.53718766] [-1.07799357 0.85639907 -2.29470142]]</td></tr><tr><td><strong>b1</strong></td><td>[[ 1.74604067] [-0.75184921]]</td></tr><tr><td><strong>W2</strong></td><td>[[ 0.32171798 -0.25467393 1.46902454] [-2.05617317 -0.31554548 -0.3756023 ] [ 1.1404819 -1.09976462 -0.1612551 ]]</td></tr><tr><td><strong>b2</strong></td><td>[[-0.88020257] [ 0.02561572] [ 0.57539477]]</td></tr></tbody></table><p>A variant of this is Stochastic Gradient Descent (SGD), which is equivalent to mini-batch gradient descent where each mini-batch has just 1 example. The update rule that you have just implemented does not change. What changes is that you would be computing gradients on just one training example at a time, rather than on the whole training set. The code examples below illustrate the difference between stochastic gradient descent and (batch) gradient descent.</p><ul><li><p><strong>(Batch) Gradient Descent</strong>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">X = data_input</span><br><span class="line">Y = labels</span><br><span class="line">parameters = initialize_parameters(layers_dims)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</span><br><span class="line">    <span class="comment"># Forward propagation</span></span><br><span class="line">    a, caches = forward_propagation(X, parameters)</span><br><span class="line">    <span class="comment"># Compute cost.</span></span><br><span class="line">    cost = compute_cost(a, Y)</span><br><span class="line">    <span class="comment"># Backward propagation.</span></span><br><span class="line">    grads = backward_propagation(a, caches, parameters)</span><br><span class="line">    <span class="comment"># Update parameters.</span></span><br><span class="line">    parameters = update_parameters(parameters, grads)</span><br></pre></td></tr></table></figure></li><li><p><strong>Stochastic Gradient Descent</strong>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">X = data_input</span><br><span class="line">Y = labels</span><br><span class="line">parameters = initialize_parameters(layers_dims)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, m):</span><br><span class="line">        <span class="comment"># Forward propagation</span></span><br><span class="line">        a, caches = forward_propagation(X[:,j], parameters)</span><br><span class="line">        <span class="comment"># Compute cost</span></span><br><span class="line">        cost = compute_cost(a, Y[:,j])</span><br><span class="line">        <span class="comment"># Backward propagation</span></span><br><span class="line">        grads = backward_propagation(a, caches, parameters)</span><br><span class="line">        <span class="comment"># Update parameters.</span></span><br><span class="line">        parameters = update_parameters(parameters, grads)</span><br></pre></td></tr></table></figure></li></ul><p>In Stochastic Gradient Descent, you use only 1 training example before updating the gradients. When the training set is large, SGD can be faster. But the parameters will “oscillate” toward the minimum rather than converge smoothly. Here is an illustration of this:</p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/images/2.png"><caption><center><u>**Figure 1** </u>**: SGD vs GD**<br>“+” denotes a minimum of the cost. SGD leads to many oscillations to reach convergence. But each step is a lot faster to compute for SGD than for GD, as it uses only one training example (vs. the whole batch for GD).</center></caption><p><strong>Note</strong> also that implementing SGD requires 3 for-loops in total:</p><ol><li>Over the number of iterations</li><li>Over the m training examples</li><li>Over the layers (to update all parameters, from ($W^{[1]}$,$b^{[1]}$) to ($W^{[L]}$,$b^{[L]}$)</li></ol><p>In practice, you’ll often get faster results if you do not use neither the whole training set, nor only one training example, to perform each update. Mini-batch gradient descent uses an intermediate number of examples for each step. With mini-batch gradient descent, you loop over the mini-batches instead of looping over individual training examples.</p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/images/3.png"><caption><center><u>**Figure 2** </u>**: SGD vs Mini-Batch GD**<br>“+” denotes a minimum of the cost. Using mini-batches in your optimization algorithm often leads to faster optimization.</center></caption><p><strong>What you should remember:</strong></p><ul><li>The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step.</li><li>You have to tune a learning rate hyperparameter α.</li><li>With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large).</li></ul><h2 id="2-Mini-Batch-Gradient-descent"><a href="#2-Mini-Batch-Gradient-descent" class="headerlink" title="2. Mini-Batch Gradient descent"></a>2. Mini-Batch Gradient descent</h2><p>Let’s learn how to build mini-batches from the training set $(X, Y)$.</p><p>There are two steps:</p><ul><li><strong>Shuffle</strong>: Create a shuffled version of the training set $(X, Y)$ as shown below. Each column of $X$ and $Y$ represents a training example. Note that the random shuffling is done synchronously between $X$ and $Y$. Such that after the shuffling the ith column of $X$ is the example corresponding to the ith label in $Y$. The shuffling step ensures that examples will be split randomly into different mini-batches.</li></ul><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/images/4.png" style="width:600px;height:400px"><ul><li><strong>Partition</strong>: Partition the shuffled $(X, Y)$ into mini-batches of size <code>mini_batch_size</code> (here 64). Note that the number of training examples is not always divisible by <code>mini_batch_size</code>. The last mini batch might be smaller, but you don’t need to worry about this. When the final mini-batch is smaller than the full <code>mini_batch_size</code>, it will look like this:</li></ul><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/images/5.png"><p><strong>Exercise</strong>: Implement <code>random_mini_batches</code>. We coded the shuffling part for you. To help you with the partitioning step, we give you the following code that selects the indexes for the 1st and 2nd mini-batches:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">first_mini_batch_X = shuffled_X[:, <span class="number">0</span> : mini_batch_size]</span><br><span class="line">second_mini_batch_X = shuffled_X[:, mini_batch_size : <span class="number">2</span> * mini_batch_size]</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><strong>Note</strong> that the last mini-batch might end up smaller than<code>mini_batch_size=64</code>. Let $\lfloor s \rfloor$ represents $s$ rounded down to the nearest integer (this is <code>math.floor(s)</code> in Python). If the total number of examples is not a multiple of <code>mini_batch_size=64</code> then there will be $\lfloor \frac{m}{mini_batch_size}\rfloor$ mini-batches with a full 64 examples, and the number of examples in the final mini-batch will be $(m-mini__batch__size \times \lfloor \frac{m}{mini_batch_size}\rfloor)$.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: random_mini_batches</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_mini_batches</span><span class="params">(X, Y, mini_batch_size = <span class="number">64</span>, seed = <span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Creates a list of random minibatches from (X, Y)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input data, of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    mini_batch_size -- size of the mini-batches, integer</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(seed)            <span class="comment"># To make your "random" minibatches the same as ours</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]                  <span class="comment"># number of training examples</span></span><br><span class="line">    mini_batches = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 1: Shuffle (X, Y)</span></span><br><span class="line">    permutation = list(np.random.permutation(m))</span><br><span class="line">    shuffled_X = X[:, permutation]</span><br><span class="line">    shuffled_Y = Y[:, permutation].reshape((<span class="number">1</span>,m))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.</span></span><br><span class="line">    num_complete_minibatches = math.floor(m/mini_batch_size) <span class="comment"># number of mini batches of size mini_batch_size in your partitionning</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>, num_complete_minibatches):</span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k + <span class="number">1</span>) * mini_batch_size];</span><br><span class="line">        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k + <span class="number">1</span>) * mini_batch_size];</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class="line">        mini_batches.append(mini_batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Handling the end case (last mini-batch &lt; mini_batch_size)</span></span><br><span class="line">    <span class="keyword">if</span> m % mini_batch_size != <span class="number">0</span>:</span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">        mini_batch_X = shuffled_X[:, mini_batch_size * num_complete_minibatches : m];</span><br><span class="line">        mini_batch_Y = shuffled_Y[:, mini_batch_size * num_complete_minibatches : m];</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class="line">        mini_batches.append(mini_batch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mini_batches</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">X_assess, Y_assess, mini_batch_size = random_mini_batches_test_case()</span><br><span class="line">mini_batches = random_mini_batches(X_assess, Y_assess, mini_batch_size)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"shape of the 1st mini_batch_X: "</span> + str(mini_batches[<span class="number">0</span>][<span class="number">0</span>].shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"shape of the 2nd mini_batch_X: "</span> + str(mini_batches[<span class="number">1</span>][<span class="number">0</span>].shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"shape of the 3rd mini_batch_X: "</span> + str(mini_batches[<span class="number">2</span>][<span class="number">0</span>].shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"shape of the 1st mini_batch_Y: "</span> + str(mini_batches[<span class="number">0</span>][<span class="number">1</span>].shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"shape of the 2nd mini_batch_Y: "</span> + str(mini_batches[<span class="number">1</span>][<span class="number">1</span>].shape)) </span><br><span class="line"><span class="keyword">print</span> (<span class="string">"shape of the 3rd mini_batch_Y: "</span> + str(mini_batches[<span class="number">2</span>][<span class="number">1</span>].shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"mini batch sanity check: "</span> + str(mini_batches[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>:<span class="number">3</span>]))</span><br></pre></td></tr></table></figure><pre><code>shape of the 1st mini_batch_X: (12288, 64)
shape of the 2nd mini_batch_X: (12288, 64)
shape of the 3rd mini_batch_X: (12288, 20)
shape of the 1st mini_batch_Y: (1, 64)
shape of the 2nd mini_batch_Y: (1, 64)
shape of the 3rd mini_batch_Y: (1, 20)
mini batch sanity check: [ 0.90085595 -0.7612069   0.2344157 ]</code></pre><p><strong>Expected Output</strong>:</p><table><thead><tr><th><strong>variabale</strong></th><th>value</th></tr></thead><tbody><tr><td><strong>shape of the 1st mini_batch_X</strong></td><td>(12288, 64)</td></tr><tr><td><strong>shape of the 2nd mini_batch_X</strong></td><td>(12288, 64)</td></tr><tr><td><strong>shape of the 3rd mini_batch_X</strong></td><td>(12288, 20)</td></tr><tr><td><strong>shape of the 1st mini_batch_Y</strong></td><td>(1, 64)</td></tr><tr><td><strong>shape of the 2nd mini_batch_Y</strong></td><td>(1, 64)</td></tr><tr><td><strong>shape of the 3rd mini_batch_Y</strong></td><td>(1, 20)</td></tr><tr><td><strong>mini batch sanity check</strong></td><td>[ 0.90085595 -0.7612069 0.2344157 ]</td></tr></tbody></table><p><strong>What you should remember</strong>:</p><ul><li>Shuffling and Partitioning are the two steps required to build mini-batches</li><li>Powers of two are often chosen to be the mini-batch size, e.g., 16, 32, 64, 128.</li></ul><h2 id="3-Momentum"><a href="#3-Momentum" class="headerlink" title="3. Momentum"></a>3. Momentum</h2><p>Because mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will “oscillate” toward convergence. Using momentum can reduce these oscillations.</p><p>Momentum takes into account the past gradients to smooth out the update. We will store the ‘direction’ of the previous gradients in the variable $v$. Formally, this will be the exponentially weighted average of the gradient on previous steps. You can also think of $v$ as the “velocity” of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hill.</p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/images/6.png"><caption><center><u>**Figure 3** </u>: The red arrows shows the direction taken by one step of mini-batch gradient descent with momentum. The blue points show the direction of the gradient (with respect to the current mini-batch) on each step. Rather than just following the gradient, we let the gradient influence $v$ and then take a step in the direction of $v$.</center></caption><p><strong>Exercise</strong>: Initialize the velocity. The velocity, $v$, is a python dictionary that needs to be initialized with arrays of zeros. Its keys are the same as those in the <code>grads</code> dictionary, that is:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> l=<span class="number">1</span>,...,L:</span><br><span class="line">    v[<span class="string">"dW"</span> + str(l+<span class="number">1</span>)] = ... <span class="comment">#(numpy array of zeros with the same shape as parameters["W" + str(l+1)])</span></span><br><span class="line">    v[<span class="string">"db"</span> + str(l+<span class="number">1</span>)] = ... <span class="comment">#(numpy array of zeros with the same shape as parameters["b" + str(l+1)])</span></span><br></pre></td></tr></table></figure><p><strong>Note</strong> that the iterator $l$ starts at $0$ in the for loop while the first parameters are <code>v[“dW1”]</code> and <code>v[“db1”]</code> (that’s a “one” on the superscript). This is why we are shifting <code>l</code> to <code>l + 1</code> in the <code>for</code> loop.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: initialize_velocity</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_velocity</span><span class="params">(parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Initializes the velocity as a python dictionary with:</span></span><br><span class="line"><span class="string">                - keys: "dW1", "db1", ..., "dWL", "dbL" </span></span><br><span class="line"><span class="string">                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters.</span></span><br><span class="line"><span class="string">                    parameters['W' + str(l)] = Wl</span></span><br><span class="line"><span class="string">                    parameters['b' + str(l)] = bl</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    v -- python dictionary containing the current velocity.</span></span><br><span class="line"><span class="string">                    v['dW' + str(l)] = velocity of dWl</span></span><br><span class="line"><span class="string">                    v['db' + str(l)] = velocity of dbl</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    L = len(parameters) // <span class="number">2</span> <span class="comment"># number of layers in the neural networks</span></span><br><span class="line">    v = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize velocity</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">        v[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] = np.zeros(parameters[<span class="string">'W'</span> + str(l + <span class="number">1</span>)].shape);</span><br><span class="line">        v[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] = np.zeros(parameters[<span class="string">'b'</span> + str(l + <span class="number">1</span>)].shape);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> v</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">parameters = initialize_velocity_test_case()</span><br><span class="line"></span><br><span class="line">v = initialize_velocity(parameters)</span><br><span class="line">print(<span class="string">"v[\"dW1\"] = "</span> + str(v[<span class="string">"dW1"</span>]))</span><br><span class="line">print(<span class="string">"v[\"db1\"] = "</span> + str(v[<span class="string">"db1"</span>]))</span><br><span class="line">print(<span class="string">"v[\"dW2\"] = "</span> + str(v[<span class="string">"dW2"</span>]))</span><br><span class="line">print(<span class="string">"v[\"db2\"] = "</span> + str(v[<span class="string">"db2"</span>]))</span><br></pre></td></tr></table></figure><pre><code>v[&quot;dW1&quot;] = [[0. 0. 0.]
 [0. 0. 0.]]
v[&quot;db1&quot;] = [[0.]
 [0.]]
v[&quot;dW2&quot;] = [[0. 0. 0.]
 [0. 0. 0.]
 [0. 0. 0.]]
v[&quot;db2&quot;] = [[0.]
 [0.]
 [0.]]</code></pre><p><strong>Expected Output</strong>:</p><table><thead><tr><th><strong>variabale</strong></th><th>value</th></tr></thead><tbody><tr><td><strong>v[“dW1”]</strong></td><td>[[ 0. 0. 0.] [ 0. 0. 0.]]</td></tr><tr><td><strong>v[“db1”]</strong></td><td>[[ 0.] [ 0.]]</td></tr><tr><td><strong>v[“dW2”]</strong></td><td>[[ 0. 0. 0.] [ 0. 0. 0.] [ 0. 0. 0.]]</td></tr><tr><td><strong>v[“db2”]</strong></td><td>[[ 0.] [ 0.] [ 0.]]</td></tr></tbody></table><p><strong>Exercise</strong>: Now, implement the parameters update with momentum. The momentum update rule is, <code>for l=1,...,L</code>:<br>$$<br>\begin{cases}<br>v_{dW^{[l]}} = \beta v_{dW^{[l]}} + (1 - \beta) dW^{[l]} \<br>W^{[l]} = W^{[l]} - \alpha v_{dW^{[l]}}<br>\end{cases}\tag{3}<br>$$<br>$$<br>\begin{cases}<br>v_{db^{[l]}} = \beta v_{db^{[l]}} + (1 - \beta) db^{[l]} \<br>b^{[l]} = b^{[l]} - \alpha v_{db^{[l]}}<br>\end{cases}\tag{4}<br>$$</p><p>where $L$ is the number of layers, $β$ is the momentum and $α$ is the learning rate. All parameters should be stored in the <code>parameters</code> dictionary. <strong>Note</strong> that the iterator $l$ starts at $0$ in the for loop while the first parameters are $W^{[1]}$ and $b^{[1]}$ (that’s a “one” on the superscript). So you will need to shift $l$ to $l + 1$ when coding.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: update_parameters_with_momentum</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters_with_momentum</span><span class="params">(parameters, grads, v, beta, learning_rate)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Update parameters using Momentum</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters:</span></span><br><span class="line"><span class="string">                    parameters['W' + str(l)] = Wl</span></span><br><span class="line"><span class="string">                    parameters['b' + str(l)] = bl</span></span><br><span class="line"><span class="string">    grads -- python dictionary containing your gradients for each parameters:</span></span><br><span class="line"><span class="string">                    grads['dW' + str(l)] = dWl</span></span><br><span class="line"><span class="string">                    grads['db' + str(l)] = dbl</span></span><br><span class="line"><span class="string">    v -- python dictionary containing the current velocity:</span></span><br><span class="line"><span class="string">                    v['dW' + str(l)] = ...</span></span><br><span class="line"><span class="string">                    v['db' + str(l)] = ...</span></span><br><span class="line"><span class="string">    beta -- the momentum hyperparameter, scalar</span></span><br><span class="line"><span class="string">    learning_rate -- the learning rate, scalar</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your updated parameters </span></span><br><span class="line"><span class="string">    v -- python dictionary containing your updated velocities</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    L = len(parameters) // <span class="number">2</span> <span class="comment"># number of layers in the neural networks</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Momentum update for each parameter</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line"></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 4 lines)</span></span><br><span class="line">        <span class="comment"># compute velocities</span></span><br><span class="line">        v[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] = beta * v[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta) * grads[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)];</span><br><span class="line">        v[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] = beta * v[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta) * grads[<span class="string">'db'</span> + str(l + <span class="number">1</span>)];</span><br><span class="line">        <span class="comment"># update parameters</span></span><br><span class="line">        parameters[<span class="string">'W'</span> + str(l + <span class="number">1</span>)] -= learning_rate * v[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)];</span><br><span class="line">        parameters[<span class="string">'b'</span> + str(l + <span class="number">1</span>)] -= learning_rate * v[<span class="string">'db'</span> + str(l + <span class="number">1</span>)];</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters, v</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">parameters, grads, v = update_parameters_with_momentum_test_case()</span><br><span class="line"></span><br><span class="line">parameters, v = update_parameters_with_momentum(parameters, grads, v, beta = <span class="number">0.9</span>, learning_rate = <span class="number">0.01</span>)</span><br><span class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]))</span><br><span class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]))</span><br><span class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]))</span><br><span class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]))</span><br><span class="line">print(<span class="string">"v[\"dW1\"] = "</span> + str(v[<span class="string">"dW1"</span>]))</span><br><span class="line">print(<span class="string">"v[\"db1\"] = "</span> + str(v[<span class="string">"db1"</span>]))</span><br><span class="line">print(<span class="string">"v[\"dW2\"] = "</span> + str(v[<span class="string">"dW2"</span>]))</span><br><span class="line">print(<span class="string">"v[\"db2\"] = "</span> + str(v[<span class="string">"db2"</span>]))</span><br></pre></td></tr></table></figure><pre><code>W1 = [[ 1.62544598 -0.61290114 -0.52907334]
 [-1.07347112  0.86450677 -2.30085497]]
b1 = [[ 1.74493465]
 [-0.76027113]]
W2 = [[ 0.31930698 -0.24990073  1.4627996 ]
 [-2.05974396 -0.32173003 -0.38320915]
 [ 1.13444069 -1.0998786  -0.1713109 ]]
b2 = [[-0.87809283]
 [ 0.04055394]
 [ 0.58207317]]
v[&quot;dW1&quot;] = [[-0.11006192  0.11447237  0.09015907]
 [ 0.05024943  0.09008559 -0.06837279]]
v[&quot;db1&quot;] = [[-0.01228902]
 [-0.09357694]]
v[&quot;dW2&quot;] = [[-0.02678881  0.05303555 -0.06916608]
 [-0.03967535 -0.06871727 -0.08452056]
 [-0.06712461 -0.00126646 -0.11173103]]
v[&quot;db2&quot;] = [[0.02344157]
 [0.16598022]
 [0.07420442]]</code></pre><p><strong>Expected Output</strong>:</p><table><thead><tr><th><strong>variable</strong></th><th>value</th></tr></thead><tbody><tr><td><strong>W1</strong></td><td>[[ 1.62544598 -0.61290114 -0.52907334] [-1.07347112 0.86450677 -2.30085497]]</td></tr><tr><td><strong>b1</strong></td><td>[[ 1.74493465] [-0.76027113]]</td></tr><tr><td><strong>W2</strong></td><td>[[ 0.31930698 -0.24990073 1.4627996 ] [-2.05974396 -0.32173003 -0.38320915] [ 1.13444069 -1.0998786 -0.1713109 ]]</td></tr><tr><td><strong>b2</strong></td><td>[[-0.87809283] [ 0.04055394] [ 0.58207317]]</td></tr><tr><td><strong>v[“dW1”]</strong></td><td>[[-0.11006192 0.11447237 0.09015907] [ 0.05024943 0.09008559 -0.06837279]]</td></tr><tr><td><strong>v[“db1”]</strong></td><td>[[-0.01228902] [-0.09357694]]</td></tr><tr><td><strong>v[“dW2”]</strong></td><td>[[-0.02678881 0.05303555 -0.06916608] [-0.03967535 -0.06871727 -0.08452056] [-0.06712461 -0.00126646 -0.11173103]]</td></tr><tr><td><strong>v[“db2”]</strong></td><td>[[ 0.02344157][ 0.16598022] [ 0.07420442]]</td></tr></tbody></table><p><strong>Note</strong> that:</p><ul><li>The velocity is initialized with zeros. So the algorithm will take a few iterations to “build up” velocity and start to take bigger steps.</li><li>If $β=0$, then this just becomes standard gradient descent without momentum.</li></ul><p><strong>How do you choose $β$</strong>?</p><p>The larger the momentum $β$ is, the smoother the update because the more we take the past gradients into account. But if $β$ is too big, it could also smooth out the updates too much.<br>Common values for $β$ range from 0.8 to 0.999. If you don’t feel inclined to tune this, $β=0.9$ is often a reasonable default.<br>Tuning the optimal $β$ for your model might need trying several values to see what works best in term of reducing the value of the cost function $J$.</p><p><strong>What you should remember</strong>:</p><ul><li>Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.</li><li>You have to tune a momentum hyperparameter $β$ and a learning rate $α$.</li></ul><h2 id="4-Adam"><a href="#4-Adam" class="headerlink" title="4. Adam"></a>4. Adam</h2><p>Adam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp (described in lecture) and Momentum.</p><p>*<em>How does Adam work? *</em></p><ol><li>It calculates an exponentially weighted average of past gradients, and stores it in variables $v$ (before bias correction) and $v^{corrected}$ (with bias correction).</li><li>It calculates an exponentially weighted average of the squares of the past gradients, and stores it in variables $s$ (before bias correction) and $s^{corrected}$ (with bias correction).</li><li>It updates parameters in a direction based on combining information from “1” and “2”.</li></ol><p>The update rule is, <code>for l=1,...,L</code>:<br>$$\begin{cases}<br>v_{dW^{[l]}} = \beta_1 v_{dW^{[l]}} + (1 - \beta_1) \frac{\partial \mathcal{J} }{ \partial W^{[l]} } \<br>v^{corrected}<em>{dW^{[l]}} = \frac{v</em>{dW^{[l]}}}{1 - (\beta_1)^t} \<br>s_{dW^{[l]}} = \beta_2 s_{dW^{[l]}} + (1 - \beta_2) (\frac{\partial \mathcal{J} }{\partial W^{[l]} })^2 \<br>s^{corrected}<em>{dW^{[l]}} = \frac{s</em>{dW^{[l]}}}{1 - (\beta_2)^t} \<br>W^{[l]} = W^{[l]} - \alpha \frac{v^{corrected}<em>{dW^{[l]}}}{\sqrt{s^{corrected}</em>{dW^{[l]}}} + \varepsilon}<br>\end{cases}$$</p><p>where:</p><ul><li>$t$ counts the number of steps taken of Adam</li><li>$L$ is the number of layers</li><li>$β_1$ and $β_2$ are hyperparameters that control the two exponentially weighted averages.</li><li>$α$ is the learning rate</li><li>$ε$ is a very small number to avoid dividing by zero<br>As usual, we will store all parameters in the parameters dictionary</li></ul><p><strong>Exercise</strong>: Initialize the Adam variables $v,s$ which keep track of the past information.</p><p><strong>Instruction</strong>: The variables $v,s$ are python dictionaries that need to be initialized with arrays of zeros. Their keys are the same as for grads, that is:<br><code>for l=1,...,L</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">v[<span class="string">"dW"</span> + str(l+<span class="number">1</span>)] = ... <span class="comment">#(numpy array of zeros with the same shape as parameters["W" + str(l+1)])</span></span><br><span class="line">v[<span class="string">"db"</span> + str(l+<span class="number">1</span>)] = ... <span class="comment">#(numpy array of zeros with the same shape as parameters["b" + str(l+1)])</span></span><br><span class="line">s[<span class="string">"dW"</span> + str(l+<span class="number">1</span>)] = ... <span class="comment">#(numpy array of zeros with the same shape as parameters["W" + str(l+1)])</span></span><br><span class="line">s[<span class="string">"db"</span> + str(l+<span class="number">1</span>)] = ... <span class="comment">#(numpy array of zeros with the same shape as parameters["b" + str(l+1)])</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: initialize_adam</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_adam</span><span class="params">(parameters)</span> :</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Initializes v and s as two python dictionaries with:</span></span><br><span class="line"><span class="string">                - keys: "dW1", "db1", ..., "dWL", "dbL" </span></span><br><span class="line"><span class="string">                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters.</span></span><br><span class="line"><span class="string">                    parameters["W" + str(l)] = Wl</span></span><br><span class="line"><span class="string">                    parameters["b" + str(l)] = bl</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    v -- python dictionary that will contain the exponentially weighted average of the gradient.</span></span><br><span class="line"><span class="string">                    v["dW" + str(l)] = ...</span></span><br><span class="line"><span class="string">                    v["db" + str(l)] = ...</span></span><br><span class="line"><span class="string">    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.</span></span><br><span class="line"><span class="string">                    s["dW" + str(l)] = ...</span></span><br><span class="line"><span class="string">                    s["db" + str(l)] = ...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    L = len(parameters) // <span class="number">2</span> <span class="comment"># number of layers in the neural networks</span></span><br><span class="line">    v = &#123;&#125;</span><br><span class="line">    s = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize v, s. Input: "parameters". Outputs: "v, s".</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 4 lines)</span></span><br><span class="line">        v[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] = np.zeros(parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)].shape);</span><br><span class="line">        v[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] = np.zeros(parameters[<span class="string">"b"</span> + str(l + <span class="number">1</span>)].shape);</span><br><span class="line">        s[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] = np.zeros(parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)].shape);</span><br><span class="line">        s[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] = np.zeros(parameters[<span class="string">"b"</span> + str(l + <span class="number">1</span>)].shape);   </span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> v, s</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">parameters = initialize_adam_test_case()</span><br><span class="line"></span><br><span class="line">v, s = initialize_adam(parameters)</span><br><span class="line">print(<span class="string">"v[\"dW1\"] = "</span> + str(v[<span class="string">"dW1"</span>]))</span><br><span class="line">print(<span class="string">"v[\"db1\"] = "</span> + str(v[<span class="string">"db1"</span>]))</span><br><span class="line">print(<span class="string">"v[\"dW2\"] = "</span> + str(v[<span class="string">"dW2"</span>]))</span><br><span class="line">print(<span class="string">"v[\"db2\"] = "</span> + str(v[<span class="string">"db2"</span>]))</span><br><span class="line">print(<span class="string">"s[\"dW1\"] = "</span> + str(s[<span class="string">"dW1"</span>]))</span><br><span class="line">print(<span class="string">"s[\"db1\"] = "</span> + str(s[<span class="string">"db1"</span>]))</span><br><span class="line">print(<span class="string">"s[\"dW2\"] = "</span> + str(s[<span class="string">"dW2"</span>]))</span><br><span class="line">print(<span class="string">"s[\"db2\"] = "</span> + str(s[<span class="string">"db2"</span>]))</span><br></pre></td></tr></table></figure><pre><code>v[&quot;dW1&quot;] = [[0. 0. 0.]
 [0. 0. 0.]]
v[&quot;db1&quot;] = [[0.]
 [0.]]
v[&quot;dW2&quot;] = [[0. 0. 0.]
 [0. 0. 0.]
 [0. 0. 0.]]
v[&quot;db2&quot;] = [[0.]
 [0.]
 [0.]]
s[&quot;dW1&quot;] = [[0. 0. 0.]
 [0. 0. 0.]]
s[&quot;db1&quot;] = [[0.]
 [0.]]
s[&quot;dW2&quot;] = [[0. 0. 0.]
 [0. 0. 0.]
 [0. 0. 0.]]
s[&quot;db2&quot;] = [[0.]
 [0.]
 [0.]]</code></pre><p><strong>Expected Output</strong>:</p><table><thead><tr><th align="left">variable</th><th align="left">value</th></tr></thead><tbody><tr><td align="left"><strong>v[“dW1”]</strong></td><td align="left">[[ 0. 0. 0.] [ 0. 0. 0.]]</td></tr><tr><td align="left"><strong>v[“db1”]</strong></td><td align="left">[[ 0.] [ 0.]]</td></tr><tr><td align="left"><strong>v[“dW2”]</strong></td><td align="left">[[ 0. 0. 0.] [ 0. 0. 0.] [ 0. 0. 0.]]</td></tr><tr><td align="left"><strong>v[“db2”]</strong></td><td align="left">[[ 0.] [ 0.] [ 0.]]</td></tr><tr><td align="left"><strong>s[“dW1”]</strong></td><td align="left">[[ 0. 0. 0.] [ 0. 0. 0.]]</td></tr><tr><td align="left"><strong>s[“db1”]</strong></td><td align="left">[[ 0.] [ 0.]]</td></tr><tr><td align="left"><strong>s[“dW2”]</strong></td><td align="left">[[ 0. 0. 0.] [ 0. 0. 0.] [ 0. 0. 0.]]</td></tr><tr><td align="left"><strong>s[“db2”]</strong></td><td align="left">[[ 0.] [ 0.] [ 0.]]</td></tr></tbody></table><p><strong>Exercise</strong>: Now, implement the parameters update with Adam. Recall the general update rule is, <code>for l=1,...,L</code>:<br>$$\begin{cases}<br>v_{dW^{[l]}} = \beta_1 v_{dW^{[l]}} + (1 - \beta_1) \frac{\partial \mathcal{J} }{ \partial W^{[l]} } \<br>v^{corrected}<em>{dW^{[l]}} = \frac{v</em>{dW^{[l]}}}{1 - (\beta_1)^t} \<br>s_{dW^{[l]}} = \beta_2 s_{dW^{[l]}} + (1 - \beta_2) (\frac{\partial \mathcal{J} }{\partial W^{[l]} })^2 \<br>s^{corrected}<em>{dW^{[l]}} = \frac{s</em>{dW^{[l]}}}{1 - (\beta_2)^t} \<br>W^{[l]} = W^{[l]} - \alpha \frac{v^{corrected}<em>{dW^{[l]}}}{\sqrt{s^{corrected}</em>{dW^{[l]}}} + \varepsilon}<br>\end{cases}$$</p><p><strong>Note</strong> that the iterator <code>l</code> starts at <code>0</code> in the for loop while the first parameters are $W^{[1]}$ and $b^{[1]}$. You need to shift <code>l</code> to <code>l+1</code> when coding.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: update_parameters_with_adam</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters_with_adam</span><span class="params">(parameters, grads, v, s, t, learning_rate = <span class="number">0.01</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                                beta1 = <span class="number">0.9</span>, beta2 = <span class="number">0.999</span>,  epsilon = <span class="number">1e-8</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Update parameters using Adam</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters:</span></span><br><span class="line"><span class="string">                    parameters['W' + str(l)] = Wl</span></span><br><span class="line"><span class="string">                    parameters['b' + str(l)] = bl</span></span><br><span class="line"><span class="string">    grads -- python dictionary containing your gradients for each parameters:</span></span><br><span class="line"><span class="string">                    grads['dW' + str(l)] = dWl</span></span><br><span class="line"><span class="string">                    grads['db' + str(l)] = dbl</span></span><br><span class="line"><span class="string">    v -- Adam variable, moving average of the first gradient, python dictionary</span></span><br><span class="line"><span class="string">    s -- Adam variable, moving average of the squared gradient, python dictionary</span></span><br><span class="line"><span class="string">    learning_rate -- the learning rate, scalar.</span></span><br><span class="line"><span class="string">    beta1 -- Exponential decay hyperparameter for the first moment estimates </span></span><br><span class="line"><span class="string">    beta2 -- Exponential decay hyperparameter for the second moment estimates </span></span><br><span class="line"><span class="string">    epsilon -- hyperparameter preventing division by zero in Adam updates</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your updated parameters </span></span><br><span class="line"><span class="string">    v -- Adam variable, moving average of the first gradient, python dictionary</span></span><br><span class="line"><span class="string">    s -- Adam variable, moving average of the squared gradient, python dictionary</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    L = len(parameters) // <span class="number">2</span>                 <span class="comment"># number of layers in the neural networks</span></span><br><span class="line">    v_corrected = &#123;&#125;                         <span class="comment"># Initializing first moment estimate, python dictionary</span></span><br><span class="line">    s_corrected = &#123;&#125;                         <span class="comment"># Initializing second moment estimate, python dictionary</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Perform Adam update on all parameters</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line">        <span class="comment"># Moving average of the gradients. Inputs: "v, grads, beta1". Output: "v".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">        v[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] = beta1 * v[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta1) * grads[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)];</span><br><span class="line">        v[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] = beta1 * v[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta1) * grads[<span class="string">'db'</span> + str(l + <span class="number">1</span>)];</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute bias-corrected first moment estimate. Inputs: "v, beta1, t". Output: "v_corrected".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">        v_corrected[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] = v[<span class="string">'dW'</span> +  str(l + <span class="number">1</span>)] / (<span class="number">1</span> - np.power(beta1, t));</span><br><span class="line">        v_corrected[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] = v[<span class="string">'db'</span> +  str(l + <span class="number">1</span>)] / (<span class="number">1</span> - np.power(beta1, t));</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Moving average of the squared gradients. Inputs: "s, grads, beta2". Output: "s".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">        s[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] = beta2 * s[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta2) * np.power(grads[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)], <span class="number">2</span>);</span><br><span class="line">        s[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] = beta2 * s[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta2) * np.power(grads[<span class="string">'db'</span> + str(l + <span class="number">1</span>)], <span class="number">2</span>);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute bias-corrected second raw moment estimate. Inputs: "s, beta2, t". Output: "s_corrected".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">        s_corrected[<span class="string">'dW'</span> +  str(l + <span class="number">1</span>)] = s[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] / (<span class="number">1</span> - np.power(beta2, t));</span><br><span class="line">        s_corrected[<span class="string">'db'</span> +  str(l + <span class="number">1</span>)] = s[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] / (<span class="number">1</span> - np.power(beta2, t));</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update parameters. Inputs: "parameters, learning_rate, v_corrected, s_corrected, epsilon". Output: "parameters".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">        parameters[<span class="string">'W'</span> + str(l + <span class="number">1</span>)] -= learning_rate * v_corrected[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)] / (np.sqrt(s_corrected[<span class="string">'dW'</span> + str(l + <span class="number">1</span>)]) + epsilon);</span><br><span class="line">        parameters[<span class="string">'b'</span> + str(l + <span class="number">1</span>)] -= learning_rate * v_corrected[<span class="string">'db'</span> + str(l + <span class="number">1</span>)] / (np.sqrt(s_corrected[<span class="string">'db'</span> + str(l + <span class="number">1</span>)]) + epsilon);</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters, v, s</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">parameters, grads, v, s = update_parameters_with_adam_test_case()</span><br><span class="line">parameters, v, s  = update_parameters_with_adam(parameters, grads, v, s, t = <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]))</span><br><span class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]))</span><br><span class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]))</span><br><span class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]))</span><br><span class="line">print(<span class="string">"v[\"dW1\"] = "</span> + str(v[<span class="string">"dW1"</span>]))</span><br><span class="line">print(<span class="string">"v[\"db1\"] = "</span> + str(v[<span class="string">"db1"</span>]))</span><br><span class="line">print(<span class="string">"v[\"dW2\"] = "</span> + str(v[<span class="string">"dW2"</span>]))</span><br><span class="line">print(<span class="string">"v[\"db2\"] = "</span> + str(v[<span class="string">"db2"</span>]))</span><br><span class="line">print(<span class="string">"s[\"dW1\"] = "</span> + str(s[<span class="string">"dW1"</span>]))</span><br><span class="line">print(<span class="string">"s[\"db1\"] = "</span> + str(s[<span class="string">"db1"</span>]))</span><br><span class="line">print(<span class="string">"s[\"dW2\"] = "</span> + str(s[<span class="string">"dW2"</span>]))</span><br><span class="line">print(<span class="string">"s[\"db2\"] = "</span> + str(s[<span class="string">"db2"</span>]))</span><br></pre></td></tr></table></figure><pre><code>W1 = [[ 1.63178673 -0.61919778 -0.53561312]
 [-1.08040999  0.85796626 -2.29409733]]
b1 = [[ 1.75225313]
 [-0.75376553]]
W2 = [[ 0.32648046 -0.25681174  1.46954931]
 [-2.05269934 -0.31497584 -0.37661299]
 [ 1.14121081 -1.09244991 -0.16498684]]
b2 = [[-0.88529979]
 [ 0.03477238]
 [ 0.57537385]]
v[&quot;dW1&quot;] = [[-0.11006192  0.11447237  0.09015907]
 [ 0.05024943  0.09008559 -0.06837279]]
v[&quot;db1&quot;] = [[-0.01228902]
 [-0.09357694]]
v[&quot;dW2&quot;] = [[-0.02678881  0.05303555 -0.06916608]
 [-0.03967535 -0.06871727 -0.08452056]
 [-0.06712461 -0.00126646 -0.11173103]]
v[&quot;db2&quot;] = [[0.02344157]
 [0.16598022]
 [0.07420442]]
s[&quot;dW1&quot;] = [[0.00121136 0.00131039 0.00081287]
 [0.0002525  0.00081154 0.00046748]]
s[&quot;db1&quot;] = [[1.51020075e-05]
 [8.75664434e-04]]
s[&quot;dW2&quot;] = [[7.17640232e-05 2.81276921e-04 4.78394595e-04]
 [1.57413361e-04 4.72206320e-04 7.14372576e-04]
 [4.50571368e-04 1.60392066e-07 1.24838242e-03]]
s[&quot;db2&quot;] = [[5.49507194e-05]
 [2.75494327e-03]
 [5.50629536e-04]]</code></pre><p><strong>Expected Output</strong>:</p><table><thead><tr><th align="left">variable</th><th align="left">value</th></tr></thead><tbody><tr><td align="left"><strong>W1</strong></td><td align="left">[[ 1.63178673 -0.61919778 -0.53561312] [-1.08040999 0.85796626 -2.29409733]]</td></tr><tr><td align="left"><strong>b1</strong></td><td align="left">[[ 1.75225313] [-0.75376553]]</td></tr><tr><td align="left"><strong>W2</strong></td><td align="left">[[ 0.32648046 -0.25681174 1.46954931] [-2.05269934 -0.31497584 -0.37661299] [ 1.14121081 -1.09245036 -0.16498684]]</td></tr><tr><td align="left"><strong>b2</strong></td><td align="left">[[-0.88529978] [ 0.03477238] [ 0.57537385]]</td></tr><tr><td align="left"><strong>v[“dW1”]</strong></td><td align="left">[[-0.11006192 0.11447237 0.09015907] [ 0.05024943 0.09008559 -0.06837279]]</td></tr><tr><td align="left"><strong>v[“db1”]</strong></td><td align="left">[[-0.01228902] [-0.09357694]]</td></tr><tr><td align="left"><strong>v[“dW2”]</strong></td><td align="left">[[-0.02678881 0.05303555 -0.06916608] [-0.03967535 -0.06871727 -0.08452056] [-0.06712461 -0.00126646 -0.11173103]]</td></tr><tr><td align="left"><strong>v[“db2”]</strong></td><td align="left">[[ 0.02344157] [ 0.16598022] [ 0.07420442]]</td></tr><tr><td align="left"><strong>s[“dW1”]</strong></td><td align="left">[[ 0.00121136 0.00131039 0.00081287] [ 0.0002525 0.00081154 0.00046748]]</td></tr><tr><td align="left"><strong>s[“db1”]</strong></td><td align="left">[[ 1.51020075e-05] [ 8.75664434e-04]]</td></tr><tr><td align="left"><strong>s[“dW2”]</strong></td><td align="left">[[ 7.17640232e-05 2.81276921e-04 4.78394595e-04] [ 1.57413361e-04 4.72206320e-04 7.14372576e-04] [ 4.50571368e-04 1.60392066e-07 1.24838242e-03]]</td></tr><tr><td align="left"><strong>s[“db2”]</strong></td><td align="left">[[ 5.49507194e-05] [ 2.75494327e-03] [ 5.50629536e-04]]</td></tr></tbody></table><p>You now have three working optimization algorithms (mini-batch gradient descent, Momentum, Adam). Let’s implement a model with each of these optimizers and observe the difference.</p><h2 id="5-Model-with-different-optimization-algorithms"><a href="#5-Model-with-different-optimization-algorithms" class="headerlink" title="5 - Model with different optimization algorithms"></a>5 - Model with different optimization algorithms</h2><p>Lets use the following “moons” dataset to test the different optimization methods. (The dataset is named “moons” because the data from each of the two classes looks a bit like a crescent-shaped moon.)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_X, train_Y = load_dataset()</span><br></pre></td></tr></table></figure><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/output_21_0.png" alt="png"></p><p>We have already implemented a 3-layer neural network. You will train it with:</p><ul><li>Mini-batch Gradient Descent: it will call your function: <code>update_parameters_with_gd()</code></li><li>Mini-batch Momentum: it will call your functions: <code>initialize_velocity()</code> and <code>update_parameters_with_momentum()</code></li><li>Mini-batch Adam: it will call your functions: <code>initialize_adam()</code> and <code>update_parameters_with_adam()</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X, Y, layers_dims, optimizer, learning_rate = <span class="number">0.0007</span>, mini_batch_size = <span class="number">64</span>, beta = <span class="number">0.9</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">          beta1 = <span class="number">0.9</span>, beta2 = <span class="number">0.999</span>,  epsilon = <span class="number">1e-8</span>, num_epochs = <span class="number">10000</span>, print_cost = True)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    3-layer neural network model which can be run in different optimizer modes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input data, of shape (2, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    layers_dims -- python list, containing the size of each layer</span></span><br><span class="line"><span class="string">    learning_rate -- the learning rate, scalar.</span></span><br><span class="line"><span class="string">    mini_batch_size -- the size of a mini batch</span></span><br><span class="line"><span class="string">    beta -- Momentum hyperparameter</span></span><br><span class="line"><span class="string">    beta1 -- Exponential decay hyperparameter for the past gradients estimates </span></span><br><span class="line"><span class="string">    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates </span></span><br><span class="line"><span class="string">    epsilon -- hyperparameter preventing division by zero in Adam updates</span></span><br><span class="line"><span class="string">    num_epochs -- number of epochs</span></span><br><span class="line"><span class="string">    print_cost -- True to print the cost every 1000 epochs</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your updated parameters </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    L = len(layers_dims)             <span class="comment"># number of layers in the neural networks</span></span><br><span class="line">    costs = []                       <span class="comment"># to keep track of the cost</span></span><br><span class="line">    t = <span class="number">0</span>                            <span class="comment"># initializing the counter required for Adam update</span></span><br><span class="line">    seed = <span class="number">10</span>                        <span class="comment"># For grading purposes, so that your "random" minibatches are the same as ours</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize parameters</span></span><br><span class="line">    parameters = initialize_parameters(layers_dims)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize the optimizer</span></span><br><span class="line">    <span class="keyword">if</span> optimizer == <span class="string">"gd"</span>:</span><br><span class="line">        <span class="keyword">pass</span> <span class="comment"># no initialization required for gradient descent</span></span><br><span class="line">    <span class="keyword">elif</span> optimizer == <span class="string">"momentum"</span>:</span><br><span class="line">        v = initialize_velocity(parameters)</span><br><span class="line">    <span class="keyword">elif</span> optimizer == <span class="string">"adam"</span>:</span><br><span class="line">        v, s = initialize_adam(parameters)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Optimization loop</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_epochs):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch</span></span><br><span class="line">        seed = seed + <span class="number">1</span></span><br><span class="line">        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Select a minibatch</span></span><br><span class="line">            (minibatch_X, minibatch_Y) = minibatch</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Forward propagation</span></span><br><span class="line">            a3, caches = forward_propagation(minibatch_X, parameters)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Compute cost</span></span><br><span class="line">            cost = compute_cost(a3, minibatch_Y)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Backward propagation</span></span><br><span class="line">            grads = backward_propagation(minibatch_X, minibatch_Y, caches)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Update parameters</span></span><br><span class="line">            <span class="keyword">if</span> optimizer == <span class="string">"gd"</span>:</span><br><span class="line">                parameters = update_parameters_with_gd(parameters, grads, learning_rate)</span><br><span class="line">            <span class="keyword">elif</span> optimizer == <span class="string">"momentum"</span>:</span><br><span class="line">                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)</span><br><span class="line">            <span class="keyword">elif</span> optimizer == <span class="string">"adam"</span>:</span><br><span class="line">                t = t + <span class="number">1</span> <span class="comment"># Adam counter</span></span><br><span class="line">                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s,</span><br><span class="line">                                                               t, learning_rate, beta1, beta2,  epsilon)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print the cost every 1000 epoch</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Cost after epoch %i: %f"</span> %(i, cost))</span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            costs.append(cost)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot the cost</span></span><br><span class="line">    plt.plot(costs)</span><br><span class="line">    plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'epochs (per 100)'</span>)</span><br><span class="line">    plt.title(<span class="string">"Learning rate = "</span> + str(learning_rate))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><p>You will now run this 3 layer neural network with each of the 3 optimization methods.</p><h3 id="5-1-Mini-batch-Gradient-descent"><a href="#5-1-Mini-batch-Gradient-descent" class="headerlink" title="5.1 Mini-batch Gradient descent"></a>5.1 Mini-batch Gradient descent</h3><p>Run the following code to see how the model does with mini-batch gradient descent.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train 3-layer model</span></span><br><span class="line">layers_dims = [train_X.shape[<span class="number">0</span>], <span class="number">5</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">parameters = model(train_X, train_Y, layers_dims, optimizer = <span class="string">"gd"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predict</span></span><br><span class="line">predictions = predict(train_X, train_Y, parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot decision boundary</span></span><br><span class="line">plt.title(<span class="string">"Model with Gradient Descent optimization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>,<span class="number">2.5</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-1</span>,<span class="number">1.5</span>])</span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y)</span><br></pre></td></tr></table></figure><pre><code>Cost after epoch 0: 0.690736
Cost after epoch 1000: 0.685273
Cost after epoch 2000: 0.647072
Cost after epoch 3000: 0.619525
Cost after epoch 4000: 0.576584
Cost after epoch 5000: 0.607243
Cost after epoch 6000: 0.529403
Cost after epoch 7000: 0.460768
Cost after epoch 8000: 0.465586
Cost after epoch 9000: 0.464518</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/output_25_1.png" alt="png"></p><pre><code>Accuracy: 0.7966666666666666</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/output_25_3.png" alt="png"></p><h3 id="5-2-Mini-batch-gradient-descent-with-momentum"><a href="#5-2-Mini-batch-gradient-descent-with-momentum" class="headerlink" title="5.2 Mini-batch gradient descent with momentum"></a>5.2 Mini-batch gradient descent with momentum</h3><p>Run the following code to see how the model does with momentum. Because this example is relatively simple, the gains from using momemtum are small; but for more complex problems you might see bigger gains.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train 3-layer model</span></span><br><span class="line">layers_dims = [train_X.shape[<span class="number">0</span>], <span class="number">5</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">parameters = model(train_X, train_Y, layers_dims, beta = <span class="number">0.9</span>, optimizer = <span class="string">"momentum"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predict</span></span><br><span class="line">predictions = predict(train_X, train_Y, parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot decision boundary</span></span><br><span class="line">plt.title(<span class="string">"Model with Momentum optimization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>,<span class="number">2.5</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-1</span>,<span class="number">1.5</span>])</span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y)</span><br></pre></td></tr></table></figure><pre><code>Cost after epoch 0: 0.690741
Cost after epoch 1000: 0.685341
Cost after epoch 2000: 0.647145
Cost after epoch 3000: 0.619594
Cost after epoch 4000: 0.576665
Cost after epoch 5000: 0.607324
Cost after epoch 6000: 0.529476
Cost after epoch 7000: 0.460936
Cost after epoch 8000: 0.465780
Cost after epoch 9000: 0.464740</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/output_27_1.png" alt="png"></p><pre><code>Accuracy: 0.7966666666666666</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/output_27_3.png" alt="png"></p><h3 id="5-3-Mini-batch-with-Adam-mode"><a href="#5-3-Mini-batch-with-Adam-mode" class="headerlink" title="5.3 Mini-batch with Adam mode"></a>5.3 Mini-batch with Adam mode</h3><p>Run the following code to see how the model does with Adam.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train 3-layer model</span></span><br><span class="line">layers_dims = [train_X.shape[<span class="number">0</span>], <span class="number">5</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">parameters = model(train_X, train_Y, layers_dims, optimizer = <span class="string">"adam"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predict</span></span><br><span class="line">predictions = predict(train_X, train_Y, parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot decision boundary</span></span><br><span class="line">plt.title(<span class="string">"Model with Adam optimization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>,<span class="number">2.5</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-1</span>,<span class="number">1.5</span>])</span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y)</span><br></pre></td></tr></table></figure><pre><code>Cost after epoch 0: 0.690552
Cost after epoch 1000: 0.185567
Cost after epoch 2000: 0.150852
Cost after epoch 3000: 0.074454
Cost after epoch 4000: 0.125936
Cost after epoch 5000: 0.104235
Cost after epoch 6000: 0.100552
Cost after epoch 7000: 0.031601
Cost after epoch 8000: 0.111709
Cost after epoch 9000: 0.197648</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/output_29_1.png" alt="png"></p><pre><code>Accuracy: 0.94</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week2/output_29_3.png" alt="png"></p><h3 id="5-4-Summary"><a href="#5-4-Summary" class="headerlink" title="5.4 Summary"></a>5.4 Summary</h3><table><thead><tr><th><strong>optimization method</strong></th><th><strong>accuracy</strong></th><th><strong>cost shape</strong></th></tr></thead><tbody><tr><td>Gradient descent</td><td>79.7%</td><td>oscillations</td></tr><tr><td>Momentum</td><td>79.7%</td><td>oscillations</td></tr><tr><td>Adam</td><td>94%</td><td>smoother</td></tr></tbody></table><p>Momentum usually helps, but given the small learning rate and the simplistic dataset, its impact is almost negligeable. Also, the huge oscillations you see in the cost come from the fact that some minibatches are more difficult thans others for the optimization algorithm.</p><p>Adam on the other hand, clearly outperforms mini-batch gradient descent and Momentum. If you run the model for more epochs on this simple dataset, all three methods will lead to very good results. However, you’ve seen that Adam converges a lot faster.</p><p>Some advantages of Adam include:<br>- Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum)<br>- Usually works well even with little tuning of hyperparameters (except $α$)</p><p><strong>References</strong>:</p><ul><li>Adam paper: <a href="https://arxiv.org/pdf/1412.6980.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1412.6980.pdf</a></li></ul>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/03/01/practical-aspects-of-deep-learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/03/01/practical-aspects-of-deep-learning/" class="post-title-link" itemprop="url">practical-aspects-of-deep-learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-03-01 00:00:00" itemprop="dateCreated datePublished" datetime="2018-03-01T00:00:00+05:30">2018-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-06 20:25:38" itemprop="dateModified" datetime="2020-04-06T20:25:38+05:30">2020-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>58k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>53 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>These are my personal programming assignments at the 1th week after studying the course <a href="https://www.coursera.org/learn/deep-neural-network/" target="_blank" rel="noopener">Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</a> and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.</p><h1 id="Part-1：Initialization"><a href="#Part-1：Initialization" class="headerlink" title="Part 1：Initialization"></a>Part 1：Initialization</h1><p>A well chosen initialization can:</p><ul><li>Speed up the convergence of gradient descent</li><li>Increase the odds of gradient descent converging to a lower training (and generalization) error</li></ul><p>To get started, run the following cell to load the packages and the planar dataset you will try to classify.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets</span><br><span class="line"><span class="keyword">from</span> init_utils <span class="keyword">import</span> sigmoid, relu, compute_loss, forward_propagation, backward_propagation</span><br><span class="line"><span class="keyword">from</span> init_utils <span class="keyword">import</span> update_parameters, predict, load_dataset, plot_decision_boundary, predict_dec</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">7.0</span>, <span class="number">4.0</span>); <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span>;</span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># load image dataset: blue/red dots in circles</span></span><br><span class="line">train_X, train_Y, test_X, test_Y = load_dataset();</span><br></pre></td></tr></table></figure><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Initialization/output_1_0.png" alt="png"></p><p>There are some import function：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Compute the sigmoid of x</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    x -- A scalar or numpy array of any size.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">    s -- sigmoid(x)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    s = <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Compute the relu of x</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    x -- A scalar or numpy array of any size.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">    s -- relu(x)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    s = np.maximum(<span class="number">0</span>,x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_loss</span><span class="params">(a3, Y)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the loss function</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    a3 -- post-activation, output of forward propagation</span></span><br><span class="line"><span class="string">    Y -- "true" labels vector, same shape as a3</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    loss - value of the loss function</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    m = Y.shape[<span class="number">1</span>]</span><br><span class="line">    logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(<span class="number">1</span> - a3), <span class="number">1</span> - Y)</span><br><span class="line">    loss = <span class="number">1.</span>/m * np.nansum(logprobs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the forward propagation (and computes the loss) presented in Figure 2.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input dataset, of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (containing 0 if cat, 1 if non-cat)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters "W1", "b1", "W2", "b2", "W3", "b3":</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape ()</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape ()</span></span><br><span class="line"><span class="string">                    W2 -- weight matrix of shape ()</span></span><br><span class="line"><span class="string">                    b2 -- bias vector of shape ()</span></span><br><span class="line"><span class="string">                    W3 -- weight matrix of shape ()</span></span><br><span class="line"><span class="string">                    b3 -- bias vector of shape ()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    loss -- the loss function (vanilla logistic loss)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># retrieve parameters</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line">    W3 = parameters[<span class="string">"W3"</span>]</span><br><span class="line">    b3 = parameters[<span class="string">"b3"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</span></span><br><span class="line">    z1 = np.dot(W1, X) + b1</span><br><span class="line">    a1 = relu(z1)</span><br><span class="line">    z2 = np.dot(W2, a1) + b2</span><br><span class="line">    a2 = relu(z2)</span><br><span class="line">    z3 = np.dot(W3, a2) + b3</span><br><span class="line">    a3 = sigmoid(z3)</span><br><span class="line"></span><br><span class="line">    cache = (z1, a1, W1, b1, z2, a2, W2, b2, z3, a3, W3, b3)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> a3, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation</span><span class="params">(X, Y, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward propagation presented in figure 2.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input dataset, of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (containing 0 if cat, 1 if non-cat)</span></span><br><span class="line"><span class="string">    cache -- cache output from forward_propagation()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    (z1, a1, W1, b1, z2, a2, W2, b2, z3, a3, W3, b3) = cache</span><br><span class="line"></span><br><span class="line">    dz3 = <span class="number">1.</span>/m * (a3 - Y)</span><br><span class="line">    dW3 = np.dot(dz3, a2.T)</span><br><span class="line">    db3 = np.sum(dz3, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    da2 = np.dot(W3.T, dz3)</span><br><span class="line">    dz2 = np.multiply(da2, np.int64(a2 &gt; <span class="number">0</span>))</span><br><span class="line">    dW2 = np.dot(dz2, a1.T)</span><br><span class="line">    db2 = np.sum(dz2, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    da1 = np.dot(W2.T, dz2)</span><br><span class="line">    dz1 = np.multiply(da1, np.int64(a1 &gt; <span class="number">0</span>))</span><br><span class="line">    dW1 = np.dot(dz1, X.T)</span><br><span class="line">    db1 = np.sum(dz1, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    gradients = &#123;<span class="string">"dz3"</span>: dz3, <span class="string">"dW3"</span>: dW3, <span class="string">"db3"</span>: db3,</span><br><span class="line">                 <span class="string">"da2"</span>: da2, <span class="string">"dz2"</span>: dz2, <span class="string">"dW2"</span>: dW2, <span class="string">"db2"</span>: db2,</span><br><span class="line">                 <span class="string">"da1"</span>: da1, <span class="string">"dz1"</span>: dz1, <span class="string">"dW1"</span>: dW1, <span class="string">"db1"</span>: db1&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gradients</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, grads, learning_rate)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Update parameters using gradient descent</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters </span></span><br><span class="line"><span class="string">    grads -- python dictionary containing your gradients, output of n_model_backward</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your updated parameters </span></span><br><span class="line"><span class="string">                  parameters['W' + str(i)] = ... </span></span><br><span class="line"><span class="string">                  parameters['b' + str(i)] = ...</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    L = len(parameters) // <span class="number">2</span> <span class="comment"># number of layers in the neural networks</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update rule for each parameter</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(L):</span><br><span class="line">        parameters[<span class="string">"W"</span> + str(k+<span class="number">1</span>)] = parameters[<span class="string">"W"</span> + str(k+<span class="number">1</span>)] - learning_rate * grads[<span class="string">"dW"</span> + str(k+<span class="number">1</span>)]</span><br><span class="line">        parameters[<span class="string">"b"</span> + str(k+<span class="number">1</span>)] = parameters[<span class="string">"b"</span> + str(k+<span class="number">1</span>)] - learning_rate * grads[<span class="string">"db"</span> + str(k+<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(X, y, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    This function is used to predict the results of a  n-layer neural network.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- data set of examples you would like to label</span></span><br><span class="line"><span class="string">    parameters -- parameters of the trained model</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    p -- predictions for the given dataset X</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    p = np.zeros((<span class="number">1</span>,m), dtype = np.int)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Forward propagation</span></span><br><span class="line">    a3, caches = forward_propagation(X, parameters)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># convert probas to 0/1 predictions</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, a3.shape[<span class="number">1</span>]):</span><br><span class="line">        <span class="keyword">if</span> a3[<span class="number">0</span>,i] &gt; <span class="number">0.5</span>:</span><br><span class="line">            p[<span class="number">0</span>,i] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            p[<span class="number">0</span>,i] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># print results</span></span><br><span class="line">    print(<span class="string">"Accuracy: "</span>  + str(np.mean((p[<span class="number">0</span>,:] == y[<span class="number">0</span>,:]))))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> p</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span><span class="params">()</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    train_X, train_Y = sklearn.datasets.make_circles(n_samples=<span class="number">300</span>, noise=<span class="number">.05</span>)</span><br><span class="line">    np.random.seed(<span class="number">2</span>)</span><br><span class="line">    test_X, test_Y = sklearn.datasets.make_circles(n_samples=<span class="number">100</span>, noise=<span class="number">.05</span>)</span><br><span class="line">    <span class="comment"># Visualize the data</span></span><br><span class="line">    plt.scatter(train_X[:, <span class="number">0</span>], train_X[:, <span class="number">1</span>], c=train_Y, s=<span class="number">40</span>, cmap=plt.cm.Spectral);</span><br><span class="line">    train_X = train_X.T</span><br><span class="line">    train_Y = train_Y.reshape((<span class="number">1</span>, train_Y.shape[<span class="number">0</span>]))</span><br><span class="line">    test_X = test_X.T</span><br><span class="line">    test_Y = test_Y.reshape((<span class="number">1</span>, test_Y.shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="keyword">return</span> train_X, train_Y, test_X, test_Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_boundary</span><span class="params">(model, X, y)</span>:</span></span><br><span class="line">    <span class="comment"># Set min and max values and give it some padding</span></span><br><span class="line">    x_min, x_max = X[<span class="number">0</span>, :].min() - <span class="number">1</span>, X[<span class="number">0</span>, :].max() + <span class="number">1</span></span><br><span class="line">    y_min, y_max = X[<span class="number">1</span>, :].min() - <span class="number">1</span>, X[<span class="number">1</span>, :].max() + <span class="number">1</span></span><br><span class="line">    h = <span class="number">0.01</span></span><br><span class="line">    <span class="comment"># Generate a grid of points with distance h between them</span></span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))</span><br><span class="line">    <span class="comment"># Predict the function value for the whole grid</span></span><br><span class="line">    Z = model(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    <span class="comment"># Plot the contour and training examples</span></span><br><span class="line">    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)</span><br><span class="line">    plt.ylabel(<span class="string">'x2'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'x1'</span>)</span><br><span class="line">    plt.scatter(X[<span class="number">0</span>, :], X[<span class="number">1</span>, :], c=np.squeeze(y), cmap=plt.cm.Spectral)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_dec</span><span class="params">(parameters, X)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Used for plotting decision boundary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters </span></span><br><span class="line"><span class="string">    X -- input data of size (m, K)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    predictions -- vector of predictions of our model (red: 0 / blue: 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Predict using forward propagation and a classification threshold of 0.5</span></span><br><span class="line">    a3, cache = forward_propagation(X, parameters)</span><br><span class="line">    predictions = (a3 &gt; <span class="number">0.5</span>)</span><br><span class="line">    <span class="keyword">return</span> predictions</span><br></pre></td></tr></table></figure><p>You would like a classifier to separate the blue dots from the red dots.</p><h2 id="1-Neural-Network-model"><a href="#1-Neural-Network-model" class="headerlink" title="1. Neural Network model"></a>1. Neural Network model</h2><p>You will use a 3-layer neural network (already implemented for you). Here are the initialization methods you will experiment with:</p><ul><li>Zeros initialization – setting initialization = “zeros” in the input argument.</li><li>Random initialization – setting initialization = “random” in the input argument. This initializes the weights to large random values.</li><li>He initialization – setting initialization = “he” in the input argument. This initializes the weights to random values scaled according to a paper by He et al., 2015.</li></ul><p><strong>Instructions</strong>: Please quickly read over the code below, and run it. In the next part you will implement the three initialization methods that this <code>model()</code> calls.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X, Y, learning_rate = <span class="number">0.01</span>, num_iterations = <span class="number">15000</span>, print_cost = True, initialization = <span class="string">"he"</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements a three-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input data, of shape (2, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (containing 0 for red dots; 1 for blue dots), of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate for gradient descent </span></span><br><span class="line"><span class="string">    num_iterations -- number of iterations to run gradient descent</span></span><br><span class="line"><span class="string">    print_cost -- if True, print the cost every 1000 iterations</span></span><br><span class="line"><span class="string">    initialization -- flag to choose which initialization to use ("zeros","random" or "he")</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- parameters learnt by the model</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    grads = &#123;&#125;</span><br><span class="line">    costs = [] <span class="comment"># to keep track of the loss</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>] <span class="comment"># number of examples</span></span><br><span class="line">    layers_dims = [X.shape[<span class="number">0</span>], <span class="number">10</span>, <span class="number">5</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize parameters dictionary.</span></span><br><span class="line">    <span class="keyword">if</span> initialization == <span class="string">"zeros"</span>:</span><br><span class="line">        parameters = initialize_parameters_zeros(layers_dims)</span><br><span class="line">    <span class="keyword">elif</span> initialization == <span class="string">"random"</span>:</span><br><span class="line">        parameters = initialize_parameters_random(layers_dims)</span><br><span class="line">    <span class="keyword">elif</span> initialization == <span class="string">"he"</span>:</span><br><span class="line">        parameters = initialize_parameters_he(layers_dims)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loop (gradient descent)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID.</span></span><br><span class="line">        a3, cache = forward_propagation(X, parameters)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Loss</span></span><br><span class="line">        cost = compute_loss(a3, Y)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backward propagation.</span></span><br><span class="line">        grads = backward_propagation(X, Y, cache)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update parameters.</span></span><br><span class="line">        parameters = update_parameters(parameters, grads, learning_rate)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print the loss every 1000 iterations</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Cost after iteration &#123;&#125;: &#123;&#125;"</span>.format(i, cost))</span><br><span class="line">            costs.append(cost)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot the loss</span></span><br><span class="line">    plt.plot(costs)</span><br><span class="line">    plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'iterations (per hundreds)'</span>)</span><br><span class="line">    plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h2 id="2-Zero-initialization"><a href="#2-Zero-initialization" class="headerlink" title="2. Zero initialization"></a>2. Zero initialization</h2><p>There are two types of parameters to initialize in a neural network:</p><ul><li>the weight matrices $(W^{[1]},W^{[2]},W^{[3]},…,W^{[L−1]},W^{[L]})$</li><li>the bias vectors $(b^{[1]},b^{[2]},b^{[3]},…,b^{[L−1]},b^{[L]})$</li></ul><p><strong>Exercise</strong>: Implement the following function to initialize all parameters to zeros. You’ll see later that this does not work well since it fails to “break symmetry”, but lets try it anyway and see what happens. Use <code>np.zeros((..,..))</code> with the correct shapes.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: initialize_parameters_zeros </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters_zeros</span><span class="params">(layers_dims)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    layer_dims -- python array (list) containing the size of each layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL":</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (layers_dims[1], 1)</span></span><br><span class="line"><span class="string">                    ...</span></span><br><span class="line"><span class="string">                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])</span></span><br><span class="line"><span class="string">                    bL -- bias vector of shape (layers_dims[L], 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    parameters = &#123;&#125;;</span><br><span class="line">    L = len(layers_dims);            <span class="comment"># number of layers in the network</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L):</span><br><span class="line">        <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span><br><span class="line">        parameters[<span class="string">'W'</span> + str(l)] = np.zeros((layers_dims[l],layers_dims[l<span class="number">-1</span>]));</span><br><span class="line">        parameters[<span class="string">'b'</span> + str(l)] = np.zeros((layers_dims[l],<span class="number">1</span>));</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> parameters;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = initialize_parameters_zeros([<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>]);</span><br><span class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]));</span><br><span class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]));</span><br><span class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]));</span><br><span class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]));</span><br></pre></td></tr></table></figure><pre><code>W1 = [[0. 0. 0.]
 [0. 0. 0.]]
b1 = [[0.]
 [0.]]
W2 = [[0. 0.]]
b2 = [[0.]]</code></pre><p>Run the following code to train your model on 15,000 iterations using zeros initialization.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y, initialization = <span class="string">"zeros"</span>);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the train set:"</span>);</span><br><span class="line">predictions_train = predict(train_X, train_Y, parameters);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the test set:"</span>);</span><br><span class="line">predictions_test = predict(test_X, test_Y, parameters);</span><br></pre></td></tr></table></figure><pre><code>Cost after iteration 0: 0.6931471805599453
Cost after iteration 1000: 0.6931471805599453
Cost after iteration 2000: 0.6931471805599453
Cost after iteration 3000: 0.6931471805599453
Cost after iteration 4000: 0.6931471805599453
Cost after iteration 5000: 0.6931471805599453
Cost after iteration 6000: 0.6931471805599453
Cost after iteration 7000: 0.6931471805599453
Cost after iteration 8000: 0.6931471805599453
Cost after iteration 9000: 0.6931471805599453
Cost after iteration 10000: 0.6931471805599455
Cost after iteration 11000: 0.6931471805599453
Cost after iteration 12000: 0.6931471805599453
Cost after iteration 13000: 0.6931471805599453
Cost after iteration 14000: 0.6931471805599453</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Initialization/output_10_1.png" alt="png"></p><pre><code>On the train set:
Accuracy: 0.5
On the test set:
Accuracy: 0.5</code></pre><p>The performance is really bad, and the cost does not really decrease, and the algorithm performs no better than random guessing. Why? Lets look at the details of the predictions and the decision boundary:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"predictions_train = "</span> + str(predictions_train));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"predictions_test = "</span> + str(predictions_test));</span><br></pre></td></tr></table></figure><pre><code>predictions_train = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0]]
predictions_test = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Model with Zeros initialization"</span>);</span><br><span class="line">axes = plt.gca();</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>,<span class="number">1.5</span>]);</span><br><span class="line">axes.set_ylim([<span class="number">-1.5</span>,<span class="number">1.5</span>]);</span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y);</span><br></pre></td></tr></table></figure><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Initialization/output_13_0.png" alt="png"></p><p>The model is predicting 0 for every example.</p><p>In general, initializing all the weights to zero results in the network failing to break symmetry. This means that every neuron in each layer will learn the same thing, and you might as well be training a neural network with $n^{[l]} = 1$ for every layer, and the network is no more powerful than a linear classifier such as logistic regression.</p><p>What you should remember:</p><ul><li>The weights $W^{[l]}$ should be initialized randomly to break symmetry.</li><li>It is however okay to initialize the biases $b^{[l]}$ to zeros. Symmetry is still broken so long as $W^{[l]}$ is initialized randomly.</li></ul><h2 id="3-Random-initialization"><a href="#3-Random-initialization" class="headerlink" title="3. Random initialization"></a>3. Random initialization</h2><p>To break symmetry, lets intialize the weights randomly. Following random initialization, each neuron can then proceed to learn a different function of its inputs. In this exercise, you will see what happens if the weights are intialized randomly, but to very large values.</p><p><strong>Exercise</strong>:</p><p>Implement the following function to initialize your weights to large random values (scaled by * 10) and your biases to zeros. Use <code>np.random.randn(...) * 10</code> for weights and <code>np.zeros((...))</code> for biases. We are using a fixed <code>np.random.seed(..)</code> to make sure your “random” weights match ours, so don’t worry if running several times your code gives you always the same initial values for the parameters.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: initialize_parameters_random</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters_random</span><span class="params">(layers_dims)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    layer_dims -- python array (list) containing the size of each layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL":</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (layers_dims[1], 1)</span></span><br><span class="line"><span class="string">                    ...</span></span><br><span class="line"><span class="string">                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])</span></span><br><span class="line"><span class="string">                    bL -- bias vector of shape (layers_dims[L], 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="number">3</span>);               <span class="comment"># This seed makes sure your "random" numbers will be the as ours</span></span><br><span class="line">    parameters = &#123;&#125;;</span><br><span class="line">    L = len(layers_dims);            <span class="comment"># integer representing the number of layers</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L):</span><br><span class="line">        <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span><br><span class="line">        parameters[<span class="string">"W"</span> + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - <span class="number">1</span>]) * <span class="number">10</span>;</span><br><span class="line">        parameters[<span class="string">"b"</span> + str(l)] = np.zeros((layers_dims[l], <span class="number">1</span>));</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = initialize_parameters_random([<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]);</span><br><span class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]));</span><br><span class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]));</span><br><span class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]));</span><br><span class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]));</span><br></pre></td></tr></table></figure><pre><code>W1 = [[ 17.88628473   4.36509851   0.96497468]
 [-18.63492703  -2.77388203  -3.54758979]]
b1 = [[0.]
 [0.]]
W2 = [[-0.82741481 -6.27000677]]
b2 = [[0.]]</code></pre><p>Run the following code to train your model on 15,000 iterations using random initialization.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y, initialization = <span class="string">"random"</span>);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the train set:"</span>);</span><br><span class="line">predictions_train = predict(train_X, train_Y, parameters);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the test set:"</span>);</span><br><span class="line">predictions_test = predict(test_X, test_Y, parameters);</span><br></pre></td></tr></table></figure><pre><code>Cost after iteration 0: inf


C:\Anaconda3\lib\site-packages\ipykernel\__main__.py:44: RuntimeWarning: divide by zero encountered in log
C:\Anaconda3\lib\site-packages\ipykernel\__main__.py:44: RuntimeWarning: invalid value encountered in multiply


Cost after iteration 1000: 0.6243339944795463
Cost after iteration 2000: 0.5983698376976234
Cost after iteration 3000: 0.5640713641303857
Cost after iteration 4000: 0.5502225777263651
Cost after iteration 5000: 0.5445189912897229
Cost after iteration 6000: 0.5374939942050982
Cost after iteration 7000: 0.47927872911735586
Cost after iteration 8000: 0.39787508336662053
Cost after iteration 9000: 0.3934925383461005
Cost after iteration 10000: 0.3920373161708829
Cost after iteration 11000: 0.38930570830972355
Cost after iteration 12000: 0.3861562072516527
Cost after iteration 13000: 0.38499595295812233
Cost after iteration 14000: 0.38280923039736164</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Initialization/output_18_3.png" alt="png"></p><pre><code>On the train set:
Accuracy: 0.83
On the test set:
Accuracy: 0.86</code></pre><p>If you see “inf” as the cost after the iteration 0, this is because of numerical roundoff; a more numerically sophisticated implementation would fix this. But this isn’t worth worrying about for our purposes.</p><p>Anyway, it looks like you have broken symmetry, and this gives better results. than before. The model is no longer outputting all 0s.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> (predictions_train);</span><br><span class="line"><span class="keyword">print</span> (predictions_test);</span><br></pre></td></tr></table></figure><pre><code>[[1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1
  1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0
  0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0
  1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0
  0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1
  1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1
  0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1
  1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1
  1 1 1 1 0 0 0 1 1 1 1 0]]
[[1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1
  0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0
  1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Model with large random initialization"</span>);</span><br><span class="line">axes = plt.gca();</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>,<span class="number">1.5</span>]);</span><br><span class="line">axes.set_ylim([<span class="number">-1.5</span>,<span class="number">1.5</span>]);</span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y);</span><br></pre></td></tr></table></figure><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Initialization/output_21_0.png" alt="png"></p><p><strong>Observations</strong>:</p><ul><li>The cost starts very high. This is because with large random-valued weights, the last activation (sigmoid) outputs results that are very close to 0 or 1 for some examples, and when it gets that example wrong it incurs a very high loss for that example. Indeed, when $log(a^{[3]})=log(0)$, the loss goes to infinity.</li><li>Poor initialization can lead to vanishing/exploding gradients, which also slows down the optimization algorithm.</li><li>If you train this network longer you will see better results, but initializing with overly large random numbers slows down the optimization.</li></ul><p><strong>In summary</strong>:</p><ul><li>Initializing weights to very large random values does not work well.</li><li>Hopefully intializing with small random values does better. The important question is: how small should be these random values be? Lets find out in the next part!</li></ul><h2 id="4-He-initialization"><a href="#4-He-initialization" class="headerlink" title="4. He initialization"></a>4. He initialization</h2><p>Finally, try “He Initialization”; this is named for the first author of He et al., 2015. (If you have heard of “Xavier initialization”, this is similar except Xavier initialization uses a scaling factor for the weights $W^{[l]}$ of <code>sqrt(1./layers_dims[l-1])</code> where He initialization would use <code>sqrt(2./layers_dims[l-1])</code>.)</p><p><strong>Exercise</strong>:</p><p>Implement the following function to initialize your parameters with He initialization.</p><p><strong>Hint</strong>:</p><p>This function is similar to the previous <code>initialize_parameters_random()</code>. The only difference is that instead of multiplying <code>np.random.randn(..,..)</code> by 10, you will multiply it by 2dimension of the previous layer $\sqrt{\frac{2}{\text{dimension of the previous layer}}}$, which is what He initialization recommends for layers with a ReLU activation.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: initialize_parameters_he</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters_he</span><span class="params">(layers_dims)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    layer_dims -- python array (list) containing the size of each layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL":</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (layers_dims[1], 1)</span></span><br><span class="line"><span class="string">                    ...</span></span><br><span class="line"><span class="string">                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])</span></span><br><span class="line"><span class="string">                    bL -- bias vector of shape (layers_dims[L], 1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="number">3</span>);</span><br><span class="line">    parameters = &#123;&#125;;</span><br><span class="line">    L = len(layers_dims) - <span class="number">1</span>; <span class="comment"># integer representing the number of layers</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L + <span class="number">1</span>):</span><br><span class="line">        <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span><br><span class="line">        parameters[<span class="string">"W"</span> + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - <span class="number">1</span>]) * np.sqrt(<span class="number">2</span> / layers_dims[l - <span class="number">1</span>]);</span><br><span class="line">        parameters[<span class="string">"b"</span> + str(l)] = np.zeros((layers_dims[l], <span class="number">1</span>));</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = initialize_parameters_he([<span class="number">2</span>, <span class="number">4</span>, <span class="number">1</span>]);</span><br><span class="line">print(<span class="string">"W1 = "</span> + str(parameters[<span class="string">"W1"</span>]));</span><br><span class="line">print(<span class="string">"b1 = "</span> + str(parameters[<span class="string">"b1"</span>]));</span><br><span class="line">print(<span class="string">"W2 = "</span> + str(parameters[<span class="string">"W2"</span>]));</span><br><span class="line">print(<span class="string">"b2 = "</span> + str(parameters[<span class="string">"b2"</span>]));</span><br></pre></td></tr></table></figure><pre><code>W1 = [[ 1.78862847  0.43650985]
 [ 0.09649747 -1.8634927 ]
 [-0.2773882  -0.35475898]
 [-0.08274148 -0.62700068]]
b1 = [[0.]
 [0.]
 [0.]
 [0.]]
W2 = [[-0.03098412 -0.33744411 -0.92904268  0.62552248]]
b2 = [[0.]]</code></pre><p>Run the following code to train your model on 15,000 iterations using He initialization.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y, initialization = <span class="string">"he"</span>);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the train set:"</span>);</span><br><span class="line">predictions_train = predict(train_X, train_Y, parameters);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the test set:"</span>);</span><br><span class="line">predictions_test = predict(test_X, test_Y, parameters);</span><br></pre></td></tr></table></figure><pre><code>Cost after iteration 0: 0.8830537463419761
Cost after iteration 1000: 0.6879825919728063
Cost after iteration 2000: 0.6751286264523371
Cost after iteration 3000: 0.6526117768893807
Cost after iteration 4000: 0.6082958970572938
Cost after iteration 5000: 0.5304944491717495
Cost after iteration 6000: 0.4138645817071795
Cost after iteration 7000: 0.31178034648444414
Cost after iteration 8000: 0.23696215330322562
Cost after iteration 9000: 0.18597287209206836
Cost after iteration 10000: 0.15015556280371808
Cost after iteration 11000: 0.12325079292273551
Cost after iteration 12000: 0.09917746546525934
Cost after iteration 13000: 0.08457055954024277
Cost after iteration 14000: 0.07357895962677363</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Initialization/output_27_1.png" alt="png"></p><pre><code>On the train set:
Accuracy: 0.9933333333333333
On the test set:
Accuracy: 0.96</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Model with He initialization"</span>);</span><br><span class="line">axes = plt.gca();</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>,<span class="number">1.5</span>]);</span><br><span class="line">axes.set_ylim([<span class="number">-1.5</span>,<span class="number">1.5</span>]);</span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y);</span><br></pre></td></tr></table></figure><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Initialization/output_28_0.png" alt="png"></p><p><strong>Observations</strong>:</p><ul><li>The model with He initialization separates the blue and the red dots very well in a small number of iterations.</li></ul><h2 id="5-Conclusions"><a href="#5-Conclusions" class="headerlink" title="5. Conclusions"></a>5. Conclusions</h2><p>You have seen three different types of initializations. For the same number of iterations and same hyperparameters the comparison is:</p><p>comparison is:</p><table><thead><tr><th align="center"><strong>Model</strong></th><th align="center"><strong>Train accuracy</strong></th><th align="center"><strong>Problem/Comment</strong></th></tr></thead><tbody><tr><td align="center">3-layer NN with zeros initialization</td><td align="center">50%</td><td align="center">fails to break symmetry</td></tr><tr><td align="center">3-layer NN with large random initialization</td><td align="center">83%</td><td align="center">too large weights</td></tr><tr><td align="center">3-layer NN with He initialization</td><td align="center">99%</td><td align="center">recommended method</td></tr></tbody></table><p>What you should remember from this notebook:</p><ul><li>Different initializations lead to different results</li><li>Random initialization is used to break symmetry and make sure different hidden units can learn different things</li><li>Don’t intialize to values that are too large</li><li>He initialization works well for networks with <code>ReLU</code> activations.</li></ul><h1 id="Part-2：Regularization"><a href="#Part-2：Regularization" class="headerlink" title="Part 2：Regularization"></a>Part 2：Regularization</h1><p>Let’s first import the packages you are going to use.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import packages</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> reg_utils <span class="keyword">import</span> sigmoid, relu, plot_decision_boundary, initialize_parameters, load_2D_dataset, predict_dec</span><br><span class="line"><span class="keyword">from</span> reg_utils <span class="keyword">import</span> compute_cost, predict, forward_propagation, backward_propagation, update_parameters</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets</span><br><span class="line"><span class="keyword">import</span> scipy.io</span><br><span class="line"><span class="keyword">from</span> testCases <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">7.0</span>, <span class="number">4.0</span>) <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></span><br></pre></td></tr></table></figure><pre><code>C:\Anaconda3\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters</code></pre><p>There are some function imported：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">(layer_dims)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    layer_dims -- python array (list) containing the dimensions of each layer in our network</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL":</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (layer_dims[l], layer_dims[l-1])</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (layer_dims[l], 1)</span></span><br><span class="line"><span class="string">                    Wl -- weight matrix of shape (layer_dims[l-1], layer_dims[l])</span></span><br><span class="line"><span class="string">                    bl -- bias vector of shape (1, layer_dims[l])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Tips:</span></span><br><span class="line"><span class="string">    - For example: the layer_dims for the "Planar Data classification model" would have been [2,2,1]. </span></span><br><span class="line"><span class="string">    This means W1's shape was (2,2), b1 was (1,2), W2 was (2,1) and b2 was (1,1). Now you have to generalize it!</span></span><br><span class="line"><span class="string">    - In the for loop, use parameters['W' + str(l)] to access Wl, where l is the iterative integer.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="number">3</span>)</span><br><span class="line">    parameters = &#123;&#125;</span><br><span class="line">    L = len(layer_dims) <span class="comment"># number of layers in the network</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L):</span><br><span class="line">        parameters[<span class="string">'W'</span> + str(l)] = np.random.randn(layer_dims[l], layer_dims[l<span class="number">-1</span>]) / np.sqrt(layer_dims[l<span class="number">-1</span>])</span><br><span class="line">        parameters[<span class="string">'b'</span> + str(l)] = np.zeros((layer_dims[l], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span>(parameters[<span class="string">'W'</span> + str(l)].shape == layer_dims[l], layer_dims[l<span class="number">-1</span>])</span><br><span class="line">        <span class="keyword">assert</span>(parameters[<span class="string">'W'</span> + str(l)].shape == layer_dims[l], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(a3, Y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the cost function</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    a3 -- post-activation, output of forward propagation</span></span><br><span class="line"><span class="string">    Y -- "true" labels vector, same shape as a3</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    cost - value of the cost function</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    m = Y.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(<span class="number">1</span> - a3), <span class="number">1</span> - Y)</span><br><span class="line">    cost = <span class="number">1.</span>/m * np.nansum(logprobs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cost</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_2D_dataset</span><span class="params">()</span>:</span></span><br><span class="line">    data = scipy.io.loadmat(<span class="string">'datasets/data.mat'</span>)</span><br><span class="line">    train_X = data[<span class="string">'X'</span>].T</span><br><span class="line">    train_Y = data[<span class="string">'y'</span>].T</span><br><span class="line">    test_X = data[<span class="string">'Xval'</span>].T</span><br><span class="line">    test_Y = data[<span class="string">'yval'</span>].T</span><br><span class="line"></span><br><span class="line">    plt.scatter(train_X[<span class="number">0</span>, :], train_X[<span class="number">1</span>, :], c=np.squeeze(train_Y), s=<span class="number">40</span>, cmap=plt.cm.Spectral);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_X, train_Y, test_X, test_Y</span><br></pre></td></tr></table></figure><pre><code>&lt;ipython-input-2-41dc022e1c22&gt;:27: SyntaxWarning: assertion is always true, perhaps remove parentheses?
  assert(parameters[&apos;W&apos; + str(l)].shape == layer_dims[l], layer_dims[l-1])
&lt;ipython-input-2-41dc022e1c22&gt;:28: SyntaxWarning: assertion is always true, perhaps remove parentheses?
  assert(parameters[&apos;W&apos; + str(l)].shape == layer_dims[l], 1)</code></pre><p><strong>Problem Statement</strong>: You have just been hired as an AI expert by the French Football Corporation. They would like you to recommend positions where France’s goal keeper should kick the ball so that the French team’s players can then hit it with their head.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Regularization/1.png" alt=""></p><p>$$\text{Figure 1 : Football field}$$<br>$$\text{The goal keeper kicks the ball in the air, the players of each team are fighting to hit the ball with their head}$$</p><p>They give you the following 2D dataset from France’s past 10 games.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_X, train_Y, test_X, test_Y = load_2D_dataset();</span><br></pre></td></tr></table></figure><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Regularization/output_6_0.png" alt="png"></p><p>Each dot corresponds to a position on the football field where a football player has hit the ball with his/her head after the French goal keeper has shot the ball from the left side of the football field.</p><ul><li>If the dot is blue, it means the French player managed to hit the ball with his/her head</li><li>If the dot is red, it means the other team’s player hit the ball with their head</li></ul><p><strong>Your goal</strong>: Use a deep learning model to find the positions on the field where the goalkeeper should kick the ball.</p><p><strong>Analysis of the dataset</strong>: This dataset is a little noisy, but it looks like a diagonal line separating the upper left half (blue) from the lower right half (red) would work well.</p><p>You will first try a non-regularized model. Then you’ll learn how to regularize it and decide which model you will choose to solve the French Football Corporation’s problem.</p><h2 id="1-Non-regularized-model"><a href="#1-Non-regularized-model" class="headerlink" title="1. Non-regularized model"></a>1. Non-regularized model</h2><p>You will use the following neural network (already implemented for you below). This model can be used:</p><ul><li>in regularization mode – by setting the lambd input to a non-zero value. We use “lambd” instead of “lambda” because “lambda” is a reserved keyword in Python.</li><li>in dropout mode – by setting the keep_prob to a value less than one</li></ul><p>You will first try the model without any regularization. Then, you will implement:</p><ul><li>L2 regularization – functions: “<code>compute_cost_with_regularization()</code>” and “<code>backward_propagation_with_regularization()</code>”</li><li>Dropout – functions: “<code>forward_propagation_with_dropout()</code>” and “<code>backward_propagation_with_dropout()</code>”</li></ul><p>In each part, you will run this model with the correct inputs so that it calls the functions you’ve implemented. Take a look at the code below to familiarize yourself with the model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X, Y, learning_rate = <span class="number">0.3</span>, num_iterations = <span class="number">30000</span>, print_cost = True, lambd = <span class="number">0</span>, keep_prob = <span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements a three-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input data, of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (1 for blue dot / 0 for red dot), of shape (output size, number of examples)</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate of the optimization</span></span><br><span class="line"><span class="string">    num_iterations -- number of iterations of the optimization loop</span></span><br><span class="line"><span class="string">    print_cost -- If True, print the cost every 10000 iterations</span></span><br><span class="line"><span class="string">    lambd -- regularization hyperparameter, scalar</span></span><br><span class="line"><span class="string">    keep_prob - probability of keeping a neuron active during drop-out, scalar.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- parameters learned by the model. They can then be used to predict.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    grads = &#123;&#125;</span><br><span class="line">    costs = []                            <span class="comment"># to keep track of the cost</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]                        <span class="comment"># number of examples</span></span><br><span class="line">    layers_dims = [X.shape[<span class="number">0</span>], <span class="number">20</span>, <span class="number">3</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize parameters dictionary.</span></span><br><span class="line">    parameters = initialize_parameters(layers_dims)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loop (gradient descent)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID.</span></span><br><span class="line">        <span class="keyword">if</span> keep_prob == <span class="number">1</span>:</span><br><span class="line">            a3, cache = forward_propagation(X, parameters)</span><br><span class="line">        <span class="keyword">elif</span> keep_prob &lt; <span class="number">1</span>:</span><br><span class="line">            a3, cache = forward_propagation_with_dropout(X, parameters, keep_prob)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Cost function</span></span><br><span class="line">        <span class="keyword">if</span> lambd == <span class="number">0</span>:</span><br><span class="line">            cost = compute_cost(a3, Y)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cost = compute_cost_with_regularization(a3, Y, parameters, lambd)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backward propagation.</span></span><br><span class="line">        <span class="keyword">assert</span>(lambd==<span class="number">0</span> <span class="keyword">or</span> keep_prob==<span class="number">1</span>)    <span class="comment"># it is possible to use both L2 regularization and dropout, </span></span><br><span class="line">                                            <span class="comment"># but this assignment will only explore one at a time</span></span><br><span class="line">        <span class="keyword">if</span> lambd == <span class="number">0</span> <span class="keyword">and</span> keep_prob == <span class="number">1</span>:</span><br><span class="line">            grads = backward_propagation(X, Y, cache)</span><br><span class="line">        <span class="keyword">elif</span> lambd != <span class="number">0</span>:</span><br><span class="line">            grads = backward_propagation_with_regularization(X, Y, cache, lambd)</span><br><span class="line">        <span class="keyword">elif</span> keep_prob &lt; <span class="number">1</span>:</span><br><span class="line">            grads = backward_propagation_with_dropout(X, Y, cache, keep_prob)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update parameters.</span></span><br><span class="line">        parameters = update_parameters(parameters, grads, learning_rate)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print the loss every 10000 iterations</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">10000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Cost after iteration &#123;&#125;: &#123;&#125;"</span>.format(i, cost))</span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            costs.append(cost)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot the cost</span></span><br><span class="line">    plt.plot(costs)</span><br><span class="line">    plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'iterations (x1,000)'</span>)</span><br><span class="line">    plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><p>Let’s train the model without any regularization, and observe the accuracy on the train/test sets.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the training set:"</span>)</span><br><span class="line">predictions_train = predict(train_X, train_Y, parameters)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the test set:"</span>)</span><br><span class="line">predictions_test = predict(test_X, test_Y, parameters)</span><br></pre></td></tr></table></figure><pre><code>Cost after iteration 0: 0.6557412523481002
Cost after iteration 10000: 0.16329987525724218
Cost after iteration 20000: 0.13851642423267105</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Regularization/output_10_1.png" alt="png"></p><pre><code>On the training set:
Accuracy: 0.9478672985781991
On the test set:
Accuracy: 0.915</code></pre><p>The train accuracy is 94.8% while the test accuracy is 91.5%. This is the <strong>baseline model</strong> (you will observe the impact of regularization on this model). Run the following code to plot the decision boundary of your model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Model without regularization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-0.75</span>,<span class="number">0.40</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-0.75</span>,<span class="number">0.65</span>])</span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y)</span><br></pre></td></tr></table></figure><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Regularization/output_12_0.png" alt="png"></p><p>The non-regularized model is obviously overfitting the training set. <strong>It is fitting the noisy points</strong>! Lets now look at two techniques to reduce overfitting.</p><h2 id="2-L2-Regularization"><a href="#2-L2-Regularization" class="headerlink" title="2. L2 Regularization"></a>2. L2 Regularization</h2><p>The standard way to avoid overfitting is called <strong>L2 regularization</strong>. It consists of appropriately modifying your cost function, from:<br>$$J = -\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small y^{(i)}\log\left(a^{<a href="i">L</a>}\right) + (1-y^{(i)})\log\left(1- a^{<a href="i">L</a>}\right) \large{)} \tag{1}$$<br>to:<br>$$J_{regularized} = \small \underbrace{-\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small y^{(i)}\log\left(a^{<a href="i">L</a>}\right) + (1-y^{(i)})\log\left(1- a^{<a href="i">L</a>}\right) \large{)} }<em>\text{cross-entropy cost} + \underbrace{\frac{1}{m} \frac{\lambda}{2} \sum\limits_l\sum\limits_k\sum\limits_j W</em>{k,j}^{[l]2} }_\text{L2 regularization cost} \tag{2}$$</p><p>Let’s modify your cost and observe the consequences.</p><p><strong>Exercise</strong>: Implement <code>compute_cost_with_regularization()</code> which computes the cost given by formula (2). To calculate $\sum\limits_k\sum\limits_j W_{k,j}^{[l]2}$, use : <code>np.sum(np.square(Wl))</code></p><p><strong>Note</strong> that you have to do this for $W^{[1]}$, $W^{[2]}$ and $W^{[3]}$, then sum the three terms and multiply by $\frac{1}{m}\frac{\lambda}{2}$.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: compute_cost_with_regularization</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost_with_regularization</span><span class="params">(A3, Y, parameters, lambd)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the cost function with L2 regularization. See formula (2) above.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    A3 -- post-activation, output of forward propagation, of shape (output size, number of examples)</span></span><br><span class="line"><span class="string">    Y -- "true" labels vector, of shape (output size, number of examples)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing parameters of the model</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    cost - value of the regularized loss function (formula (2))</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    m = Y.shape[<span class="number">1</span>];</span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>];</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>];</span><br><span class="line">    W3 = parameters[<span class="string">"W3"</span>];</span><br><span class="line"></span><br><span class="line">    cross_entropy_cost = compute_cost(A3, Y); <span class="comment"># This gives you the cross-entropy part of the cost</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 1 line)</span></span><br><span class="line">    L2_regularization_cost = lambd / m / <span class="number">2</span> * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)));</span><br><span class="line">    <span class="comment">### END CODER HERE ###</span></span><br><span class="line"></span><br><span class="line">    cost = cross_entropy_cost + L2_regularization_cost;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cost;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A3, Y_assess, parameters = compute_cost_with_regularization_test_case();</span><br><span class="line">print(<span class="string">"cost = "</span> + str(compute_cost_with_regularization(A3, Y_assess, parameters, lambd = <span class="number">0.1</span>)));</span><br></pre></td></tr></table></figure><pre><code>cost = 1.7864859451590758</code></pre><p>Of course, because you changed the cost, you have to change backward propagation as well! All the gradients have to be computed with respect to this new cost.</p><p><strong>Exercise</strong>: Implement the changes needed in backward propagation to take into account regularization. The changes only concern dW1, dW2 and dW3. For each, you have to add the regularization term’s gradient $(\frac{d}{dW} ( \frac{1}{2}\frac{\lambda}{m} W^2) = \frac{\lambda}{m} W)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: backward_propagation_with_regularization</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation_with_regularization</span><span class="params">(X, Y, cache, lambd)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the backward propagation of our baseline model to which we added an L2 regularization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input dataset, of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    Y -- "true" labels vector, of shape (output size, number of examples)</span></span><br><span class="line"><span class="string">    cache -- cache output from forward_propagation()</span></span><br><span class="line"><span class="string">    lambd -- regularization hyperparameter, scalar</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    m = X.shape[<span class="number">1</span>];</span><br><span class="line">    (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache;</span><br><span class="line"></span><br><span class="line">    dZ3 = A3 - Y;</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 1 line)</span></span><br><span class="line">    dW3 = <span class="number">1</span> / m * np.dot(dZ3, A2.T) + lambd / m * W3;</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    db3 = <span class="number">1.</span>/m * np.sum(dZ3, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>);</span><br><span class="line"></span><br><span class="line">    dA2 = np.dot(W3.T, dZ3);</span><br><span class="line">    dZ2 = np.multiply(dA2, np.int64(A2 &gt; <span class="number">0</span>));</span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 1 line)</span></span><br><span class="line">    dW2 = <span class="number">1</span> / m * np.dot(dZ2, A1.T) + lambd / m * W2;</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    db2 = <span class="number">1.</span>/m * np.sum(dZ2, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>);</span><br><span class="line"></span><br><span class="line">    dA1 = np.dot(W2.T, dZ2);</span><br><span class="line">    dZ1 = np.multiply(dA1, np.int64(A1 &gt; <span class="number">0</span>));</span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 1 line)</span></span><br><span class="line">    dW1 = <span class="number">1</span> / m * np.dot(dZ1, X.T) + lambd / m * W1;</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    db1 = <span class="number">1.</span>/m * np.sum(dZ1, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>);</span><br><span class="line"></span><br><span class="line">    gradients = &#123;<span class="string">"dZ3"</span>: dZ3, <span class="string">"dW3"</span>: dW3, <span class="string">"db3"</span>: db3,<span class="string">"dA2"</span>: dA2,</span><br><span class="line">                 <span class="string">"dZ2"</span>: dZ2, <span class="string">"dW2"</span>: dW2, <span class="string">"db2"</span>: db2, <span class="string">"dA1"</span>: dA1, </span><br><span class="line">                 <span class="string">"dZ1"</span>: dZ1, <span class="string">"dW1"</span>: dW1, <span class="string">"db1"</span>: db1&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gradients;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X_assess, Y_assess, cache = backward_propagation_with_regularization_test_case()</span><br><span class="line"></span><br><span class="line">grads = backward_propagation_with_regularization(X_assess, Y_assess, cache, lambd = <span class="number">0.7</span>)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dW1 = "</span>+ str(grads[<span class="string">"dW1"</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dW2 = "</span>+ str(grads[<span class="string">"dW2"</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dW3 = "</span>+ str(grads[<span class="string">"dW3"</span>]))</span><br></pre></td></tr></table></figure><pre><code>dW1 = [[-0.25604646  0.12298827 -0.28297129]
 [-0.17706303  0.34536094 -0.4410571 ]]
dW2 = [[ 0.79276486  0.85133918]
 [-0.0957219  -0.01720463]
 [-0.13100772 -0.03750433]]
dW3 = [[-1.77691347 -0.11832879 -0.09397446]]</code></pre><p>Let’s now run the model with L2 regularization $(λ=0.7)$. The <code>model()</code> function will call:</p><ul><li><code>compute_cost_with_regularization</code> instead of <code>compute_cost</code></li><li><code>backward_propagation_with_regularization</code> instead of <code>backward_propagation</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y, lambd = <span class="number">0.7</span>);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the train set:"</span>);</span><br><span class="line">predictions_train = predict(train_X, train_Y, parameters);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the test set:"</span>);</span><br><span class="line">predictions_test = predict(test_X, test_Y, parameters);</span><br></pre></td></tr></table></figure><pre><code>Cost after iteration 0: 0.6974484493131264
Cost after iteration 10000: 0.2684918873282239
Cost after iteration 20000: 0.26809163371273004</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Regularization/output_20_1.png" alt="png"></p><pre><code>On the train set:
Accuracy: 0.9383886255924171
On the test set:
Accuracy: 0.93</code></pre><p>Congrats, the test set accuracy increased to 93%. You have saved the French football team!</p><p>You are not overfitting the training data anymore. Let’s plot the decision boundary.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Model with L2-regularization"</span>);</span><br><span class="line">axes = plt.gca();</span><br><span class="line">axes.set_xlim([<span class="number">-0.75</span>, <span class="number">0.40</span>]);</span><br><span class="line">axes.set_ylim([<span class="number">-0.75</span>, <span class="number">0.65</span>]);</span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y);</span><br></pre></td></tr></table></figure><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Regularization/output_22_0.png" alt="png"></p><p><strong>Observations</strong>:</p><ul><li>The value of $λ$ is a hyperparameter that you can tune using a dev set.</li><li>L2 regularization makes your decision boundary smoother. If $λ$ is too large, it is also possible to “oversmooth”, resulting in a model with high bias.</li></ul><p>What is L2-regularization actually doing?:</p><p>L2-regularization relies on the assumption that a model with small weights is simpler than a model with large weights. Thus, by penalizing the square values of the weights in the cost function you drive all the weights to smaller values. It becomes too costly for the cost to have large weights! This leads to a smoother model in which the output changes more slowly as the input changes.</p><p>What you should remember – the implications of L2-regularization on:</p><ul><li>The cost computation:<ul><li>A regularization term is added to the cost</li></ul></li><li>The backpropagation function:<ul><li>There are extra terms in the gradients with respect to weight matrices</li></ul></li><li>Weights end up smaller (“weight decay”):<ul><li>Weights are pushed to smaller values.</li></ul></li></ul><h2 id="3-Dropout"><a href="#3-Dropout" class="headerlink" title="3. Dropout"></a>3. Dropout</h2><p>Finally, dropout is a widely used regularization technique that is specific to deep learning.<br>It randomly shuts down some neurons in each iteration.</p><p>When you shut some neurons down, you actually modify your model. The idea behind drop-out is that at each iteration, you train a different model that uses only a subset of your neurons. With dropout, your neurons thus become less sensitive to the activation of one other specific neuron, because that other neuron might be shut down at any time.</p><h3 id="3-1-Forward-propagation-with-dropout"><a href="#3-1-Forward-propagation-with-dropout" class="headerlink" title="3.1 Forward propagation with dropout"></a>3.1 Forward propagation with dropout</h3><p><strong>Exercise</strong>: Implement the forward propagation with dropout. You are using a 3 layer neural network, and will add dropout to the first and second hidden layers. We will not apply dropout to the input layer or output layer.</p><p><strong>Instructions</strong>:</p><p>You would like to shut down some neurons in the first and second layers. To do that, you are going to carry out 4 Steps:</p><ol><li><p>In lecture, we dicussed creating a variable $d^{[1]}$ with the same shape as $a^{[1]}$ using <code>np.random.rand()</code> to randomly get numbers between 0 and 1. Here, you will use a vectorized implementation, so create a random matrix $D^{[1]}=[d^{[1]}<em>{(1)}d^{[1]}</em>{(2)}…d^{[1]}_{(m)}]$ of the same dimension as $A^{[1]}$.</p></li><li><p>Set each entry of $D^{[1]}$ to be 0 with probability (<code>1 - keep_prob</code>) or 1 with probability (<code>keep_prob</code>), by thresholding values in $D^{[1]}$ appropriately. <strong>Hint</strong>: to set all the entries of a matrix X to 0 (if entry is less than 0.5) or 1 (if entry is more than 0.5) you would do: <code>X = (X &lt; 0.5)</code>. Note that 0 and 1 are respectively equivalent to False and True.</p></li><li><p>Set $A^{[1]}$ to $A^{[1]}∗ D^{[1]}$. (You are shutting down some neurons). You can think of $D^{[1]}$ as a mask, so that when it is multiplied with another matrix, it shuts down some of the values.</p></li><li><p>Divide $A^{[1]}$ by <code>keep_prob</code>. By doing this you are assuring that the result of the cost will still have the same expected value as without drop-out. (This technique is also called inverted dropout.)</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: forward_propagation_with_dropout</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation_with_dropout</span><span class="params">(X, parameters, keep_prob = <span class="number">0.5</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the forward propagation: LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; SIGMOID.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input dataset, of shape (2, number of examples)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters "W1", "b1", "W2", "b2", "W3", "b3":</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (20, 2)</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (20, 1)</span></span><br><span class="line"><span class="string">                    W2 -- weight matrix of shape (3, 20)</span></span><br><span class="line"><span class="string">                    b2 -- bias vector of shape (3, 1)</span></span><br><span class="line"><span class="string">                    W3 -- weight matrix of shape (1, 3)</span></span><br><span class="line"><span class="string">                    b3 -- bias vector of shape (1, 1)</span></span><br><span class="line"><span class="string">    keep_prob - probability of keeping a neuron active during drop-out, scalar</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    A3 -- last activation value, output of the forward propagation, of shape (1,1)</span></span><br><span class="line"><span class="string">    cache -- tuple, information stored for computing the backward propagation</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    np.random.seed(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment"># retrieve parameters</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>];</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>];</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>];</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>];</span><br><span class="line">    W3 = parameters[<span class="string">"W3"</span>];</span><br><span class="line">    b3 = parameters[<span class="string">"b3"</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment"># LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</span></span><br><span class="line">    Z1 = np.dot(W1, X) + b1;</span><br><span class="line">    A1 = relu(Z1);</span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 4 lines)         # Steps 1-4 below correspond to the Steps 1-4 described above. </span></span><br><span class="line">    D1 = np.random.rand(A1.shape[<span class="number">0</span>], A1.shape[<span class="number">1</span>]);</span><br><span class="line">    D1 = D1 &lt; keep_prob;</span><br><span class="line">    A1 = np.multiply(D1, A1);</span><br><span class="line">    A1 /= keep_prob;</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    Z2 = np.dot(W2, A1) + b2;</span><br><span class="line">    A2 = relu(Z2);</span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 4 lines)</span></span><br><span class="line">    D2 = np.random.rand(A2.shape[<span class="number">0</span>], A2.shape[<span class="number">1</span>]);</span><br><span class="line">    D2 = D2 &lt; keep_prob;</span><br><span class="line">    A2 = np.multiply(D2, A2);</span><br><span class="line">    A2 /= keep_prob;</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    Z3 = np.dot(W3, A2) + b3;</span><br><span class="line">    A3 = sigmoid(Z3);</span><br><span class="line"></span><br><span class="line">    cache = (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> A3, cache;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X_assess, parameters = forward_propagation_with_dropout_test_case();</span><br><span class="line">A3, cache = forward_propagation_with_dropout(X_assess, parameters, keep_prob = <span class="number">0.7</span>);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"A3 = "</span> + str(A3));</span><br></pre></td></tr></table></figure><pre><code>A3 = [[0.36974721 0.00305176 0.04565099 0.49683389 0.36974721]]</code></pre><h2 id="3-2-Backward-propagation-with-dropout"><a href="#3-2-Backward-propagation-with-dropout" class="headerlink" title="3.2 Backward propagation with dropout"></a>3.2 Backward propagation with dropout</h2><p><strong>Exercise</strong>: Implement the backward propagation with dropout. As before, you are training a 3 layer network. Add dropout to the first and second hidden layers, using the masks $D^{[1]}$ and $D^{[2]}$ stored in the cache.</p><p><strong>Instruction</strong>: Backpropagation with dropout is actually quite easy. You will have to carry out 2 Steps:</p><ol><li>You had previously shut down some neurons during forward propagation, by applying a mask $D^{[1]}$ to A1. In backpropagation, you will have to shut down the same neurons, by reapplying the same mask $D^{[1]}$ to dA1.</li><li>During forward propagation, you had divided A1 by <code>keep_prob</code>. In backpropagation, you’ll therefore have to divide dA1 by <code>keep_prob</code> again (the calculus interpretation is that if $A^{[1]}$ is scaled by <code>keep_prob</code>, then its derivative $dA^{[1]}$ is also scaled by the same <code>keep_prob</code>).</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: backward_propagation_with_dropout</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation_with_dropout</span><span class="params">(X, Y, cache, keep_prob)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the backward propagation of our baseline model to which we added dropout.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input dataset, of shape (2, number of examples)</span></span><br><span class="line"><span class="string">    Y -- "true" labels vector, of shape (output size, number of examples)</span></span><br><span class="line"><span class="string">    cache -- cache output from forward_propagation_with_dropout()</span></span><br><span class="line"><span class="string">    keep_prob - probability of keeping a neuron active during drop-out, scalar</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    m = X.shape[<span class="number">1</span>];</span><br><span class="line">    (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) = cache;</span><br><span class="line"></span><br><span class="line">    dZ3 = A3 - Y;</span><br><span class="line">    dW3 = <span class="number">1.</span>/m * np.dot(dZ3, A2.T);</span><br><span class="line">    db3 = <span class="number">1.</span>/m * np.sum(dZ3, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>);</span><br><span class="line">    dA2 = np.dot(W3.T, dZ3);</span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span><br><span class="line">    dA2 = np.multiply(D2, dA2);             <span class="comment"># Step 1: Apply mask D2 to shut down the same neurons as during the forward propagation</span></span><br><span class="line">    dA2 /= keep_prob;                       <span class="comment"># Step 2: Scale the value of neurons that haven't been shut down</span></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    dZ2 = np.multiply(dA2, np.int64(A2 &gt; <span class="number">0</span>));</span><br><span class="line">    dW2 = <span class="number">1.</span>/m * np.dot(dZ2, A1.T);</span><br><span class="line">    db2 = <span class="number">1.</span>/m * np.sum(dZ2, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>);</span><br><span class="line"></span><br><span class="line">    dA1 = np.dot(W2.T, dZ2)</span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span><br><span class="line">    dA1 = np.multiply(D1, dA1);             <span class="comment"># Step 1: Apply mask D1 to shut down the same neurons as during the forward propagation</span></span><br><span class="line">    dA1 /= keep_prob;             <span class="comment"># Step 2: Scale the value of neurons that haven't been shut down</span></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    dZ1 = np.multiply(dA1, np.int64(A1 &gt; <span class="number">0</span>));</span><br><span class="line">    dW1 = <span class="number">1.</span>/m * np.dot(dZ1, X.T);</span><br><span class="line">    db1 = <span class="number">1.</span>/m * np.sum(dZ1, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>);</span><br><span class="line"></span><br><span class="line">    gradients = &#123;<span class="string">"dZ3"</span>: dZ3, <span class="string">"dW3"</span>: dW3, <span class="string">"db3"</span>: db3,<span class="string">"dA2"</span>: dA2,</span><br><span class="line">                 <span class="string">"dZ2"</span>: dZ2, <span class="string">"dW2"</span>: dW2, <span class="string">"db2"</span>: db2, <span class="string">"dA1"</span>: dA1, </span><br><span class="line">                 <span class="string">"dZ1"</span>: dZ1, <span class="string">"dW1"</span>: dW1, <span class="string">"db1"</span>: db1&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gradients;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X_assess, Y_assess, cache = backward_propagation_with_dropout_test_case();</span><br><span class="line"></span><br><span class="line">gradients = backward_propagation_with_dropout(X_assess, Y_assess, cache, keep_prob = <span class="number">0.8</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dA1 = "</span> + str(gradients[<span class="string">"dA1"</span>]));</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dA2 = "</span> + str(gradients[<span class="string">"dA2"</span>]));</span><br></pre></td></tr></table></figure><pre><code>dA1 = [[ 0.36544439  0.         -0.00188233  0.         -0.17408748]
 [ 0.65515713  0.         -0.00337459  0.         -0.        ]]
dA2 = [[ 0.58180856  0.         -0.00299679  0.         -0.27715731]
 [ 0.          0.53159854 -0.          0.53159854 -0.34089673]
 [ 0.          0.         -0.00292733  0.         -0.        ]]</code></pre><p>Let’s now run the model with dropout (<code>keep_prob = 0.86</code>). It means at every iteration you shut down each neurons of layer 1 and 2 with 24% probability. The function <code>model()</code> will now call:</p><ul><li><code>forward_propagation_with_dropout</code> instead of <code>forward_propagation</code>.</li><li><code>backward_propagation_with_dropout</code> instead of <code>backward_propagation</code>.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y, keep_prob = <span class="number">0.86</span>, learning_rate = <span class="number">0.3</span>);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the train set:"</span>);</span><br><span class="line">predictions_train = predict(train_X, train_Y, parameters);</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"On the test set:"</span>);</span><br><span class="line">predictions_test = predict(test_X, test_Y, parameters);</span><br></pre></td></tr></table></figure><pre><code>Cost after iteration 0: 0.6543912405149825


C:\Anaconda3\lib\site-packages\ipykernel\__main__.py:47: RuntimeWarning: divide by zero encountered in log
C:\Anaconda3\lib\site-packages\ipykernel\__main__.py:47: RuntimeWarning: invalid value encountered in multiply


Cost after iteration 10000: 0.061016986574905584
Cost after iteration 20000: 0.060582435798513114</code></pre><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Regularization/output_31_3.png" alt="png"></p><pre><code>On the train set:
Accuracy: 0.9289099526066351
On the test set:
Accuracy: 0.95</code></pre><p>Dropout works great! The test accuracy has increased again (to 95%)! Your model is not overfitting the training set and does a great job on the test set. The French football team will be forever grateful to you!</p><p>Run the code below to plot the decision boundary.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Model with dropout"</span>);</span><br><span class="line">axes = plt.gca();</span><br><span class="line">axes.set_xlim([<span class="number">-0.75</span>,<span class="number">0.40</span>]);</span><br><span class="line">axes.set_ylim([<span class="number">-0.75</span>,<span class="number">0.65</span>]);</span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y);</span><br></pre></td></tr></table></figure><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/Regularization/output_33_0.png" alt="png"></p><p><strong>Note</strong>:</p><ul><li>A common mistake when using dropout is to use it both in training and testing. You should use dropout (randomly eliminate nodes) only in training.</li><li>Deep learning frameworks like tensorflow, PaddlePaddle, keras or caffe come with a dropout layer implementation. Don’t stress - you will soon learn some of these frameworks.</li></ul><p><strong>What you should remember about dropout</strong>:</p><ul><li>Dropout is a regularization technique.</li><li>You only use dropout during training. Don’t use dropout (randomly eliminate nodes) during test time.</li><li>Apply dropout both during forward and backward propagation.</li><li>During training time, divide each dropout layer by keep_prob to keep the same expected value for the activations. For example, if keep_prob is 0.5, then we will on average shut down half the nodes, so the output will be scaled by 0.5 since only the remaining half are contributing to the solution. Dividing by 0.5 is equivalent to multiplying by 2. Hence, the output now has the same expected value. You can check that this works even when <code>keep_prob</code> is other values than 0.5.</li></ul><h2 id="4-Conclusions"><a href="#4-Conclusions" class="headerlink" title="4. Conclusions"></a>4. Conclusions</h2><p>Here are the results of our three models:</p><table><thead><tr><th><strong>model</strong></th><th><strong>train accuracy</strong></th><th><strong>test accuracy</strong></th></tr></thead><tbody><tr><td>3-layer NN without regularization</td><td>95%</td><td>91.5%</td></tr><tr><td>3-layer NN with L2-regularization</td><td>94%</td><td>93%</td></tr><tr><td>3-layer NN with dropout</td><td>93%</td><td>95%</td></tr></tbody></table><p>Note that regularization hurts training set performance! This is because it limits the ability of the network to overfit to the training set. But since it ultimately gives better test accuracy, it is helping your system.</p><p>Congratulations for finishing this assignment! And also for revolutionizing French football. :-)</p><p>What we want you to remember from this notebook:</p><ul><li>Regularization will help you reduce overfitting.</li><li>Regularization will drive your weights to lower values.</li><li>L2 regularization and Dropout are two very effective regularization techniques.</li></ul><h1 id="Part-3：Gradient-Checking"><a href="#Part-3：Gradient-Checking" class="headerlink" title="Part 3：Gradient Checking"></a>Part 3：Gradient Checking</h1><p>Welcome to the final assignment for this week! In this assignment you will learn to implement and use gradient checking.</p><p>You are part of a team working to make mobile payments available globally, and are asked to build a deep learning model to detect fraud–whenever someone makes a payment, you want to see if the payment might be fraudulent, such as if the user’s account has been taken over by a hacker.</p><p>But backpropagation is quite challenging to implement, and sometimes has bugs. Because this is a mission-critical application, your company’s CEO wants to be really certain that your implementation of backpropagation is correct. Your CEO says, “Give me a proof that your backpropagation is actually working!” To give this reassurance, you are going to use “gradient checking”.</p><p>Let’s do it!</p><p>First import the libs which you will need.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Packages</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> testCases <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> gc_utils <span class="keyword">import</span> sigmoid, relu, dictionary_to_vector, vector_to_dictionary, gradients_to_vector</span><br></pre></td></tr></table></figure><h2 id="1-How-does-gradient-checking-work"><a href="#1-How-does-gradient-checking-work" class="headerlink" title="1. How does gradient checking work?"></a>1. How does gradient checking work?</h2><p>Backpropagation computes the gradients $\frac{∂J}{∂θ}$ , where $θ$ denotes the parameters of the model. $J$ is computed using forward propagation and your loss function.</p><p>Because forward propagation is relatively easy to implement, you’re confident you got that right, and so you’re almost 100% sure that you’re computing the cost $J$ correctly. Thus, you can use your code for computing $J$ to verify the code for computing $\frac{∂J}{∂θ}$.</p><p>Let’s look back at the definition of a derivative (or gradient):<br>$$\frac{\partial J}{\partial \theta} = \lim_{\varepsilon \to 0} \frac{J(\theta + \varepsilon) - J(\theta - \varepsilon)}{2 \varepsilon} \tag{1}$$</p><p>If you’re not familiar with the “$limε→0$” notation, it’s just a way of saying “when $ε$ is really really small.”</p><p>We know the following:</p><p>$\frac{∂J}{∂θ}$ is what you want to make sure you’re computing correctly.<br>You can compute $J(θ+ε)$ and $J(θ−ε)$ (in the case that $θ$ is a real number), since you’re confident your implementation for $J$ is correct.<br>Lets use equation (1) and a small value for $ε$ to convince your CEO that your code for computing $\frac{∂J}{∂θ}$ is correct!</p><h2 id="2-1-dimensional-gradient-checking"><a href="#2-1-dimensional-gradient-checking" class="headerlink" title="2. 1-dimensional gradient checking"></a>2. 1-dimensional gradient checking</h2><p>Consider a 1D linear function $J(θ)=θx$. The model contains only a single real-valued parameter $θ$, and takes $x$ as input.</p><p>You will implement code to compute $J(.)$ and its derivative $\frac{∂J}{∂θ}$. You will then use gradient checking to make sure your derivative computation for $J$ is correct.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/GradientChecking/1.png" alt=""><br>$$\text{Figure 1 : 1D linear model}$$</p><p>The diagram above shows the key computation steps: First start with $x$, then evaluate the function $J(x)$ (“forward propagation”). Then compute the derivative $\frac{∂J}{∂θ}$ (“backward propagation”).</p><p><strong>Exercise</strong>: implement “<code>forward propagation</code>” and “<code>backward propagation</code>” for this simple function. I.e., compute both $J(.)$ (“<code>forward propagation</code>”) and its derivative with respect to $θ$ (“<code>backward propagation</code>”), in two separate functions.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: forward_propagation</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(x, theta)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the linear forward propagation (compute J) presented in Figure 1 (J(theta) = theta * x)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    x -- a real-valued input</span></span><br><span class="line"><span class="string">    theta -- our parameter, a real number as well</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    J -- the value of function J, computed using the formula J(theta) = theta * x</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 1 line)</span></span><br><span class="line">    J = theta*x</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> J</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x, theta = <span class="number">2</span>, <span class="number">4</span></span><br><span class="line">J = forward_propagation(x, theta)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"J = "</span> + str(J))</span><br></pre></td></tr></table></figure><pre><code>J = 8</code></pre><p><strong>Exercise</strong>: Now, implement the backward propagation step (derivative computation) of Figure 1. That is, compute the derivative of $J(θ)=θx$ with respect to $θ$. To save you from doing the calculus, you should get $d\theta=\frac{∂J}{∂θ}=x$.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: backward_propagation</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation</span><span class="params">(x, theta)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Computes the derivative of J with respect to theta (see Figure 1).</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    x -- a real-valued input</span></span><br><span class="line"><span class="string">    theta -- our parameter, a real number as well</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    dtheta -- the gradient of the cost with respect to theta</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 1 line)</span></span><br><span class="line">    dtheta = x;</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dtheta</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x, theta = <span class="number">2</span>, <span class="number">4</span></span><br><span class="line">dtheta = backward_propagation(x, theta)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dtheta = "</span> + str(dtheta))</span><br></pre></td></tr></table></figure><pre><code>dtheta = 2</code></pre><p><strong>Exercise</strong>: To show that the <code>backward_propagation()</code> function is correctly computing the gradient $\frac{∂J}{∂θ}$, let’s implement gradient checking.</p><p><strong>Instructions</strong>:</p><ul><li>First compute “<code>gradapprox</code>” using the formula above (1) and a small value of $ε$. Here are the Steps to follow:<ol><li>$\theta^+ = \theta + \epsilon$</li><li>$\theta^- = \theta - \epsilon$</li><li>$J^+ = J(\theta^+)$</li><li>$J^- = J(\theta^-)$</li><li>$gradapprox=\frac{J^+-J^-}{2\epsilon}$</li></ol></li><li>Then compute the gradient using backward propagation, and store the result in a variable “grad”</li><li>Finally, compute the relative difference between “gradapprox” and the “grad” using the following formula:<br>$$difference = \frac {\mid\mid grad - gradapprox \mid\mid_2}{\mid\mid grad \mid\mid_2 + \mid\mid gradapprox \mid\mid_2} \tag{2}$$</li></ul><p>You will need 3 Steps to compute this formula:</p><ul><li>1’. compute the numerator using <code>np.linalg.norm(…)</code></li><li>2’. compute the denominator. You will need to call <code>np.linalg.norm(…)</code> twice.</li><li>3’. divide them.</li></ul><p>If this difference is small (say less than 10−7), you can be quite confident that you have computed your gradient correctly. Otherwise, there may be a mistake in the gradient computation.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: gradient_check</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_check</span><span class="params">(x, theta, epsilon = <span class="number">1e-7</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward propagation presented in Figure 1.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    x -- a real-valued input</span></span><br><span class="line"><span class="string">    theta -- our parameter, a real number as well</span></span><br><span class="line"><span class="string">    epsilon -- tiny shift to the input to compute approximated gradient with formula(1)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    difference -- difference (2) between the approximated gradient and the backward propagation gradient</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute gradapprox using left side of formula (1). epsilon is small enough, you don't need to worry about the limit.</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 5 lines)</span></span><br><span class="line">    thetaplus = theta + epsilon</span><br><span class="line">    thetaminus = theta - epsilon</span><br><span class="line">    J_plus = forward_propagation(x, thetaplus)</span><br><span class="line">    J_minus = forward_propagation(x, thetaminus)</span><br><span class="line">    gradapprox = (J_plus-J_minus)/(<span class="number">2.</span>*epsilon)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Check if gradapprox is close enough to the output of backward_propagation()</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 1 line)</span></span><br><span class="line">    grad = backward_propagation(x, theta)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 1 line)</span></span><br><span class="line">    difference = np.linalg.norm(grad-gradapprox)/(np.linalg.norm(grad) + np.linalg.norm(gradapprox))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> difference &lt; <span class="number">1e-7</span>:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"The gradient is correct!"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"The gradient is wrong!"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> difference</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x, theta = <span class="number">2</span>, <span class="number">4</span></span><br><span class="line">difference = gradient_check(x, theta)</span><br><span class="line">print(<span class="string">"difference = "</span> + str(difference))</span><br></pre></td></tr></table></figure><pre><code>The gradient is correct!
difference = 2.919335883291695e-10</code></pre><p>Congrats, the difference is smaller than the $10^{−7}$ threshold. So you can have high confidence that you’ve correctly computed the gradient in <code>backward_propagation()</code>.</p><p>Now, in the more general case, your cost function $J$ has more than a single 1D input. When you are training a neural network, $θ$ actually consists of multiple matrices $W^{[l]}$ and biases $b^{[l]}$! It is important to know how to do a gradient check with higher-dimensional inputs. Let’s do it!</p><h2 id="3-N-dimensional-gradient-checking"><a href="#3-N-dimensional-gradient-checking" class="headerlink" title="3. N-dimensional gradient checking"></a>3. N-dimensional gradient checking</h2><p>The following figure describes the forward and backward propagation of your fraud detection model.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/GradientChecking/2.png" alt=""><br>$$\text{Figure 2 : deep neural network} \ LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID$$</p><p>Let’s look at your implementations for forward propagation and backward propagation.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation_n</span><span class="params">(X, Y, parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements the forward propagation (and computes the cost) presented in Figure 3.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- training set for m examples</span></span><br><span class="line"><span class="string">    Y -- labels for m examples </span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters "W1", "b1", "W2", "b2", "W3", "b3":</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (5, 4)</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (5, 1)</span></span><br><span class="line"><span class="string">                    W2 -- weight matrix of shape (3, 5)</span></span><br><span class="line"><span class="string">                    b2 -- bias vector of shape (3, 1)</span></span><br><span class="line"><span class="string">                    W3 -- weight matrix of shape (1, 3)</span></span><br><span class="line"><span class="string">                    b3 -- bias vector of shape (1, 1)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    cost -- the cost function (logistic cost for one example)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># retrieve parameters</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line">    W3 = parameters[<span class="string">"W3"</span>]</span><br><span class="line">    b3 = parameters[<span class="string">"b3"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</span></span><br><span class="line">    Z1 = np.dot(W1, X) + b1</span><br><span class="line">    A1 = relu(Z1)</span><br><span class="line">    Z2 = np.dot(W2, A1) + b2</span><br><span class="line">    A2 = relu(Z2)</span><br><span class="line">    Z3 = np.dot(W3, A2) + b3</span><br><span class="line">    A3 = sigmoid(Z3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Cost</span></span><br><span class="line">    logprobs = np.multiply(-np.log(A3),Y) + np.multiply(-np.log(<span class="number">1</span> - A3), <span class="number">1</span> - Y)</span><br><span class="line">    cost = <span class="number">1.</span>/m * np.sum(logprobs)</span><br><span class="line">    </span><br><span class="line">    cache = (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost, cache</span><br></pre></td></tr></table></figure><p>Now, run backward propagation.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation_n</span><span class="params">(X, Y, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the backward propagation presented in figure 2.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input datapoint, of shape (input size, 1)</span></span><br><span class="line"><span class="string">    Y -- true "label"</span></span><br><span class="line"><span class="string">    cache -- cache output from forward_propagation_n()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    gradients -- A dictionary with the gradients of the cost with respect to each parameter, activation and pre-activation variables.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache</span><br><span class="line"></span><br><span class="line">    dZ3 = A3 - Y</span><br><span class="line">    dW3 = <span class="number">1.</span>/m * np.dot(dZ3, A2.T)</span><br><span class="line">    db3 = <span class="number">1.</span>/m * np.sum(dZ3, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    dA2 = np.dot(W3.T, dZ3)</span><br><span class="line">    dZ2 = np.multiply(dA2, np.int64(A2 &gt; <span class="number">0</span>))</span><br><span class="line">    <span class="comment"># 这里是故意使用一个错误的形式来验证gradient_check是否正常工作</span></span><br><span class="line">    dW2 = <span class="number">1.</span>/m * np.dot(dZ2, A1.T) * <span class="number">2</span></span><br><span class="line">    <span class="comment"># 正确的形式，最后再修改的</span></span><br><span class="line">    <span class="comment"># dW2 = 1./m * np.dot(dZ2, A1.T)</span></span><br><span class="line">    db2 = <span class="number">1.</span>/m * np.sum(dZ2, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    dA1 = np.dot(W2.T, dZ2)</span><br><span class="line">    dZ1 = np.multiply(dA1, np.int64(A1 &gt; <span class="number">0</span>))</span><br><span class="line">    dW1 = <span class="number">1.</span>/m * np.dot(dZ1, X.T)</span><br><span class="line">    <span class="comment"># 这里是故意使用一个错误的形式来验证gradient_check是否正常工作</span></span><br><span class="line">    db1 = <span class="number">4.</span>/m * np.sum(dZ1, axis=<span class="number">1</span>, keepdims = <span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 正确的形式，最后再修改的</span></span><br><span class="line">    <span class="comment"># db1 = 1./m * np.sum(dZ1, axis=1, keepdims = True)</span></span><br><span class="line"></span><br><span class="line">    gradients = &#123;<span class="string">"dZ3"</span>: dZ3, <span class="string">"dW3"</span>: dW3, <span class="string">"db3"</span>: db3,</span><br><span class="line">                 <span class="string">"dA2"</span>: dA2, <span class="string">"dZ2"</span>: dZ2, <span class="string">"dW2"</span>: dW2, <span class="string">"db2"</span>: db2,</span><br><span class="line">                 <span class="string">"dA1"</span>: dA1, <span class="string">"dZ1"</span>: dZ1, <span class="string">"dW1"</span>: dW1, <span class="string">"db1"</span>: db1&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure><p>You obtained some results on the fraud detection test set but you are not 100% sure of your model. Nobody’s perfect! Let’s implement gradient checking to verify if your gradients are correct.</p><p><strong>How does gradient checking work?</strong></p><p>As in 1) and 2), you want to compare “<code>gradapprox</code>” to the gradient computed by backpropagation. The formula is still:<br>$$\frac{\partial J}{\partial \theta} = \lim_{\varepsilon \to 0} \frac{J(\theta + \varepsilon) - J(\theta - \varepsilon)}{2 \varepsilon} \tag{1}$$</p><p>However, $θ$ is not a scalar anymore. It is a dictionary called “<code>parameters</code>”. We implemented a function “<code>dictionary_to_vector()</code>” for you. It converts the “<code>parameters</code>” dictionary into a vector called “<code>values</code>”, obtained by reshaping all parameters <code>(W1, b1, W2, b2, W3, b3)</code> into vectors and concatenating them.</p><p>The inverse function is “<code>vector_to_dictionary</code>” which outputs back the “<code>parameters</code>” dictionary.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/week1/GradientChecking/3.png" alt="Figure 2 : `dictionary_to_vector()` and `vector_to_dictionary()`"></p><p>$$\text{Figure 2 : dictionary_to_vector() and vector_to_dictionary()} \ \text{ You will need these functions in gradient_check_n()}$$</p><p>We have also converted the “gradients” dictionary into a vector “grad” using <code>gradients_to_vector()</code>. You don’t need to worry about that.</p><p><strong>Exercise</strong>: Implement<code>gradient_check_n()</code>.</p><p><strong>Instructions</strong>: Here is pseudo-code that will help you implement the gradient check.</p><p>For each i in num_parameters:</p><ul><li>To compute <code>J_plus[i]</code>:<ol><li>Set $θ^+$ to <code>np.copy(parameters_values)</code></li><li>Set $θ^+_i$ to $θ^+_i+ε$</li><li>Calculate $J^+_i$ using to <code>forward_propagation_n(x, y, vector_to_dictionary(theta_plus))</code>.</li></ol></li><li>To compute <code>J_minus[i]</code>: do the same thing with $θ^−$</li><li>Compute <code>gradapprox[i]</code>=$\frac{J^+_i−J^-_i}{2ε}$</li></ul><p>Thus, you get a vector gradapprox, where <code>gradapprox[i]</code> is an approximation of the gradient with respect to <code>parameter_values[i]</code>. You can now compare this gradapprox vector to the gradients vector from backpropagation. Just like for the 1D case (Steps 1’, 2’, 3’), compute:<br>$$difference = \frac {| grad - gradapprox |_2}{| grad |_2 + | gradapprox |_2 } \tag{2}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: gradient_check_n</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_check_n</span><span class="params">(parameters, gradients, X, Y, epsilon = <span class="number">1e-7</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Checks if backward_propagation_n computes correctly the gradient of the cost output by forward_propagation_n</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters "W1", "b1", "W2", "b2", "W3", "b3":</span></span><br><span class="line"><span class="string">    grad -- output of backward_propagation_n, contains gradients of the cost with respect to the parameters. </span></span><br><span class="line"><span class="string">    x -- input datapoint, of shape (input size, 1)</span></span><br><span class="line"><span class="string">    y -- true "label"</span></span><br><span class="line"><span class="string">    epsilon -- tiny shift to the input to compute approximated gradient with formula(1)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    difference -- difference (2) between the approximated gradient and the backward propagation gradient</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set-up variables</span></span><br><span class="line">    parameters_values, _ = dictionary_to_vector(parameters)</span><br><span class="line">    grad = gradients_to_vector(gradients)</span><br><span class="line">    num_parameters = parameters_values.shape[<span class="number">0</span>]</span><br><span class="line">    J_plus = np.zeros((num_parameters, <span class="number">1</span>))</span><br><span class="line">    J_minus = np.zeros((num_parameters, <span class="number">1</span>))</span><br><span class="line">    gradapprox = np.zeros((num_parameters, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute gradapprox</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_parameters):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute J_plus[i]. Inputs: "parameters_values, epsilon". Output = "J_plus[i]".</span></span><br><span class="line">        <span class="comment"># "_" is used because the function you have to outputs two parameters but we only care about the first one</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 3 lines)</span></span><br><span class="line">        thetaplus = np.copy(parameters_values)                                      <span class="comment"># Step 1</span></span><br><span class="line">        thetaplus[i][<span class="number">0</span>] = thetaplus[i][<span class="number">0</span>] + epsilon                                <span class="comment"># Step 2</span></span><br><span class="line">        J_plus[i], _ = forward_propagation_n(X, Y, vector_to_dictionary(thetaplus))                                   <span class="comment"># Step 3</span></span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute J_minus[i]. Inputs: "parameters_values, epsilon". Output = "J_minus[i]".</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 3 lines)</span></span><br><span class="line">        thetaminus = np.copy(parameters_values)                                     <span class="comment"># Step 1</span></span><br><span class="line">        thetaminus[i][<span class="number">0</span>] = thetaminus[i][<span class="number">0</span>] - epsilon                               <span class="comment"># Step 2        </span></span><br><span class="line">        J_minus[i], _ = forward_propagation_n(X, Y, vector_to_dictionary(thetaminus))                                  <span class="comment"># Step 3</span></span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute gradapprox[i]</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### (approx. 1 line)</span></span><br><span class="line">        gradapprox[i] = (J_plus[i] - J_minus[i]) / (<span class="number">2</span> * epsilon)</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compare gradapprox to backward propagation gradients by computing difference.</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 1 line)</span></span><br><span class="line"><span class="comment">#     print("grad: &#123;&#125;".format(grad))</span></span><br><span class="line"><span class="comment">#     print("gradapprox: &#123;&#125;".format(gradapprox))</span></span><br><span class="line">    numerator = np.linalg.norm(grad-gradapprox, ord=<span class="number">2</span>)                                           <span class="comment"># Step 1'</span></span><br><span class="line">    denominator = np.linalg.norm(grad, ord=<span class="number">2</span>) + np.linalg.norm(gradapprox, ord=<span class="number">2</span>)                                         <span class="comment"># Step 2'</span></span><br><span class="line">    difference = numerator / denominator                                        <span class="comment"># Step 3'</span></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> difference &gt; <span class="number">2e-7</span>:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"\033[93m"</span> + <span class="string">"There is a mistake in the backward propagation! difference = "</span> + str(difference) + <span class="string">"\033[0m"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"\033[92m"</span> + <span class="string">"Your backward propagation works perfectly fine! difference = "</span> + str(difference) + <span class="string">"\033[0m"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> difference</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X, Y, parameters = gradient_check_n_test_case()</span><br><span class="line"></span><br><span class="line">cost, cache = forward_propagation_n(X, Y, parameters)</span><br><span class="line">gradients = backward_propagation_n(X, Y, cache)</span><br><span class="line">difference = gradient_check_n(parameters, gradients, X, Y)</span><br></pre></td></tr></table></figure><pre><code>[93mThere is a mistake in the backward propagation! difference = 0.28509315678069896[0m</code></pre><p>It seems that there were errors in the <code>backward_propagation_n</code> code we gave you! Good that you’ve implemented the gradient check. Go back to backward_propagation and try to find/correct the errors (Hint: check dW2 and db1). Return the gradient check when you think you’ve fixed it. Remember you’ll need to re-execute the cell defining <code>backward_propagation_n()</code> if you modify the code.</p><p>Can you get gradient check to declare your derivative computation correct? Even though this part of the assignment isn’t graded, we strongly urge you to try to find the bug and re-run gradient check until you’re convinced backprop is now correctly implemented.</p><p><strong>Note</strong></p><ul><li>Gradient Checking is slow! Approximating the gradient with $\frac{∂J}{∂θ}≈\frac{J(θ+ε)−J(θ−ε)}{2ε}$ is computationally costly. For this reason, we don’t run gradient checking at every iteration during training. Just a few times to check if the gradient is correct.</li><li>Gradient Checking, at least as we’ve presented it, doesn’t work with dropout. You would usually run the gradient check algorithm without dropout to make sure your backprop is correct, then add dropout.</li></ul><p>Congrats, you can be confident that your deep learning model for fraud detection is working correctly! You can even use this to convince your CEO. :)</p><p>*<em>What you should remember from this notebook: *</em></p><ul><li>Gradient checking verifies closeness between the gradients from backpropagation and the numerical approximation of the gradient (computed using forward propagation).</li><li>Gradient checking is slow, so we don’t run it in every iteration of training. You would usually run it only to make sure your code is correct, then turn it off and use backprop for the actual learning process.</li></ul>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/03/01/01_practical-aspects-of-deep-learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/03/01/01_practical-aspects-of-deep-learning/" class="post-title-link" itemprop="url">01_practical-aspects-of-deep-learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-03-01 00:00:00" itemprop="dateCreated datePublished" datetime="2018-03-01T00:00:00+05:30">2018-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-06 20:25:15" itemprop="dateModified" datetime="2020-04-06T20:25:15+05:30">2020-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>79k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>1:12</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>This is my personal note at the first week after studying the course <a href="https://www.coursera.org/learn/deep-neural-network/" target="_blank" rel="noopener">Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</a> and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.</p><h2 id="01-setting-up-your-machine-learning-application"><a href="#01-setting-up-your-machine-learning-application" class="headerlink" title="01_setting-up-your-machine-learning-application"></a>01_setting-up-your-machine-learning-application</h2><h3 id="01-train-dev-test-sets"><a href="#01-train-dev-test-sets" class="headerlink" title="01_train-dev-test-sets"></a>01_train-dev-test-sets</h3><p>Welcome to this course on the practical aspects of deep learning. Perhaps now you’ve learned how to implement a neural network. In this week you’ll learn the practical aspects of how to make your neural network work well. Ranging from things like <strong>hyperparameter tuning</strong> to how to set up your data, to how to make sure your optimization algorithm runs quickly so that you get your learning algorithm to learn in a reasonable time. In this first week we’ll first talk about the cellular machine learning problem, then we’ll talk about randomization. And we’ll talk about some tricks for making sure your neural network implementation is correct.</p><p>With that, let’s get started. Making good choices in how you set up your training, development, and test sets can make a huge difference in helping you quickly find a good high performance neural network.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/1.png" alt=""></p><p>When training a neural network you have to make a lot of decisions, such as how many layers will your neural network have? And how many hidden units do you want each layer to have? And what’s the learning rates? And what are the activation functions you want to use for the different layers? <strong>When you’re starting on a new application, it’s almost impossible to correctly guess the right values for all of these, and for other hyperparameter choices, on your first attempt</strong>. So in practice applied machine learning is <strong>a highly iterative process</strong>, in which you often start with an idea, such as you want to build a neural network of a certain number of layers, certain number of hidden units, maybe on certain data sets and so on. And then you just have to code it up and try it by running your code. You run and experiment and you get back a result that tells you how well this particular network, or this particular configuration works. And based on the outcome, you might then refine your ideas and change your choices and maybe keep iterating in order to try to find a better and a better neural network.</p><p>So in practice applied machine learning is a highly iterative process, in which you often start with an idea, such as you want to build a neural network of a certain number of layers, certain number of hidden units, maybe on certain data sets and so on. And then you just have to code it up and try it by running your code. You run and experiment and you get back a result that tells you how well this particular network, or this particular configuration works. And based on the outcome, you might then refine your ideas and change your choices and maybe keep iterating in order to try to find a better and a better neural network. Today, deep learning has found great success in a lot of areas. Ranging from natural language processing to computer vision to speech recognition to a lot of applications on also structured data. And structured data includes everything from advertisements to web search, which isn’t just Internet search engines it’s also, for example, shopping websites. Already any websites that wants deliver great search results when you enter terms into a search bar. To computer security, to logistics, such as figuring out where to send drivers to pick up and drop off things, to many more. So what I’m seeing is that sometimes a researcher with a lot of experience in NLP might try to do something in computer vision. Or maybe a researcher with a lot of experience in speech recognition might jump in and try to do something on advertising. Or someone from security might want to jump in and do something on logistics. <strong>And what I’ve seen is that intuitions from one domain or from one application area often do not transfer to other application areas</strong>. And the best choices may depend on the amount of data you have, the number of input features you have through your computer configuration and whether you’re training on GPUs or CPUs. And if so, exactly what configuration of GPUs and CPUs, and many other things. So for a lot of applications I think it’s almost impossible. <strong>Even very experienced deep learning people find it almost impossible to correctly guess the best choice of hyperparameters the very first time</strong>. And so today, applied deep learning is a very <strong>iterative process</strong> where you just have to go around this cycle many times to hopefully find a good choice of network for your application. <strong>So one of the things that determine how quickly you can make progress is how efficiently you can go around this cycle</strong>. And setting up your data sets well in terms of your train, development and test sets can make you much more efficient at that.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/2.png" alt=""><br>So if this is your training data, let’s draw that as a big box. Then traditionally you might take all the data you have and carve off some portion of it to be your <strong>training set</strong>. Some portion of it to be your <strong>hold-out cross validation set</strong>, and this is sometimes <strong>also called the development set</strong>. And <strong>for brevity I’m just going to call this the dev set</strong>, but all of these terms mean roughly the same thing. And then you might carve out some final portion of it to be your <strong>test set</strong>. And so the workflow is that you keep on training algorithms on your training sets. And use your dev set or your hold-out cross validation set to see which of many different models performs best on your dev set. And then after having done this long enough, when you have a final model that you want to evaluate, you can take the best model you have found and evaluate it on your test set. In order to get an unbiased estimate of how well your algorithm is doing. <strong>So in the previous era of machine learning, it was common practice to take all your data and split it according to maybe a 70/30% in terms of a people often talk about the 70/30 train test splits. If you don’t have an explicit dev set or maybe a 60/20/20% split in terms of 60% train, 20% dev and 20% test. And several years ago this was widely considered best practice in machine learning</strong>. If you have maybe 100 examples in total, maybe 1000 examples in total, maybe after 10,000 examples. <strong>These sorts of ratios were perfectly reasonable rules of thumb. But in the modern big data era</strong>, where, for example, you might have a million examples in total, <strong>then the trend is that your dev and test sets have been becoming a much smaller percentage of the total. Because remember, the goal of the dev set or the development set is that you’re going to test different algorithms on it and see which algorithm works better. So the dev set just needs to be big enough for you to evaluate, say, two different algorithm choices or ten different algorithm choices and quickly decide which one is doing better. And you might not need a whole 20% of your data for that</strong>. So, for example, if you have a million training examples you might decide that just having 10,000 examples in your dev set is more than enough to evaluate which one or two algorithms does better. <strong>And in a similar vein, the main goal of your test set is, given your final classifier, to give you a pretty confident estimate of how well it’s doing</strong>. And again, if you have a million examples maybe you might decide that 10,000 examples is more than enough in order to evaluate a single classifier and give you a good estimate of how well it’s doing. So in this example where you have a million examples, if you need just 10,000 for your dev and 10,000 for your test, your ratio will be more like his 10,000 is 1% of 1 million <strong>so you’ll have 98% train, 1% dev, 1% test. And I’ve also seen applications where, if you have even more than a million examples, you might end up with 99.5% train and 0.25% dev, 0.25% test. Or maybe a 0.4% dev, 0.1% test</strong>. So just to recap, when setting up your machine learning problem, I’ll often set it up into a train, dev and test sets, and if you have a relatively small dataset, these traditional ratios might be okay. But if you have a much larger data set, it’s also fine to set your dev and test sets to be much smaller than your 20% or even 10% of your data. <strong>We’ll give more specific guidelines on the sizes of dev and test sets later in this specialization</strong>.</p><p>One other trend we’re seeing in the era of modern deep learning is that more and more people train on mismatched train and test distributions.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/3.png" alt=""></p><p>Let’s say you’re building an app that lets users upload a lot of pictures and your goal is to find pictures of cats in order to show your users. Maybe all your users are cat lovers. Maybe your training set comes from cat pictures downloaded off the Internet, but your dev and test sets might comprise cat pictures from users using our app. So maybe your training set has a lot of pictures crawled off the Internet but the dev and test sets are pictures uploaded by users. Turns out a lot of webpages have very high resolution, very professional, very nicely framed pictures of cats. But maybe your users are uploading blurrier, lower resolution images just taken with a cell phone camera in a more casual condition. And so these two distributions of data may be different. <strong>The rule of thumb I’d encourage you to follow in this case is to make sure that the dev and test sets come from the same distribution.</strong> We’ll say more about this particular guideline as well, but <strong>because you will be using the dev set to evaluate a lot of different models and trying really hard to improve performance on the dev set. It’s nice if your dev set comes from the same distribution as your test set</strong>. But because deep learning algorithms have such a huge larger for training data, one trend I’m seeing is that you might use all sorts of creative tactics, such as crawling webpages, in order to acquire a much bigger training set than you would otherwise have. Even if part of the cost of that is then that your training set data might not come from the same distribution as your dev and test sets. <strong>But you find that so long as you follow this rule of thumb, that progress in your machine learning algorithm will be faster</strong>. And I’ll give a more detailed explanation for this particular rule of thumb later in the specialization as well.</p><p><strong>Finally, it might be okay to not have a test set</strong>. <em>Remember the goal of the test set is to give you a unbiased estimate of the performance of your final network, of the network that you selected</em>. But if you don’t need that unbiased estimate, then it might be okay to not have a test set. So what you do, if you have only a dev set but not a test set, is you train on the training set and then you try different model architectures. Evaluate them on the dev set, and then use that to iterate and try to get to a good model. Because you’ve fit your data to the dev set, this no longer gives you an unbiased estimate of performance. But if you don’t need one, that might be perfectly fine. <strong>In the machine learning world, when you have just a train and a dev set but no separate test set. Most people will call this a training set and they will call the dev set the test set. But what they actually end up doing is using the test set as a hold-out cross validation set. Which maybe isn’t completely a great use of terminology, because they’re then overfitting to the test set</strong>. So when the team tells you that they have only a train and a test set, I would just be cautious and think, do they really have a train dev set? Because they’re overfitting to the test set. Culturally, it might be difficult tochange some of these team’s terminology and get them to call it a trained devset rather than a trained test set. Even though I think calling it a train and development set would be more correct terminology. And this is actually okay practice if you don’t need a completely unbiased estimate of the performance of your algorithm. So having set up a train dev and test set will allow you to integrate more quickly. It will also allow you to more efficiently measure the bias and variance of your algorithm so you can more efficiently select ways to improve your algorithm. Let’s start to talk about that in the next video.</p><h3 id="02-bias-variance"><a href="#02-bias-variance" class="headerlink" title="02_bias-variance"></a>02_bias-variance</h3><p>I’ve noticed that almost all the really good machine learning practitioners tend to be very sophisticated in understanding of Bias and Variance. Bias and Variance is one of those concepts that’s easily learned but difficult to master. Even if you think you’ve seen the basic concepts of Bias and Variance, there’s often more new ones to it than you’d expect. In the Deep Learning Error, another trend is that there’s been less discussion of what’s called the bias-variance trade-off. You might have heard this thing called the bias-variance trade-off. But in Deep Learning Error there’s less of a trade-off, so we’d still still solve the bias, we still solve the variance, but we just talk less about the bias-variance trade-off. Let’s see what this means.</p><p>Let’s see the data set that looks like this. If you fit a straight line to the data, maybe get a logistic regression fit to that. This is not a very good fit to the data. And so this is class of a high bias, what we say that this is <strong>underfitting</strong> the data.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/4-1.png" alt=""><br>On the opposite end, if you fit an incredibly complex classifier, maybe deep neural network, or neural network with all the hidden units, maybe you can fit the data perfectly, but that doesn’t look like a great fit either. So there’s a classifier of high variance and this is <strong>overfitting</strong> the data.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/4-3.png" alt=""><br>And there might be some classifier in between, with a medium level of complexity, that maybe fits it correctly like that.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/4-2.png" alt=""><br>That looks like a much more reasonable fit to the data, so we call that <strong>just right</strong>. It’s somewhere in between. So in a 2D example like this, with just two features, X-1 and X-2, you can plot the data and visualize bias and variance. In high dimensional problems, you can’t plot the data and visualize division boundary.</p><p>Instead, there are couple of different metrics, that we’ll look at, to try to understand bias and variance. So continuing our example of cat picture classification, where that’s a positive example and that’s a negative example, the two key numbers to look at to understand bias and variance will be the train set error and the dev set or the development set error. So for the sake of argument, let’s say that you’re recognizing cats in pictures, is something that people can do nearly perfectly, right?</p><p>So let’s say, your training set error is 1% and your dev set error is, for the sake of argument, let’s say is 11%.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/5.png" alt=""><br>So in this example, you’re doing very well on the training set, but you’re doing relatively poorly on the development set. <strong>So this looks like you might have overfit the training set, that somehow you’re not generalizing well, to this whole cross-validation set in the development set</strong>. And so if you have an example like this, we would say this has <strong>high variance</strong>.</p><p><strong>So by looking at the training set error and the development set error, you would be able to render a diagnosis of your algorithm having high variance. Now, let’s say, that you measure your training set and your dev set error, and you get a different result.</strong></p><p>Let’s say, that your training set error is 15%. I’m writing your training set error in the top row, and your dev set error is 16%.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/5.png" alt=""><br><strong>In this case, assuming that humans achieve roughly 0% error, that humans can look at these pictures and just tell if it’s cat or not</strong>, then it looks like the algorithm is not even doing very well on the training set. So if it’s not even fitting the training data set well, then this is <strong>underfitting</strong> the data. And so this algorithm has <strong>high bias</strong>. <strong>But in contrast, this actually generalizing at a reasonable level to the dev set, whereas performance in the dev set is only 1% worse than performance in the training set. So this algorithm has a problem of high bias, because it was not even fitting the training set</strong>. Well, this is similar to the leftmost plots we had on the previous slide.</p><p>Now, here’s another example. Let’s say that you have 15% training set error, so that’s pretty high bias, but when you evaluate to the dev set it does even worse, maybe it does 30%.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/5.png" alt=""><br>In this case, I would diagnose this algorithm as having high bias, because it’s not doing that well on the training set, and high variance. So this has really the worst of both worlds. And one last example, if you have 0.5 training set error, and 1% dev set error, then maybe our users are quite happy, that you have a cat classifier with only 1%, than just we have <strong>low bias and low variance</strong>.</p><p>One subtlety, that I’ll just briefly mention that we’ll leave to a later video to discuss in detail, is that this analysis is predicated on the assumption, that human level performance gets nearly 0% error or, more generally, that the <strong>optimal error</strong>, sometimes called <strong>base error</strong>, so the base in optimal error is nearly 0%. I don’t want to go into detail on this in this particular video, but it turns out that if the optimal error or the base error were much higher, say, it were 15%, then if you look at this classifier, 15% is actually perfectly reasonable for training set and you wouldn’t see it as high bias and also a pretty low variance. So the case of how to analyze bias and variance, when no classifier can do very well, for example, if you have really blurry images, so that even a human or just no system could possibly do very well, then maybe base error is much higher, and then there are some details of how this analysis will change. <strong>But leaving aside this subtlety for now, the takeaway is that by looking at your training set error you can get a sense of how well you are fitting, at least the training data, and so that tells you if you have a bias problem. And then looking at how much higher your error goes, when you go from the training set to the dev set, that should give you a sense of how bad is the variance problem, so you’ll be doing a good job generalizing from a training set to the dev set, that gives you sense of your variance. All this is under the assumption that the base error is quite small and that your training and your dev sets are drawn from the same distribution. If those assumptions are violated, there’s a more sophisticated analysis you could do</strong>, which we’ll talk about in the later video.</p><p>Now, on the previous slide, you saw what high bias, high variance looks like? and I guess you have the sense of what it a good class can look like. What does high bias and high variance looks like? This is kind of the worst of both worlds. So you remember, we said that a classifier like this, then your classifier has high bias, because it underfits the data.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/4-1.png" alt=""><br>So this would be a classifier that is mostly linear and therefore underfits the data, we’re drawing this is purple. But if somehow your classifier does some weird things, then it is actually overfitting parts of the data as well.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/6.png" alt=""><br>So <strong>this would be a classifier that is <em>mostly</em> linear and therefore underfits the data</strong>, we’re drawing this is <strong>purple</strong>. But if somehow your classifier does some weird things, <strong>then it is actually overfitting <em>parts</em> of the data as well</strong>. So the classifier that I drew in purple, has both high bias and high variance. Where it has high bias, because, by being a mostly linear classifier, is just not fitting. You know, this quadratic line shape that well, but by having too much flexibility in the middle, it somehow gets this example, and this example overfits those two examples as well. So this classifier kind of has high bias because it was mostly linear, but you need maybe a curve function or quadratic function. And it has high variance, because it had too much flexibility to fit those two mislabel, or those live examples in the middle as well. <strong>In case this seems contrived, well, this example is a little bit contrived in two dimensions, but with very high dimensional inputs. You actually do get things with high bias in some regions and high variance in some regions, and so it is possible to get classifiers like this in high dimensional inputs that seem less contrived</strong>.</p><p>So to summarize, you’ve seen how by looking at your algorithm’s error on the training set and your algorithm’s error on the dev set you can try to diagnose, whether it has problems of high bias or high variance, or maybe both, or maybe neither. And depending on whether your algorithm suffers from bias or variance, it turns out that there are different things you could try. <strong>So in the next video, I want to present to you, what I call a basic recipe for Machine Learning, that lets you more systematically try to improve your algorithm, depending on whether it has high bias or high variance issues</strong>. So let’s go on to the next video.</p><h3 id="03-basic-recipe-for-machine-learning"><a href="#03-basic-recipe-for-machine-learning" class="headerlink" title="03_basic-recipe-for-machine-learning"></a>03_basic-recipe-for-machine-learning</h3><p>In the previous video, you saw how looking at training error and depth error can help you diagnose whether your algorithm has a bias or a variance problem, or maybe both. It turns out that this information that lets you much more systematically using what they call a basic recipe for machine learning and lets you much more systematically go about improving your algorithms’ performance. Let’s take a look.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/7.png" alt=""><br>When training a neural network, here’s a basic recipe I will use. After having trained an initial model, I will <strong>first ask, does your algorithm have high bias?</strong> And so to try and evaluate if there is high bias, you should look at, really, the training set or the training data performance. Right. And so, <em>if it does have high bias, does not even fit in the training set that well, some things you could try would be to try pick a network, <strong>such as more hidden layers or more hidden units</strong>, or you could train it longer. <strong>Maybe run trains longer or try some more advanced optimization algorithms</strong>, which we’ll talk about later in this course. Or you can also try, this is kind of a, maybe it work, maybe it won’t. But we’ll see later that there are a lot of different neural network architectures and <strong>maybe you can find a new network architecture that’s better suited for this problem</strong>. Putting this in parentheses because one of those things that, you just have to try. Maybe you can make it work, maybe not. Whereas getting a bigger network almost always helps. And training longer doesn’t always help, but it certainly never hurts. So when training a learning algorithm, I would try these things until I can at least get rid of the bias problems</em>, as in go back after I’ve tried this and keep doing that until I can fit, at least, fit the training set pretty well.</p><p>And usually if you have a big enough network, you should usually be able to fit the training data well so long as it’s a problem that is possible for someone to do, alright? If the image is very blurry, it may be impossible to fit it. But if at least a human can do well on the task, if you think base error is not too high, then by training a big enough network you should be able to, hopefully, do well, at least on the training set. To at least fit or overfit the training set. <strong>Once you reduce bias to acceptable amounts then ask, do you have a variance problem?</strong> And so to evaluate that I would look at dev set performance. Are you able to generalize from a pretty good training set performance to having a pretty good dev set performance? And if you have high variance, well, <strong>best way to solve a high variance problem is to get more data</strong>. If you can get it this, you know, can only help. <strong>But sometimes you can’t get more data. Or you could try regularization</strong>, which we’ll talk about in the next video, to try to reduce overfitting. <strong>And then also, again, sometimes you just have to try it. But if you can find a more appropriate neural network architecture, sometimes that can reduce your variance problem as well, as well as reduce your bias problem</strong>.</p><p><strong>But how to do that? It’s harder to be totally systematic how you do that. But so I try these things and I kind of keep going back, until hopefully you find something with both low bias and low variance, whereupon you would be done. So a couple of points to notice</strong>. <strong>First</strong> is that, depending on whether you have high bias or high variance, the set of things you should try could be quite different. So I’ll usually use the training dev set to try to diagnose if you have a bias or variance problem, and then use that to select the appropriate subset of things to try. So for example, if you actually have a high bias problem, getting more training data is actually not going to help. Or at least it’s not the most efficient thing to do. <strong>So being clear on how much of a bias problem or variance problem or both can help you focus on selecting the most useful things to try</strong>. <strong>Second</strong>, in the earlier era of machine learning, there used to be a lot of discussion on what is called <strong>the bias variance tradeoff</strong>. And the reason for that was that, for a lot of the things you could try, you could increase bias and reduce variance, or reduce bias and increase variance. <em>But back in the pre-deep learning era, we didn’t have many tools, we didn’t have as many tools that just reduce bias or that just reduce variance without hurting the other one. But in the modern deep learning, big data era, so long as you can keep training a bigger network, and so long as you can keep getting more data, which isn’t always the case for either of these, but if that’s the case, then getting a bigger network almost always just reduces your bias without necessarily hurting your variance, so long as you regularize appropriately. And getting more data pretty much always reduces your variance and doesn’t hurt your bias much</em>. <strong>So what’s really happened is that, with these two steps, the ability to train, pick a network, or get more data, we now have tools to drive down bias and just drive down bias, or drive down variance and just drive down variance, without really hurting the other thing that much</strong>. <em>And I think this has been one of the big reasons that deep learning has been so useful for supervised learning, that there’s much less of this tradeoff where you have to carefully balance bias and variance, but sometimes you just have more options for reducing bias or reducing variance without necessarily increasing the other one.</em></p><p>And, in fact, [inaudible] you have a well regularized network. We’ll talk about regularization starting from the next video. <strong>Training a bigger network almost never hurts. And the main cost of training a neural network that’s too big is just computational time, so long as you’re regularizing</strong>.</p><p>So I hope this gives you a sense of the basic structure of how to organize your machine learning problem to diagnose bias and variance, and then try to select the right operation for you to make progress on your problem. <strong>One of the things I mentioned several times in the video is regularization, is a very useful technique for reducing variance. There is a little bit of a bias variance tradeoff when you use regularization. It might increase the bias a little bit, although often not too much if you have a huge enough network. But let’s dive into more details in the next video so you can better understand how to apply regularization to your neural network.</strong></p><h2 id="02-regularizing-your-neural-network"><a href="#02-regularizing-your-neural-network" class="headerlink" title="02_regularizing-your-neural-network"></a>02_regularizing-your-neural-network</h2><h3 id="01-regularization"><a href="#01-regularization" class="headerlink" title="01_regularization"></a>01_regularization</h3><p>If you suspect your neural network is over fitting your data. That is you have a high variance problem, one of the first things you should try per probably regularization. The other way to address high variance, is to get more training data that’s also quite reliable. But you can’t always get more training data, or it could be expensive to get more data. But adding regularization will often help to prevent overfitting, or to reduce the errors in your network. So let’s see how regularization works.</p><h4 id="regularization-for-logistic-regression"><a href="#regularization-for-logistic-regression" class="headerlink" title="regularization for logistic regression"></a>regularization for logistic regression</h4><p>Let’s develop these ideas using logistic regression. Recall that for logistic regression, you try to minimize the cost function J, which is defined as this cost function. Some of your training examples of the losses of the individual predictions in the different examples, where you recall that w and b in the logistic regression, are the parameters.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/8.png" alt=""><br>So w is an x-dimensional parameter vector, and b is a real number. And so to add regularization to the logistic regression, what you do is add to it this thing, lambda, which is called the <strong>regularization parameter</strong>. I’ll say more about that in a second. But lambda/2m times the norm of w squared. So here, the norm of w squared is just equal to sum from j equals 1 to nx of wj squared, or this can also be written w transpose w, it’s just a square Euclidean norm of the prime to vector w. And this is called <strong>L2 regularization</strong>. <strong>Because here, you’re using the Euclidean normals, or else the L2 norm with the prime to vector w</strong>. Now, why do you regularize just the parameter w? Why don’t we add something here about b as well? In practice, you could do this, but I usually just omit this. Because if you look at your parameters, w is usually a pretty high dimensional parameter vector, especially with a high variance problem. Maybe w just has a lot of parameters, so you aren’t fitting all the parameters well, whereas b is just a single number. So almost all the parameters are in w rather b. And if you add this last term in practice, it won’t make much of a difference, because b is just one parameter over a very large number of parameters. In practice, I usually just don’t bother to include it. But you can if you want. So L2 regularization is the most common type of regularization. You might have also heard of some people talk about <strong>L1 regularization</strong>. <strong>And that’s when you add, instead of this L2 norm, you instead add a term that is lambda/m of sum over of this. And this is also called the L1 norm of the parameter vector w</strong>, so the little subscript 1 down there, right? And I guess whether you put m or 2m in the denominator, is just a scaling constant. If you use L1 regularization, then w will end up being <strong>sparse</strong>. And what that means is that the w vector will have a lot of zeros in it. <strong>And some people say that this can help with compressing the model, because the set of parameters are zero, and you need less memory to store the model. Although, I find that, in practice, L1 regularization to make your model sparse, helps only a little bit. So I don’t think it’s used that much, at least not for the purpose of compressing your model. And when people train your networks, L2 regularization is just used much much more often</strong>. Sorry, just fixing up some of the notation here. So <strong>one last detail. Lambda here is called the regularization, Parameter. And usually, you set this using your development set, or using [INAUDIBLE] cross validation. When you a variety of values and see what does the best, in terms of trading off between doing well in your training set versus also setting that two normal of your parameters to be small. Which helps prevent over fitting. So lambda is another hyper parameter that you might have to tune</strong>.</p><p><strong>And by the way, for the programming exercises, lambda is a reserved keyword in the Python programming language. So in the programming exercise, we’ll have lambd, without the a, so as not to clash with the reserved keyword in Python. So we use lambd to represent the lambda regularization parameter</strong>. So this is how you implement L2 regularization for logistic regression.</p><h4 id="regularization-for-neural-network"><a href="#regularization-for-neural-network" class="headerlink" title="regularization for neural network"></a>regularization for neural network</h4><p>How about a neural network? In a neural network, you have a cost function that’s a function of all of your parameters, w[1], b[1] through w[L], b[L], <strong>where capital L is the number of layers in your neural network</strong>. And so the cost function is this, sum of the losses, summed over your m training examples.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/9.png" alt=""><br>And says at regularization, you add lambda over 2m of sum over all of your parameters W, your parameter matrix is w, of their, that’s called the squared norm. Where this norm of a matrix, meaning the squared norm is defined as the sum of the i sum of j, of each of the elements of that matrix, squared. And if you want the indices of this summation. This is sum from i=1 through n[l-1]. Sum from j=1 through n[l], because w is an n[l-1] by n[l] dimensional matrix, where these are the number of units in layers [l-1] in layer l. So this matrix norm, it turns out is called the Frobenius norm of the matrix, denoted with a F in the subscript. So for arcane linear algebra technical reasons, this is not called <strong>the l2 normal of a matrix</strong>. Instead, it’s called the <strong>Frobenius norm of a matrix</strong>. I know it sounds like it would be more natural to just call the l2 norm of the matrix, but for really arcane reasons that you don’t need to know, by convention, this is called the Frobenius norm. It just means the sum of square of elements of a matrix. So how do you implement gradient descent with this? Previously, we would complete dw using backprop, where backprop would give us the partial derivative of J with respect to w, or really w for any given [l]. And then you update w[l], as w[l]- the learning rate times d. So this is before we added this extra regularization term to the objective. Now that we’ve added this regularization term to the objective, what you do is you take dw and you add to it, lambda/m times w. And then you just compute this update, same as before. And it turns out that with this new definition of dw[l], this new dw[l] is still a correct definition of the derivative of your cost function, with respect to your parameters, now that you’ve added the extra regularization term at the end. And it’s for this reason that L2 regularization is sometimes also called weight decay. So if I take this definition of dw[l] and just plug it in here, then you see that the update is w[l] = w[l] times the learning rate alpha times the thing from backprop, +lambda of m times w[l]. Throw the minus sign there. And so this is equal to w[l]- alpha lambda / m times w[l]- alpha times the thing you got from backpop. And so this term shows that whatever the matrix w[l] is, you’re going to make it a little bit smaller, right? <strong>This is actually as if you’re taking the matrix w and you’re multiplying it by 1-alpha lambda/m. You’re really taking the matrix w and subtracting alpha lambda/m times this. Like you’re multiplying matrix w by this number, which is going to be a little bit less than 1. So this is why L2 norm regularization is also called weight decay</strong>. Because it’s just like the ordinally gradient descent, where you update w by subtracting alpha times the original gradient you got from backprop. But now you’re also multiplying w by this thing, which is a little bit less than 1. So the alternative name for L2 regularization is weight decay. I’m not really going to use that name, but the intuition for it’s called weight decay is that this first term here, is equal to this. So you’re just multiplying the weight metrics by a number slightly less than 1. So that’s how you implement L2 regularization in neural network. Now, one question that [INAUDIBLE] has asked me is, hey, Andrew, why does regularization prevent over-fitting? Let’s look at the next video, and gain some intuition for how regularization prevents over-fitting.</p><h3 id="02-why-regularization-reduces-overfitting"><a href="#02-why-regularization-reduces-overfitting" class="headerlink" title="02_why-regularization-reduces-overfitting"></a>02_why-regularization-reduces-overfitting</h3><p>Why does regularization help with overfitting? Why does it help with reducing variance problems? Let’s go through a couple examples to gain some intuition about how it works. So, recall that high bias, high variance. And I just write pictures from our earlier video that looks something like this. Now, let’s see a fitting large and deep neural network.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/10.png" alt=""></p><p>I know I haven’t drawn this one too large or too deep, unless you think some neural network and this currently overfitting. So you have some cost function like J of W, B equals sum of the losses. So what we did for regularization was add this extra term that penalizes the weight matrices from being too large. So that was the Frobenius norm. So why is it that shrinking the L two norm or the Frobenius norm or the parameters might cause less overfitting?</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/11.png" alt=""></p><p><strong>One piece of intuition is that if you crank regularisation lambda to be really, really big, they’ll be really incentivized to set the weight matrices W to be reasonably close to zero. So one piece of intuition is maybe it set the weight to be so close to zero for a lot of hidden units that’s basically zeroing out a lot of the impact of these hidden units. And if that’s the case, then this much simplified neural network becomes a much smaller neural network. In fact, it is almost like a logistic regression unit, but stacked most probably as deep. And so that will take you from this overfitting case much closer to the left to other high bias case</strong>.</p><p><strong>But hopefully there’ll be an intermediate value of lambda that results in a result closer to this just right case in the middle</strong>. But the intuition is that by cranking up lambda to be really big they’ll set W close to zero, which in practice this isn’t actually what happens. We can think of it as zeroing out or at least reducing the impact of a lot of the hidden units so you end up with what might feel like a simpler network. They get closer and closer as if you’re just using logistic regression. <strong>The intuition of completely zeroing out of a bunch of hidden units isn’t quite right. It turns out that what actually happens is they’ll still use all the hidden units, but each of them would just have a much smaller effect. But you do end up with a simpler network and as if you have a smaller network that is therefore less prone to overfitting</strong>. So a lot of this intuition helps better when you implement regularization in the program exercise, you actually see some of these variance reduction results yourself.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/12.png" alt=""></p><p>Here’s another attempt at additional intuition for why regularization helps prevent overfitting. And for this, I’m going to assume that we’re using the tanh activation function which looks like this. This is a g of z equals tanh of z. So if that’s the case, notice that so long as Z is quite small, so if Z takes on only a smallish range of parameters, maybe around here, then you’re just using the linear regime of the tanh function. Is only if Z is allowed to wander up to larger values or smaller values like so, that the activation function starts to become less linear. So the intuition you might take away from this is that if lambda, the regularization parameter, is large, then you have that your parameters will be relatively small, because they are penalized being large into a cos function. And so if the blades W are small then because Z is equal to W and then technically is plus b, but if W tends to be very small, then Z will also be relatively small. And in particular, if Z ends up taking relatively small values, just in this whole range, then G of Z will be roughly linear. So it’s as if every layer will be roughly linear. As if it is just linear regression. And we saw in course one that if every layer is linear then your whole network is just a linear network. And so even a very deep network, with a deep network with a linear activation function is at the end they are only able to compute a linear function. So it’s not able to fit those very very complicated decision. Very non-linear decision boundaries that allow it to really overfit right to data sets like we saw on the overfitting high variance case on the previous slide. <strong>So just to summarize, if the regularization becomes very large, the parameters W very small, so Z will be relatively small, kind of ignoring the effects of b for now, so Z will be relatively small or, really, I should say it takes on a small range of values. And so the activation function if is tanh, say, will be relatively linear. And so your whole neural network will be computing something not too far from a big linear function which is therefore pretty simple function rather than a very complex highly non-linear function. And so is also much less able to overfit</strong>.</p><p>And again, when you enter in regularization for yourself in the program exercise, you’ll be able to see some of these effects yourself. Before wrapping up our discussion on regularization, I just want to give you one implementational tip. Which is that, when implanting regularization, we took our definition of the cost function J and we actually modified it by adding this extra term that penalizes the weight being too large.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/13.png" alt=""><br>And so if you implement gradient descent, one of the steps to debug gradient descent is to plot the cost function J as a function of the number of elevations of gradient descent and you want to see that the cost function J decreases monotonically after every elevation of gradient descent. And if you’re implementing regularization then please remember that J now has this new definition. If you plot the old definition of J, just this first term, then you might not see a decrease monotonically. So to debug gradient descent make sure that you’re plotting this new definition of J that includes this second term as well. Otherwise you might not see J decrease monotonically on every single elevation. So that’s it for L two regularization which is actually a regularization technique that I use the most in training deep learning modules. In deep learning there is another sometimes used regularization technique called dropout regularization. Let’s take a look at that in the next video.</p><h3 id="03-dropout-regularization"><a href="#03-dropout-regularization" class="headerlink" title="03_dropout-regularization"></a>03_dropout-regularization</h3><p>In addition to L2 regularization, another very powerful regularization techniques is called “dropout.”</p><p>Let’s see how that works. Let’s say you train a neural network like the one on the left and there’s over-fitting. Here’s what you do with dropout. Let me make a copy of the neural network.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/15.png" alt=""><br>With dropout, what we’re going to do is go through each of the layers of the network and set some probability of eliminating a node in neural network. Let’s say that for each of these layers, we’re going to- for each node, toss a coin and have a 0.5 chance of keeping each node and 0.5 chance of removing each node.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/14.png" alt=""><br>So, after the coin tosses, maybe we’ll decide to eliminate those nodes, then what you do is actually remove all the outgoing things from that no as well. So you end up with a much smaller, really much diminished network.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/16.png" alt=""><br>And then you do back propagation training. There’s one example on this much diminished network. <strong>And then on different examples, you would toss a set of coins again and keep a different set of nodes and then dropout or eliminate different than nodes. And so for each training example, you would train it using one of these neural based networks.</strong></p><p>So, <strong>maybe it seems like a slightly crazy technique. They just go around coding those are random, but this actually works. But you can imagine that because you’re training a much smaller network on each example or maybe just give a sense for why you end up able to regularize the network, because these much smaller networks are being trained</strong>.</p><h4 id="Inverted-dropout"><a href="#Inverted-dropout" class="headerlink" title="Inverted dropout"></a>Inverted dropout</h4><p>Let’s look at how you implement dropout. There are a few ways of implementing dropout. I’m going to show you the most common one, which is technique called <strong>inverted dropout</strong>.</p><p>For the sake of completeness, let’s say we want to illustrate this with layer l=3. So, in the code I’m going to write- there will be a bunch of 3s here. <strong>I’m just illustrating how to represent dropout in a single layer</strong>.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/17.png" alt=""></p><p>So, what we are going to do is set a vector d and d^3 is going to be the dropout vector for the layer 3. That’s what the d3 is to be np.random.rand(a). And this is going to be the same shape as a3. And when I see if this is less than some number, which I’m going to call <strong>keep.prob</strong>. And so, keep.prob is a number. It was 0.5 on the previous time, and maybe now I’ll use 0.8 in this example, and there will be the probability that a given hidden unit will be kept. <strong>So to set keep.prob = 0.8, then this means that there’s a 0.2 chance of eliminating any hidden unit</strong>. So, what it does is it generates a random matrix. And this works as well if you have factorized. So d3 will be a matrix. Therefore, each example have a each hidden unit there’s a 0.8 chance that the corresponding d3 will be one, and a 20% chance there will be zero. So, this random numbers being less than 0.8 it has a 0.8 chance of being one or be true, and 20% or 0.2 chance of being false, of being zero.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keep_prob = <span class="number">0.8</span>  <span class="comment"># 设置神经元保留概率</span></span><br><span class="line">d3 = np.random.rand(a3.shape[<span class="number">0</span>], a3.shape[<span class="number">1</span>]) &lt; keep_prob</span><br><span class="line">a3 = np.multiply(a3, d3) <span class="comment"># equal to a3 *= d3;</span></span><br><span class="line">a3 /= keep_prob</span><br></pre></td></tr></table></figure><p><strong>There was a 20% chance of each of the elements of d3 being zero, just multiply operation ends up zeroing out, the corresponding element of d3. If you do this in python, technically d3 will be a boolean array where value is true and false, rather than one and zero. But the multiply operation works and will interpret the true and false values as one and zero</strong>.</p><p><strong>Then finally, we’re going to take a3 and scale it up by dividing by 0.8 or really dividing by our keep.prob parameter</strong>.</p><p>So, let me explain what this final step is doing. Let’s say for the sake of argument that you have 50 units or 50 neurons in the third hidden layer. So maybe a3 is 50 by one dimensional or if you- factorization maybe it’s 50 by m dimensional. So, if you have a 80% chance of keeping them and 20% chance of eliminating them. This means that on average, you end up with 10 units shut off or 10 units zeroed out. And so now, if you look at the value of z^4, $Z^{[4]}=W^{[4]}\cdot a^{[3]}+b^{[4]}$ . And so, on expectation, this will be reduced by 20%. <strong>By which I mean that 20% of the elements of a3 will be zeroed out. So, in order to not reduce the expected value of z^4, what you do is you need to take this, and divide it by 0.8 because this will correct or just a bump that back up by roughly 20% that you need</strong>. So it’s not changed the expected value of a3. And, so this line here is what’s called the <strong>inverted dropout technique</strong>. And its effect is that, no matter what you set to keep.prob to, whether it’s 0.8 or 0.9 or even one, if it’s set to one then there’s no dropout, because it’s keeping everything or 0.5 or whatever, <strong>this inverted dropout technique by dividing by the keep.prob, it ensures that the expected value of a3 remains the same</strong>.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/17.png" alt=""><br>And <strong>it turns out that at test time, when you trying to evaluate a neural network, which we’ll talk about on the next slide, this inverted dropout technique, there is line to are due to the green box at dropping out. This makes test time easier because you have less of a scaling problem</strong>.</p><p>By far the most common implementation of dropouts today as far as I know is inverted dropouts. I recommend you just implement this. But there were some early iterations of dropout that missed this divide by keep.prob line, and so at test time the average becomes more and more complicated. But again, people tend not to use those other versions. <strong>So, what you do is you use the d vector, and you’ll notice that for different training examples, you zero out different hidden units</strong>. And in fact, if you make multiple passes through the same training set, then on different pauses through the training set, you should randomly zero out different hidden units. <strong>So, it’s not that for one example, you should keep zeroing out the same hidden units is that, on iteration one of gradient descent, you might zero out some hidden units. And on the second iteration of gradient descent where you go through the training set the second time, maybe you’ll zero out a different pattern of hidden units.</strong></p><p>And the vector d or d3, for the third layer, is used to decide what to zero out, both in foreprob as well as in that backprob. We are just showing for prob here.</p><h4 id="Don’t-use-dropout-at-test-time"><a href="#Don’t-use-dropout-at-test-time" class="headerlink" title="Don’t use dropout at test time"></a>Don’t use dropout at test time</h4><p>At test time, you’re given some x or which you want to make a prediction. And using our standard notation, I’m going to use a^0, the activations of the zeroes layer to denote just test example x. <strong>So what we’re going to do is not to use dropout at test time</strong> in particular which is in a sense. Z^1= w^1.a^0 + b^1. a^1 = g^1(z^1 Z). Z^2 = w^2.a^1 + b^2. a^2 =… And so on. Until you get to the last layer and that you make a prediction y^. But notice that the test time you’re not using dropout explicitly and you’re not tossing coins at random, you’re not flipping coins to decide which hidden units to eliminate. <strong>And that’s because when you are making predictions at the test time, you don’t really want your output to be random. If you are implementing dropout at test time, that just add noise to your predictions. In theory, one thing you could do is run a prediction process many times with different hidden units randomly dropped out and have it across them. But that’s computationally inefficient and will give you roughly the same result; very, very similar results to this different procedure as well. And just to mention, the inverted dropout thing, you remember the step on the previous line when we divided by the keep_prob. The effect of that was to ensure that even when you don’t see men dropout at test time to the scaling, the expected value of these activations don’t change. So, you don’t need to add in an extra funny scaling parameter at test time. That’s different than when you have that training time</strong>.</p><p>So that’s dropouts. And when you implement this in week’s premier exercise, you gain more firsthand experience with it as well. But why does it really work? What I want to do the next video is give you some better intuition about what dropout really is doing. Let’s go on to the next video.</p><h3 id="04-understanding-dropout"><a href="#04-understanding-dropout" class="headerlink" title="04_understanding-dropout"></a>04_understanding-dropout</h3><p>Drop out does this seemingly crazy thing of randomly knocking out units on your network. Why does it work so well with a regularizer? Let’s gain some better intuition. In the previous video, I gave this intuition that drop-out randomly knocks out units in your network. <strong>So it’s as if on every iteration you’re working with a smaller neural network, and so using a smaller neural network seems like it should have a regularizing effect</strong>.</p><h4 id="spread-out-weights"><a href="#spread-out-weights" class="headerlink" title="spread out weights"></a>spread out weights</h4><p>Here’s a second intuition which is, let’s look at it from the perspective of a single unit. Let’s say this one. Now, for this unit to do his job as for inputs and it needs to generate some meaningful output. <strong>Now with drop out, the inputs can get randomly eliminated</strong>.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/19.png" alt=""><br>Sometimes those two units will get eliminated, sometimes a different unit will get eliminated. <strong>So, what this means is that this unit, which I’m circling in purple, it can’t rely on any one feature because any one feature could go away at random or any one of its own inputs could go away at random</strong>. Some particular would be reluctant to put all of its bets on, say, just this input, right? <strong>The weights, we’re reluctant to put too much weight on any one input because it can go away. So this unit will be more motivated to spread out this way and give you a little bit of weight to each of the four inputs to this unit. And by spreading all the weights, this will tend to have an effect of shrinking the squared norm of the weights. And so, similar to what we saw with L2 regularization, the effect of implementing drop out is that it shrinks the weights and does some of those outer regularization that helps prevent over-fitting</strong>. But it turns out that drop out can formally be shown to be an adaptive form without a regularization. But L2 penalty on different weights are different, depending on the size of the activations being multiplied that way.</p><p>But to summarize, it is possible to show that drop out has a similar effect to L2 regularization. Only to L2 regularization applied to different ways can be a little bit different and even more adaptive to the scale of different inputs.</p><h4 id="One-more-detail-for-when-you’re-implementing-drop-out"><a href="#One-more-detail-for-when-you’re-implementing-drop-out" class="headerlink" title="One more detail for when you’re implementing drop out"></a>One more detail for when you’re implementing drop out</h4><p>Here’s a network where you have three input features.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/20.png" alt=""><br>This is seven hidden units here, seven, three, two, one. <strong>So, one of the parameters we had to choose was the keep_prop which has a chance of keeping a unit in each layer</strong>. So, it is also feasible to vary keep_prop by layer. So for the first layer, your matrix W1 will be three by seven. Your second weight matrix will be seven by seven. W3 will be seven by three and so on. <strong>And so W2 is actually the biggest weight matrix, because they’re actually the largest set of parameters would be in W2 which is seven by seven. So to prevent, to reduce over-fitting of that matrix, maybe for this layer, I guess this is layer two, you might have a keep_prop that’s relatively low, say $0.5$, whereas for different layers where you might worry less about over-fitting, you could have a higher keep_prop, maybe just $0.7$ . And if a layers we don’t worry about over-fitting at all, you can have a key prop of one point zero.</strong><br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/21.png" alt=""><br>For clarity, <strong>these are numbers I’m drawing on the purple boxes</strong>. These could be different keep_props for different layers. <strong>Notice that the keep_prop of one point zero means that you’re keeping every unit and so, you’re really not using drop out for that layer. But for layers where you’re more worried about over-fitting, really the layers with a lot of parameters, you can set the key prop to be smaller to apply a more powerful form of drop out. It’s kind of like cranking up the regularization parameter lambda of L2 regularization where you try to regularize some layers more than others. And technically, you can also apply drop out to the input layer, where you can have some chance of just maxing out one or more of the input features. Although in practice, usually don’t do that that often. And so, a key prop of one point zero was quite common for the input there. You can also use a very high value, maybe zero point nine, but it’s much less likely that you want to eliminate half of the input features.</strong> So usually keep_prop, if you apply the law, will be a number close to one if you even apply drop out at all to the input there.</p><p>So just to summarize, if you’re more worried about some layers overfitting than others, you can set a lower key prop for some layers than others. The downside is, this gives you even more hyper parameters to search for using cross-validation. One other alternative might be to have some layers where you apply drop out and some layers where you don’t apply drop out and then just have one hyper parameter, which is a keep_prop for the layers for which you do apply drop outs.</p><p>And before we wrap up, just a couple implementational tips. Many of the first successful implementations of drop outs were to computer vision. <strong>So in computer vision, the input size is so big, inputting all these pixels that you almost never have enough data. And so drop out is very frequently used by computer vision. And there’s some computer vision researchers that pretty much always use it, almost as a default.</strong> But really the thing to remember is that drop out is a regularization technique, it helps prevent over-fitting. And so, unless my algorithm is over-fitting, I wouldn’t actually bother to use drop out. So it’s used somewhat less often than other application areas. There’s just with computer vision, you usually just don’t have enough data, so you’re almost always overfitting, which is why there tends to be some computer vision researchers who swear by drop out. But their intuition doesn’t always generalize I think to other disciplines.</p><p><strong>One big downside of drop out is that the cost function J is no longer well-defined</strong>. On every iteration, you are randomly killing off a bunch of nodes. And so, if you are double checking the performance of gradient descent, it’s actually harder to double check that you have a well defined cost function J that is going downhill on every iteration. Because the cost function J that you’re optimizing is actually less. Less well defined, or is certainly hard to calculate. So you lose this debugging tool to will a plot, a graph like this.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/21.png" alt=""><br><strong>So what I usually do is turn off drop out, you will set keep_prop equals one, and I run my code and make sure that it is monotonically decreasing J, and then turn on drop out and hope that I didn’t introduce bugs into my code during drop out</strong>. Because you need other ways, I guess, but not plotting these figures to make sure that your code is working to greatness and it’s working even with drop outs. So with that, there’s still a few more regularization techniques that are worth your knowing. Let’s talk about a few more such techniques in the next video.</p><h3 id="05-other-regularization-methods"><a href="#05-other-regularization-methods" class="headerlink" title="05_other-regularization-methods"></a>05_other-regularization-methods</h3><p>In addition to L2 regularization and drop out regularization there are few other techniques to reducing over fitting in your neural network.</p><h4 id="cat-recognition"><a href="#cat-recognition" class="headerlink" title="cat recognition"></a>cat recognition</h4><p>Let’s take a look. Let’s say you fitting a cat classifier. <strong>If you are overfitting getting more training data can help, but getting more training data can be expensive and sometimes you just can’t get more data</strong>. But what you can do is augment your training set by taking image like this.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/22.png" alt=""><br>And for example, <strong>flipping it horizontally</strong> and adding that also with your training set. So now instead of just this one example in your training set, you can add this to your training example. So by flipping the images horizontally, you could double the size of your training set. <strong>Because you’re training set is now a bit redundant this isn’t as good as if you had collected an additional set of brand new independent examples. But you could do this Without needing to pay the expense of going out to take more pictures of cats.</strong> And then other than flipping horizontally, you can <strong>also take random crops of the image</strong>. So here we’re <strong>rotated and sort of randomly zoom into the image</strong> and this still looks like a cat. <strong>So by taking random distortions and translations of the image you could augment your data set and make additional fake training examples. Again, these extra fake training examples they don’t add as much information as they were to call. They get a brand new independent example of a cat. But because you can do this, almost for free, other than for some confrontational costs. This can be an inexpensive way to give your algorithm more data and therefore sort of regularize it and reduce overfitting.</strong> And by synthesizing examples like this what you’re really telling your algorithm is that If something is a cat then flipping it horizontally is still a cat. Notice I didn’t flip it vertically, because maybe we don’t want upside down cats, right? And then also maybe randomly zooming in to part of the image it’s probably still a cat.</p><h4 id="optical-character-recognition"><a href="#optical-character-recognition" class="headerlink" title="optical character recognition"></a>optical character recognition</h4><p>For optical character recognition you can also bring your data set by taking digits and <strong>imposing random rotations and distortions to it</strong>. So If you add these things to your training set, these are also still digit force. For illustration I applied a very strong distortion. So this look very wavy for, in practice you don’t need to distort the four quite as aggressively, but just a more subtle distortion than what I’m showing here, to make this example clearer for you, right? But a more subtle distortion is usually used in practice, because this looks like really warped fours. So data augmentation can be used as a regularization technique, in fact similar to regularization.</p><h4 id="early-stopping"><a href="#early-stopping" class="headerlink" title="early stopping"></a>early stopping</h4><p>There’s one other technique that is often used called early stopping. So what you’re going to do is as you run gradient descent you’re going to plot your, either the training error, you’ll use 01 classification error on the training set. Or just plot the cost function J optimizing, and that should decrease monotonically, like so, all right? Because as you trade, hopefully, you’re trading around your cost function J should decrease. So with early stopping, what you do is you plot this, and you also plot your dev set error. And again, this could be a classification error in a development sense, or something like the cost function, like the logistic loss or the log loss of the dev set. Now what you find is that your dev set error will usually go down for a while, and then it will increase from there.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/23.png" alt=""><br>So what early stopping does is, you will say well, it looks like your neural network was doing best around that iteration, so we just want to stop trading on your neural network halfway and take whatever value achieved this dev set error. So why does this work? Well when you’ve haven’t run many iterations for your neural network yet your parameters w will be close to zero. Because with random initialization you probably initialize w to small random values so before you train for a long time, w is still quite small. And as you iterate, as you train, w will get bigger and bigger and bigger until here maybe you have a much larger value of the parameters w for your neural network. <strong>So what early stopping does is by stopping halfway you have only a mid-size rate w. And so similar to L2 regularization by picking a neural network with smaller norm for your parameters w, hopefully your neural network is over fitting less. And the term early stopping refers to the fact that you’re just stopping the training of your neural network earlier</strong>. I sometimes use early stopping when training a neural network.</p><p>But it does have <strong>one downside</strong>, let me explain. I think of the <strong>machine learning process as comprising several different steps</strong>. One, is that you want an algorithm to optimize the cost function j and we have various tools to do that, such as gradient descent. And then we’ll talk later about other algorithms, like <strong>momentum and RMSprop and Adam and so on</strong>. But after optimizing the cost function j, you also wanted to not over-fit. And we have some tools to do that such as your regularization, getting more data and so on. <strong>Now in machine learning, we already have so many hyper-parameters</strong>. It surge over. It’s already very complicated to choose among the space of possible algorithms. And so I find machine learning easier to think about when you have one set of tools for optimizing the cost function J, and when you’re focusing on optimizing the cost function J. All you care about is finding w and b, so that J(w,b) is as small as possible. You just don’t think about anything else other than reducing this. And then it’s completely separate task to not over fit, in other words, to reduce variance. And when you’re doing that, you have a separate set of tools for doing it. And this principle is sometimes called <strong>orthogonalization</strong>. <strong>And there’s this idea, that you want to be able to think about one task at a time</strong>. I’ll say more about orthorganization in a later video, so if you don’t fully get the concept yet, don’t worry about it.</p><p><strong>But to me the main downside of early stopping is that this couples, these two tasks. So you no longer can work on these two problems independently, because by stopping gradient decent early, you’re sort of breaking whatever you’re doing to optimize cost function J, because now you’re not doing a great job reducing the cost function J. You’ve sort of not done that that well. And then you also simultaneously trying to not over fit. So instead of using different tools to solve the two problems, you’re using one that kind of mixes the two. And this just makes the set of things you could try are more complicated to think about</strong>.</p><p>Rather than using early stopping, one alternative is just use <strong>L2 regularization</strong> then you can just train the neural network as long as possible. <strong>I find that this makes the search space of hyper parameters easier to decompose, and easier to search over. But the downside of this though is that you might have to try a lot of values of the regularization parameter lambda. And so this makes searching over many values of lambda more computationally expensive</strong>.</p><p><strong>And the advantage of early stopping is that running the gradient descent process just once, you get to try out values of small w, mid-size w, and large w, without needing to try a lot of values of the L2 regularization hyperparameter lambda</strong>. If this concept doesn’t completely make sense to you yet, don’t worry about it. We’re going to talk about orthogonalization in greater detail in a later video, I think this will make a bit more sense. Despite it’s disadvantages, many people do use it. <strong>I personally prefer to just use L2 regularization and try different values of lambda. That’s assuming you can afford the computation to do so. But early stopping does let you get</strong> a similar effect <strong>without needing to explicitly try lots of different values of lambda</strong>.</p><p>So you’ve now seen how to use data augmentation as well as if you wish early stopping in order to reduce variance or prevent over fitting your neural network. Next let’s talk about some techniques for setting up your optimization problem to make your training go quickly.</p><h2 id="03-setting-up-your-optimization-problem"><a href="#03-setting-up-your-optimization-problem" class="headerlink" title="03_setting-up-your-optimization-problem"></a>03_setting-up-your-optimization-problem</h2><h3 id="01-normalizing-inputs"><a href="#01-normalizing-inputs" class="headerlink" title="01_normalizing-inputs"></a>01_normalizing-inputs</h3><p>When training a neural network, one of the techniques that will speed up your training is if you normalize your inputs. Let’s see what that means.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/24.png" alt=""><br>Let’s see if a training sets with two input features. So the input features x are two dimensional, and here’s a scatter plot of your training set. <strong>Normalizing your inputs corresponds to two steps. The first is to subtract out or to zero out the mean</strong>. So you set $\mu = \dfrac{1}{m}\sum_{i=1}^{m}x^{(i)}$. So this is a vector, and then $x : =x-\mu$ for every training example, so this means you just move the training set until it has 0 mean. <strong>And then the second step is to normalize the variances</strong>. So notice here that the feature X1 has a much larger variance than the feature X2 here. So what we do is set $\sigma^{2} = \dfrac{1}{m}\sum\limits_{i=1}^{m}x^{(i)^{2}}$, <code>sigma_square = np.sum(Xi**2)</code> in python. I guess this is a element y squaring. And so now sigma squared is a vector with the variances of each of the features, and notice we’ve already subtracted out the mean, so Xi squared, element y squared is just the variances. And you take each example and divide it by this vector sigma squared. And so in pictures, you end up with this. Where now the variance of X1 and X2 are both equal to one.</p><p>And one tip, if you use this to scale your training data, then use the same mu and sigma squared to normalize your test set, right? In particular, you don’t want to normalize the training set and the test set differently. <strong>Whatever this value $\mu$ is and whatever this value $\alpha$ is, use them in these two formulas so that you scale your test set in exactly the same way, rather than estimating mu and sigma squared separately on your training set and test set. Because you want your data, both training and test examples, to go through the same transformation defined by the same mu and sigma squared calculated on your training data</strong>.</p><p>So, why do we do this? Why do we want to normalize the input features? Recall that a cost function is defined as written on the top right. It turns out that if you use unnormalized input features, it’s more likely that your cost function will look like this, it’s a very squished out bowl, <strong>very elongated cost function</strong>, where the minimum you’re trying to find is maybe over there.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/25.png" alt=""><br>But if your features are on very different scales, say the feature X1 ranges from 1 to 1,000, and the feature X2 ranges from 0 to 1, then it turns out that the ratio or the range of values for the parameters w1 and w2 will end up taking on very different values. And so maybe these axes should be w1 and w2, but I’ll plot w and b, then your cost function can be a very elongated bowl like that. <strong>So if you part the contours of this function, you can have a very elongated function like that. Whereas if you normalize the features, then your cost function will on average look more symmetric</strong>. And if you’re running gradient descent on the cost function like the one on the left, then you might have to use a very small learning rate because if you’re here that gradient descent might need a lot of steps to oscillate back and forth before it finally finds its way to the minimum.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/25.png" alt=""><br><strong>Whereas if you have a more spherical contours, then wherever you start gradient descent can pretty much go straight to the minimum. You can take much larger steps with gradient descent rather than needing to oscillate around like like the picture on the left</strong>.</p><p>Of course in practice w is a high-dimensional vector, and so trying to plot this in 2D doesn’t convey all the intuitions correctly. But the rough intuition that your cost function will be more round and easier to optimize when your features are all on similar scales. Not from one to 1000, zero to one, but mostly from minus one to one or of about similar variances of each other. That just makes your cost function J easier and faster to optimize. In practice if one feature, say X1, ranges from zero to one, and X2 ranges from minus one to one, and X3 ranges from one to two, these are fairly similar ranges, so this will work just fine. It’s when they’re on dramatically different ranges like ones from 1 to a 1000, and the another from 0 to 1, that that really hurts your optimization algorithm. But <strong>by just setting all of them to a 0 mean and say, variance 1, like we did in the last slide, that just guarantees that all your features on a similar scale and will usually help your learning algorithm run faster</strong>. So, if your input features came from very different scales, maybe some features are from 0 to 1, some from 1 to 1,000, then it’s important to normalize your features. <strong>If your features came in on similar scales, then this step is less important. Although performing this type of normalization pretty much never does any harm, so I’ll often do it anyway if I’m not sure whether or not it will help with speeding up training for your algebra</strong>.</p><p>So that’s it for normalizing your input features. Next, let’s keep talking about ways to speed up the training of your new network.</p><h3 id="02-vanishing-exploding-gradients"><a href="#02-vanishing-exploding-gradients" class="headerlink" title="02_vanishing-exploding-gradients"></a>02_vanishing-exploding-gradients</h3><p>One of the problems of training neural network, especially very deep neural networks, is <strong>vanishing and exploding gradients</strong>. What that means is that <strong>when you’re training a very deep network your derivatives or your slopes can sometimes get either very, very big or very, very small, maybe even exponentially small, and this makes training difficult</strong>. In this video you see what this problem of exploding and vanishing gradients really means, as well as how you can use careful choices of the random weight initialization to significantly reduce this problem.</p><p>let’s say you’re training a very deep neural network like this, to save space on the slide, I’ve drawn it as if you have only two hidden units per layer, but it could be more as well. But this neural network will have parameters W1, W2, W3 and so on up to WL.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/26.png" alt=""><br>For the sake of simplicity, let’s say we’re using an activaton function $g(z) = z, b = 0$, so linear activation function. So in that case you can show that the output $\hat{y} = W^{[L]}\times W^{[L-1]}\times\cdots\times W^{[2]}\times W^{[1]}X$. Now, let’s say that <strong>each of you weight matrices $W^{[L]}$ is just a little bit larger than one times the identity</strong>. For example, it’s $W^{[l]}=\left[ \begin{array}{l} 1.5 &amp; 0 \ 0 &amp; 1.5\end{array} \right]$ . Technically, the last one has different dimensions so maybe this is just the rest of these weight matrices. Then Y-hat will be, $\hat y = W^{[L]}\left[ \begin{array}{l}1.5 &amp; 0 \\ 0 &amp; 1.5\end{array} \right]^{L-1}X$, because we assume that each one of these matrices is equal to this thing. It’s really 1.5 times the identity matrix, then you end up with this calculation, $\hat y = W^{[L]}1.5^{L-1}\left[ \begin{array}{l} 1 &amp; 0 \\ 0 &amp; 1\end{array} \right]X $. And so Y-hat will be essentially $\hat y = W^{[L]}1.5^{L-1}X$, and <strong>if L was large for very deep neural network, Y-hat will be very large. In fact, it just grows exponentially, it grows like 1.5 to the number of layers. And so if you have a very deep neural network, the value of Y will explode</strong>.</p><p>Now, conversely, if we replace 1.5 with 0.5, so something less than 1, then this becomes 0.5 to the power of L. This matrix becomes $\hat y = W^{[L]}0.5^{L-1}X$. <strong>And so each of your matrices are less than 1</strong>, then let’s say X1, X2 were one one, then the activations will be one half, one half, one fourth, one fourth, one eighth, one eighth, and so on until this becomes one over two to the L.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/27.png" alt=""><br><strong>So the activation values will decrease exponentially as a function of the def, as a function of the number of layers L of the network. So in the very deep network, the activations end up decreasing exponentially</strong>.</p><p>So the intuition I hope you can take away from this is that at <strong>the weights W, if they’re all just a little bit bigger than one or just a little bit bigger than the identity matrix, then with a very deep network the activations can explode. And if W is just a little bit less than identity. So this maybe here’s 0.9, 0.9, then you have a very deep network, the activations will decrease exponentially</strong>.</p><p>And even though I went through this argument in terms of activations increasing or decreasing exponentially as a function of L, a similar argument can be used to show that the derivatives or the gradients the computer is going to send will also increase exponentially or decrease exponentially as a function of the number of layers. With some of the modern neural networks, L equals 150. Microsoft recently got great results with 152 layer neural network. <strong>But with such a deep neural network, if your activations or gradients increase or decrease exponentially as a function of L, then these values could get really big or really small. And this makes training difficult, especially if your gradients are exponentially smaller than L, then gradient descent will take tiny little steps. It will take a long time for gradient descent to learn anything</strong>.</p><p>To summarize, you’ve seen how deep networks suffer from the problems of vanishing or exploding gradients. In fact, for a long time this problem was a huge barrier to training deep neural networks. <strong>It turns out there’s a partial solution that doesn’t completely solve this problem but it helps a lot which is careful choice of how you initialize the weights</strong>. To see that, let’s go to the next video.</p><h3 id="03-weight-initialization-for-deep-networks"><a href="#03-weight-initialization-for-deep-networks" class="headerlink" title="03_weight-initialization-for-deep-networks"></a>03_weight-initialization-for-deep-networks</h3><p>In the last video you saw how very deep neural networks can have the problems of vanishing and exploding gradients. It turns out that a partial solution to this, doesn’t solve it entirely but helps a lot, is better or more careful choice of the random initialization for your neural network. To understand this lets start with the example of initializing the ways for a single neuron and then we’re going to generalize this to a deep network.</p><p>Let’s go through this with an example with just a single neuron and then we’ll talk about the deep net later. So a single neuron you might input four features x1 through x4 and then you have some a=g(z) and end it up with some y and later on for a deeper net you know these inputs will be right, some layer a(l), but for now let’s just call this x for now. So z is going to be equal to w1x1 + w2x2 +… + it goes WnXn and let’s set b=0 so you know lets just ignore b for now. <strong>So in order to make z not blow up and not become too small you notice that the larger n is, the smaller you want Wi to be, right?</strong><br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/28.png" alt=""><br>Because z is the sum of the WiXi and so if you’re adding up a lot of these terms you want each of these terms to be smaller. <strong>One reasonable thing to do would be to set the variance of Wi to be equal to 1 over n, $Variance(W^{[i]}) = {1 \over n}$, where n is the number of input features that’s going into a neuron</strong>. So in practice, what you can do is set the weight matrix <code>WL = np.random.randn(WL.shape[0],WL.shape[1]) * np.sqrt(1/n)</code> whose n is the number of features that I fed into each neuron and there else is going to be $n^{(l-1)}$ because that’s the number of units that I’m feeding into each of the units and they are l. <strong>It turns out that if you’re using a ReLU activation function, to set in the variance that 2 over n works a little bit better.</strong></p><p>So you often see that in initialization especially if you’re using a ReLU activation function so if g(z) is ReLu(z), oh and it depend on how familiar you are with random variables. It turns out that something, a Gaussian random variable and then multiplying it by a square root of this, that says the variance to be quoted this way, to be to 2 over n.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/29.png" alt=""></p><p>And <strong>the reason I went from n to this n superscript l-1 was, in this example with logistic regression which is to input features but the more general case they are l would have an l-1 inputs each of the units in that layer</strong>.</p><p><strong>So if the input features of activations are roughly mean 0 and standard variance and variance 1 then this would cause z to also take on a similar scale and this doesn’t solve, but it definitely helps reduce the vanishing, exploding gradients problem because it’s trying to set each of the weight matrices w not too much bigger than 1 and not too much less than 1 so it doesn’t explode or vanish too quickly</strong>.</p><p>I’ve just mention some other variants. <strong>The version we just described is assuming a <code>ReLU</code> activation function and this by a paper by Herd at al. A few other variants, if you are using a <code>tanh</code> activation function then there’s a paper that shows that instead of using the constant 2 it’s better use the constant 1 and so 1 over this instead of 2 and so you multiply it by the square root of this</strong>. So this square root term will plays this term and you use this if you’re using a TanH activation function. This is called <strong>Xavier initialization</strong>.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/30.png" alt=""></p><p>And another version we’re taught by Yoshua Bengio and his colleagues, you might see in some papers, but is to use this formula, $\sqrt{\frac{2}{n^{[l-1]}+n^{[l]}}}$, which you know has some other theoretical justification. But I would say if you’re using a <code>ReLU</code> activation function, which is really the most common activation function, I would use this formula, $\sqrt{\frac{2}{n^{[l-1]}}}$ . If you’re using <code>tanh</code> you could try this version, $\sqrt{\frac{1}{n^{[l-1]}}}$, instead and some authors will also use $\sqrt{\frac{2}{n^{[l-1]}}}$, <strong>But in practice I think all of these formulas just give you a starting point, it gives you a default value to use for the variance of the initialization of your weight matrices</strong>. If you wish the variance here, this variance parameter could be another thing that you could tune of your hyperparameters so you could have another parameter that multiplies into this formula (pointed by the green arrow) and <strong>tune that multiplier</strong> as part of your hyperparameter surge.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/31.png" alt=""><br>Sometimes tuning the hyperparameter has a modest size effect. <em>It’s not one of the first hyperparameters I would usually try to tune but I’ve also seen some problems with tuning this you know helps a reasonable amount but this is usually lower down for me in terms of how important it is relative to the other hyperparameters you can tune</em>.</p><p>So I hope that gives you some intuition about the problem of vanishing or exploding gradients as well as how choosing a reasonable scaling for how you initialize the weights. Hopefully that makes your weights you know not explode too quickly and not decay to zero too quickly so you can train a reasonably deep network without the weights or the gradients exploding or vanishing too much. When you train deep networks this is another trick that will help you make your neural networks trained much.</p><h3 id="04-numerical-approximation-of-gradients"><a href="#04-numerical-approximation-of-gradients" class="headerlink" title="04_numerical-approximation-of-gradients"></a>04_numerical-approximation-of-gradients</h3><p>When you implement back propagation you’ll find that there’s a test called <strong>creating checking that can really help you make sure that your implementation of back prop is correct</strong>. Because sometimes you write all these equations and you’re just not 100% sure if you’ve got all the details right and internal back propagation. So in order to build up to gradient and checking, let’s first talk about how to numerically approximate computations of gradients and in the next video, we’ll talk about how you can implement gradient checking to make sure the implementation of backdrop is correct.</p><h4 id="one-sided-difference"><a href="#one-sided-difference" class="headerlink" title="one sided difference"></a>one sided difference</h4><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/32.png" alt=""><br>So lets take the function f and replot it here and remember this is f of theta equals theta cubed, and let’s again start off to some value of theta. Let’s say theta equals 1. Now instead of just nudging theta to the right to get theta plus epsilon, we’re going to nudge it to the right and nudge it to the left to get theta minus epsilon, as was theta plus epsilon. So this is 1, this is 1.01, this is 0.99 where, again, epsilon is same as before, it is 0.01. It turns out that rather than taking this little triangle and computing the height over the width, you can get a much better estimate of the gradient if you take this point, f of theta minus epsilon and this point, and you instead compute the height over width of this bigger triangle. So for technical reasons which I won’t go into, the height over width of this bigger green triangle gives you a much better approximation to the derivative at theta. And you saw it yourself, taking just this lower triangle in the upper right is as if you have two triangles, right? This one on the upper right and this one on the lower left. And you’re kind of taking both of them into account by using this bigger green triangle.</p><h4 id="two-sided-difference"><a href="#two-sided-difference" class="headerlink" title="two sided difference"></a>two sided difference</h4><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/33.png" alt=""><br>So rather than a one sided difference, you’re taking a two sided difference. So let’s work out the math. This point here is F of theta plus epsilon. This point here is F of theta minus epsilon. So the height of this big green triangle is f of theta plus epsilon minus f of theta minus epsilon. And then the width, this is 1 epsilon, this is 2 epsilon. So the width of this green triangle is 2 epsilon. So the height of the width is going to be first the height, so that’s F of theta plus epsilon minus F of theta minus epsilon divided by the width. So that was 2 epsilon which we write that down here. And this should hopefully be close to g of theta. So plug in the values, remember f of theta is theta cubed. So this is theta plus epsilon is 1.01. So I take a cube of that minus 0.99 theta cube of that divided by 2 times 0.01. Feel free to pause the video and practice in the calculator. You should get that this is 3.0001. Whereas from the previous slide, we saw that g of theta, this was 3 theta squared so when theta was 1, so these two values are actually very close to each other. The approximation error is now 0.0001. Whereas on the previous slide, we’ve taken the one sided of difference just theta + theta + epsilon we had gotten 3.0301 and so the approximation error was 0.03 rather than 0.0001. So this two sided difference way of approximating the derivative you find that this is extremely close to 3. And so this gives you a much greater confidence that g of theta is probably a correct implementation of the derivative of F. When you use this method for grading, checking and back propagation, this turns out to run twice as slow as you were to use a one-sided difference. It turns out that in practice I think it’s worth it to use this other method because it’s just much more accurate. The little bit of optional theory for those of you that are a little bit more familiar of Calculus, it turns out that, and it’s okay if you don’t get what I’m about to say here. But it turns out that the formal definition of a derivative is for very small values of epsilon is f of theta plus epsilon minus f of theta minus epsilon over 2 epsilon. And the formal definition of derivative is in the limits of exactly that formula on the right as epsilon those as 0. And the definition of unlimited is something that you learned if you took a Calculus class but I won’t go into that here. <strong>And it turns out that for a non zero value of epsilon, you can show that the error of this approximation, $f’(\theta) = \frac{f(\theta+\epsilon)-f(\theta-\epsilon)}{\epsilon}$ , is on the order of epsilon squared, $O(\epsilon^2)$, and remember epsilon is a very small number</strong>. So if epsilon is 0.01 which it is here then epsilon squared is 0.0001. <strong>The big O notation means the error is actually some constant times this, but this is actually exactly our approximation error. So the big O constant happens to be 1</strong>. <strong>Whereas in contrast if we were to use this formula, $f’(\theta) = \frac{f(\theta - \epsilon)}{\epsilon}$, the other one, then the error is on the order of epsilon $O(\epsilon)$.</strong></p><p>And again, <strong>when epsilon is a number less than 1, then epsilon is actually much bigger than epsilon squared which is why this formula here is actually much less accurate approximation than this formula on the left. Which is why when doing gradient checking, we rather use this two-sided difference when you compute $f’(\theta) = \frac{f(\theta+\epsilon)-f(\theta-\epsilon)}{\epsilon}$ rather than just one sided difference, $f’(\theta) = \frac{f(\theta - \epsilon)}{\epsilon}$, which is less accurate</strong>.</p><p>If you didn’t understand my last two comments, all of these things are on here. Don’t worry about it. That’s really more for those of you that are a bit more familiar with Calculus, and with numerical approximations. But the takeaway is that this two-sided difference formula is much more accurate.</p><p>And so that’s what we’re going to use when we do gradient checking in the next video. So you’ve seen how by taking a two sided difference, you can numerically verify whether or not a function g, g of theta that someone else gives you is a correct implementation of the derivative of a function f. <strong>Let’s now see how we can use this to verify whether or not your back propagation implementation is correct or if there might be a bug in there that you need to go and tease out</strong></p><h3 id="05-gradient-checking"><a href="#05-gradient-checking" class="headerlink" title="05_gradient-checking"></a>05_gradient-checking</h3><p>Gradient checking is a technique that’s helped me save tons of time, and helped me find bugs in my implementations of back propagation many times. Let’s see how you could use it too to debug, or to verify that your implementation and back process correct.</p><p>So your new network will have some sort of parameters, W1, B1 and so on up to WL bL. So to implement gradient checking, the first thing you should do is take all your parameters and reshape them into a giant vector data. So what you should do is take W which is a matrix, and reshape it into a vector. You gotta take all of these Ws and reshape them into vectors, and then concatenate all of these things, so that you have a giant vector theta. Giant vector pronounced as theta. So we say that the cos function J being a function of the Ws and Bs, You would now have the cost function J being just a function of theta. Next, with W and B ordered the same way, you can also take dW[1], db[1] and so on, and initiate them into big, giant vector d theta of the same dimension as theta. So same as before, we shape dW[1] into the matrix, db[1] is already a vector. We shape dW[L], all of the dW’s which are matrices. Remember, dW1 has the same dimension as W1. db1 has the same dimension as b1. So the same sort of reshaping and concatenation operation, you can then reshape all of these derivatives into a giant vector d theta. Which has the same dimension as theta.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/36.png" alt=""><br><strong>So the question is, now, is the theta the gradient or the slope of the cost function J</strong>? So here’s how you implement gradient checking, and often abbreviate gradient checking to grad check. So first we remember that J Is now a function of the giant parameter, theta, right? So expands to j is a function of theta 1, theta 2, theta 3, and so on. Whatever’s the dimension of this giant parameter vector theta.</p><p><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/37.png" alt=""><br><strong>So to implement grad check, what you’re going to do is implements a loop so that for each I, so for each component of theta, let’s compute D theta approx i to b. And let me take a two sided difference</strong>. So I’ll take J of theta. Theta 1, theta 2, up to theta i. And we’re going to nudge theta i to add epsilon to this. So just increase theta i by epsilon, and keep everything else the same. And because we’re taking a two sided difference, we’re going to do the same on the other side with theta i, but now minus epsilon. And then all of the other elements of theta are left alone. And then we’ll take this, and we’ll divide it by 2 theta. And what we saw from the previous video is that this should be approximately equal to d theta i. Of which is supposed to be the partial derivative of J or of respect to, I guess theta i, if d theta i is the derivative of the cost function J. So what you going to do is you’re going to compute to this for every value of i. And at the end, you now end up with two vectors. You end up with this d theta approx, and this is going to be the same dimension as d theta. And both of these are in turn the same dimension as theta. <strong>And what you want to do is check if these vectors , $d_{approx}\theta, d\theta $, are approximately equal to each other</strong>.</p><p>So, in detail, well <strong>how you do you define whether or not two vectors are really reasonably close to each other? What I do is the following. I would compute the Euclidean distance between these two vectors</strong>, d theta approx minus d theta, so just the Euclidean norm of this. Notice there’s no square on top, so this is the sum of squares of elements of the differences, and then you take a square root, as you get the <strong>Euclidean distance</strong>. And then just to normalize by the lengths of these vectors, divide by d theta approx plus d theta. Just take the Euclidean lengths of these vectors. <strong>And the row for the denominator is just in case any of these vectors are really small or really large, your the denominator turns this formula into a ratio</strong>.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/38.png" alt=""><br>So we implement this in practice, I use epsilon equals maybe 10 to the minus 7, so minus 7. And with this range of epsilon, if you find that <strong>this formula gives you a value like 10 to the minus 7 or smaller, then that’s great. It means that your derivative approximation is very likely correct</strong>. This is just a very small value. <strong>If it’s maybe on the range of 10 to the -5, I would take a careful look. Maybe this is okay. But I might double-check the components of this vector, and make sure that none of the components are too large. And if some of the components of this difference are very large, then maybe you have a bug somewhere. And if this formula on the left is on the other is -3, then I would wherever you have would be much more concerned that maybe there’s a bug somewhere. But you should really be getting values much smaller then 10 minus 3. If any bigger than 10 to minus 3, then I would be quite concerned. I would be seriously worried that there might be a bug</strong>. And I would then, you should then look at the individual components of data to see if there’s a specific value of i for which d theta across i is very different from d theta i. And use that to try to track down whether or not some of your derivative computations might be incorrect. And after some amounts of debugging, it finally, it ends up being this kind of very small value, then you probably have a correct implementation.</p><p>So when implementing a neural network, what often happens is I’ll implement foreprop, implement backprop. And then I might find that this grad check has a relatively big value. And then I will suspect that there must be a bug, go in debug, debug, debug. And after debugging for a while, If I find that it passes grad check with a small value, then you can be much more confident that it’s then correct.</p><p>So you now know how gradient checking works. This has helped me find lots of bugs in my implementations of neural nets, and I hope it’ll help you too. In the next video, I want to share with you some tips or some notes on how to actually implement gradient checking. Let’s go onto the next video.</p><h3 id="06-gradient-checking-implementation-notes"><a href="#06-gradient-checking-implementation-notes" class="headerlink" title="06_gradient-checking-implementation-notes"></a>06_gradient-checking-implementation-notes</h3><p>In the last video you learned about gradient checking. In this video, I want to share with you some practical tips or some notes on how to actually go about implementing this for your neural network.<br><img src="http://q6gm8fomw.bkt.clouddn.com/gitpage/deeplearning.ai/deep-neural-network/01_practical-aspects-of-deep-learning/39.png" alt=""><br><strong>First</strong>, don’t use grad check in training, only to debug. So what I mean is that, computing d theta approx i, for all the values of i, this is a very slow computation. So to implement gradient descent, you’d use backprop to compute d theta and just use backprop to compute the derivative. And it’s only when you’re debugging that you would compute this to make sure it’s close to d theta. But once you’ve done that, then you would turn off the grad check, and don’t run this during every iteration of gradient descent, because that’s just much too slow.</p><p><strong>Second</strong>, if an algorithm fails grad check, look at the components, look at the individual components, and try to identify the bug. So what I mean by that is if d theta approx is very far from d theta, what I would do is look at the different values of i to see which are the values of d theta approx that are really very different than the values of d theta. So for example, if you find that the values of theta or d theta, they’re very far off, all correspond to dbl for some layer or for some layers, but the components for dw are quite close, right? Remember, different components of theta correspond to different components of b and w. When you find this is the case, then maybe you find that the bug is in how you’re computing db, the derivative with respect to parameters b. And similarly, vice versa, if you find that the values that are very far, the values from d theta approx that are very far from d theta, you find all those components came from dw or from dw in a certain layer, then that might help you hone in on the location of the bug. This doesn’t always let you identify the bug right away, but sometimes it helps you give you some guesses about where to track down the bug.</p><p><strong>Next</strong>, when doing grad check, remember your regularization term if you’re using regularization. So if your cost function is J of theta equals 1 over m sum of your losses and then plus this regularization term. And sum over l of wl squared, <strong>then this is the definition of J. And you should have that d theta is gradient of J with respect to theta, including this regularization term. So just remember to include that term</strong>.</p><p><strong>Next</strong>, grad check doesn’t work with dropout, because in every iteration, dropout is randomly eliminating different subsets of the hidden units. There isn’t an easy to compute cost function J that dropout is doing gradient descent on. It turns out that dropout can be viewed as optimizing some cost function J, but it’s cost function J defined by summing over all exponentially large subsets of nodes they could eliminate in any iteration. So the cost function J is very difficult to compute, and you’re just sampling the cost function every time you eliminate different random subsets in those we use dropout. So it’s difficult to use grad check to double check your computation with dropouts. So what I usually do is implement grad check without dropout. So if you want, you can set keep-prob and dropout to be equal to 1.0. And then turn on dropout and hope that my implementation of dropout was correct. There are some other things you could do, like fix the pattern of nodes dropped and verify that grad check for that pattern of [INAUDIBLE] is correct, but in practice I don’t usually do that. <strong>So my recommendation is turn off dropout, use grad check to double check that your algorithm is at least correct without dropout, and then turn on dropout.</strong></p><p><strong>Finally</strong>, this is a subtlety. It is not impossible, rarely happens, but it’s not impossible that your implementation of gradient descent is correct when w and b are close to 0, so at random initialization. But that as you run gradient descent and w and b become bigger, maybe your implementation of backprop is correct only when w and b is close to 0, but it gets more inaccurate when w and b become large. So one thing you could do, I don’t do this very often, but one thing you could do is run grad check at random initialization and then train the network for a while so that w and b have some time to wander away from 0, from your small random initial values. And then run grad check again after you’ve trained for some number of iterations. So that’s it for gradient checking.</p><h2 id="conclusion-of-this-week"><a href="#conclusion-of-this-week" class="headerlink" title="conclusion of this week"></a>conclusion of this week</h2><p>And congratulations for coming to the end of this week’s materials. In this week, you’ve learned about how to set up your train, dev, and test sets, how to analyze bias and variance and what things to do if you have high bias versus high variance versus maybe high bias and high variance. You also saw how to apply different forms of regularization, like L2 regularization and dropout on your neural network. So some tricks for speeding up the training of your neural network. And then finally, gradient checking. So I think you’ve seen a lot in this week and you get to exercise a lot of these ideas in this week’s programming exercise. So best of luck with that, and I look forward to seeing you in the week two materials.</p>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://snakecoding.com/2018/02/08/summary_of_neural-networks-deep-learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Karan">
      <meta itemprop="description" content="Refuse to Fall">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Machine Learning">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/02/08/summary_of_neural-networks-deep-learning/" class="post-title-link" itemprop="url">summary of neural-networks-deep-learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-02-08 00:00:00" itemprop="dateCreated datePublished" datetime="2018-02-08T00:00:00+05:30">2018-02-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-06 20:25:10" itemprop="dateModified" datetime="2020-04-06T20:25:10+05:30">2020-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>3.3k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>3 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>This is my personal summary after studying the course <a href="https://www.coursera.org/learn/neural-networks-deep-learning/" target="_blank" rel="noopener">neural-networks-deep-learning</a>, which belongs to <a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">Deep Learning Specialization</a>. and the copyright belongs to <a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a>.</p><h2 id="My-personal-notes"><a href="#My-personal-notes" class="headerlink" title="My personal notes"></a>My personal notes</h2><p>$1_{st}$ week: <a href="/2018/02/01/01_introduction-to-deep-learning/">introduction-to-deep-learning</a></p><ul><li><a href="/2018-04-02/01_introduction-to-deep-learning/#01_introduction-to-deep-learning">01_introduction-to-deep-learning</a><ul><li>[01_What is neural network?](/2018-04-02/01_introduction-to-deep-learning/#01_What is neural network?)<ul><li>[Example 1 – single neural network](/2018-04-02//01_introduction-to-deep-learning/#Example 1 – single neural network)</li><li>[Example 2 – Multiple neural network](/2018-04-02//01_introduction-to-deep-learning/#Example 2 – Multiple neural network)</li></ul></li></ul></li><li><a href="/2018-04-02/01_introduction-to-deep-learning/#02_supervised-learning-with-neural-networks">02_supervised-learning-with-neural-networks</a><ul><li>[Supervised learning for Neural Network](/2018-04-02/01_introduction-to-deep-learning/#Supervised learning for Neural Network)</li><li>[Structured vs unstructured data](/2018-04-02/01_introduction-to-deep-learning/#Structured vs unstructured data)</li></ul></li><li><a href="/2018-04-02/01_introduction-to-deep-learning/#03_why-is-deep-learning-taking-off">03_why-is-deep-learning-taking-off</a><ul><li>[Why is deep learning taking off?](/2018-04-02/01_introduction-to-deep-learning/#Why is deep learning taking off?)</li></ul></li><li><a href="/2018-04-02/01_introduction-to-deep-learning/#04_about-this-course">04_about-this-course</a><ul><li>[Outline of this Course](/2018-04-02/01_introduction-to-deep-learning/#Outline of this Course)</li></ul></li></ul><p>$2_{nd}$ week: <a href="/2018/02/02/02_neural-networks-basics/">neural-networks-basics</a></p><ul><li><a href="/2018/02/02/02_neural-networks-basics/#01_logistic-regression-as-a-neural-network">01_logistic-regression-as-a-neural-network</a><ul><li><a href="/2018/02/02/02_neural-networks-basics/#01_binary-classification">01_binary-classification</a><ul><li>[Binary Classification](/2018/02/02/02_neural-networks-basics/#Binary Classification)</li><li><a href="/2018/02/02/02_neural-networks-basics/#notation">notation</a></li></ul></li><li>[02_Logistic Regression](/2018/02/02/02_neural-networks-basics/#02_Logistic Regression)<ul><li>[Example: Cat vs No - cat](/2018/02/02/02_neural-networks-basics/#Example: Cat vs No - cat)</li><li><a href="/2018/02/02/02_neural-networks-basics/#notation">notation</a></li></ul></li><li><a href="/2018/02/02/02_neural-networks-basics/#03_logistic-regression-cost-function">03_logistic-regression-cost-function</a></li><li><a href="/2018/02/02/02_neural-networks-basics/#04_gradient-descent">04_gradient-descent</a></li><li><a href="/2018/02/02/02_neural-networks-basics/#05_06_derivatives">05_06_derivatives</a></li><li><a href="/2018/02/02/02_neural-networks-basics/#07_computation-graph">07_computation-graph</a></li><li><a href="/2018/02/02/02_neural-networks-basics/#09_logistic-regression-gradient-descent">09_logistic-regression-gradient-descent</a></li><li><a href="/2018/02/02/02_neural-networks-basics/#10_gradient-descent-on-m-examples">10_gradient-descent-on-m-examples</a><ul><li>[one single step gradient descent](/2018/02/02/02_neural-networks-basics/#one single step gradient descent)</li></ul></li></ul></li><li><a href="/2018/02/02/02_neural-networks-basics/#02_python-and-vectorization">02_python-and-vectorization</a><ul><li><a href="/2018/02/02/02_neural-networks-basics/#01_vectorization">01_vectorization</a></li><li><a href="/2018/02/02/02_neural-networks-basics/#02_more-vectorization-examples">02_more-vectorization-examples</a></li><li><a href="/2018/02/02/02_neural-networks-basics/#03_vectorizing-logistic-regression">03_vectorizing-logistic-regression</a></li><li><a href="/2018/02/02/02_neural-networks-basics/#04_vectorizing-logistic-regressions-gradient-output">04_vectorizing-logistic-regressions-gradient-output</a></li><li><a href="/2018/02/02/02_neural-networks-basics/#05_broadcasting-in-python">05_broadcasting-in-python</a></li><li><a href="/2018/02/02/02_neural-networks-basics/#06_a-note-on-python-numpy-vectors">06_a-note-on-python-numpy-vectors</a><ul><li>[one rank array](/2018/02/02/02_neural-networks-basics/#one rank array)</li><li>[practical tips](/2018/02/02/02_neural-networks-basics/#practical tips)</li></ul></li><li><a href="/2018/02/02/02_neural-networks-basics/#07_quick-tour-of-jupyter-ipython-notebooks">07_quick-tour-of-jupyter-ipython-notebooks</a></li><li><a href="/2018/02/02/02_neural-networks-basics/#08_explanation-of-logistic-regression-cost-function-optional">08_explanation-of-logistic-regression-cost-function-optional</a></li></ul></li></ul><p>$3_{rd}$ week: <a href="/2018/02/03/03_shallow-neural-networks/">shallow-neural-networks</a></p><ul><li><a href="/2018/02/03/03_shallow-neural-networks/#01_neural-networks-overview">01_neural-networks-overview</a></li><li><a href="/2018/02/03/03_shallow-neural-networks/#02_neural-network-representation">02_neural-network-representation</a></li><li><a href="/2018/02/03/03_shallow-neural-networks/#03_computing-a-neural-networks-output">03_computing-a-neural-networks-output</a></li><li><a href="/2018/02/03/03_shallow-neural-networks/#04_vectorizing-across-multiple-examples">04_vectorizing-across-multiple-examples</a></li><li><a href="/2018/02/03/03_shallow-neural-networks/#05_explanation-for-vectorized-implementation">05_explanation-for-vectorized-implementation</a></li><li><a href="/2018/02/03/03_shallow-neural-networks/#06_activation-functions">06_activation-functions</a></li><li><a href="/2018/02/03/03_shallow-neural-networks/#07_why-do-you-need-non-linear-activation-functions">07_why-do-you-need-non-linear-activation-functions</a></li><li><a href="/2018/02/03/03_shallow-neural-networks/#08_derivatives-of-activation-functions">08_derivatives-of-activation-functions</a></li><li><a href="/2018/02/03/03_shallow-neural-networks/#09_gradient-descent-for-neural-networks">09_gradient-descent-for-neural-networks</a></li><li><a href="/2018/02/03/03_shallow-neural-networks/#10_backpropagation-intuition-optional">10_backpropagation-intuition-optional</a></li><li><a href="/2018/02/03/03_shallow-neural-networks/#11_random-initialization">11_random-initialization</a></li></ul><p>$4_{th}$ week: <a href="/2018/02/04/04_deep-neural-networks/">deep-neural-networks</a></p><ul><li><a href="/2018/02/04/04_deep-neural-networks/#01_deep-neural-network">01_deep-neural-network</a></li><li><a href="/2018/02/04/04_deep-neural-networks/#02_forward-propagation-in-a-deep-network">02_forward-propagation-in-a-deep-network</a></li><li><a href="/2018/02/04/04_deep-neural-networks/#03_getting-your-matrix-dimensions-right">03_getting-your-matrix-dimensions-right</a><ul><li>[one training example](/2018/02/04/04_deep-neural-networks/#one training example)</li><li>[m training examples](/2018/02/04/04_deep-neural-networks/#m training examples)</li></ul></li><li><a href="/2018/02/04/04_deep-neural-networks/#04_why-deep-representations">04_why-deep-representations</a></li><li><a href="/2018/02/04/04_deep-neural-networks/#05_building-blocks-of-deep-neural-networks">05_building-blocks-of-deep-neural-networks</a></li><li><a href="/2018/02/04/04_deep-neural-networks/#06_forward-and-backward-propagation">06_forward-and-backward-propagation</a></li><li><a href="/2018/02/04/04_deep-neural-networks/#07_parameters-vs-hyperparameters">07_parameters-vs-hyperparameters</a></li><li><a href="/2018/02/04/04_deep-neural-networks/#08_what-does-this-have-to-do-with-the-brain">08_what-does-this-have-to-do-with-the-brain</a></li></ul><h2 id="My-personal-programming-assignments"><a href="#My-personal-programming-assignments" class="headerlink" title="My personal programming assignments"></a>My personal programming assignments</h2><p>week 1 and week 2: <a href="/2018/02/05/logistic-regression-with-a-neural-network-mindset_week1_and_week2/">logistic-regression-with-a-neural-network-mindset</a><br>week 3: <a href="/2018/02/06/planar-data-classification-with-one-hidden%20layer_week3/">Planar data classification with a hidden layer</a><br>week 4 part 1: <a href="/2018/02/07/Building-your-Deep-Neural-Network_week4/">Building your deep neural network: Step by Step</a><br>week 4 part 2: <a href="/2018/02/07/Building-your-Deep-Neural-Network_week4/#Part-2%EF%BC%9ADeep-Neural-Network-for-Image-Classification-Application">deep-neural-network-application</a></p>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Karan"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Karan</p>
  <div class="site-description" itemprop="description">Refuse to Fall</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yourname" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yourname@gmail.com" title="E-Mail → mailto:yourname@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://youtube.com/yourname" title="YouTube → https:&#x2F;&#x2F;youtube.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/yourname" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i></a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="/www.massivefile.com" title="www.massivefile.com">DataBases</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Karan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">2.1m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">32:08</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


    </div>
</body>
</html>
